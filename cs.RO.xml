<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://raw.githubusercontent.com/chrunx/cn-chat-arxiv/master/cs.RO.xml</link><description>This is arxiv RSS feed for cs.RO</description><item><title>该文章提出了一种名为LAC-Net的线性融合注意力指导卷积网络，旨在通过融合来自RGB图像的语义特征和来自深度图像的几何信息，提高机器人对遮挡场景中目标对象的准确抓取能力。</title><link>https://arxiv.org/abs/2408.03238</link><description>&lt;p&gt;
LAC-Net: Linear-Fusion Attention-Guided Convolutional Network for Accurate Robotic Grasping Under the Occlusion
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03238
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为LAC-Net的线性融合注意力指导卷积网络，旨在通过融合来自RGB图像的语义特征和来自深度图像的几何信息，提高机器人对遮挡场景中目标对象的准确抓取能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03238v1 Announce Type: new  Abstract: This paper addresses the challenge of perceiving complete object shapes through visual perception. While prior studies have demonstrated encouraging outcomes in segmenting the visible parts of objects within a scene, amodal segmentation, in particular, has the potential to allow robots to infer the occluded parts of objects. To this end, this paper introduces a new framework that explores amodal segmentation for robotic grasping in cluttered scenes, thus greatly enhancing robotic grasping abilities. Initially, we use a conventional segmentation algorithm to detect the visible segments of the target object, which provides shape priors for completing the full object mask. Particularly, to explore how to utilize semantic features from RGB images and geometric information from depth images, we propose a Linear-fusion Attention-guided Convolutional Network (LAC-Net). LAC-Net utilizes the linear-fusion strategy to effectively fuse this cross-m
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为PFedSIS的联邦学习方法，用于个性化手术器械分割。该方法通过引入视觉先验，结合全局个性化 disentanglement、外观调节个性化增强和形状相似性全局增强机制，解决了现有方法未能充分考虑多头自我注意力个性化的问题，并且能够捕捉手术场景中的外观多样性与器械形状相似性。通过对多头自我注意力的头权重个性化，该方法实现了对单个训练站点特征的精确适应，提高了在多个独立站点上的器械分割性能。</title><link>https://arxiv.org/abs/2408.03208</link><description>&lt;p&gt;
Personalizing Federated Instrument Segmentation with Visual Trait Priors in Robotic Surgery
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03208
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为PFedSIS的联邦学习方法，用于个性化手术器械分割。该方法通过引入视觉先验，结合全局个性化 disentanglement、外观调节个性化增强和形状相似性全局增强机制，解决了现有方法未能充分考虑多头自我注意力个性化的问题，并且能够捕捉手术场景中的外观多样性与器械形状相似性。通过对多头自我注意力的头权重个性化，该方法实现了对单个训练站点特征的精确适应，提高了在多个独立站点上的器械分割性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03208v1 Announce Type: cross  Abstract: Personalized federated learning (PFL) for surgical instrument segmentation (SIS) is a promising approach. It enables multiple clinical sites to collaboratively train a series of models in privacy, with each model tailored to the individual distribution of each site. Existing PFL methods rarely consider the personalization of multi-headed self-attention, and do not account for appearance diversity and instrument shape similarity, both inherent in surgical scenes. We thus propose PFedSIS, a novel PFL method with visual trait priors for SIS, incorporating global-personalized disentanglement (GPD), appearance-regulation personalized enhancement (APE), and shape-similarity global enhancement (SGE), to boost SIS performance in each site. GPD represents the first attempt at head-wise assignment for multi-headed self-attention personalization. To preserve the unique appearance representation of each site and gradually leverage the inter-site d
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用自然istic人类驾驶先验和强化学习技术的对抗性安全关键场景生成方法，旨在从现实和挑战性的自动驾驶车辆决策系统评估中获取大规模测试场景。这种方法能够通过模拟真实交通交互环境以及实施的两阶段流程，模拟驾驶策略，进而生成既有真实感又具备挑战性的多样化场景。</title><link>https://arxiv.org/abs/2408.03200</link><description>&lt;p&gt;
Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03200
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用自然istic人类驾驶先验和强化学习技术的对抗性安全关键场景生成方法，旨在从现实和挑战性的自动驾驶车辆决策系统评估中获取大规模测试场景。这种方法能够通过模拟真实交通交互环境以及实施的两阶段流程，模拟驾驶策略，进而生成既有真实感又具备挑战性的多样化场景。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03200v1 Announce Type: new  Abstract: Evaluating the decision-making system is indispensable in developing autonomous vehicles, while realistic and challenging safety-critical test scenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks to the long-tailed distribution, sparsity, and rarity in real-world data sets. To tackle this problem, in this paper, we introduce a natural adversarial scenario generation solution using naturalistic human driving priors and reinforcement learning techniques. By doing this, we can obtain large-scale test scenarios that are both diverse and realistic. Specifically, we build a simulation environment that mimics natural traffic interaction scenarios. Informed by this environment, we implement a two-stage procedure. The first stage incorporates conventional rule-based models, e.g., IDM~(Intelligent Driver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes) model, to coarsely and discretely capture and ca
&lt;/p&gt;</description></item><item><title>该文章提出了一种结合频谱注意力网络和近端策略优化的方法，旨在自动驾驶中实现对周围车辆意图的高效预测和决策制定。该方法通过捕捉频率成分随时间的变化趋势和它们的相互关系，预测周围车辆的意图，同时避免了在执行过程中将预测的意图解码成轨迹，从而提高了意图预测模块的计算效率。此外，通过近端策略优化，该方法实现了安全有效的决策制定。</title><link>https://arxiv.org/abs/2408.03191</link><description>&lt;p&gt;
Integrated Intention Prediction and Decision-Making with Spectrum Attention Net and Proximal Policy Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03191
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种结合频谱注意力网络和近端策略优化的方法，旨在自动驾驶中实现对周围车辆意图的高效预测和决策制定。该方法通过捕捉频率成分随时间的变化趋势和它们的相互关系，预测周围车辆的意图，同时避免了在执行过程中将预测的意图解码成轨迹，从而提高了意图预测模块的计算效率。此外，通过近端策略优化，该方法实现了安全有效的决策制定。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03191v1 Announce Type: new  Abstract: For autonomous driving in highly dynamic environments, it is anticipated to predict the future behaviors of surrounding vehicles (SVs) and make safe and effective decisions. However, modeling the inherent coupling effect between the prediction and decision-making modules has been a long-standing challenge, especially when there is a need to maintain appropriate computational efficiency. To tackle these problems, we propose a novel integrated intention prediction and decision-making approach, which explicitly models the coupling relationship and achieves efficient computation. Specifically, a spectrum attention net is designed to predict the intentions of SVs by capturing the trends of each frequency component over time and their interrelations. Fast computation of the intention prediction module is attained as the predicted intentions are not decoded to trajectories in the executing process. Furthermore, the proximal policy optimization 
&lt;/p&gt;</description></item><item><title>该文章提出了一种新颖的针对纳米无人机在有限资源下进行自我监督学习的实时训练方法，有效解决了域迁移问题，提高了模型的感知性能。</title><link>https://arxiv.org/abs/2408.03168</link><description>&lt;p&gt;
Training on the Fly: On-device Self-supervised Learning aboard Nano-drones within 20 mW
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03168
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新颖的针对纳米无人机在有限资源下进行自我监督学习的实时训练方法，有效解决了域迁移问题，提高了模型的感知性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03168v1 Announce Type: new  Abstract: Miniaturized cyber-physical systems (CPSes) powered by tiny machine learning (TinyML), such as nano-drones, are becoming an increasingly attractive technology. Their small form factor (i.e., ~10cm diameter) ensures vast applicability, ranging from the exploration of narrow disaster scenarios to safe human-robot interaction. Simple electronics make these CPSes inexpensive, but strongly limit the computational, memory, and sensing resources available on board. In real-world applications, these limitations are further exacerbated by domain shift. This fundamental machine learning problem implies that model perception performance drops when moving from the training domain to a different deployment one. To cope with and mitigate this general problem, we present a novel on-device fine-tuning approach that relies only on the limited ultra-low power resources available aboard nano-drones. Then, to overcome the lack of ground-truth training label
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Stochastic Trajectory Optimization for Demonstration Imitation (STODI)的算法，它使用随机轨迹优化方法帮助机器人模仿人类专家的演示运动轨迹，并在此过程中提升机器人的动态性能。这种算法通过在保证演示轨迹形状的同时，利用噪声提高轨迹探索效率，为机器人学习新技能提供了一种新型方法。</title><link>https://arxiv.org/abs/2408.03131</link><description>&lt;p&gt;
Stochastic Trajectory Optimization for Demonstration Imitation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03131
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Stochastic Trajectory Optimization for Demonstration Imitation (STODI)的算法，它使用随机轨迹优化方法帮助机器人模仿人类专家的演示运动轨迹，并在此过程中提升机器人的动态性能。这种算法通过在保证演示轨迹形状的同时，利用噪声提高轨迹探索效率，为机器人学习新技能提供了一种新型方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03131v1 Announce Type: new  Abstract: Humans often learn new skills by imitating the experts and gradually developing their proficiency. In this work, we introduce Stochastic Trajectory Optimization for Demonstration Imitation (STODI), a trajectory optimization framework for robots to imitate the shape of demonstration trajectories with improved dynamic performance. Consistent with the human learning process, demonstration imitation serves as an initial step, while trajectory optimization aims to enhance robot motion performance. By generating random noise and constructing proper cost functions, the STODI effectively explores and exploits generated noisy trajectories while preserving the demonstration shape characteristics. We employ three metrics to measure the similarity of trajectories in both the time and frequency domains to help with demonstration imitation. Theoretical analysis reveals relationships among these metrics, emphasizing the benefits of frequency-domain ana
&lt;/p&gt;</description></item><item><title>该文章提出并验证了一项针对具有不确定动态、振动干扰和负载变化干扰的机器人臂轨迹跟踪控制的适应性滑动模式控制方法。通过MATLAB-SIMULINK软件进行模拟验证，结果表明设计的控制器能在扰动和不确定性的影响下保持稳定性，并且具有良好的准确性和可实施性。</title><link>https://arxiv.org/abs/2408.03102</link><description>&lt;p&gt;
Adaptive-Sliding Mode Trajectory Control of Robot Manipulators with Uncertainties
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03102
&lt;/p&gt;
&lt;p&gt;
该文章提出并验证了一项针对具有不确定动态、振动干扰和负载变化干扰的机器人臂轨迹跟踪控制的适应性滑动模式控制方法。通过MATLAB-SIMULINK软件进行模拟验证，结果表明设计的控制器能在扰动和不确定性的影响下保持稳定性，并且具有良好的准确性和可实施性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03102v1 Announce Type: cross  Abstract: In this paper, we propose and demonstrate an adaptive-sliding mode control for trajectory tracking control of robot manipulators subjected to uncertain dynamics, vibration disturbance, and payload variation disturbance. Throughout this work we seek a controller that is, robust to the uncertainty and disturbance, accurate, and implementable. To perform these requirements, we use a nonlinear Lyapunov-based approach for designing the controller and guaranteeing its stability. MATLAB-SIMULINK software is used to validate the approach and demonstrate the performance of the controller. Simulation results show that the derived controller is stable, robust to the disturbance and uncertainties, accurate, and implementable.
&lt;/p&gt;</description></item><item><title>该文章针对机器人臂在遭遇外部振动和负载不确定性的情况，提出针对性的非线性控制策略，确保了系统的稳定性和有效性，并通过精确控制输入实现了关节轨迹跟踪任务。</title><link>https://arxiv.org/abs/2408.03098</link><description>&lt;p&gt;
Dedicated Nonlinear Control of Robot Manipulators in the Presence of External Vibration and Uncertain Payload
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03098
&lt;/p&gt;
&lt;p&gt;
该文章针对机器人臂在遭遇外部振动和负载不确定性的情况，提出针对性的非线性控制策略，确保了系统的稳定性和有效性，并通过精确控制输入实现了关节轨迹跟踪任务。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03098v1 Announce Type: cross  Abstract: Robot manipulators are often tasked with working in environments with vibrations and are subject to load uncertainty. Providing an accurate tracking control design with implementable torque input for these robots is a complex topic. This paper presents two approaches to solve this problem. The approaches consider joint space tracking control design in the presence of nonlinear uncertain torques caused by external vibration and payload variation. The properties of the uncertain torques are used in both approaches. The first approach is based on the boundedness property, while the second approach considers the differentiability and boundedness together. The controllers derived from each approach differ from the perspectives of accuracy, control effort, and disturbance properties. A Lyapunov-based analysis is utilized to guarantee the stability of the control design in each case. Simulation results validate the approaches and demonstrate 
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一种面向手术应用的开放域单目视觉SLAM框架BodySLAM，该框架能够充分利用单目摄像头的输入，无需任何传统的传感器输入，有效提高了手术操作中的深度感知和操纵精准度。</title><link>https://arxiv.org/abs/2408.03078</link><description>&lt;p&gt;
BodySLAM: A Generalized Monocular Visual SLAM Framework for Surgical Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03078
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一种面向手术应用的开放域单目视觉SLAM框架BodySLAM，该框架能够充分利用单目摄像头的输入，无需任何传统的传感器输入，有效提高了手术操作中的深度感知和操纵精准度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03078v1 Announce Type: cross  Abstract: Endoscopic surgery relies on two-dimensional views, posing challenges for surgeons in depth perception and instrument manipulation. While Simultaneous Localization and Mapping (SLAM) has emerged as a promising solution to address these limitations, its implementation in endoscopic procedures presents significant challenges due to hardware limitations, such as the use of a monocular camera and the absence of odometry sensors. This study presents a robust deep learning-based SLAM approach that combines state-of-the-art and newly developed models. It consists of three main parts: the Monocular Pose Estimation Module that introduces a novel unsupervised method based on the CycleGAN architecture, the Monocular Depth Estimation Module that leverages the novel Zoe architecture, and the 3D Reconstruction Module which uses information from the previous models to create a coherent surgical map. The performance of the procedure was rigorously eva
&lt;/p&gt;</description></item><item><title>该文章介绍了SYLPH框架，它是一种新的学习方法，用于解决团队路径搜索问题。这种方法的创新之处在于，它允许代理学习不同的社会行为以应对交通堵塞等特定情况，同时保持了跨代理参数共享的效率。通过这种方式，SYLPH能够提高路径搜索中的灵活性和效率，减少了碰撞并防止了死锁现象。</title><link>https://arxiv.org/abs/2408.03063</link><description>&lt;p&gt;
Social Behavior as a Key to Learning-based Multi-Agent Pathfinding Dilemmas
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03063
&lt;/p&gt;
&lt;p&gt;
该文章介绍了SYLPH框架，它是一种新的学习方法，用于解决团队路径搜索问题。这种方法的创新之处在于，它允许代理学习不同的社会行为以应对交通堵塞等特定情况，同时保持了跨代理参数共享的效率。通过这种方式，SYLPH能够提高路径搜索中的灵活性和效率，减少了碰撞并防止了死锁现象。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03063v1 Announce Type: new  Abstract: The Multi-agent Path Finding (MAPF) problem involves finding collision-free paths for a team of agents in a known, static environment, with important applications in warehouse automation, logistics, or last-mile delivery. To meet the needs of these large-scale applications, current learning-based methods often deploy the same fully trained, decentralized network to all agents to improve scalability. However, such parameter sharing typically results in homogeneous behaviors among agents, which may prevent agents from breaking ties around symmetric conflict (e.g., bottlenecks) and might lead to live-/deadlocks. In this paper, we propose SYLPH, a novel learning-based MAPF framework aimed to mitigate the adverse effects of homogeneity by allowing agents to learn and dynamically select different social behaviors (akin to individual, dynamic roles), without affecting the scalability offered by parameter sharing. Specifically, SYLPH agents lear
&lt;/p&gt;</description></item><item><title>该文章提出了一个使用扩散政策进行模仿学习的策略，用于训练机器人如何在植被茂密的农业环境中进行稳健的路线转弯，解决了GPS信号弱、视觉混淆、遮挡和复杂车辆动态等问题。</title><link>https://arxiv.org/abs/2408.03059</link><description>&lt;p&gt;
Learning to Turn: Diffusion Imitation for Robust Row Turning in Under-Canopy Robots
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03059
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个使用扩散政策进行模仿学习的策略，用于训练机器人如何在植被茂密的农业环境中进行稳健的路线转弯，解决了GPS信号弱、视觉混淆、遮挡和复杂车辆动态等问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03059v1 Announce Type: new  Abstract: Under-canopy agricultural robots require robust navigation capabilities to enable full autonomy but struggle with tight row turning between crop rows due to degraded GPS reception, visual aliasing, occlusion, and complex vehicle dynamics. We propose an imitation learning approach using diffusion policies to learn row turning behaviors from demonstrations provided by human operators or privileged controllers. Simulation experiments in a corn field environment show potential in learning this task with only visual observations and velocity states. However, challenges remain in maintaining control within rows and handling varied initial conditions, highlighting areas for future improvement.
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为CSI的框架，能够将多种不同风格的运动技能整合到一个单一的控制器中，无需复杂的奖励工程。这为 legged robots 的多技能整合提供了一种新的灵活方法，可以应用于各种不同的任务环境中。</title><link>https://arxiv.org/abs/2408.03018</link><description>&lt;p&gt;
Integrating Controllable Motion Skills from Demonstrations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03018
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为CSI的框架，能够将多种不同风格的运动技能整合到一个单一的控制器中，无需复杂的奖励工程。这为 legged robots 的多技能整合提供了一种新的灵活方法，可以应用于各种不同的任务环境中。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03018v1 Announce Type: new  Abstract: The expanding applications of legged robots require their mastery of versatile motion skills. Correspondingly, researchers must address the challenge of integrating multiple diverse motion skills into controllers. While existing reinforcement learning (RL)-based approaches have achieved notable success in multi-skill integration for legged robots, these methods often require intricate reward engineering or are restricted to integrating a predefined set of motion skills constrained by specific task objectives, resulting in limited flexibility. In this work, we introduce a flexible multi-skill integration framework named Controllable Skills Integration (CSI). CSI enables the integration of a diverse set of motion skills with varying styles into a single policy without the need for complex reward tuning. Furthermore, in a hierarchical control manner, the trained low-level policy can be coupled with a high-level Natural Language Inference (N
&lt;/p&gt;</description></item><item><title>该文章展示了通过一个单一旋转的永久磁铁所装备的磁性驱动系统，实现了对磁性软连续体机器人（MSCRs）的闭环偏转控制。通过建立非均匀磁场中MSCR的不同态动态模型，文章推导出了机器人几何位置与雅可比矩阵存在唯一性的关系，并证明了雅可比矩阵准确的控制方向在模拟中至关重要。此外，文章还介绍了相应的准静态控制（QSC）框架，该框架结合了一个线性扩展状态观测器以估计模型不确定性。最后，文章讨论了该方法在实际应用中的影响。</title><link>https://arxiv.org/abs/2408.03017</link><description>&lt;p&gt;
Closed-Loop Magnetic Control of Medical Soft Continuum Robots for Deflection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03017
&lt;/p&gt;
&lt;p&gt;
该文章展示了通过一个单一旋转的永久磁铁所装备的磁性驱动系统，实现了对磁性软连续体机器人（MSCRs）的闭环偏转控制。通过建立非均匀磁场中MSCR的不同态动态模型，文章推导出了机器人几何位置与雅可比矩阵存在唯一性的关系，并证明了雅可比矩阵准确的控制方向在模拟中至关重要。此外，文章还介绍了相应的准静态控制（QSC）框架，该框架结合了一个线性扩展状态观测器以估计模型不确定性。最后，文章讨论了该方法在实际应用中的影响。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03017v1 Announce Type: new  Abstract: Magnetic soft continuum robots (MSCRs) have emerged as powerful devices in endovascular interventions owing to their hyperelastic fibre matrix and enhanced magnetic manipulability. Effective closed-loop control of tethered magnetic devices contributes to the achievement of autonomous vascular robotic surgery. In this article, we employ a magnetic actuation system equipped with a single rotatable permanent magnet to achieve closed-loop deflection control of the MSCR. To this end, we establish a differential kinematic model of MSCRs exposed to non-uniform magnetic fields. The relationship between the existence and uniqueness of Jacobian and the geometric position between robots is deduced. The accurate control direction induced by Jacobian is demonstrated to be crucial in simulations. Then, the corresponding quasi-static control (QSC) framework integrates a linear extended state observer to estimate model uncertainties. Finally, the effect
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用深度核感知方法训练的新型元学习策略，用于在极端域偏移下的自主机械臂少样本采矿任务。该方法通过模拟最大部署间隙并在训练过程中专门训练模型以克服这些间隙，从而能够适应巨大的域偏移。在贝叶斯优化序贯决策框架中使用该方法，不仅提高了采矿任务的效率，还有效地提升了样本采掘的质量。</title><link>https://arxiv.org/abs/2408.02949</link><description>&lt;p&gt;
Few-shot Scooping Under Domain Shift via Simulated Maximal Deployment Gaps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02949
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用深度核感知方法训练的新型元学习策略，用于在极端域偏移下的自主机械臂少样本采矿任务。该方法通过模拟最大部署间隙并在训练过程中专门训练模型以克服这些间隙，从而能够适应巨大的域偏移。在贝叶斯优化序贯决策框架中使用该方法，不仅提高了采矿任务的效率，还有效地提升了样本采掘的质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02949v1 Announce Type: new  Abstract: Autonomous lander missions on extraterrestrial bodies need to sample granular materials while coping with domain shifts, even when sampling strategies are extensively tuned on Earth. To tackle this challenge, this paper studies the few-shot scooping problem and proposes a vision-based adaptive scooping strategy that uses the deep kernel Gaussian process method trained with a novel meta-training strategy to learn online from very limited experience on out-of-distribution target terrains. Our Deep Kernel Calibration with Maximal Deployment Gaps (kCMD) strategy explicitly trains a deep kernel model to adapt to large domain shifts by creating simulated maximal deployment gaps from an offline training dataset and training models to overcome these deployment gaps during training. Employed in a Bayesian Optimization sequential decision-making framework, the proposed method allows the robot to perform high-quality scooping actions on out-of-dist
&lt;/p&gt;</description></item><item><title>该文章提供了一种名为KOI的在线模仿学习加速方法，通过整合关键状态指导来精确估计任务相关奖励，从而实现更有效的在线探索。</title><link>https://arxiv.org/abs/2408.02912</link><description>&lt;p&gt;
KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02912
&lt;/p&gt;
&lt;p&gt;
该文章提供了一种名为KOI的在线模仿学习加速方法，通过整合关键状态指导来精确估计任务相关奖励，从而实现更有效的在线探索。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02912v1 Announce Type: new  Abstract: Online Imitation Learning methods struggle with the gap between extensive online exploration space and limited expert trajectories, which hinder efficient exploration due to inaccurate task-aware reward estimation. Inspired by the findings from cognitive neuroscience that task decomposition could facilitate cognitive processing for efficient learning, we hypothesize that an agent could estimate precise task-aware imitation rewards for efficient online exploration by decomposing the target task into the objectives of "what to do" and the mechanisms of "how to do". In this work, we introduce the hybrid Key-state guided Online Imitation (KOI) learning approach, which leverages the integration of semantic and motion key states as guidance for task-aware reward estimation. Initially, we utilize the visual-language models to segment the expert trajectory into semantic key states, indicating the objectives of "what to do". Within the intervals 
&lt;/p&gt;</description></item><item><title>该文章提出了一种新型的路径规划框架Larp，它通过将潜在场分割成具有不同障碍物距离限制区的高级层次细胞来提高路径的安全性。与现有方法相比，Larp在避免局部最小值和保证远离障碍物方面表现出更高的效率，显着提升了数十亿领域中无人机运输的安全性。</title><link>https://arxiv.org/abs/2408.02786</link><description>&lt;p&gt;
Multi-Scale Cell Decomposition for Path Planning using Restrictive Routing Potential Fields
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02786
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新型的路径规划框架Larp，它通过将潜在场分割成具有不同障碍物距离限制区的高级层次细胞来提高路径的安全性。与现有方法相比，Larp在避免局部最小值和保证远离障碍物方面表现出更高的效率，显着提升了数十亿领域中无人机运输的安全性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02786v1 Announce Type: new  Abstract: In burgeoning domains, like urban goods distribution, the advent of aerial cargo transportation necessitates the development of routing solutions that prioritize safety. This paper introduces Larp, a novel path planning framework that leverages the concept of restrictive potential fields to forge routes demonstrably safer than those derived from existing methods. The algorithm achieves it by segmenting a potential field into a hierarchy of cells, each with a designated restriction zone determined by obstacle proximity. While the primary impetus behind Larp is to enhance the safety of aerial pathways for cargo-carrying Unmanned Aerial Vehicles (UAVs), its utility extends to a wide array of path planning scenarios. Comparative analyses with both established and contemporary potential field-based methods reveal Larp's proficiency in maintaining a safe distance from restrictions and its adeptness in circumventing local minima.
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于双目立体视觉的方法，成功实现了对仅有几毫米直径的带状微尺度连续机器人（NTCR）的三维形态重建。该方法采用两台相对放置的静态立体摄像头，即使原始点云采集质量不高，也能够通过预设几何参考下的KD树算法对采集的点云进行正确的定位，从而确保了NTCR形态的准确性。</title><link>https://arxiv.org/abs/2408.01615</link><description>&lt;p&gt;
Three-dimensional Morphological Reconstruction of Millimeter-Scale Soft Continuum Robots based on Dual Stereo Vision
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01615
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于双目立体视觉的方法，成功实现了对仅有几毫米直径的带状微尺度连续机器人（NTCR）的三维形态重建。该方法采用两台相对放置的静态立体摄像头，即使原始点云采集质量不高，也能够通过预设几何参考下的KD树算法对采集的点云进行正确的定位，从而确保了NTCR形态的准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01615v1 Announce Type: new  Abstract: Continuum robots can be miniaturized to just a few millimeters in diameter. Among these, notched tubular continuum robots (NTCR) show great potential in many delicate applications. Existing works in robotic modeling focus on kinematics and dynamics but still face challenges in reproducing the robot's morphology -- a significant factor that can expand the research landscape of continuum robots, especially for those with asymmetric continuum structures. This paper proposes a dual stereo vision-based method for the three-dimensional morphological reconstruction of millimeter-scale NTCRs. The method employs two oppositely located stationary binocular cameras to capture the point cloud of the NTCR, then utilizes predefined geometry as a reference for the KD tree method to relocate the capture point clouds, resulting in a morphologically correct NTCR despite the low-quality raw point cloud collection. The method has been proved feasible for an
&lt;/p&gt;</description></item><item><title>该文章提出了一种结合启发式搜索和可见性图构建路径以及基于强化学习的低级运动命令生成方法，以改善室内环境中的无人机自主飞行性能。</title><link>https://arxiv.org/abs/2408.00275</link><description>&lt;p&gt;
A Reinforcement Learning Based Motion Planner for Quadrotor Autonomous Flight in Dense Environment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.00275
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种结合启发式搜索和可见性图构建路径以及基于强化学习的低级运动命令生成方法，以改善室内环境中的无人机自主飞行性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.00275v2 Announce Type: replace  Abstract: Quadrotor motion planning is critical for autonomous flight in complex environments, such as rescue operations. Traditional methods often employ trajectory generation optimization and passive time allocation strategies, which can limit the exploitation of the quadrotor's dynamic capabilities and introduce delays and inaccuracies. To address these challenges, we propose a novel motion planning framework that integrates visibility path searching and reinforcement learning (RL) motion generation. Our method constructs collision-free paths using heuristic search and visibility graphs, which are then refined by an RL policy to generate low-level motion commands. We validate our approach in simulated indoor environments, demonstrating better performance than traditional methods in terms of time span.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为SimEndoGS的新型高效数据驱动的手术场景模拟方法，该方法使用机器人手术视频中的物理嵌入式3D高斯分布来模拟场景。这种方法能够从三维立体内窥镜视频中自动学习手术场景的三维结构，并在保证场景几何正确性的同时，利用深度监督和各向异性约束来防止过拟合，从而提供更真实和可扩大的模拟体验。</title><link>https://arxiv.org/abs/2405.00956</link><description>&lt;p&gt;
SimEndoGS: Efficient Data-driven Scene Simulation using Robotic Surgery Videos via Physics-embedded 3D Gaussians
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.00956
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为SimEndoGS的新型高效数据驱动的手术场景模拟方法，该方法使用机器人手术视频中的物理嵌入式3D高斯分布来模拟场景。这种方法能够从三维立体内窥镜视频中自动学习手术场景的三维结构，并在保证场景几何正确性的同时，利用深度监督和各向异性约束来防止过拟合，从而提供更真实和可扩大的模拟体验。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.00956v3 Announce Type: replace  Abstract: Surgical scene simulation plays a crucial role in surgical education and simulator-based robot learning. Traditional approaches for creating these environments with surgical scene involve a labor-intensive process where designers hand-craft tissues models with textures and geometries for soft body simulations. This manual approach is not only time-consuming but also limited in the scalability and realism. In contrast, data-driven simulation offers a compelling alternative. It has the potential to automatically reconstruct 3D surgical scenes from real-world surgical video data, followed by the application of soft body physics. This area, however, is relatively uncharted. In our research, we introduce 3D Gaussian as a learnable representation for surgical scene, which is learned from stereo endoscopic video. To prevent over-fitting and ensure the geometrical correctness of these scenes, we incorporate depth supervision and anisotropy r
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为MambaMOS的基于LiDAR的3D移动对象分割方法，该方法通过引入一个名为Time Clue Bootstrapping Embedding（TCBE）的新嵌入模块来增强点云中时空信息的耦合，并缓解了忽略时空线索的问题。同时，文章还引入了Motion-aware State Space Model（MSSM），以让模型能够理解不同时间步之间同一对象的空间状态，强调了移动对象的运动状态，从而在LiDAR点云数据中实现了更精确的移动对象分割。</title><link>https://arxiv.org/abs/2404.12794</link><description>&lt;p&gt;
MambaMOS: LiDAR-based 3D Moving Object Segmentation with Motion-aware State Space Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.12794
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为MambaMOS的基于LiDAR的3D移动对象分割方法，该方法通过引入一个名为Time Clue Bootstrapping Embedding（TCBE）的新嵌入模块来增强点云中时空信息的耦合，并缓解了忽略时空线索的问题。同时，文章还引入了Motion-aware State Space Model（MSSM），以让模型能够理解不同时间步之间同一对象的空间状态，强调了移动对象的运动状态，从而在LiDAR点云数据中实现了更精确的移动对象分割。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.12794v2 Announce Type: replace-cross  Abstract: LiDAR-based Moving Object Segmentation (MOS) aims to locate and segment moving objects in point clouds of the current scan using motion information from previous scans. Despite the promising results achieved by previous MOS methods, several key issues, such as the weak coupling of temporal and spatial information, still need further study. In this paper, we propose a novel LiDAR-based 3D Moving Object Segmentation with Motion-aware State Space Model, termed MambaMOS. Firstly, we develop a novel embedding module, the Time Clue Bootstrapping Embedding (TCBE), to enhance the coupling of temporal and spatial information in point clouds and alleviate the issue of overlooked temporal clues. Secondly, we introduce the Motion-aware State Space Model (MSSM) to endow the model with the capacity to understand the temporal correlations of the same object across different time steps. Specifically, MSSM emphasizes the motion states of the sa
&lt;/p&gt;</description></item><item><title>该文章提出了一个新颖的框架，旨在通过整合来自不同领域的标签去噪策略来解决skeleton-based人类动作识别中的标签噪声问题，并在处理稀疏骨架数据时显著提高了识别性能。</title><link>https://arxiv.org/abs/2403.09975</link><description>&lt;p&gt;
Skeleton-Based Human Action Recognition with Noisy Labels
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.09975
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个新颖的框架，旨在通过整合来自不同领域的标签去噪策略来解决skeleton-based人类动作识别中的标签噪声问题，并在处理稀疏骨架数据时显著提高了识别性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.09975v2 Announce Type: replace-cross  Abstract: Understanding human actions from body poses is critical for assistive robots sharing space with humans in order to make informed and safe decisions about the next interaction. However, precise temporal localization and annotation of activity sequences is time-consuming and the resulting labels are often noisy. If not effectively addressed, label noise negatively affects the model's training, resulting in lower recognition quality. Despite its importance, addressing label noise for skeleton-based action recognition has been overlooked so far. In this study, we bridge this gap by implementing a framework that augments well-established skeleton-based human action recognition methods with label-denoising strategies from various research areas to serve as the initial benchmark. Observations reveal that these baselines yield only marginal performance when dealing with sparse skeleton data. Consequently, we introduce a novel methodolo
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为EchoTrack的端到端框架，用于在自动驾驶场景中的音频指代多对象跟踪（AR-MOT）。EchoTrack通过双向频率域跨注意力融合模块（Bi-FCFM）实现了音频和视频特征的双流端到端融合，解决了传统音频视频融合方法和文本依赖的多对象跟踪在应用中的局限性。</title><link>https://arxiv.org/abs/2402.18302</link><description>&lt;p&gt;
EchoTrack: Auditory Referring Multi-Object Tracking for Autonomous Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.18302
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为EchoTrack的端到端框架，用于在自动驾驶场景中的音频指代多对象跟踪（AR-MOT）。EchoTrack通过双向频率域跨注意力融合模块（Bi-FCFM）实现了音频和视频特征的双流端到端融合，解决了传统音频视频融合方法和文本依赖的多对象跟踪在应用中的局限性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.18302v2 Announce Type: replace-cross  Abstract: This paper introduces the task of Auditory Referring Multi-Object Tracking (AR-MOT), which dynamically tracks specific objects in a video sequence based on audio expressions and appears as a challenging problem in autonomous driving. Due to the lack of semantic modeling capacity in audio and video, existing works have mainly focused on text-based multi-object tracking, which often comes at the cost of tracking quality, interaction efficiency, and even the safety of assistance systems, limiting the application of such methods in autonomous driving. In this paper, we delve into the problem of AR-MOT from the perspective of audio-video fusion and audio-video tracking. We put forward EchoTrack, an end-to-end AR-MOT framework with dual-stream vision transformers. The dual streams are intertwined with our Bidirectional Frequency-domain Cross-attention Fusion Module (Bi-FCFM), which bidirectionally fuses audio and video features from 
&lt;/p&gt;</description></item><item><title>该文章提出了一种多智能体三维环境重建和微重力条件下变化检测的方法，使用自由飞行的机器人来维护太空基地。其中一个机器人通过图像和深度信息重建环境的三维模型，另一个机器人定期检查环境的变化，使用真实数据进行验证，适用于未来的太空探索活动。</title><link>https://arxiv.org/abs/2311.02558</link><description>&lt;p&gt;
Multi-Agent 3D Map Reconstruction and Change Detection in Microgravity with Free-Flying Robots
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.02558
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种多智能体三维环境重建和微重力条件下变化检测的方法，使用自由飞行的机器人来维护太空基地。其中一个机器人通过图像和深度信息重建环境的三维模型，另一个机器人定期检查环境的变化，使用真实数据进行验证，适用于未来的太空探索活动。
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.02558v3 Announce Type: replace  Abstract: Assistive free-flyer robots autonomously caring for future crewed outposts -- such as NASA's Astrobee robots on the International Space Station (ISS) -- must be able to detect day-to-day interior changes to track inventory, detect and diagnose faults, and monitor the outpost status. This work presents a framework for multi-agent cooperative mapping and change detection to enable robotic maintenance of space outposts. One agent is used to reconstruct a 3D model of the environment from sequences of images and corresponding depth information. Another agent is used to periodically scan the environment for inconsistencies against the 3D model. Change detection is validated after completing the surveys using real image and pose data collected by Astrobee robots in a ground testing environment and from microgravity aboard the ISS. This work outlines the objectives, requirements, and algorithmic modules for the multi-agent reconstruction sys
&lt;/p&gt;</description></item><item><title>该文章探讨了一种基于数据驱动的方法，用于在多Agent协作环境中解决由于视角变化造成的视觉定位问题。研究工作通过对比现有方法和提出的多个基线，提出了一种新颖的数据驱动策略，旨在选择在特定位置进行最佳的视角选择。实验结果表明，该策略在模拟环境中超越了现有方法的表现。</title><link>https://arxiv.org/abs/2310.02650</link><description>&lt;p&gt;
Active Visual Localization for Multi-Agent Collaboration: A Data-Driven Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.02650
&lt;/p&gt;
&lt;p&gt;
该文章探讨了一种基于数据驱动的方法，用于在多Agent协作环境中解决由于视角变化造成的视觉定位问题。研究工作通过对比现有方法和提出的多个基线，提出了一种新颖的数据驱动策略，旨在选择在特定位置进行最佳的视角选择。实验结果表明，该策略在模拟环境中超越了现有方法的表现。
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.02650v3 Announce Type: replace  Abstract: Rather than having each newly deployed robot create its own map of its surroundings, the growing availability of SLAM-enabled devices provides the option of simply localizing in a map of another robot or device. In cases such as multi-robot or human-robot collaboration, localizing all agents in the same map is even necessary. However, localizing e.g. a ground robot in the map of a drone or head-mounted MR headset presents unique challenges due to viewpoint changes. This work investigates how active visual localization can be used to overcome such challenges of viewpoint changes. Specifically, we focus on the problem of selecting the optimal viewpoint at a given location. We compare existing approaches in the literature with additional proposed baselines and propose a novel data-driven approach. The result demonstrates the superior performance of the data-driven approach when compared to existing methods, both in controlled simulation
&lt;/p&gt;</description></item><item><title>该文章提出了一种针对开放环境下运动中激活肌肉组估计（AMGE）的新任务，并创建了一个大规模的MuscleMap数据集，包含多种类型运动视频和多种物运动中激活肌肉组的标注信息。通过这一数据集和提出的解决方案，该研究旨在开发可在真实环境中有效工作的视频分析工具，尤其是在体育和康复医疗领域。</title><link>https://arxiv.org/abs/2303.00952</link><description>&lt;p&gt;
Towards Activated Muscle Group Estimation in the Wild
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.00952
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种针对开放环境下运动中激活肌肉组估计（AMGE）的新任务，并创建了一个大规模的MuscleMap数据集，包含多种类型运动视频和多种物运动中激活肌肉组的标注信息。通过这一数据集和提出的解决方案，该研究旨在开发可在真实环境中有效工作的视频分析工具，尤其是在体育和康复医疗领域。
&lt;/p&gt;
&lt;p&gt;
arXiv:2303.00952v5 Announce Type: replace-cross  Abstract: In this paper, we tackle the new task of video-based Activated Muscle Group Estimation (AMGE) aiming at identifying active muscle regions during physical activity in the wild. To this intent, we provide the MuscleMap dataset featuring &amp;gt;15K video clips with 135 different activities and 20 labeled muscle groups. This dataset opens the vistas to multiple video-based applications in sports and rehabilitation medicine under flexible environment constraints. The proposed MuscleMap dataset is constructed with YouTube videos, specifically targeting High-Intensity Interval Training (HIIT) physical exercise in the wild. To make the AMGE model applicable in real-life situations, it is crucial to ensure that the model can generalize well to numerous types of physical activities not present during training and involving new combinations of activated muscles. To achieve this, our benchmark also covers an evaluation setting where the model is
&lt;/p&gt;</description></item></channel></rss>