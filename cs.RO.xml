<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>Chat Arxiv cs.RO</title><link>https://raw.githubusercontent.com/chrunx/cn-chat-arxiv/master/cs.RO.xml</link><description>This is arxiv RSS feed for cs.RO</description><item><title>该文章描述了首个通过学习达到业余人类水平表现的自主任务型（AT-DT）代理，实现了在竞争性桌球运动中的物理技能，填补了从模拟环境到真实世界应用中的技术差距。</title><link>https://arxiv.org/abs/2408.03906</link><description>&lt;p&gt;
Achieving Human Level Competitive Robot Table Tennis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03906
&lt;/p&gt;
&lt;p&gt;
该文章描述了首个通过学习达到业余人类水平表现的自主任务型（AT-DT）代理，实现了在竞争性桌球运动中的物理技能，填补了从模拟环境到真实世界应用中的技术差距。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03906v1 Announce Type: new  Abstract: Achieving human-level speed and performance on real world tasks is a north star for the robotics research community. This work takes a step towards that goal and presents the first learned robot agent that reaches amateur human-level performance in competitive table tennis. Table tennis is a physically demanding sport which requires human players to undergo years of training to achieve an advanced level of proficiency. In this paper, we contribute (1) a hierarchical and modular policy architecture consisting of (i) low level controllers with their detailed skill descriptors which model the agent's capabilities and help to bridge the sim-to-real gap and (ii) a high level controller that chooses the low level skills, (2) techniques for enabling zero-shot sim-to-real including an iterative approach to defining the task distribution that is grounded in the real-world and defines an automatic curriculum, and (3) real time adaptation to unseen
&lt;/p&gt;</description></item><item><title>该文章的创新贡献在于开发了一种使用小型光学时间飞行传感器进行平面表面几何偏差检测的方法，通过分析完整的时间飞行数据信息，识别并克服了表面几何与反射特性之间的关键差异。通过在小型数据集中训练高斯混合模型，该模型能够捕捉平面表面的预期几何和反射特性的分布，从而能够区分出可能包含偏差的测量值。文章还详细测试了该方法在不同表面和偏差情况下的有效性。</title><link>https://arxiv.org/abs/2408.03838</link><description>&lt;p&gt;
Using a Distance Sensor to Detect Deviations in a Planar Surface
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03838
&lt;/p&gt;
&lt;p&gt;
该文章的创新贡献在于开发了一种使用小型光学时间飞行传感器进行平面表面几何偏差检测的方法，通过分析完整的时间飞行数据信息，识别并克服了表面几何与反射特性之间的关键差异。通过在小型数据集中训练高斯混合模型，该模型能够捕捉平面表面的预期几何和反射特性的分布，从而能够区分出可能包含偏差的测量值。文章还详细测试了该方法在不同表面和偏差情况下的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03838v1 Announce Type: new  Abstract: We investigate methods for determining if a planar surface contains geometric deviations (e.g., protrusions, objects, divots, or cliffs) using only an instantaneous measurement from a miniature optical time-of-flight sensor. The key to our method is to utilize the entirety of information encoded in raw time-of-flight data captured by off-the-shelf distance sensors. We provide an analysis of the problem in which we identify the key ambiguity between geometry and surface photometrics. To overcome this challenging ambiguity, we fit a Gaussian mixture model to a small dataset of planar surface measurements. This model implicitly captures the expected geometry and distribution of photometrics of the planar surface and is used to identify measurements that are likely to contain deviations. We characterize our method on a variety of surfaces and planar deviations across a range of scenarios. We find that our method utilizing raw time-of-flight 
&lt;/p&gt;</description></item><item><title>该文章提出了一种创新的实时3D Gaussian Splatting（3DGS）技术，通过将3DGS与直接稀疏位姿估计算法相结合，显著优化了对单个摄像头捕捉视频的高质量容积重建过程。通过使用Direct Sparse Odometry输出的点云数据，相比于使用传统的结构光方法，可以大大减少达到高质图像渲染所需的训练时间。该研究预示了将3DGS与SLAM系统实时集成，以便在移动设备上运行的可能性。这一创新有望在增强现实和视频处理领域引发重要变革。</title><link>https://arxiv.org/abs/2408.03825</link><description>&lt;p&gt;
Towards Real-Time Gaussian Splatting: Accelerating 3DGS through Photometric SLAM
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03825
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种创新的实时3D Gaussian Splatting（3DGS）技术，通过将3DGS与直接稀疏位姿估计算法相结合，显著优化了对单个摄像头捕捉视频的高质量容积重建过程。通过使用Direct Sparse Odometry输出的点云数据，相比于使用传统的结构光方法，可以大大减少达到高质图像渲染所需的训练时间。该研究预示了将3DGS与SLAM系统实时集成，以便在移动设备上运行的可能性。这一创新有望在增强现实和视频处理领域引发重要变革。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03825v1 Announce Type: new  Abstract: Initial applications of 3D Gaussian Splatting (3DGS) in Visual Simultaneous Localization and Mapping (VSLAM) demonstrate the generation of high-quality volumetric reconstructions from monocular video streams. However, despite these promising advancements, current 3DGS integrations have reduced tracking performance and lower operating speeds compared to traditional VSLAM. To address these issues, we propose integrating 3DGS with Direct Sparse Odometry, a monocular photometric SLAM system. We have done preliminary experiments showing that using Direct Sparse Odometry point cloud outputs, as opposed to standard structure-from-motion methods, significantly shortens the training time needed to achieve high-quality renders. Reducing 3DGS training time enables the development of 3DGS-integrated SLAM systems that operate in real-time on mobile hardware. These promising initial findings suggest further exploration is warranted in combining tradit
&lt;/p&gt;</description></item><item><title>该文章提出了一种结合目标条件生成模型和采样式模型预测控制的算法，实现了在拥挤环境中实时机器人的路径规划，通过预测周围人群的反应来减少碰撞风险并缩短路径长度，并在实际机器人平台上得到了验证。</title><link>https://arxiv.org/abs/2408.03807</link><description>&lt;p&gt;
Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03807
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种结合目标条件生成模型和采样式模型预测控制的算法，实现了在拥挤环境中实时机器人的路径规划，通过预测周围人群的反应来减少碰撞风险并缩短路径长度，并在实际机器人平台上得到了验证。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03807v1 Announce Type: new  Abstract: This paper addresses navigation in crowded environments by integrating goal-conditioned generative models with Sampling-based Model Predictive Control (SMPC). We introduce goal-conditioned autoregressive models to generate crowd behaviors, capturing intricate interactions among individuals. The model processes potential robot trajectory samples and predicts the reactions of surrounding individuals, enabling proactive robotic navigation in complex scenarios. Extensive experiments show that this algorithm enables real-time navigation, significantly reducing collision rates and path lengths, and outperforming selected baseline methods. The practical effectiveness of this algorithm is validated on an actual robotic platform, demonstrating its capability in dynamic settings.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为HDPlanner的深度强化学习框架，该框架通过层级注意网络使移动机器人能够在未知环境中进行自主探索和导航，其能够处理两个核心任务：一是优化动作轨迹以适应环境并根据长期目标分配短期任务，二是选择最合适的路径。通过对环境的多层级认知和短期长期目标的高效结合，该框架展现了其在增强机器学习功能和提高环境中移动机器人的导航能力方面的显著优势。</title><link>https://arxiv.org/abs/2408.03768</link><description>&lt;p&gt;
HDPlanner: Advancing Autonomous Deployments in Unknown Environments through Hierarchical Decision Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03768
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为HDPlanner的深度强化学习框架，该框架通过层级注意网络使移动机器人能够在未知环境中进行自主探索和导航，其能够处理两个核心任务：一是优化动作轨迹以适应环境并根据长期目标分配短期任务，二是选择最合适的路径。通过对环境的多层级认知和短期长期目标的高效结合，该框架展现了其在增强机器学习功能和提高环境中移动机器人的导航能力方面的显著优势。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03768v1 Announce Type: new  Abstract: In this paper, we introduce HDPlanner, a deep reinforcement learning (DRL) based framework designed to tackle two core and challenging tasks for mobile robots: autonomous exploration and navigation, where the robot must optimize its trajectory adaptively to achieve the task objective through continuous interactions in unknown environments. Specifically, HDPlanner relies on novel hierarchical attention networks to empower the robot to reason about its belief across multiple spatial scales and sequence collaborative decisions, where our networks decompose long-term objectives into short-term informative task assignments and informative path plannings. We further propose a contrastive learning-based joint optimization to enhance the robustness of HDPlanner. We empirically demonstrate that HDPlanner significantly outperforms state-of-the-art conventional and learning-based baselines on an extensive set of simulations, including hundreds of t
&lt;/p&gt;</description></item><item><title>该文章通过自动神经ODE控制（ANODEC）方法，无需系统模型信息和人工调参，成功实现了软机器人精确敏捷运动的自学习。</title><link>https://arxiv.org/abs/2408.03754</link><description>&lt;p&gt;
A Soft Robotic System Automatically Learns Precise Agile Motions Without Model Information
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03754
&lt;/p&gt;
&lt;p&gt;
该文章通过自动神经ODE控制（ANODEC）方法，无需系统模型信息和人工调参，成功实现了软机器人精确敏捷运动的自学习。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03754v1 Announce Type: new  Abstract: Many application domains, e.g., in medicine and manufacturing, can greatly benefit from pneumatic Soft Robots (SRs). However, the accurate control of SRs has remained a significant challenge to date, mainly due to their nonlinear dynamics and viscoelastic material properties. Conventional control design methods often rely on either complex system modeling or time-intensive manual tuning, both of which require significant amounts of human expertise and thus limit their practicality. In recent works, the data-driven method, Automatic Neural ODE Control (ANODEC) has been successfully used to -- fully automatically and utilizing only input-output data -- design controllers for various nonlinear systems in silico, and without requiring prior model knowledge or extensive manual tuning. In this work, we successfully apply ANODEC to automatically learn to perform agile, non-repetitive reference tracking motion tasks in a real-world SR and within
&lt;/p&gt;</description></item><item><title>该文章创新性地提出MS-Mapping系统，用于解决大型多时段LiDAR地图构建问题，通过增量地图构建方案提高了复杂环境下的地图整合速度和准确性。此外，该系统还引入了关键帧选择方法，通过分析地图分布的相似性来筛选最有意义的帧，避免了数据冗余，优化了图优化速度。同时，文章介绍了一种基于协方差矩阵的自动最小二乘调整的 uncertainty模型，能够根据不确定性程度自动调整地图构建过程中的参数，提高了地图构建的鲁棒性和精确度。</title><link>https://arxiv.org/abs/2408.03723</link><description>&lt;p&gt;
MS-Mapping: An Uncertainty-Aware Large-Scale Multi-Session LiDAR Mapping System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03723
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出MS-Mapping系统，用于解决大型多时段LiDAR地图构建问题，通过增量地图构建方案提高了复杂环境下的地图整合速度和准确性。此外，该系统还引入了关键帧选择方法，通过分析地图分布的相似性来筛选最有意义的帧，避免了数据冗余，优化了图优化速度。同时，文章介绍了一种基于协方差矩阵的自动最小二乘调整的 uncertainty模型，能够根据不确定性程度自动调整地图构建过程中的参数，提高了地图构建的鲁棒性和精确度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03723v1 Announce Type: new  Abstract: Large-scale multi-session LiDAR mapping is essential for a wide range of applications, including surveying, autonomous driving, crowdsourced mapping, and multi-agent navigation. However, existing approaches often struggle with data redundancy, robustness, and accuracy in complex environments. To address these challenges, we present MS-Mapping, an novel multi-session LiDAR mapping system that employs an incremental mapping scheme for robust and accurate map assembly in large-scale environments. Our approach introduces three key innovations: 1) A distribution-aware keyframe selection method that captures the subtle contributions of each point cloud frame to the map by analyzing the similarity of map distributions. This method effectively reduces data redundancy and pose graph size, while enhancing graph optimization speed; 2) An uncertainty model that automatically performs least-squares adjustments according to the covariance matrix durin
&lt;/p&gt;</description></item><item><title>该文章提出通过整合车辆动态特性对智能驾驶员模型进行改进，包括微观参数校准和宏观验证，以提高仿真结果的效度。作者增加了部分已在扩展智能驾驶员模型中应用的物理驱动模型扩展，以改善模拟结果并更准确地复制实际车辆轨迹。此外，文章还介绍了基于无人机拍摄数据的框架，用于校准卡鲁斯模型并对其参数进行选择，从而显著减少了校准误差。</title><link>https://arxiv.org/abs/2408.03722</link><description>&lt;p&gt;
Improving the Intelligent Driver Model by Incorporating Vehicle Dynamics: Microscopic Calibration and Macroscopic Validation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03722
&lt;/p&gt;
&lt;p&gt;
该文章提出通过整合车辆动态特性对智能驾驶员模型进行改进，包括微观参数校准和宏观验证，以提高仿真结果的效度。作者增加了部分已在扩展智能驾驶员模型中应用的物理驱动模型扩展，以改善模拟结果并更准确地复制实际车辆轨迹。此外，文章还介绍了基于无人机拍摄数据的框架，用于校准卡鲁斯模型并对其参数进行选择，从而显著减少了校准误差。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03722v1 Announce Type: new  Abstract: Microscopic traffic simulations are used to evaluate the impact of infrastructure modifications and evolving vehicle technologies, such as connected and automated driving. Simulated vehicles are controlled via car-following, lane-changing and junction models, which are designed to imitate human driving behavior. However, physics-based car-following models (CFMs) cannot fully replicate measured vehicle trajectories. Therefore, we present model extensions for the Intelligent Driver Model (IDM), of which some are already included in the Extended Intelligent Driver Model (EIDM), to improve calibration and validation results. They consist of equations based on vehicle dynamics and drive off procedures. In addition, parameter selection plays a decisive role. Thus, we introduce a framework to calibrate CFMs using drone data captured at a signalized intersection in Stuttgart, Germany. We compare the calibration error of the Krauss Model with the
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了对ROS~2的事件执行器进行微小修改，使其适应经典实时调度理论，从而允许对任务处理进行更好的分析和优化，提高了任务执行效率和系统的稳定性。</title><link>https://arxiv.org/abs/2408.03696</link><description>&lt;p&gt;
Bridging the Gap between ROS~2 and Classical Real-Time Scheduling for Periodic Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03696
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了对ROS~2的事件执行器进行微小修改，使其适应经典实时调度理论，从而允许对任务处理进行更好的分析和优化，提高了任务执行效率和系统的稳定性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03696v1 Announce Type: new  Abstract: The Robot Operating System 2 (ROS~2) is a widely used middleware that provides software libraries and tools for developing robotic systems. In these systems, tasks are scheduled by ROS~2 executors. Since the scheduling behavior of the default ROS~2 executor is inherently different from classical real-time scheduling theory, dedicated analyses or alternative executors, requiring substantial changes to ROS~2, have been required. In 2023, the events executor, which features an events queue and allows the possibility to make scheduling decisions immediately after a job completes, was introduced into ROS~2. In this paper, we show that, with only minor modifications of the events executor, a large body of research results from classical real-time scheduling theory becomes applicable. Hence, this enables analytical bounds on the worst-case response time and the end-to-end latency, outperforming bounds for the default ROS 2 executor in many scen
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为DRAMA的Mamba-based端到端自动驾驶车辆运动规划算法，它能够高效地融合摄像头和激光雷达的感知数据，并通过引入Mamba-Transformer解码器增强规划性能，适用于处理多样化的复杂环境。</title><link>https://arxiv.org/abs/2408.03601</link><description>&lt;p&gt;
DRAMA: An Efficient End-to-end Motion Planner for Autonomous Driving with Mamba
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03601
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为DRAMA的Mamba-based端到端自动驾驶车辆运动规划算法，它能够高效地融合摄像头和激光雷达的感知数据，并通过引入Mamba-Transformer解码器增强规划性能，适用于处理多样化的复杂环境。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03601v1 Announce Type: new  Abstract: Motion planning is a challenging task to generate safe and feasible trajectories in highly dynamic and complex environments, forming a core capability for autonomous vehicles. In this paper, we propose DRAMA, the first Mamba-based end-to-end motion planner for autonomous vehicles. DRAMA fuses camera, LiDAR Bird's Eye View images in the feature space, as well as ego status information, to generate a series of future ego trajectories. Unlike traditional transformer-based methods with quadratic attention complexity for sequence length, DRAMA is able to achieve a less computationally intensive attention complexity, demonstrating potential to deal with increasingly complex scenarios. Leveraging our Mamba fusion module, DRAMA efficiently and effectively fuses the features of the camera and LiDAR modalities. In addition, we introduce a Mamba-Transformer decoder that enhances the overall planning performance. This module is universally adaptable
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为VPOcc的框架，该框架利用vanishing point（VP）对单摄像头3D语义占据预测进行了改进。其框架包括三个新的模块：VPZoomer用于实现视角几何信息平衡的特征提取，VPCA模块用于进行视角几何敏感的特征聚合，以及一个将原始和放大后的voxel特征融合的模块，以创建信息平衡的特征体积。通过这些创新模块，VPOcc能够更准确地预测场景的3D语义占据，从而提高了机器人视觉中单摄像头系统的性能。</title><link>https://arxiv.org/abs/2408.03551</link><description>&lt;p&gt;
VPOcc: Exploiting Vanishing Point for Monocular 3D Semantic Occupancy Prediction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03551
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为VPOcc的框架，该框架利用vanishing point（VP）对单摄像头3D语义占据预测进行了改进。其框架包括三个新的模块：VPZoomer用于实现视角几何信息平衡的特征提取，VPCA模块用于进行视角几何敏感的特征聚合，以及一个将原始和放大后的voxel特征融合的模块，以创建信息平衡的特征体积。通过这些创新模块，VPOcc能够更准确地预测场景的3D语义占据，从而提高了机器人视觉中单摄像头系统的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03551v1 Announce Type: cross  Abstract: Monocular 3D semantic occupancy prediction is becoming important in robot vision due to the compactness of using a single RGB camera. However, existing methods often do not adequately account for camera perspective geometry, resulting in information imbalance along the depth range of the image. To address this issue, we propose a vanishing point (VP) guided monocular 3D semantic occupancy prediction framework named VPOcc. Our framework consists of three novel modules utilizing VP. First, in the VPZoomer module, we initially utilize VP in feature extraction to achieve information balanced feature extraction across the scene by generating a zoom-in image based on VP. Second, we perform perspective geometry-aware feature aggregation by sampling points towards VP using a VP-guided cross-attention (VPCA) module. Finally, we create an information-balanced feature volume by effectively fusing original and zoom-in voxel feature volumes with a 
&lt;/p&gt;</description></item><item><title>该文章总结了深度强化学习（DRL）在机器人领域中的应用，特别是其在实现机器人多种关键技能方面的真实世界成功案例。文章强调了DRL在机器人技术中的潜力，并分析了实现这些成功的关键因素，以及未充分探索的领域。此外，文章还强调了未来研究中需要稳定、高效的真实世界RL模式的必要性，并提出了综合方法。</title><link>https://arxiv.org/abs/2408.03539</link><description>&lt;p&gt;
Deep Reinforcement Learning for Robotics: A Survey of Real-World Successes
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03539
&lt;/p&gt;
&lt;p&gt;
该文章总结了深度强化学习（DRL）在机器人领域中的应用，特别是其在实现机器人多种关键技能方面的真实世界成功案例。文章强调了DRL在机器人技术中的潜力，并分析了实现这些成功的关键因素，以及未充分探索的领域。此外，文章还强调了未来研究中需要稳定、高效的真实世界RL模式的必要性，并提出了综合方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03539v1 Announce Type: new  Abstract: Reinforcement learning (RL), particularly its combination with deep neural networks referred to as deep RL (DRL), has shown tremendous promise across a wide range of applications, suggesting its potential for enabling the development of sophisticated robotic behaviors. Robotics problems, however, pose fundamental difficulties for the application of RL, stemming from the complexity and cost of interacting with the physical world. This article provides a modern survey of DRL for robotics, with a particular focus on evaluating the real-world successes achieved with DRL in realizing several key robotic competencies. Our analysis aims to identify the key factors underlying those exciting successes, reveal underexplored areas, and provide an overall characterization of the status of DRL in robotics. We highlight several important avenues for future work, emphasizing the need for stable and sample-efficient real-world RL paradigms, holistic app
&lt;/p&gt;</description></item><item><title>该文章提出了一种模仿中枢神经系统分层结构与协作互动行为的学习控制框架，旨在提升机器人控制系统的灵活性与可靠性，并实现多样化的自主行为。通过在模拟和实际实验中验证对六足机器人的应用，该框架展现了其在复杂环境下的有效性。</title><link>https://arxiv.org/abs/2408.03525</link><description>&lt;p&gt;
Hierarchical learning control for autonomous robots inspired by central nervous system
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03525
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种模仿中枢神经系统分层结构与协作互动行为的学习控制框架，旨在提升机器人控制系统的灵活性与可靠性，并实现多样化的自主行为。通过在模拟和实际实验中验证对六足机器人的应用，该框架展现了其在复杂环境下的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03525v1 Announce Type: new  Abstract: Mammals can generate autonomous behaviors in various complex environments through the coordination and interaction of activities at different levels of their central nervous system. In this paper, we propose a novel hierarchical learning control framework by mimicking the hierarchical structure of the central nervous system along with their coordination and interaction behaviors. The framework combines the active and passive control systems to improve both the flexibility and reliability of the control system as well as to achieve more diverse autonomous behaviors of robots. Specifically, the framework has a backbone of independent neural network controllers at different levels and takes a three-level dual descending pathway structure, inspired from the functionality of the cerebral cortex, cerebellum, and spinal cord. We comprehensively validated the proposed approach through the simulation as well as the experiment of a hexapod robot i
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为AirSLAM的视觉SLAM系统，该系统能够高效地处理短期和长期的照明挑战。该系统采用混合方法，结合深度学习进行特征检测和匹配，以及传统优化算法。它使用一个统一的卷积神经网络同时提取关键点和结构线，并在耦合过程中进行关联、匹配和三角测量优化。此外，文章还介绍了一个轻量级的重新定位管线，该管线重用构建的地图，使用关键点、线和结构图来匹配查询帧与地图的匹配。通过在多个数据集上的广泛实验，证明了其系统的有效性。</title><link>https://arxiv.org/abs/2408.03520</link><description>&lt;p&gt;
AirSLAM: An Efficient and Illumination-Robust Point-Line Visual SLAM System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03520
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为AirSLAM的视觉SLAM系统，该系统能够高效地处理短期和长期的照明挑战。该系统采用混合方法，结合深度学习进行特征检测和匹配，以及传统优化算法。它使用一个统一的卷积神经网络同时提取关键点和结构线，并在耦合过程中进行关联、匹配和三角测量优化。此外，文章还介绍了一个轻量级的重新定位管线，该管线重用构建的地图，使用关键点、线和结构图来匹配查询帧与地图的匹配。通过在多个数据集上的广泛实验，证明了其系统的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03520v1 Announce Type: new  Abstract: In this paper, we present an efficient visual SLAM system designed to tackle both short-term and long-term illumination challenges. Our system adopts a hybrid approach that combines deep learning techniques for feature detection and matching with traditional backend optimization methods. Specifically, we propose a unified convolutional neural network (CNN) that simultaneously extracts keypoints and structural lines. These features are then associated, matched, triangulated, and optimized in a coupled manner. Additionally, we introduce a lightweight relocalization pipeline that reuses the built map, where keypoints, lines, and a structure graph are used to match the query frame with the map. To enhance the applicability of the proposed system to real-world robots, we deploy and accelerate the feature detection and matching networks using C++ and NVIDIA TensorRT. Extensive experiments conducted on various datasets demonstrate that our syst
&lt;/p&gt;</description></item><item><title>该文章提出了一种利用大型语言模型（LLMs）结合3D场景理解和自动驾驶的开放词汇方法，通过生成语境相关的标准短语来改进推理、分割和场景解释。这种方法通过将语言特征编码到3D高斯分布中，有效提高了在陌生环境中对感兴趣物体的检测精度，同时在处理未知词汇时表现出色，对于自动驾驶环境下的开放词汇物体检测和分割具有显著的提升效果。</title><link>https://arxiv.org/abs/2408.03516</link><description>&lt;p&gt;
Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in Autonomous Driving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03516
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种利用大型语言模型（LLMs）结合3D场景理解和自动驾驶的开放词汇方法，通过生成语境相关的标准短语来改进推理、分割和场景解释。这种方法通过将语言特征编码到3D高斯分布中，有效提高了在陌生环境中对感兴趣物体的检测精度，同时在处理未知词汇时表现出色，对于自动驾驶环境下的开放词汇物体检测和分割具有显著的提升效果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03516v1 Announce Type: cross  Abstract: This paper introduces a novel method for open-vocabulary 3D scene understanding in autonomous driving by combining Language Embedded 3D Gaussians with Large Language Models (LLMs) for enhanced inference. We propose utilizing LLMs to generate contextually relevant canonical phrases for segmentation and scene interpretation. Our method leverages the contextual and semantic capabilities of LLMs to produce a set of canonical phrases, which are then compared with the language features embedded in the 3D Gaussians. This LLM-guided approach significantly improves zero-shot scene understanding and detection of objects of interest, even in the most challenging or unfamiliar environments. Experimental results on the WayveScenes101 dataset demonstrate that our approach surpasses state-of-the-art methods in terms of accuracy and flexibility for open-vocabulary object detection and segmentation. This work represents a significant advancement toward
&lt;/p&gt;</description></item><item><title>该文章揭示了当大型语言模型集成到移动机器人系统中时，多模态提示注入攻击可能导致的导航性能和安全风险，并探讨了如何通过制定更安全的提示策略来缓解这类威胁。</title><link>https://arxiv.org/abs/2408.03515</link><description>&lt;p&gt;
A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03515
&lt;/p&gt;
&lt;p&gt;
该文章揭示了当大型语言模型集成到移动机器人系统中时，多模态提示注入攻击可能导致的导航性能和安全风险，并探讨了如何通过制定更安全的提示策略来缓解这类威胁。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03515v1 Announce Type: new  Abstract: The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot's understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings
&lt;/p&gt;</description></item><item><title>该文章介绍了VECTOR，一个能够改进立体重建优化（BA）过程的错误分析工具。VECTOR能够帮助分析师更深入地理解立体重建过程中的误差来源，从而提高了误差检测和分析的效率和精确度。</title><link>https://arxiv.org/abs/2408.03503</link><description>&lt;p&gt;
Opening the Black Box of 3D Reconstruction Error Analysis with VECTOR
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03503
&lt;/p&gt;
&lt;p&gt;
该文章介绍了VECTOR，一个能够改进立体重建优化（BA）过程的错误分析工具。VECTOR能够帮助分析师更深入地理解立体重建过程中的误差来源，从而提高了误差检测和分析的效率和精确度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03503v1 Announce Type: cross  Abstract: Reconstruction of 3D scenes from 2D images is a technical challenge that impacts domains from Earth and planetary sciences and space exploration to augmented and virtual reality. Typically, reconstruction algorithms first identify common features across images and then minimize reconstruction errors after estimating the shape of the terrain. This bundle adjustment (BA) step optimizes around a single, simplifying scalar value that obfuscates many possible causes of reconstruction errors (e.g., initial estimate of the position and orientation of the camera, lighting conditions, ease of feature detection in the terrain). Reconstruction errors can lead to inaccurate scientific inferences or endanger a spacecraft exploring a remote environment. To address this challenge, we present VECTOR, a visual analysis tool that improves error inspection for stereo reconstruction BA. VECTOR provides analysts with previously unavailable visibility into 
&lt;/p&gt;</description></item><item><title>该文章提出了一种针对多吸盘爪 grippers 的快速和可靠的pick-and-place方法的创新，通过引入新的约束用于轨迹规划和优化，可以实现对各种物体的高效可靠抓取。这些约束考虑了吸盘爪抓握力的大小和分布，特别是在抓取重物时，确保了抓取过程的稳定性和准确性。</title><link>https://arxiv.org/abs/2408.03498</link><description>&lt;p&gt;
Grasp Failure Constraints for Fast and Reliable Pick-and-Place Using Multi-Suction-Cup Grippers
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03498
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种针对多吸盘爪 grippers 的快速和可靠的pick-and-place方法的创新，通过引入新的约束用于轨迹规划和优化，可以实现对各种物体的高效可靠抓取。这些约束考虑了吸盘爪抓握力的大小和分布，特别是在抓取重物时，确保了抓取过程的稳定性和准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03498v1 Announce Type: new  Abstract: Multi-suction-cup grippers are frequently employed to perform pick-and-place robotic tasks, especially in industrial settings where grasping a wide range of light to heavy objects in limited amounts of time is a common requirement. However, most existing works focus on using one or two suction cups to grasp only irregularly shaped but light objects. There is a lack of research on robust manipulation of heavy objects using larger arrays of suction cups, which introduces challenges in modeling and predicting grasp failure. This paper presents a general approach to modeling grasp strength in multi-suction-cup grippers, introducing new constraints usable for trajectory planning and optimization to achieve fast and reliable pick-and-place maneuvers. The primary modeling challenge is the accurate prediction of the distribution of loads at each suction cup while grasping objects. To solve for this load distribution, we find minimum spring poten
&lt;/p&gt;</description></item><item><title>该文章通过引入一种交互式增强现实界面，开发了一种个性化的上下文感知方法来建模在人类-机器人交互中老年用户对个人空间的偏好。利用这种界面，文章运用了一种主动转移学习方法，对深度学习模型进行了定制化精调，该模型可以学习用户与其交互的机器人之间的理想距离。通过两个用户研究，文章验证了这种方法的有效性，并评估了系统在老年人身上使用的易用性。此外，文章还比较了使用这个增强现实界面所收集的数据与与物理机器人交互的数据，以探究虚拟机器人与物理实体机器人之间的个人空间偏好是否存在差异。</title><link>https://arxiv.org/abs/2408.03453</link><description>&lt;p&gt;
An Interactive Augmented Reality Interface for Personalized Proxemics Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03453
&lt;/p&gt;
&lt;p&gt;
该文章通过引入一种交互式增强现实界面，开发了一种个性化的上下文感知方法来建模在人类-机器人交互中老年用户对个人空间的偏好。利用这种界面，文章运用了一种主动转移学习方法，对深度学习模型进行了定制化精调，该模型可以学习用户与其交互的机器人之间的理想距离。通过两个用户研究，文章验证了这种方法的有效性，并评估了系统在老年人身上使用的易用性。此外，文章还比较了使用这个增强现实界面所收集的数据与与物理机器人交互的数据，以探究虚拟机器人与物理实体机器人之间的个人空间偏好是否存在差异。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03453v1 Announce Type: new  Abstract: Understanding and respecting personal space preferences is essential for socially assistive robots designed for older adult users. This work introduces and evaluates a novel personalized context-aware method for modeling users' proxemics preferences during human-robot interactions. Using an interactive augmented reality interface, we collected a set of user-preferred distances from the robot and employed an active transfer learning approach to fine-tune a specialized deep learning model. We evaluated this approach through two user studies: 1) a convenience population study (N = 24) to validate the efficacy of the active transfer learning approach; and 2) a user study involving older adults (N = 15) to assess the system's usability. We compared the data collected with the augmented reality interface and with the physical robot to examine the relationship between proxemics preferences for a virtual robot versus a physically embodied robot.
&lt;/p&gt;</description></item><item><title>该文章创新地提出使用时间序列聚类和强化学习结合的方法来估计太空船在运行期间发生的动态惯性参数变化，并通过实际的例子证明了该方法在面对多卫星部署系统的常见干扰时的高稳定性。</title><link>https://arxiv.org/abs/2408.03445</link><description>&lt;p&gt;
Spacecraft inertial parameters estimation using time series clustering and reinforcement learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03445
&lt;/p&gt;
&lt;p&gt;
该文章创新地提出使用时间序列聚类和强化学习结合的方法来估计太空船在运行期间发生的动态惯性参数变化，并通过实际的例子证明了该方法在面对多卫星部署系统的常见干扰时的高稳定性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03445v1 Announce Type: cross  Abstract: This paper presents a machine learning approach to estimate the inertial parameters of a spacecraft in cases when those change during operations, e.g. multiple deployments of payloads, unfolding of appendages and booms, propellant consumption as well as during in-orbit servicing and active debris removal operations. The machine learning approach uses time series clustering together with an optimised actuation sequence generated by reinforcement learning to facilitate distinguishing among different inertial parameter sets. The performance of the proposed strategy is assessed against the case of a multi-satellite deployment system showing that the algorithm is resilient towards common disturbances in such kinds of operations.
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于深度确定性策略梯度（DDPG）算法的强化学习框架，用于解决在移动车辆中，时间敏感且计算密集型的任务从车辆迁移到附近的边缘服务器、V2I系统或通过V2V通信的其他协作车辆时，频繁的网络访问点（AP）手操作和任务迁移造成的服务效率问题。这种方法旨在通过协同优化通信和计算资源，来提高服务质量，并减少由于频繁切换和网络重连导致的延迟。通过这种方式，该框架有助于保持连续的网络连接，并提高了移动环境中任务执行的效率和稳定性。</title><link>https://arxiv.org/abs/2408.03435</link><description>&lt;p&gt;
Communication-Aware Consistent Edge Selection for Mobile Users and Autonomous Vehicles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03435
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于深度确定性策略梯度（DDPG）算法的强化学习框架，用于解决在移动车辆中，时间敏感且计算密集型的任务从车辆迁移到附近的边缘服务器、V2I系统或通过V2V通信的其他协作车辆时，频繁的网络访问点（AP）手操作和任务迁移造成的服务效率问题。这种方法旨在通过协同优化通信和计算资源，来提高服务质量，并减少由于频繁切换和网络重连导致的延迟。通过这种方式，该框架有助于保持连续的网络连接，并提高了移动环境中任务执行的效率和稳定性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03435v1 Announce Type: cross  Abstract: Offloading time-sensitive, computationally intensive tasks-such as advanced learning algorithms for autonomous driving-from vehicles to nearby edge servers, vehicle-to-infrastructure (V2I) systems, or other collaborating vehicles via vehicle-to-vehicle (V2V) communication enhances service efficiency. However, whence traversing the path to the destination, the vehicle's mobility necessitates frequent handovers among the access points (APs) to maintain continuous and uninterrupted wireless connections to maintain the network's Quality of Service (QoS). These frequent handovers subsequently lead to task migrations among the edge servers associated with the respective APs. This paper addresses the joint problem of task migration and access-point handover by proposing a deep reinforcement learning framework based on the Deep Deterministic Policy Gradient (DDPG) algorithm. A joint allocation method of communication and computation of APs is 
&lt;/p&gt;</description></item><item><title>该文章提出了一种通过自监督初始化学习加速模型预测控制的方法，该方法结合了离线自监督学习和在线强化学习精调，能够在保持控制性能的同时显著减少优化时间。</title><link>https://arxiv.org/abs/2408.03394</link><description>&lt;p&gt;
Faster Model Predictive Control via Self-Supervised Initialization Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03394
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种通过自监督初始化学习加速模型预测控制的方法，该方法结合了离线自监督学习和在线强化学习精调，能够在保持控制性能的同时显著减少优化时间。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03394v1 Announce Type: new  Abstract: Optimization for robot control tasks, spanning various methodologies, includes Model Predictive Control (MPC). However, the complexity of the system, such as non-convex and non-differentiable cost functions and prolonged planning horizons often drastically increases the computation time, limiting MPC's real-world applicability. Prior works in speeding up the optimization have limitations on solving convex problem and generalizing to hold out domains. To overcome this challenge, we develop a novel framework aiming at expediting optimization processes. In our framework, we combine offline self-supervised learning and online fine-tuning through reinforcement learning to improve the control performance and reduce optimization time. We demonstrate the effectiveness of our method on a novel, challenging Formula-1-track driving task, achieving 3.9\% higher performance in optimization time and 3.6\% higher performance in tracking accuracy on cha
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用自然istic人类驾驶先验和强化学习技术的对抗性安全关键场景生成方法，旨在从现实和挑战性的自动驾驶车辆决策系统评估中获取大规模测试场景。这种方法能够通过模拟真实交通交互环境以及实施的两阶段流程，模拟驾驶策略，进而生成既有真实感又具备挑战性的多样化场景。</title><link>https://arxiv.org/abs/2408.03200</link><description>&lt;p&gt;
Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03200
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用自然istic人类驾驶先验和强化学习技术的对抗性安全关键场景生成方法，旨在从现实和挑战性的自动驾驶车辆决策系统评估中获取大规模测试场景。这种方法能够通过模拟真实交通交互环境以及实施的两阶段流程，模拟驾驶策略，进而生成既有真实感又具备挑战性的多样化场景。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03200v1 Announce Type: new  Abstract: Evaluating the decision-making system is indispensable in developing autonomous vehicles, while realistic and challenging safety-critical test scenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks to the long-tailed distribution, sparsity, and rarity in real-world data sets. To tackle this problem, in this paper, we introduce a natural adversarial scenario generation solution using naturalistic human driving priors and reinforcement learning techniques. By doing this, we can obtain large-scale test scenarios that are both diverse and realistic. Specifically, we build a simulation environment that mimics natural traffic interaction scenarios. Informed by this environment, we implement a two-stage procedure. The first stage incorporates conventional rule-based models, e.g., IDM~(Intelligent Driver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes) model, to coarsely and discretely capture and ca
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Stochastic Trajectory Optimization for Demonstration Imitation (STODI)的算法，它使用随机轨迹优化方法帮助机器人模仿人类专家的演示运动轨迹，并在此过程中提升机器人的动态性能。这种算法通过在保证演示轨迹形状的同时，利用噪声提高轨迹探索效率，为机器人学习新技能提供了一种新型方法。</title><link>https://arxiv.org/abs/2408.03131</link><description>&lt;p&gt;
Stochastic Trajectory Optimization for Demonstration Imitation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03131
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Stochastic Trajectory Optimization for Demonstration Imitation (STODI)的算法，它使用随机轨迹优化方法帮助机器人模仿人类专家的演示运动轨迹，并在此过程中提升机器人的动态性能。这种算法通过在保证演示轨迹形状的同时，利用噪声提高轨迹探索效率，为机器人学习新技能提供了一种新型方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03131v1 Announce Type: new  Abstract: Humans often learn new skills by imitating the experts and gradually developing their proficiency. In this work, we introduce Stochastic Trajectory Optimization for Demonstration Imitation (STODI), a trajectory optimization framework for robots to imitate the shape of demonstration trajectories with improved dynamic performance. Consistent with the human learning process, demonstration imitation serves as an initial step, while trajectory optimization aims to enhance robot motion performance. By generating random noise and constructing proper cost functions, the STODI effectively explores and exploits generated noisy trajectories while preserving the demonstration shape characteristics. We employ three metrics to measure the similarity of trajectories in both the time and frequency domains to help with demonstration imitation. Theoretical analysis reveals relationships among these metrics, emphasizing the benefits of frequency-domain ana
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用视觉语言模型（VLMs）的轨迹生成与选择方法，能够在无地图的户外环境中处理复杂的导航任务，确保路径既满足特定环境的可通行性约束又能符合人类的路径偏好。文章通过条件变分自编码器（CVAE）模型生成多条候选轨迹，并通过视觉提示和VLMs的零射能力进行路径的选择，以适配任务的上下文信息。实验结果表明，该方法在真实环境下的表现优于传统全局导航算法。</title><link>https://arxiv.org/abs/2408.02454</link><description>&lt;p&gt;
TGS: Trajectory Generation and Selection using Vision Language Models in Mapless Outdoor Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02454
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用视觉语言模型（VLMs）的轨迹生成与选择方法，能够在无地图的户外环境中处理复杂的导航任务，确保路径既满足特定环境的可通行性约束又能符合人类的路径偏好。文章通过条件变分自编码器（CVAE）模型生成多条候选轨迹，并通过视觉提示和VLMs的零射能力进行路径的选择，以适配任务的上下文信息。实验结果表明，该方法在真实环境下的表现优于传统全局导航算法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02454v1 Announce Type: new  Abstract: We present a multi-modal trajectory generation and selection algorithm for real-world mapless outdoor navigation in challenging scenarios with unstructured off-road features like buildings, grass, and curbs. Our goal is to compute suitable trajectories that (1) satisfy the environment-specific traversability constraints and (2) match human-like paths while navigating in crosswalks, sidewalks, etc. Our formulation uses a Conditional Variational Autoencoder (CVAE) generative model enhanced with traversability constraints to generate multiple candidate trajectories for global navigation. We use VLMs and a visual prompting approach with their zero-shot ability of semantic understanding and logical reasoning to choose the best trajectory given the contextual information about the task. We evaluate our methods in various outdoor scenes with wheeled robots and compare the performance with other global navigation algorithms. In practice, we obse
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为EqvAfford的框架，它通过保证点级 affordance学习中的equivariance，为下游的机器人操作任务提供了一种新的设计，能够在不同的对象姿态下实现良好的性能和泛化能力。</title><link>https://arxiv.org/abs/2408.01953</link><description>&lt;p&gt;
EqvAfford: SE(3) Equivariance for Point-Level Affordance Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01953
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为EqvAfford的框架，它通过保证点级 affordance学习中的equivariance，为下游的机器人操作任务提供了一种新的设计，能够在不同的对象姿态下实现良好的性能和泛化能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01953v1 Announce Type: new  Abstract: Humans perceive and interact with the world with the awareness of equivariance, facilitating us in manipulating different objects in diverse poses. For robotic manipulation, such equivariance also exists in many scenarios. For example, no matter what the pose of a drawer is (translation, rotation and tilt), the manipulation strategy is consistent (grasp the handle and pull in a line). While traditional models usually do not have the awareness of equivariance for robotic manipulation, which might result in more data for training and poor performance in novel object poses, we propose our EqvAfford framework, with novel designs to guarantee the equivariance in point-level affordance learning for downstream robotic manipulation, with great performance and generalization ability on representative tasks on objects in diverse poses.
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于Therblig的Backbone Framework（TBBF），通过将高阶机器人任务分解为基本动作元素（therbligs），并结合当前的基础模型，提高了机器人对任务的理解能力和泛化能力。这种框架通过两个阶段来实现：首先通过Meta-RGate SynerFusion（MGSF）网络在离线训练阶段进行准确的动作元素分割，然后在使用新任务演示后，通过ActionREG方法将高阶知识编码到图像中，从而在线上测试阶段实现任务的理解。</title><link>https://arxiv.org/abs/2408.01334</link><description>&lt;p&gt;
A Backbone for Long-Horizon Robot Task Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01334
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于Therblig的Backbone Framework（TBBF），通过将高阶机器人任务分解为基本动作元素（therbligs），并结合当前的基础模型，提高了机器人对任务的理解能力和泛化能力。这种框架通过两个阶段来实现：首先通过Meta-RGate SynerFusion（MGSF）网络在离线训练阶段进行准确的动作元素分割，然后在使用新任务演示后，通过ActionREG方法将高阶知识编码到图像中，从而在线上测试阶段实现任务的理解。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01334v2 Announce Type: replace  Abstract: End-to-end robot learning, particularly for long-horizon tasks, often results in unpredictable outcomes and poor generalization. To address these challenges, we propose a novel Therblig-based Backbone Framework (TBBF) to enhance robot task understanding and transferability. This framework uses therbligs (basic action elements) as the backbone to decompose high-level robot tasks into elemental robot configurations, which are then integrated with current foundation models to improve task understanding. The approach consists of two stages: offline training and online testing. During the offline training stage, we developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig segmentation across various tasks. In the online testing stage, after a one-shot demonstration of a new task is collected, our MGSF network extracts high-level knowledge, which is then encoded into the image using Action Registration (ActionREG). Addition
&lt;/p&gt;</description></item><item><title>该文章介绍了一种名为IG-SLAM的快速RGB-only SLAM系统，它结合了3D Gaussian Splatting和Dense-SLAM跟踪技术，以提供精确的地图更新和快速操作速度。</title><link>https://arxiv.org/abs/2408.01126</link><description>&lt;p&gt;
IG-SLAM: Instant Gaussian SLAM
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01126
&lt;/p&gt;
&lt;p&gt;
该文章介绍了一种名为IG-SLAM的快速RGB-only SLAM系统，它结合了3D Gaussian Splatting和Dense-SLAM跟踪技术，以提供精确的地图更新和快速操作速度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01126v2 Announce Type: replace-cross  Abstract: 3D Gaussian Splatting has recently shown promising results as an alternative scene representation in SLAM systems to neural implicit representations. However, current methods either lack dense depth maps to supervise the mapping process or detailed training designs that consider the scale of the environment. To address these drawbacks, we present IG-SLAM, a dense RGB-only SLAM system that employs robust Dense-SLAM methods for tracking and combines them with Gaussian Splatting. A 3D map of the environment is constructed using accurate pose and dense depth provided by tracking. Additionally, we utilize depth uncertainty in map optimization to improve 3D reconstruction. Our decay strategy in map optimization enhances convergence and allows the system to run at 10 fps in a single process. We demonstrate competitive performance with state-of-the-art RGB-only SLAM systems while achieving faster operation speeds. We present our experi
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一种基于视觉和反向强化学习的机臂操纵方法，通过仅利用人类视觉演示来学习成本函数，并运用TD视觉模型预测控制(MPC)对该成本函数进行优化，成功在现实物理平台上实现了复杂物体的操作任务。</title><link>https://arxiv.org/abs/2407.12941</link><description>&lt;p&gt;
Robotic Arm Manipulation with Inverse Reinforcement Learning &amp;amp; TD-MPC
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.12941
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一种基于视觉和反向强化学习的机臂操纵方法，通过仅利用人类视觉演示来学习成本函数，并运用TD视觉模型预测控制(MPC)对该成本函数进行优化，成功在现实物理平台上实现了复杂物体的操作任务。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.12941v2 Announce Type: replace  Abstract: One unresolved issue is how to scale model-based inverse reinforcement learning (IRL) to actual robotic manipulation tasks with unpredictable dynamics. The ability to learn from both visual and proprioceptive examples, creating algorithms that scale to high-dimensional state-spaces, and mastering strong dynamics models are the main obstacles. In this work, we provide a gradient-based inverse reinforcement learning framework that learns cost functions purely from visual human demonstrations. The shown behavior and the trajectory is then optimized using TD visual model predictive control(MPC) and the learned cost functions. We test our system using fundamental object manipulation tasks on hardware.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为“命令学习”（Imperative Learning）的自监督神经符号学习框架，用于提高机器人的自主能力。该框架通过三部分组成——神经模块、推理引擎和记忆系统，实现了神经和符号推理的结合，不需要大量标记数据，通过形式化的双层优化问题，解决了数据驱动方法的标签依赖问题和基于符号推理的长处。</title><link>https://arxiv.org/abs/2406.16087</link><description>&lt;p&gt;
Imperative Learning: A Self-supervised Neural-Symbolic Learning Framework for Robot Autonomy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.16087
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为“命令学习”（Imperative Learning）的自监督神经符号学习框架，用于提高机器人的自主能力。该框架通过三部分组成——神经模块、推理引擎和记忆系统，实现了神经和符号推理的结合，不需要大量标记数据，通过形式化的双层优化问题，解决了数据驱动方法的标签依赖问题和基于符号推理的长处。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.16087v4 Announce Type: replace  Abstract: Data-driven methods such as reinforcement and imitation learning have achieved remarkable success in robot autonomy. However, their data-centric nature still hinders them from generalizing well to ever-changing environments. Moreover, collecting large datasets for robotic tasks is often impractical and expensive. To overcome these challenges, we introduce a new self-supervised neural-symbolic (NeSy) computational framework, imperative learning (IL), for robot autonomy, leveraging the generalization abilities of symbolic reasoning. The framework of IL consists of three primary components: a neural module, a reasoning engine, and a memory system. We formulate IL as a special bilevel optimization (BLO), which enables reciprocal learning over the three modules. This overcomes the label-intensive obstacles associated with data-driven approaches and takes advantage of symbolic reasoning concerning logical reasoning, physical principles, ge
&lt;/p&gt;</description></item><item><title>该文章利用深度强化学习算法增强的Proximal Policy Optimization方法在模拟环境中训练轮式机器人进行安全导航，通过引入改进的神经网络结构和有效的奖励函数，提升了导航性能，使得机器人能在复杂环境中避开障碍物并高效地到达目标点。</title><link>https://arxiv.org/abs/2405.16266</link><description>&lt;p&gt;
Deep Reinforcement Learning with Enhanced PPO for Safe Mobile Robot Navigation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.16266
&lt;/p&gt;
&lt;p&gt;
该文章利用深度强化学习算法增强的Proximal Policy Optimization方法在模拟环境中训练轮式机器人进行安全导航，通过引入改进的神经网络结构和有效的奖励函数，提升了导航性能，使得机器人能在复杂环境中避开障碍物并高效地到达目标点。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.16266v2 Announce Type: replace  Abstract: Collision-free motion is essential for mobile robots. Most approaches to collision-free and efficient navigation with wheeled robots require parameter tuning by experts to obtain good navigation behavior. This study investigates the application of deep reinforcement learning to train a mobile robot for autonomous navigation in a complex environment. The robot utilizes LiDAR sensor data and a deep neural network to generate control signals guiding it toward a specified target while avoiding obstacles. We employ two reinforcement learning algorithms in the Gazebo simulation environment: Deep Deterministic Policy Gradient and proximal policy optimization. The study introduces an enhanced neural network structure in the Proximal Policy Optimization algorithm to boost performance, accompanied by a well-designed reward function to improve algorithm efficacy. Experimental results conducted in both obstacle and obstacle-free environments und
&lt;/p&gt;</description></item><item><title>该文章创新地提出了一种使用正态化流动(normalizing flows)进行模型预测轨迹规划的方法，这项技术能够高效地探索输入域，并在模拟场景中进行了评估。</title><link>https://arxiv.org/abs/2404.09657</link><description>&lt;p&gt;
Sampling for Model Predictive Trajectory Planning in Autonomous Driving using Normalizing Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.09657
&lt;/p&gt;
&lt;p&gt;
该文章创新地提出了一种使用正态化流动(normalizing flows)进行模型预测轨迹规划的方法，这项技术能够高效地探索输入域，并在模拟场景中进行了评估。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.09657v3 Announce Type: replace  Abstract: Alongside optimization-based planners, sampling-based approaches are often used in trajectory planning for autonomous driving due to their simplicity. Model predictive path integral control is a framework that builds upon optimization principles while incorporating stochastic sampling of input trajectories. This paper investigates several sampling approaches for trajectory generation. In this context, normalizing flows originating from the field of variational inference are considered for the generation of sampling distributions, as they model transformations of simple to more complex distributions. Accordingly, learning-based normalizing flow models are trained for a more efficient exploration of the input domain for the task at hand. The developed algorithm and the proposed sampling distributions are evaluated in two simulation scenarios.
&lt;/p&gt;</description></item><item><title>该文章介绍了基于Motion Transformer模型的自动驾驶车辆轨迹预测的迁移学习研究，旨在减少从模拟环境到真实环境预测的差距。通过研究迁移学习技术，作者希望能够了解在计算时间和预测准确性之间可能的权衡，以适应不同传感系统、感知算法、交通规则和法律的变化，并为模型在不同环境下的适应性提供见解。</title><link>https://arxiv.org/abs/2404.08271</link><description>&lt;p&gt;
Transfer Learning Study of Motion Transformer-based Trajectory Predictions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.08271
&lt;/p&gt;
&lt;p&gt;
该文章介绍了基于Motion Transformer模型的自动驾驶车辆轨迹预测的迁移学习研究，旨在减少从模拟环境到真实环境预测的差距。通过研究迁移学习技术，作者希望能够了解在计算时间和预测准确性之间可能的权衡，以适应不同传感系统、感知算法、交通规则和法律的变化，并为模型在不同环境下的适应性提供见解。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.08271v3 Announce Type: replace-cross  Abstract: Trajectory planning in autonomous driving is highly dependent on predicting the emergent behavior of other road users. Learning-based methods are currently showing impressive results in simulation-based challenges, with transformer-based architectures technologically leading the way. Ultimately, however, predictions are needed in the real world. In addition to the shifts from simulation to the real world, many vehicle- and country-specific shifts, i.e. differences in sensor systems, fusion and perception algorithms as well as traffic rules and laws, are on the agenda. Since models that can cover all system setups and design domains at once are not yet foreseeable, model adaptation plays a central role. Therefore, a simulation-based study on transfer learning techniques is conducted on basis of a transformer-based model. Furthermore, the study aims to provide insights into possible trade-offs between computational time and perfo
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于线性混合皮肤（LBS）的全新方法，用于通过声音输入驱动具有仿生面部表情的机械机器人。这种方法不仅优化了机器人的外观设计，而且使得表情动作的生成更加准确和同步。通过这种方式，实现了实时、高质量的面部表情，对于推动机器人与人类的自然互动具有重要意义。</title><link>https://arxiv.org/abs/2403.12670</link><description>&lt;p&gt;
Driving Animatronic Robot Facial Expression From Speech
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.12670
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于线性混合皮肤（LBS）的全新方法，用于通过声音输入驱动具有仿生面部表情的机械机器人。这种方法不仅优化了机器人的外观设计，而且使得表情动作的生成更加准确和同步。通过这种方式，实现了实时、高质量的面部表情，对于推动机器人与人类的自然互动具有重要意义。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.12670v3 Announce Type: replace  Abstract: Animatronic robots hold the promise of enabling natural human-robot interaction through lifelike facial expressions. However, generating realistic, speech-synchronized robot expressions poses significant challenges due to the complexities of facial biomechanics and the need for responsive motion synthesis. This paper introduces a novel, skinning-centric approach to drive animatronic robot facial expressions from speech input. At its core, the proposed approach employs linear blend skinning (LBS) as a unifying representation, guiding innovations in both embodiment design and motion synthesis. LBS informs the actuation topology, facilitates human expression retargeting, and enables efficient speech-driven facial motion generation. This approach demonstrates the capability to produce highly realistic facial expressions on an animatronic face in real-time at over 4000 fps on a single Nvidia RTX 4090, significantly advancing robots' abili
&lt;/p&gt;</description></item><item><title>该文章提出并验证了大型语言模型在自动生成机器人路线方面的潜力，使得机器人调度问题可以通过自然语言描述直接得到解决方案。</title><link>https://arxiv.org/abs/2403.10795</link><description>&lt;p&gt;
Can Large Language Models Solve Robot Routing?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10795
&lt;/p&gt;
&lt;p&gt;
该文章提出并验证了大型语言模型在自动生成机器人路线方面的潜力，使得机器人调度问题可以通过自然语言描述直接得到解决方案。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10795v2 Announce Type: replace-cross  Abstract: Routing problems are common in mobile robotics, encompassing tasks such as inspection, surveillance, and coverage. Depending on the objective and constraints, these problems often reduce to variants of the Traveling Salesman Problem (TSP), with solutions traditionally derived by translating high-level objectives into an optimization formulation and using modern solvers to arrive at a solution. Here, we explore the potential of Large Language Models (LLMs) to replace the entire pipeline from tasks described in natural language to the generation of robot routes. We systematically investigate the performance of LLMs in robot routing by constructing a dataset with 80 unique robot routing problems across 8 variants in both single and multi-robot settings. We evaluate LLMs through three frameworks: single attempt, self-debugging, and self-debugging with self-verification and various contexts, including mathematical formulations, pseu
&lt;/p&gt;</description></item><item><title>该文章提出了DrPlanner，一种利用大型语言模型自动诊断和修复自动化车辆运动规划器的框架。通过从自然语言和编程语言生成规划器及其路径的详细描述，DrPlanner能够返回经过修复的规划器，并提供详细的诊断说明。这种方法通过迭代反馈不断提升性能，已在多种运动规划器上得到验证。</title><link>https://arxiv.org/abs/2403.07470</link><description>&lt;p&gt;
DrPlanner: Diagnosis and Repair of Motion Planners for Automated Vehicles Using Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.07470
&lt;/p&gt;
&lt;p&gt;
该文章提出了DrPlanner，一种利用大型语言模型自动诊断和修复自动化车辆运动规划器的框架。通过从自然语言和编程语言生成规划器及其路径的详细描述，DrPlanner能够返回经过修复的规划器，并提供详细的诊断说明。这种方法通过迭代反馈不断提升性能，已在多种运动规划器上得到验证。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.07470v2 Announce Type: replace  Abstract: Motion planners are essential for the safe operation of automated vehicles across various scenarios. However, no motion planning algorithm has achieved perfection in the literature, and improving its performance is often time-consuming and labor-intensive. To tackle the aforementioned issues, we present DrPlanner, the first framework designed to automatically diagnose and repair motion planners using large language models. Initially, we generate a structured description of the planner and its planned trajectories from both natural and programming languages. Leveraging the profound capabilities of large language models, our framework returns repaired planners with detailed diagnostic descriptions. Furthermore, our framework advances iteratively with continuous feedback from the evaluation of the repaired outcomes. Our approach is validated using both search- and sampling-based motion planners for automated vehicles; experimental resul
&lt;/p&gt;</description></item><item><title>该文章提出了SAFE-SIM，一种利用扩散模型生成的具有可控对抗行为的封闭式安全关键性仿真框架，能够模拟接近真实世界条件下的长尾安全关键性场景，并允许对规划器进行更全面和互动的评估。</title><link>https://arxiv.org/abs/2401.00391</link><description>&lt;p&gt;
SAFE-SIM: Safety-Critical Closed-Loop Traffic Simulation with Diffusion-Controllable Adversaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.00391
&lt;/p&gt;
&lt;p&gt;
该文章提出了SAFE-SIM，一种利用扩散模型生成的具有可控对抗行为的封闭式安全关键性仿真框架，能够模拟接近真实世界条件下的长尾安全关键性场景，并允许对规划器进行更全面和互动的评估。
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.00391v3 Announce Type: replace  Abstract: Evaluating the performance of autonomous vehicle planning algorithms necessitates simulating long-tail safety-critical traffic scenarios. However, traditional methods for generating such scenarios often fall short in terms of controllability and realism; they also neglect the dynamics of agent interactions. To address these limitations, we introduce SAFE-SIM, a novel diffusion-based controllable closed-loop safety-critical simulation framework. Our approach yields two distinct advantages: 1) generating realistic long-tail safety-critical scenarios that closely reflect real-world conditions, and 2) providing controllable adversarial behavior for more comprehensive and interactive evaluations. We develop a novel approach to simulate safety-critical scenarios through an adversarial term in the denoising process of diffusion models, which allows an adversarial agent to challenge a planner with plausible maneuvers while all agents in the 
&lt;/p&gt;</description></item><item><title>该文章提出了一个针对移动地面至空中充电系统的能量感知路由算法，旨在在特定情况下优化无人机与无人地面车辆的合作规划。该算法通过解决旅行者销售商问题生成指导路径，并使用蒙特卡洛树搜索算法进一步优化路径，以减少整体任务执行时间并确保车辆能量限制下的运行。通过仿真和实际实验验证了算法的有效性，展示了其在多种场景下的优化能力。</title><link>https://arxiv.org/abs/2310.07729</link><description>&lt;p&gt;
Energy-Aware Routing Algorithm for Mobile Ground-to-Air Charging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.07729
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个针对移动地面至空中充电系统的能量感知路由算法，旨在在特定情况下优化无人机与无人地面车辆的合作规划。该算法通过解决旅行者销售商问题生成指导路径，并使用蒙特卡洛树搜索算法进一步优化路径，以减少整体任务执行时间并确保车辆能量限制下的运行。通过仿真和实际实验验证了算法的有效性，展示了其在多种场景下的优化能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.07729v2 Announce Type: replace  Abstract: We investigate the problem of energy-constrained planning for a cooperative system of an Unmanned Ground Vehicles (UGV) and an Unmanned Aerial Vehicle (UAV). In scenarios where the UGV serves as a mobile base to ferry the UAV and as a charging station to recharge the UAV, we formulate a novel energy-constrained routing problem. To tackle this problem, we design an energy-aware routing algorithm, aiming to minimize the overall mission duration under the energy limitations of both vehicles. The algorithm first solves a Traveling Salesman Problem (TSP) to generate a guided tour. Then, it employs the Monte-Carlo Tree Search (MCTS) algorithm to refine the tour and generate paths for the two vehicles. We evaluate the performance of our algorithm through extensive simulations and a proof-of-concept experiment. The results show that our algorithm consistently achieves near-optimal mission time and maintains fast running time across a wide ra
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于Systems Modeling Language（SysML）的新语言——Simulation-Physical Systems Modeling Language（SPSysML），用于改善设计分析，并通过定义定量因素和基于需求的系统结构方法，评估模拟和物理系统的完整性。</title><link>https://arxiv.org/abs/2303.09565</link><description>&lt;p&gt;
Component reusability evaluation and requirement tracing for agent-based simulation-physical systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2303.09565
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于Systems Modeling Language（SysML）的新语言——Simulation-Physical Systems Modeling Language（SPSysML），用于改善设计分析，并通过定义定量因素和基于需求的系统结构方法，评估模拟和物理系统的完整性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2303.09565v4 Announce Type: replace-cross  Abstract: In the early stages of product development, evaluating design concepts is crucial due to its impact on quality and cost. However, this process is often hindered by vague and uncertain design information. We use the Domain Specification Language (DSL) to improve design analysis and evaluation of systems incorporating simulation and physical parts. '   Goal: Our method evaluates the integrity between the simulated and physical embodiment of the system. The assessment is done in various scopes, e.g. per pair of Digital Twins (DT) and its physical counterpart- Physical Twin (PT), system-wide, or one of many system setups.   Method: We propose a DSL based on Systems Modeling Language (SysML). The Simulation-Physical Systems Modeling Language (SPSysML) defines the taxonomy of CPS consisting of at least a physical or simulated part. Based on SPSysML, we define quantitative factors and a requirement-based system structuring method, whi
&lt;/p&gt;</description></item><item><title>该文章提出了一种结合学习和序列优化的方法，用于解决无信号控制交叉口的机器人交通管理问题。该方法通过学习一个共享策略来确定机器人根据实时交通状态信息的通行顺序，并在此基础上对机器人进行序列化的轨迹优化，以保证在任何时刻的行驶安全。</title><link>https://arxiv.org/abs/2302.05082</link><description>&lt;p&gt;
Reinforcement Learning Aided Sequential Optimization for Unsignalized Intersection Management of Robot Traffic
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2302.05082
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种结合学习和序列优化的方法，用于解决无信号控制交叉口的机器人交通管理问题。该方法通过学习一个共享策略来确定机器人根据实时交通状态信息的通行顺序，并在此基础上对机器人进行序列化的轨迹优化，以保证在任何时刻的行驶安全。
&lt;/p&gt;
&lt;p&gt;
arXiv:2302.05082v3 Announce Type: replace  Abstract: We consider the problem of optimal unsignalized intersection management, wherein we seek to obtain safe and optimal trajectories, for a set of robots that arrive randomly and continually. This problem involves repeatedly solving a mixed integer program (with robot acceleration trajectories as decision variables) with different parameters, for which the computation time using a naive optimization algorithm scales exponentially with the number of robots and lanes. Hence, such an approach is not suitable for real-time implementation. In this paper, we propose a solution framework that combines learning and sequential optimization. In particular, we propose an algorithm for learning a shared policy that given the traffic state information, determines the crossing order of the robots. Then, we optimize the trajectories of the robots sequentially according to that crossing order. This approach inherently guarantees safety at all times. We 
&lt;/p&gt;</description></item></channel></rss>