# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting](https://arxiv.org/abs/2408.01423) | 本文提出了一种递归提示搜索框架，该框架通过自适应地扩展提示集并调整提示调用，以优化提示使用效率和增强大型语言模型在处理复杂和非标准问题时的能力。 |
| [^2] | [Mission Impossible: A Statistical Perspective on Jailbreaking LLMs](https://arxiv.org/abs/2408.01420) | 本研究发现，大型语言模型训练数据中的不良行为可能导致模型在偏好对齐策略下仍可能表现出有害行为，并提出从统计学角度理解和避免这种“逃逸”现象的方法。 |
| [^3] | [Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs](https://arxiv.org/abs/2408.01417) | "我们的研究揭示了多模态语言模型在对话过程中缺乏自适应和形成即兴约定的能力，这些能力是沟通效率提高的关键。" |
| [^4] | [The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability](https://arxiv.org/abs/2408.01416) | 本文提出了一种基于因果中介分析的解释性研究视角，分类并讨论了各种调解者类型、搜索方法及其在神经网络学习和更好理解其潜在因果机制时的适用性。 |
| [^5] | [Conditional LoRA Parameter Generation](https://arxiv.org/abs/2408.01415) | 本文提出了一种通过条件潜在扩散模型在特定任务条件下生成高质量LoRA参数的新方法，该方法在计算机视觉和自然语言处理领域均显示出了高效率。 |
| [^6] | [PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval](https://arxiv.org/abs/2408.01349) | 本文提出PC²框架，融合了伪分类和伪描述的方法，用于解决跨模态检索中的噪声对应学习问题。通过对描述进行分类，并为每个错配对生成伪描述，来提供更具有信息和直观的监督，提高学习效率和模型性能。 |
| [^7] | [StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation](https://arxiv.org/abs/2408.01343) | 本文提出了一种新的多模态特征融合框架StitchFusion，它能够将任何视觉模态有效融合，提高多模态语义分割的准确性。 |
| [^8] | [Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation](https://arxiv.org/abs/2408.01342) | 本研究提出了一种基于知识图谱的对话推荐系统，通过动态图嵌入技术和专家系统模型的结合，有效改进了对话推荐系统的交互性和准确性。 |
| [^9] | [A Backbone for Long-Horizon Robot Task Understanding](https://arxiv.org/abs/2408.01334) | 该研究提出了一种基于Therblig的框架，通过将高级机器人任务分解为基本配置，并结合基础模型，提高了机器人任务的理解和泛化能力。 |
| [^10] | [A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes](https://arxiv.org/abs/2408.01322) | 该研究提出了一种基于机器学习模型的扫描路径算法，它在动态场景中通过不确定性和语义对象线索的结合，有效引导视线行为，并模拟了观察者的实际观看行为。 |
| [^11] | [A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks](https://arxiv.org/abs/2408.01319) | 本文全面综述了多模态大型语言模型在多种任务中的性能与挑战，并指出了未来研究的方向。en_tldr: This paper provides a comprehensive review of the performance and challenges of multimodal large language models across various tasks, suggesting future research directions. |
| [^12] | [A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment](https://arxiv.org/abs/2408.01301) | 本文介绍了旨在提高AI预测透明度、可靠性和可信度的一系列工具和方法，为AI如何自我评估其预测的可靠性提供了指导。 |
| [^13] | [The virtual CAT: A tool for algorithmic thinking assessment in Swiss compulsory education](https://arxiv.org/abs/2408.01263) | 本文介绍了一款评估瑞士义务教育中算法思维能力的虚拟CAT工具，它通过自动化的平台降低了人力成本并且提供了针对性的反馈。 |
| [^14] | [TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling](https://arxiv.org/abs/2408.01254) | TrIM 三角形输入运动同步阵列提出了一种新的架构，旨在通过特定数据流减少对大规模内存的访问次数，为卷积神经网络的复杂计算提供更高能效。 |
| [^15] | [Metareasoning in uncertain environments: a meta-BAMDP framework](https://arxiv.org/abs/2408.01253) | 本文提出了一种新的元推理框架，该框架在代理人不完全了解所面临的MDP的概率分布时，能够动态地优化推理过程的选择，提高了代理人在资源受限环境中的决策能力。 |
| [^16] | [Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system](https://arxiv.org/abs/2408.01248) | 研究提出了一种基于深度渐进强化学习的可变资源调度框架，用于优化IRS和UAV辅助的MEC系统中的能耗，通过使用多任务代理和渐进时间调度器解决了混合整数非线性规划问题。 |
| [^17] | [High-Throughput Phenotyping of Clinical Text Using Large Language Models](https://arxiv.org/abs/2408.01214) | 本研究证实了 GPT-4 在自动化临床文本表型分析方面超越了 GPT-3.5-Turbo，为精确医学提供了一种高效工具。 |
| [^18] | [Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems](https://arxiv.org/abs/2408.01188) | 本文采用了名为Deep W-Learning（DWN）的多目标强化学习技术，将其应用于新兴Web服务器示例，以在运行时找到最佳性能优化配置，并与两种单一目标优化实现（ε-贪婪算法和深度Q网络）进行了对比。 |
| [^19] | [Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning](https://arxiv.org/abs/2408.01187) | 本研究整合了多种元启发式优化算法（Particle Swarm Optimization, Ant Colony Optimization等）于量子强化学习中，展示了它们能够优化参数，并且在模拟退火和粒子群优化下获得了最佳效果。 |
| [^20] | [Misinforming LLMs: vulnerabilities, challenges and opportunities](https://arxiv.org/abs/2408.01168) | 该论文探讨了大型语言模型在自然语言处理中的潜力与挑战，尤其关注了它们存在的误导性问题和在确保信息准确性的研究机会。 |
| [^21] | [TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation](https://arxiv.org/abs/2408.01156) | TCR-GPT模型通过使用自回归模型和强化学习结合的方法，提高了生成T细胞受体序列的准确性，并在人源化TCRs的序列生成中取得了良好的效果。 |
| [^22] | [DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs](https://arxiv.org/abs/2408.01154) | 这种新的密集实体检索方法利用语言模型统一编码跨知识图实体的各种信息特征，提高了实体对齐的准确性，促进了跨KG等效实体的快速检索。 |
| [^23] | [Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition](https://arxiv.org/abs/2408.01139) | 该研究提出了一种无模型的全局解释性方法，用于理解和评估图像模型在全球扰动下的鲁棒性。通过分析受扰自然图像的谱信噪比随频率的指数下降趋势，揭示了低频信号在模型鲁棒性中的正面作用，并发现高频率信号的贡献与模型的鲁棒性度量负相关。这些发现有助于设计更加鲁棒的模型结构。 |
| [^24] | [A Survey of Mamba](https://arxiv.org/abs/2408.01129) | Mamba架构以经典状态空间模型的灵感为基础，提出了一种新型解决方案，可以在保持序列长度相关近线性可扩展性的同时，提供与Transformer相当的建模能力，有望在人工智能领域带来新的发展。 |
| [^25] | [BioRAG: A RAG-LLM Framework for Biological Question Reasoning](https://arxiv.org/abs/2408.01107) | BioRAG是一种采用RAG-LLM技术的问答系统，旨在解决生命科学研究领域中的知识仓库维护和信息检索难题。 |
| [^26] | [Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration](https://arxiv.org/abs/2408.01099) | 本文提出了一种高效参数调优方法CoLoRA，通过随机失真预训练（PROD）和贡献性低秩适应性，针对多个真实图像修复任务，大幅简化了模型的复杂性，并在精度与内存需求上超越了现有方法。 |
| [^27] | [Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions](https://arxiv.org/abs/2408.01091) | 中文总结要点 |
| [^28] | [The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes](https://arxiv.org/abs/2408.01075) | 本研究提议了一种适应性AI评价尺度，专门为英语学术用途设计，以适应人工智能的快速发展，并在评估中更有效地应用，确保评估的质量和一致性。 |
| [^29] | [A Survey on Self-play Methods in Reinforcement Learning](https://arxiv.org/abs/2408.01072) | 自对弈强化学习的方法在帮助智能体通过与自身复制或历史版本的对弈中学习，其在不同场景中有广泛的应用，并提出了相关的开放问题和研究方向。 |
| [^30] | [LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems](https://arxiv.org/abs/2408.01055) | 一种基于LLMs的新方法可以自适应地处理软件系统的运行时错误，提高系统的自我恢复能力。 |
| [^31] | [Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments](https://arxiv.org/abs/2408.01024) | 本文提出了一个SemGro框架，通过迭代分解技能，使预训练的语言模型能够针对不同领域规划指令遵循任务。 |
| [^32] | [GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs](https://arxiv.org/abs/2408.01018) | 该研究提出了一种结合KAN架构的GNNs，GNN-MolKAN和GNN-MolKAN+，以提高分子表示学习的性能，展现了其在预测不同分子特性任务中的优越性。 |
| [^33] | [IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model](https://arxiv.org/abs/2408.01016) | 本文介绍了一种新的IBB交通图数据集，以解决现有道路交通数据集在适用性和多样性方面的问题，并提出了一个预测模型，旨在提高智能交通系统的效率和安全性。 |
| [^34] | [Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs](https://arxiv.org/abs/2408.01008) | 本文提出了一种名为TT-LoRA的低秩张量束近似方法，旨在通过更快的LLMs微调加速人工智能民主化。 |
| [^35] | [FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation](https://arxiv.org/abs/2408.00998) | 本文提出了一种将预训练的文本到图像扩散模型高效地转换为图像到图像编辑工具的新型方法，使得用户可以根据文本描述灵活地控制图像内容。 |
| [^36] | [A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments](https://arxiv.org/abs/2408.00997) | 我们的研究提出了一个无模型策略，确保机器人能够在遵守安全限制的同时，学习和适应新任务，这个方法对于处理复杂环境中的未知条件和障碍特别有利，如可能包括的障碍物。 |
| [^37] | [IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing](https://arxiv.org/abs/2408.00996) | IncidentNet是一种通过训练稀疏放置在城市的传感器收集数据的深度学习模型，用于检测、定位和评估交通事件的严重性。 |
| [^38] | [ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models](https://arxiv.org/abs/2408.00994) | 本文介绍了ARCHCODE框架，该框架利用大型语言模型通过在上下文中学习的方式，组织并推断软件需求，从而提升代码生成质量。 |
| [^39] | [On the Resilience of Multi-Agent Systems with Malicious Agents](https://arxiv.org/abs/2408.00989) | 本文研究了面对恶意代理时multi-agent系统的弹性，并探讨了增加系统抵御能力的方法。 |
| [^40] | [Integrating ESG and AI: A Comprehensive Responsible AI Assessment Framework](https://arxiv.org/abs/2408.00965) | 本文介绍了一个新的ESG-AI框架，旨在帮助投资者评估和管理AI投资，同时推动公司的可持续性和盈利能力。 |
| [^41] | [PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting](https://arxiv.org/abs/2408.00960) | PERSOMA是一种用于个性化语言提示的软提示适配器架构，能高效处理和个性化用户交互历史。 |
| [^42] | [CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression](https://arxiv.org/abs/2408.00938) | 本研究提出了一种基于临床知识改进的扩散模型，用于更准确地预测特发性肺纤维化（IPF）的进展。 |
| [^43] | [Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research](https://arxiv.org/abs/2408.00930) | 我们介绍了一个名为WarpSci的框架，该框架能够显著提高在GPU上进行强化学习的性能，尤其适用于需要复杂环境模型数据的科学研究。 |
| [^44] | [WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes](https://arxiv.org/abs/2408.00925) | 本文揭示了一项新的数据泄露技术，即在利用生成语言模型协助时，通过注入恶意指令并使用GCG后缀提高数据泄露的成功率，尤其在企业环境中，这种攻击可能对业务造成约450万美元的损失。虽然存在风险，但通过管理和安全策略的改进，可以降低此类攻击的成功率。 |
| [^45] | [Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection](https://arxiv.org/abs/2408.00914) | 本研究通过在事件检测中使用GPT-4的少样本学习方法，实现了增强的准确性和置信度估计，通过为GPT-4提供的“许可证和机会”（L&O），实现了0.759 AUC的置信度指标。 |
| [^46] | [Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations](https://arxiv.org/abs/2408.00906) | 本文提出了一种基于静息状态EEG的新方法，使用多层感知机和梯度加权图注意力解释来检测帕金森病，旨在提高模型的可解释性和对复杂大脑连接的建模能力。 |
| [^47] | [Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability](https://arxiv.org/abs/2408.00872) | AnoT通过将时序知识图转换成规则图，提供了一种易理解和可解释的在线异常检测方法，它可以适应知识更新的模式变化和语义漂移。 |
| [^48] | [UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation](https://arxiv.org/abs/2408.00863) | UniMoT是一种统一的分子-文本语言模型，通过使用基于向量量化的tokenizer，它在自回归模型中将分子转换成序列的分子令牌，实现分子与文本的高效集成。 |
| [^49] | [UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization](https://arxiv.org/abs/2408.00860) | 该模型通过将超声反射方向参数化和谐波编码与神经渲染结合，生成接近真实物理的3D超声图像，提高了图像质量和处理复杂反射的能力。 |
| [^50] | [Y Social: an LLM-powered Social Media Digital Twin](https://arxiv.org/abs/2408.00818) | Y 社交是一个使用最新自然语言处理技术的社交媒体数字双胞胎，它能够模拟复杂的用户行为和在线平台的动态，为研究人员提供了宝贵的分析工具。 |
| [^51] | [Adaptive traffic signal safety and efficiency improvement by multi objective deep reinforcement learning approach](https://arxiv.org/abs/2408.00814) | 这项研究提出了一种新型的多目标深度强化学习方法，可以提高交通信号控制的安全性和效率，并减少碳排放，特别是在动态交通条件下性能更佳，显示了其广阔的实用前景。 |
| [^52] | [ChipExpert: The Open-Source Integrated-Circuit-Design-Specific Large Language Model](https://arxiv.org/abs/2408.00804) | ChipExpert是专门为集成电路设计领域设计的开放源代码大型语言模型，旨在解决该领域的专业知识和高门槛问题。 |
| [^53] | [A Comprehensive Survey on Root Cause Analysis in (Micro) Services: Methodologies, Challenges, and Trends](https://arxiv.org/abs/2408.00803) | 本论文调查了在微服务中识别和解决复杂依赖和传播性故障挑战的根本原因分析(RCA)技术，强调了快速恢复和维护系统稳定性的重要性。 |
| [^54] | [Leveraging LLM Reasoning Enhances Personalized Recommender Systems](https://arxiv.org/abs/2408.00802) | 本研究利用LLM推理增强个性化推荐系统，证明了在零射程和微调设置中使用LLM推理能够提高任务质量。我们还提出了RecSAVER方法，这是一种自动评价LLM推理响应质量的工具。 |
| [^55] | [Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards](https://arxiv.org/abs/2408.00800) | 本研究提出了一个使用大型语言模型和领域特定标准的大语言模型对话式本体交互概念，能够将用户提问准确转化为SPARQL查询，有效防止了虚假信息的产生。 |
| [^56] | [Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base](https://arxiv.org/abs/2408.00798) | 一种名为Golden-Retriever的系统被设计用来增强工业知识库的检索效率，通过推敲式的查询增强和明确的上下文解释，提升了RAG框架的检索准确性。 |
| [^57] | [CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution](https://arxiv.org/abs/2408.00794) | 通过协作共进化，本研究提出了一种稳健的SNN剪枝方法，旨在在不牺牲准确性与鲁棒性的前提下，减少计算资源需求。 |
| [^58] | [Improving Air Mobility for Pre-Disaster Planning with Neural Network Accelerated Genetic Algorithm](https://arxiv.org/abs/2408.00790) | 本研究提出了一种新的遗传算法框架，通过神经网络加速机场运营计划的优化，以应对天气灾害的紧急疏散需求，即使是在数据有限的情况下也能有效提高疏散效率。 |
| [^59] | [Whether to trust: the ML leap of faith](https://arxiv.org/abs/2408.00786) | 本文提出了一种创新方法，通过辨识和测量用户信任机器学习时的信仰飞跃，直接在机器学习中构建内在信任。 |
| [^60] | [In-Depth Analysis of Emotion Recognition through Knowledge-Based Large Language Models](https://arxiv.org/abs/2408.00780) | 本研究提出了一种结合情绪识别方法和贝叶斯线索整合的方法，利用大型语言模型获得的情境知识来提高在社交情境中分析面部表情的准确性，并在囚徒困境这一社会任务中得到了验证。 |
| [^61] | [Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions](https://arxiv.org/abs/2408.00778) | 本文提出Frontend Diffusion工具，旨在通过用户的草图和端到端语言模型实现从抽象意图到详细网页的生成过程。 |
| [^62] | [Decoding AI and Human Authorship: Nuances Revealed Through NLP and Statistical Analysis](https://arxiv.org/abs/2408.00769) | 该研究揭示了人工智能与人“更高的总字数、复杂性和多样性”撰写者在语言表达上的微妙差异，并突出展示了AI在特定语言模式和句子结构上的独特一致性。 |
| [^63] | [Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves](https://arxiv.org/abs/2408.00768) | 本文提出了一种结合光流、深度学习和空间填满曲线的框架，实现了对车辆前向摄像头捕获的视频数据中交通事件的实时、高效检测。该框架有助于为驾驶员或自动驾驶车辆提供实时反馈，识别前方道路潜在的威胁或突发事件，提高驾驶情况感知，并可能提高安全性。 |
| [^64] | [SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models](https://arxiv.org/abs/2408.00655) | SentenceVAE是一种创新的模型，它通过将大型语言模型的推理过程改为由句子逐个处理的策略，大幅提高了这些模型的推理速度和准确性。 |
| [^65] | [Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving](https://arxiv.org/abs/2408.00374) | V2INet 提出了一个创新的端到端训练框架，用于结合多角度信息进行轨迹预测，以克服单一视角的局限性，提高校正后的多模态轨迹预测的性能。 |
| [^66] | [Gemma 2: Improving Open Language Models at a Practical Size](https://arxiv.org/abs/2408.00118) | Gemma 2是Gemma系列中新型轻量级开放模型，通过改进Transformer架构和应用蒸馏知识培训，在20亿和90亿参数规模上表现最佳。 |
| [^67] | [Characterizing User Archetypes and Discussions on Scored.co](https://arxiv.org/abs/2407.21753) | 本研究开发了一个多维框架来分析极右翼社交平台“评分网”上的用户类型和互动，揭示了平台用户特征、活跃度、讨论内容和社区成员的行为 |
| [^68] | [Social and Ethical Risks Posed by General-Purpose LLMs for Settling Newcomers in Canada](https://arxiv.org/abs/2407.20240) | 本文讨论了加拿大非营利性融入领域面临的新来者面临的生成AI潜在风险，并建议加强相关研究与开发以促进AI教育和定制化LLM技术与服务提供者相应地对接。 |
| [^69] | [Improving Retrieval Augmented Language Model with Self-Reasoning](https://arxiv.org/abs/2407.19813) | 本文提出了一种自我推理框架，旨在改进检索增强的语言模型的可靠性和可追溯性，通过在生成过程中整合外部知识，减少无帮助或误导性响应的产生，并改善模型的透明度和可信度。 |
| [^70] | ["A Good Bot Always Knows Its Limitations": Assessing Autonomous System Decision-making Competencies through Factorized Machine Self-confidence](https://arxiv.org/abs/2407.19631) | 通过创建自评估系统能力的新框架，科学家们寻求提高自主系统的决策透明度和可靠性。 |
| [^71] | [LLMs' Understanding of Natural Language Revealed](https://arxiv.org/abs/2407.19630) | 本文揭示了LLMs语言理解能力的夸大。虽然LLMs能够生成连贯的语言，但其对语言的理解能力并未得到充分测试。Abstract中的操作表明，评估LLMs的语言理解能力需要辨识语言的语法结构并执行逻辑推理。 |
| [^72] | [Co-designing an AI Impact Assessment Report Template with AI Practitioners and AI Compliance Experts](https://arxiv.org/abs/2407.17374) | 本研究提出了一个基于欧盟AI法案和NIST框架的AI影响评估报告模板，并通过用户研究验证了其有效性。 |
| [^73] | [CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging](https://arxiv.org/abs/2407.11652) | 本文提出了一种名为“跨客户端变异性自适应联邦学习”（CCVA-FL）的方法，通过生成合成医学图像解决医疗图像数据中的跨客户端变异问题，从而提高联邦学习的性能。 |
| [^74] | [A Survey on LoRA of Large Language Models](https://arxiv.org/abs/2407.11046) | 这篇综述详细介绍了LoRA技术，它通过更新低秩矩阵来提高大规模语言模型的性能，并探讨了其在提升计算效率和保护数据隐私方面的应用。 |
| [^75] | [D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions](https://arxiv.org/abs/2407.02604) | D-Rax 是一个新的域特定放射学助手，能够通过结合多模态数据和专家模型预测，更精确地帮助放射科医生处理胸部X光片。 |
| [^76] | [Diffusion Models for Offline Multi-agent Reinforcement Learning with Safety Constraints](https://arxiv.org/abs/2407.00741) | 本文提出了一种在离线多智能体强化学习中整合扩散模型的创新方法，该方法通过风险管理和协同动作建模提高了多个代理行动的安全性。框架基于集成就地、分布式执行的架构，并利用扩散模型进行预测轨迹生成。我们的方法在DSRL基准测试中实现了与命令和控制相比的性能提升，并能更有效地应对复杂的动态环境。 |
| [^77] | [Chat AI: A Seamless Slurm-Native Solution for HPC-Based Services](https://arxiv.org/abs/2407.00110) | 该论文提出了一种架构，能够在HPC集群上运行实时AI应用的托管和云VM服务，同时保证用户数据的隐私和安全，避免了存储用户数据而不经用户同意的情况。 |
| [^78] | [Enhancing Solar Driver Forecasting with Multivariate Transformers](https://arxiv.org/abs/2406.15847) | 本文提出了一种使用自定义损失函数对高、低太阳能活动水平进行平衡的时间序列Transformer模型，实现了SET数据集上太阳能驱动器的准确预报，尤其是在高峰期间。 |
| [^79] | [Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation](https://arxiv.org/abs/2406.07867) | 我们介绍了一个新型的面向面对面对话的口语对话模型，该模型能够处理音频-视觉言语输入并产生相应的回应。这是创建不依赖中间文本虚拟助手的第一步。我们新引入了MultiDialog，这是首个大规模的多模态口语对话语料库，含约340小时的9,000多个对话的平行音频-视觉记录，这些记录是基于开放域对话数据集TopicalChat录制的。 |
| [^80] | [Improving Geo-diversity of Generated Images with Contextualized Vendi Score Guidance](https://arxiv.org/abs/2406.04551) | 该研究提出了一种称为上下文化Vendi分数指引的方法，旨在提高生成图像的地理多样性，使特定地区的图像表现与现实世界相符。 |
| [^81] | [RepCNN: Micro-sized, Mighty Models for Wakeword Detection](https://arxiv.org/abs/2406.02652) | 本文提出了RepCNN模型，这是一种轻量级的卷积模型，通过重新架构和重新参数化技术，在保持低内存和计算开销的同时，显著提高了唤醒词检测的准确性。 |
| [^82] | [Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory](https://arxiv.org/abs/2405.19024) | 这篇论文提出了一个新的统一框架，能够解决逆凹效用强化学习问题，即使在凹效用设置中也能够确保可行奖励函数的识别。 |
| [^83] | [Eliciting Informative Text Evaluations with Large Language Models](https://arxiv.org/abs/2405.15077) | 本文提出了一种使用大型语言模型提高信息丰富文本评估机制的效力的方法，旨在扩大同行预测机制的应用范围。 |
| [^84] | [Bond Graphs for multi-physics informed Neural Networks for multi-variate time series](https://arxiv.org/abs/2405.13586) | 这项研究提出了一种结合绑定图和消息传递图神经网络的神经网络体系结构，旨在为多物理和复杂多域现象任务提供多信息输出的深度学习模型。 |
| [^85] | [A Novel Method for News Article Event-Based Embedding](https://arxiv.org/abs/2405.13071) | 本文提出了一种新方法，优化了新闻文章的嵌入生成，该方法专注于文章中提到的实体和主题，并对它们与特定事件的历史联系进行优化，提高了主题识别的准确性，并有助于减少媒体偏见。 |
| [^86] | [The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems](https://arxiv.org/abs/2405.11053) | 本文介绍了一种收集用户对未经历电影的信念的方法，并实现了一个结合用户评分、信念和推荐的丰富数据集。 |
| [^87] | [FloorSet -- a VLSI Floorplanning Dataset with Design Constraints of Real-World SoCs](https://arxiv.org/abs/2405.05480) | FloorSet是一个包含带有真实世界SoC设计约束的VLSI布局规划数据的合成数据集，旨在为机器学习方法提供一个更接近真实世界情况的挑战。 |
| [^88] | [Don't Waste Your Time: Early Stopping Cross-Validation](https://arxiv.org/abs/2405.03389) | 通过早期停止交叉验证的过程，研究人员减少了模型选择中不必要的计算成本，同时保持或提高了性能，这对于在有限的时间预算内有效进行模型选择至关重要。 |
| [^89] | [A Comprehensive Evaluation on Event Reasoning of Large Language Models](https://arxiv.org/abs/2404.17513) | 本文评估了大型语言模型在不同关系和推理范式上的事件推理能力，发现虽然模型有完成事件推理的能力，但总体表现并不令人满意，同时也发现模型在事件推理能力上的不均衡性。 |
| [^90] | [Breaching the Bottleneck: Evolutionary Transition from Reward-Driven Learning to Reward-Agnostic Domain-Adapted Learning in Neuromodulated Neural Nets](https://arxiv.org/abs/2404.12631) | 论文讨论了如何在生物智能中突破信息瓶颈，让机器学习能像生物智能一样高效地从多样非奖励刺激信息中学习。 |
| [^91] | [Deep Reinforcement Learning for Traveling Purchaser Problems](https://arxiv.org/abs/2404.02476) | 我们提出了一种新方法，利用深度强化学习将旅行采购问题中的路线构建和采购计划分开处理，并从全局视角优化解决方案。我们的方法是高效的，能够为旅游采购问题提供有效解决方案。 |
| [^92] | [DASA: Delay-Adaptive Multi-Agent Stochastic Approximation](https://arxiv.org/abs/2403.17247) | DASA算法是针对多代理随机逼近问题设计的，能够在处理延迟和异步通信的延迟环境中实现快速收敛。 |
| [^93] | [Automated System-level Testing of Unmanned Aerial Systems](https://arxiv.org/abs/2403.15857) | 该论文提出了一种基于模型的测试和人工智能技术的自动化系统级测试方法，为无人航空系统的有效测试提供了可行的解决方案，提高了测试效率和准确性。 |
| [^94] | [An Optimization Framework to Enforce Multi-View Consistency for Texturing 3D Meshes](https://arxiv.org/abs/2403.15559) | 本文提出了一种四阶段的优化框架，用于通过非刚性对齐和MRF问题解决，确保多视角纹理化处理，以达到高效的3D网格多视角纹理化处理 |
| [^95] | [A multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers](https://arxiv.org/abs/2403.13940) | 在一组反事实解释中，由多种集成解释方法生成，本文提出了一种多标准方法，通过考虑多个质量标准，减少冲突，并为用户提供易于理解的指导，从而选择最合适的一个。 |
| [^96] | [A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing](https://arxiv.org/abs/2403.02504) | 论文介绍了自然语言处理领域中预训练-微调范式的重要性和优势，该范式通过使用大型预训练语言模型，可以在特定任务上进行微调和微调，以相对较小的标注数据集获得接近从零开始的性能，并且提供丰富的上下文表示和语言理解能力。 |
| [^97] | [Routoo: Learning to Route to Large Language Models Effectively](https://arxiv.org/abs/2401.13979) | 论文创新：开发了一种名为“Routoo”的建筑，旨在根据性能、成本和效率来优化大型语言模型的选择，以提高特定提示的响应质量。 |
| [^98] | [Differentiable Tree Search Network](https://arxiv.org/abs/2401.11660) | D-TSN利用可微树搜索优化策略性能，适用于在复杂任务中进行高效和准确的行动决策。 |
| [^99] | [MERA: A Comprehensive LLM Evaluation in Russian](https://arxiv.org/abs/2401.04531) | MERA是一个用于评估面向俄语语言的基础模型的新指令基准，它包括21个评估任务，旨在更好地理解这些模型的能力、局限性和风险。 |
| [^100] | [Efficient Test Data Generation for MC/DC with OCL and Search](https://arxiv.org/abs/2401.03469) | 本文提出了一种基于模型的有效方法，利用启发式方法和案例推理来提高基于OCL的MC/DC测试数据生成效率。 |
| [^101] | [Nonparametric Strategy Test](https://arxiv.org/abs/2312.10695) | 我们提出了一种非参数统计检验，用于评估代理人是否遵循给定的混合策略。通过卡方拟合优度检验和广义沃尔德-沃尔夫瓦兹位移检验相结合的方式，以确保代理人的行为模式符合预期。 |
| [^102] | [Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy](https://arxiv.org/abs/2312.09436) | 本文提出了一种时间转移学习方法，用来提高咨询自治下的交通效率。这种方法通过在特定的车流量和速度条件下训练策略，然后将其应用于实际交通场景，即使在缺乏完全自动驾驶车辆的情况下，也能有效提高交通流量的通过率并减少事故发生率。 |
| [^103] | [Data Management For Training Large Language Models: A Survey](https://arxiv.org/abs/2312.01700) | 本论文提供了大型语言模型数据管理策略的全面概述，重点关注了如何通过优化训练数据来提升模型的训练效率和性能。 |
| [^104] | [SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios](https://arxiv.org/abs/2309.04421) | 我们提出了一个使用虚拟3D模型的全新框架，该框架使用Unreal Engine生成现实的手势动作，通过节省时间和努力，为驾驶情景中的动态手势生成提供了更高效的方法。 |
| [^105] | [Rule-Based Error Detection and Correction to Operationalize Movement Trajectory Classification](https://arxiv.org/abs/2308.14250) | 本文提出了一套规则基础的错误检测和修正方法，大幅度提高了运动轨迹分类模型的性能，特别是在应对数据分布变化时。 |
| [^106] | [Arithmetic with Language Models: from Memorization to Computation](https://arxiv.org/abs/2308.01154) | 本文研究了大型语言模型的算术计算能力，发现它们能够通过一种“编码-回归-解码”机制进行泛化计算。 |
| [^107] | [SARN: Structurally-Aware Recurrent Network for Spatio-Temporal Disaggregation](https://arxiv.org/abs/2306.07292) | 本文提出了一种称为SARN的模型，该模型整合了结构感知空间注意层和GRU模型，能够准确地从低分辨率空间聚合数据重建到高分辨率的不规则分区。 |
| [^108] | [Answering Questions by Meta-Reasoning over Multiple Chains of Thought](https://arxiv.org/abs/2304.13007) | 我们介绍了一种名为“Multi-Chain Reasoning”（MCR）的新方法，它通过元推理多个思想链来改进多跳问答系统的性能，同时提升最终答案的统一解释性。 |
| [^109] | [Modelling Assessment Rubrics through Bayesian Networks: a Pragmatic Approach](https://arxiv.org/abs/2209.05467) | 本文提出了一种直接从评估 rubric中获取学习者模型的方法，该方法基于贝叶斯网络，通过逻辑门简化参数获取，以自动化智能教学系统中的技能测试。 |

# 详细

[^1]: 递归提示搜索：在LLM自动提示中具有自适应增长的生命框架

    Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting

    [https://arxiv.org/abs/2408.01423](https://arxiv.org/abs/2408.01423)

    本文提出了一种递归提示搜索框架，该框架通过自适应地扩展提示集并调整提示调用，以优化提示使用效率和增强大型语言模型在处理复杂和非标准问题时的能力。

    

    arXiv:2408.01423v1 公告类型：交叉 摘要：大型语言模型（LLMs）在自然语言处理（NLP）领域执行了一系列不同任务，其中各种提示设计策略显著提升了它们的性能。然而，这些提示本身存在固有局限性。主要的提示设计方法有两种：第一种，例如链式思想（CoT），涉及针对特定数据集手动设计提示，因此称为专家设计提示（EDPs）。一旦这些提示确立，它们就是不可改变的，并且它们的效果上限由人类设计者的专业知识决定。当将这些静态EDPs应用于LLMs时，对于同一数据集中的简单和复杂问题，都会采取统一的方法，导致文本模式对简单问题的使用效率低下。第二种方法涉及由LLM自主生成的提示，此类提示被称为自助式生成提示（AGPs）。传统的AGPs通过自适应性维持LLMs在各种情况下的性能，但其灵活性仍然受到局限，特别是对于离标准模式偏差的聚类问题。此外，AGPs不区分问题的复杂性和简单性，导致在相对简单的问题上使用的提示长度比实际需求要长，而在复杂的任务上发挥作用较弱。为此，本文提出了递归提示搜索（RRS）框架，该框架通过调整提示调用来适应问题复杂性，自适应地扩展提示集。递归搜索一方面通过深度学习模型识别不同类型的任务复杂性，另一方面通过调整提示参数，提供对LLM局部能力增强的动态提示机制。这种机制的作用是优化提示使用效率，并增加LLM在非标准问题上的响应能力。通过实验验证，在多个具有不同复杂性的基准数据集上，我们展示了RRS框架的优越性能，证明其在简化复杂的问题处理和强化对非标准问题的处理能力方面超过了现有的专家设计提示和自助式生成提示策略。

    arXiv:2408.01423v1 Announce Type: cross  Abstract: Large Language Models (LLMs) exhibit remarkable proficiency in addressing a diverse array of tasks within the Natural Language Processing (NLP) domain, with various prompt design strategies significantly augmenting their capabilities. However, these prompts, while beneficial, each possess inherent limitations. The primary prompt design methodologies are twofold: The first, exemplified by the Chain of Thought (CoT), involves manually crafting prompts specific to individual datasets, hence termed Expert-Designed Prompts (EDPs). Once these prompts are established, they are unalterable, and their effectiveness is capped by the expertise of the human designers. When applied to LLMs, the static nature of EDPs results in a uniform approach to both simple and complex problems within the same dataset, leading to the inefficient use of tokens for straightforward issues. The second method involves prompts autonomously generated by the LLM, known 
    
[^2]: 《不可能的任务：从统计视角看大型语言模型逃逸》

    Mission Impossible: A Statistical Perspective on Jailbreaking LLMs

    [https://arxiv.org/abs/2408.01420](https://arxiv.org/abs/2408.01420)

    本研究发现，大型语言模型训练数据中的不良行为可能导致模型在偏好对齐策略下仍可能表现出有害行为，并提出从统计学角度理解和避免这种“逃逸”现象的方法。

    

    arXiv:2408.01420v1 公告类型：十字交叉 摘要：大型语言模型（LLMs）在有限的质控条件下接受了海量文本数据的训练。因此，LLMs可能会出现意料之外的或甚至是有害的行为，例如泄露信息、散播虚假新闻或传播仇恨言论。抵御措施，通常被称为偏好对齐，包括使用精心编写的文本实例，对预训练的LLMs进行微调，这些实例体现了期望的行为。即使这样，经验证据表明，偏好对齐的LLMs可能会被引诱从事有害的行为。这种大型语言模型的逃逸现象通常是通过修改输入的提示文本来实现的，这种提示文本具有对LLM的恶意的修改。我们的论文从统计学视角为偏好对齐和逃逸现象提供了理论洞察。在我们构建的理论框架下，首先证明了如果训练数据集中存在有害行为，预训练的LLMs将模仿这些行为。基于同一个理论框架，我们还提出了对齐行为的统计概念，并对逃逸行为进行了下界估计。在面对对齐策略的潜在弱点时，我们的研究表明，通过适当的统计方法已经可以很好地理解并且尝试避免大型语言模型的这些潜在威胁。

    arXiv:2408.01420v1 Announce Type: cross  Abstract: Large language models (LLMs) are trained on a deluge of text data with limited quality control. As a result, LLMs can exhibit unintended or even harmful behaviours, such as leaking information, fake news or hate speech. Countermeasures, commonly referred to as preference alignment, include fine-tuning the pretrained LLMs with carefully crafted text examples of desired behaviour. Even then, empirical evidence shows preference aligned LLMs can be enticed to harmful behaviour. This so called jailbreaking of LLMs is typically achieved by adversarially modifying the input prompt to the LLM. Our paper provides theoretical insights into the phenomenon of preference alignment and jailbreaking from a statistical perspective. Under our framework, we first show that pretrained LLMs will mimic harmful behaviour if present in the training corpus. Under that same framework, we then introduce a statistical notion of alignment, and lower-bound the jai
    
[^3]: "少说话，多互动：在多模态LLM中评估上下文对话适应性"

    Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs

    [https://arxiv.org/abs/2408.01417](https://arxiv.org/abs/2408.01417)

    "我们的研究揭示了多模态语言模型在对话过程中缺乏自适应和形成即兴约定的能力，这些能力是沟通效率提高的关键。"

    

    "在本文中，我们研究了人类如何在互动过程中自发地使用越来越高效的言语，通过调整和形成即兴约定。这种现象已经在参考游戏中得到了广泛的研究，显示出人类语言的一些特性，这些特性超出了传达意图的范围。至今尚未探讨的是，多模态大型语言模型(MLLM)是否会像人类一样在互动中提高沟通效率，以及它们可能采用哪些机制来实现这一目标。我们介绍了一个自动框架ICCA，用于评估MLLM在互动中的对话适应性作为一种内在行为。我们评估了几种最先进的多模态语言模型，并观察到尽管它们可能理解他们的对话者的言语变得越来越高效，但它们并不能像人类那样在互动过程中自发地使自己的语言变得更加高效。后者能力只能在某些模型(例如GPT-4)中通过被动的提示方式激发出来。这表明了这种自然语言交互的特性还没有完全被当前的模型所掌握。"

    arXiv:2408.01417v1 Announce Type: cross  Abstract: Humans spontaneously use increasingly efficient language as interactions progress, by adapting and forming ad-hoc conventions. This phenomenon has been studied extensively using reference games, showing properties of human language that go beyond relaying intents. It remains unexplored whether multimodal large language models (MLLMs) similarly increase communication efficiency during interactions, and what mechanisms they may adopt for this purpose. We introduce ICCA, an automated framework to evaluate such conversational adaptation as an in-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and observe that while they may understand the increasingly efficient language of their interlocutor, they do not spontaneously make their own language more efficient over time. This latter ability can only be elicited in some models (e.g., GPT-4) with heavy-handed prompting. This shows that this property of linguistic interacti
    
[^4]: 寻找合适的调解者：因果解释性研究的历史、综述和理论基础

    The Quest for the Right Mediator: A History, Survey, and Theoretical Grounding of Causal Interpretability

    [https://arxiv.org/abs/2408.01416](https://arxiv.org/abs/2408.01416)

    本文提出了一种基于因果中介分析的解释性研究视角，分类并讨论了各种调解者类型、搜索方法及其在神经网络学习和更好理解其潜在因果机制时的适用性。

    

    arXiv:2408.01416v1 公告类型：交叉 摘要：解释性为理解神经网络如何以及为什么在特定方式下行为提供了一套工具。然而，该领域缺乏统一性：大多数研究采用专用的评估方法，并且不共享理论基础，这使得难以衡量进展并与不同技术的优势和劣势进行比较。此外，虽然机制理解经常被讨论，但这些机制的基础因果单位通常没有被明确定义。在本文中，我们提出了一种基于因果中介分析的解释性研究观点。具体来说，我们描述了解释性研究的历史和当前状态，这些研究根据使用的因果单位（调解者）的类型以及用于搜索调解者的方法进行了分类。我们讨论了每种调解者的优缺点，提供了见解，说明在根据不同的情况下，特别是在了解和改进神经网络时，何时最适应用特定类型的调解者和搜索方法取决于多种因素，包括神经网络的结构、工作方式及其潜在的因果机制。

    arXiv:2408.01416v1 Announce Type: cross  Abstract: Interpretability provides a toolset for understanding how and why neural networks behave in certain ways. However, there is little unity in the field: most studies employ ad-hoc evaluations and do not share theoretical foundations, making it difficult to measure progress and compare the pros and cons of different techniques. Furthermore, while mechanistic understanding is frequently discussed, the basic causal units underlying these mechanisms are often not explicitly defined. In this paper, we propose a perspective on interpretability research grounded in causal mediation analysis. Specifically, we describe the history and current state of interpretability taxonomized according to the types of causal units (mediators) employed, as well as methods used to search over mediators. We discuss the pros and cons of each mediator, providing insights as to when particular kinds of mediators and search methods are most appropriate depending on 
    
[^5]: 条件LoRA参数生成技术

    Conditional LoRA Parameter Generation

    [https://arxiv.org/abs/2408.01415](https://arxiv.org/abs/2408.01415)

    本文提出了一种通过条件潜在扩散模型在特定任务条件下生成高质量LoRA参数的新方法，该方法在计算机视觉和自然语言处理领域均显示出了高效率。

    

    本文提出了一种名为COND P-DIFF的新方法，该方法显示了对特定任务条件下的高性能LoRA（低秩适应）参数进行控制可生成。我们采用一个自动编码器提取参数的效率潜在表示，并训练了一个条件潜在扩散模型，它基于特定的任务条件从随机噪声中合成具有高表现力的模型参数。无论是计算机视觉还是自然语言处理领域，实验结果均一致表明COND P-DIFF可以在计算机视觉和自然语言处理领域实现高效率参数生成。

    arXiv:2408.01415v1 Announce Type: new  Abstract: Generative models have achieved remarkable success in image, video, and text domains. Inspired by this, researchers have explored utilizing generative models to generate neural network parameters. However, these efforts have been limited by the parameter size and the practicality of generating high-performance parameters. In this paper, we propose COND P-DIFF, a novel approach that demonstrates the feasibility of controllable high-performance parameter generation, particularly for LoRA (Low-Rank Adaptation) weights, during the fine-tuning process. Specifically, we employ an autoencoder to extract efficient latent representations for parameters. We then train a conditional latent diffusion model to synthesize high-performing model parameters from random noise based on specific task conditions. Experimental results in both computer vision and natural language processing domains consistently demonstrate that COND P-DIFF can generate high-pe
    
[^6]: PC²：基于伪分类的伪描述生成方法在跨模态检索中的噪声对应学习

    PC$^2$: Pseudo-Classification Based Pseudo-Captioning for Noisy Correspondence Learning in Cross-Modal Retrieval

    [https://arxiv.org/abs/2408.01349](https://arxiv.org/abs/2408.01349)

    本文提出PC²框架，融合了伪分类和伪描述的方法，用于解决跨模态检索中的噪声对应学习问题。通过对描述进行分类，并为每个错配对生成伪描述，来提供更具有信息和直观的监督，提高学习效率和模型性能。

    

    在这篇论文中，我们探讨了跨模态检索中不同模态数据的无缝集成问题，尤其是对于噪声对应学习(NCL)所带来的复杂性。这种噪声通常源于数据对的错配，这是与传统有噪声标签问题相比的一个显著障碍。我们提出了一个基于伪分类的伪描述生成方法(PC²)框架来应对这一挑战。PC²提供了一个三重策略：首先，我们建立了一个辅助的“伪分类”任务，将描述解释为分类标签，通过非对比机制引导模型学习图像-文本语义相似性。其次，与现有的基于边际的技术不同，我们利用PC²的伪分类能力，生成伪描述，为每个错配对提供更具有信息和直观的监督。最后，我们通过伪描述的振荡来进一步增加损失函数的复杂性，以提升学习效率和模型性能。通过在多个具有挑战性的零样本和少样本检索任务上进行广泛的实验验证，我们的方法优于最先进的同类方法。

    arXiv:2408.01349v1 Announce Type: cross  Abstract: In the realm of cross-modal retrieval, seamlessly integrating diverse modalities within multimedia remains a formidable challenge, especially given the complexities introduced by noisy correspondence learning (NCL). Such noise often stems from mismatched data pairs, which is a significant obstacle distinct from traditional noisy labels. This paper introduces Pseudo-Classification based Pseudo-Captioning (PC$^2$) framework to address this challenge. PC$^2$ offers a threefold strategy: firstly, it establishes an auxiliary "pseudo-classification" task that interprets captions as categorical labels, steering the model to learn image-text semantic similarity through a non-contrastive mechanism. Secondly, unlike prevailing margin-based techniques, capitalizing on PC$^2$'s pseudo-classification capability, we generate pseudo-captions to provide more informative and tangible supervision for each mismatched pair. Thirdly, the oscillation of pse
    
[^7]: StitchFusion: 一种融合任何视觉模态以提高多模态语义分割准确性的方法

    StitchFusion: Weaving Any Visual Modalities to Enhance Multimodal Semantic Segmentation

    [https://arxiv.org/abs/2408.01343](https://arxiv.org/abs/2408.01343)

    本文提出了一种新的多模态特征融合框架StitchFusion，它能够将任何视觉模态有效融合，提高多模态语义分割的准确性。

    

    arXiv:2408.01343v1 公告类型：新  摘要：多模态语义分割在复杂场景中显著提高了分割的准确性。然而，现有的方法往往包含专门的特征融合模块，这些模块特地为特定的模态设计，因此限制了输入的灵活性和增加了训练参数的数量。为了解决这些挑战，我们提出了一种简洁且有效的大模融合框架StitchFusion，该框架直接将大规模预训练模型作为编码器和特征融合器。这种方法在编码过程中实现模融合，通过共享多模态视觉信息，从而促进了信息流在编码过程中的双向传输。通过引入多模态特征融合模块，我们的框架能够更好地处理多模态和多尺度特征融合问题，并能够适应任何视觉模态的输入。特别是，我们的框架通过共享多模态视觉信息在编码过程中实现模融合。为了增强模态间的信息交流，我们引入了一个多方向适配器模块（MultiAdapter），以在编码过程中实现跨模态信息传输。通过利用MultiAdapter，我们的方法实现了多模态特征的有效融合，并在多个公共数据集上取得了优于现有方法的性能。

    arXiv:2408.01343v1 Announce Type: new  Abstract: Multimodal semantic segmentation shows significant potential for enhancing segmentation accuracy in complex scenes. However, current methods often incorporate specialized feature fusion modules tailored to specific modalities, thereby restricting input flexibility and increasing the number of training parameters. To address these challenges, we propose StitchFusion, a straightforward yet effective modal fusion framework that integrates large-scale pre-trained models directly as encoders and feature fusers. This approach facilitates comprehensive multi-modal and multi-scale feature fusion, accommodating any visual modal inputs. Specifically, Our framework achieves modal integration during encoding by sharing multi-modal visual information. To enhance information exchange across modalities, we introduce a multi-directional adapter module (MultiAdapter) to enable cross-modal information transfer during encoding. By leveraging MultiAdapter t
    
[^8]: 利用知识图谱嵌入技术提高对话推荐系统效率

    Leveraging Knowledge Graph Embedding for Effective Conversational Recommendation

    [https://arxiv.org/abs/2408.01342](https://arxiv.org/abs/2408.01342)

    本研究提出了一种基于知识图谱的对话推荐系统，通过动态图嵌入技术和专家系统模型的结合，有效改进了对话推荐系统的交互性和准确性。

    

    arXiv:2408.01342v1 公告类型：交叉 摘要：最近，对话推荐系统（CRS）引起了越来越多的兴趣，它结合了对话系统和推荐系统的技术。与传统的推荐系统相比，CRS通过互动（即对话）更好地学习用户的偏好，从而进一步提高推荐效果。然而，现有的CRS研究忽视了有效处理属性、用户和项目之间的关系，这可能导致提出不当的问题和推荐不当的建议。因此，我们提出了一个基于知识图谱的对话推荐系统（称为KG-CRS）。具体来说，我们首先将用户-项目图和项目-属性图整合到一个动态图中，即在对话过程中动态变化，通过移除负面项目或属性。然后，我们通过考虑邻接节点之间的传播，学习了用户、项目和属性的信息嵌入。此外，我们还提出了一个专家系统模型来理解和生成候选问题。该模型通过学习用户语言的表示来解释用户选择，提高了对话推荐系统的交互性和准确性。我们实验验证了提出的动态图嵌入方法在对话推荐上的有效性，并与当前最先进的对话推荐方法进行了对比。结果表明，KG-CRS在提高推荐准确性和降低冷启动成本方面表现出了优越性。我们的方法对于对话推荐领域的研究和实际应用都具有重要的意义。

    arXiv:2408.01342v1 Announce Type: cross  Abstract: Conversational recommender system (CRS), which combines the techniques of dialogue system and recommender system, has obtained increasing interest recently. In contrast to traditional recommender system, it learns the user preference better through interactions (i.e. conversations), and then further boosts the recommendation performance. However, existing studies on CRS ignore to address the relationship among attributes, users, and items effectively, which might lead to inappropriate questions and inaccurate recommendations. In this view, we propose a knowledge graph based conversational recommender system (referred as KG-CRS). Specifically, we first integrate the user-item graph and item-attribute graph into a dynamic graph, i.e., dynamically changing during the dialogue process by removing negative items or attributes. We then learn informative embedding of users, items, and attributes by also considering propagation through neighbo
    
[^9]: 机器人长期任务理解的骨干框架

    A Backbone for Long-Horizon Robot Task Understanding

    [https://arxiv.org/abs/2408.01334](https://arxiv.org/abs/2408.01334)

    该研究提出了一种基于Therblig的框架，通过将高级机器人任务分解为基本配置，并结合基础模型，提高了机器人任务的理解和泛化能力。

    

    arXiv:2408.01334v1 公告类型: 新  翻译摘要: 端到端机器人学习，特别是在长期任务领域，常常导致不可预测的结果和不良的泛化。为了解决这些挑战，我们提出了一种基于Therblig的框架，即TBBF (Therblig-based Backbone Framework)，来提高机器人任务理解的能力和转移性。该框架将高级机器人任务分解为基本机器人配置，使用therbligs（基本动作元素）作为支撑，并与当前的基础模型相结合，以提高任务理解的效果。该方法包括两个阶段：离线训练和在线测试。在离线训练阶段，我们开发了Meta-RGate SynerFusion (MGSF)网络来准确地分割各种任务的therbligs。在线测试阶段，在收集一个新的任务演示之后，我们的MGSF网络提取高阶知识，并通过ActionREG（动作注册）将其编码成图像。此外，我们还开发了一种有效的Meta-Learner，它可以从单个任务的表现中提取知识并泛化到不同任务中，从而提高了模型的泛化能力。这种综合方法通过在多个复杂的实际任务中进行验证，展示了提升机器人任务理解性能的有效性。

    arXiv:2408.01334v1 Announce Type: new  Abstract: End-to-end robot learning, particularly for long-horizon tasks, often results in unpredictable outcomes and poor generalization. To address these challenges, we propose a novel Therblig-based Backbone Framework (TBBF) to enhance robot task understanding and transferability. This framework uses therbligs (basic action elements) as the backbone to decompose high-level robot tasks into elemental robot configurations, which are then integrated with current foundation models to improve task understanding. The approach consists of two stages: offline training and online testing. During the offline training stage, we developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig segmentation across various tasks. In the online testing stage, after a one-shot demonstration of a new task is collected, our MGSF network extracts high-level knowledge, which is then encoded into the image using Action Registration (ActionREG). Additionally
    
[^10]: 启发自机器人的扫描路径模型揭示动态场景中不确定性和语义对象线索对于视线引导的重要性

    A Robotics-Inspired Scanpath Model Reveals the Importance of Uncertainty and Semantic Object Cues for Gaze Guidance in Dynamic Scenes

    [https://arxiv.org/abs/2408.01322](https://arxiv.org/abs/2408.01322)

    该研究提出了一种基于机器学习模型的扫描路径算法，它在动态场景中通过不确定性和语义对象线索的结合，有效引导视线行为，并模拟了观察者的实际观看行为。

    

    arXiv:2408.01322v1 宣布类型：新 摘要：我们周围世界感知的方式取决于我们所积极关注的内容，但我们眼球的移动又依赖于感知到的事物。然而，物体分割和眼球运动的通常被看作是两个独立的过程。我们提出一个机制模型，它对于动态的真实世界场景模拟这些过程，并借鉴了机器人学中的信息处理模式。我们的图像可计算模型在动态场景下，不仅使用当前的物体分割进行基于物体的跳跃决策，而且还使用聚焦点物体来反复改进其场景分割结果。为了模拟这种改进，我们使用贝叶斯滤波器，还提供了对于分割的不确定性估计，以用于指导主动场景探索。我们展示了这个模型在模拟观察者自由观看行为时，与扫描路径统计数据密切相关，包括用于参数拟合的聚焦持续时间和跳跃幅度分布以及更高的层面上的观测数据。我们不仅展示了这个模型在模拟观察者自由观看行为时，与扫描路径统计数据密切相关，包括用于参数拟合的聚焦持续时间和跳跃幅度分布以及更高的层面上的观测数据。此外，我们还展示了这个模型在模拟观察者自由观看行为时，与扫描路径统计数据密切相关，包括用于参数拟合的聚焦持续时间和跳跃幅度分布以及更高的层面上的观测数据。

    arXiv:2408.01322v1 Announce Type: new  Abstract: How we perceive objects around us depends on what we actively attend to, yet our eye movements depend on the perceived objects. Still, object segmentation and gaze behavior are typically treated as two independent processes. Drawing on an information processing pattern from robotics, we present a mechanistic model that simulates these processes for dynamic real-world scenes. Our image-computable model uses the current scene segmentation for object-based saccadic decision-making while using the foveated object to refine its scene segmentation recursively. To model this refinement, we use a Bayesian filter, which also provides an uncertainty estimate for the segmentation that we use to guide active scene exploration. We demonstrate that this model closely resembles observers' free viewing behavior, measured by scanpath statistics, including foveation duration and saccade amplitude distributions used for parameter fitting and higher-level s
    
[^11]: 全面回顾多模态大型语言模型：不同任务上的性能与挑战

    A Comprehensive Review of Multimodal Large Language Models: Performance and Challenges Across Different Tasks

    [https://arxiv.org/abs/2408.01319](https://arxiv.org/abs/2408.01319)

    本文全面综述了多模态大型语言模型在多种任务中的性能与挑战，并指出了未来研究的方向。en_tldr: This paper provides a comprehensive review of the performance and challenges of multimodal large language models across various tasks, suggesting future research directions.

    

    在这个数据爆炸和科技快速发展的时代，多模态大型语言模型（MLLMs）处于人工智能（AI）系统的前沿。这种模型设计用于无缝整合多样化的数据类型，包括文本、图像、视频、音频和生理序列，远超单一模式系统的复杂应用。在本文中，我们对MLLM在多模态任务中的应用进行了系统的梳理，例如自然语言处理、视觉识别和音频分析。我们还提供了不同MLLM在特定任务之间的重点比较分析，并指出了现有MLLM的不足之处，并提出了未来研究的方向。通过这些讨论，本文希望能够为MLLM的未来发展和应用提供宝贵的见解。

    arXiv:2408.01319v1 Announce Type: new  Abstract: In an era defined by the explosive growth of data and rapid technological advancements, Multimodal Large Language Models (MLLMs) stand at the forefront of artificial intelligence (AI) systems. Designed to seamlessly integrate diverse data types-including text, images, videos, audio, and physiological sequences-MLLMs address the complexities of real-world applications far beyond the capabilities of single-modality systems. In this paper, we systematically sort out the applications of MLLM in multimodal tasks such as natural language, vision, and audio. We also provide a comparative analysis of the focus of different MLLMs in the tasks, and provide insights into the shortcomings of current MLLMs, and suggest potential directions for future research. Through these discussions, this paper hopes to provide valuable insights for the further development and application of MLLM.
    
[^12]: 一种基于决策的为设计不确定性的AI自我评估方法

    A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment

    [https://arxiv.org/abs/2408.01301](https://arxiv.org/abs/2408.01301)

    本文介绍了旨在提高AI预测透明度、可靠性和可信度的一系列工具和方法，为AI如何自我评估其预测的可靠性提供了指导。

    

    arXiv:2408.01301v1 公告类型: 交叉  翻译摘要: 人工智能(AI)已经革命化了社会的决策制定过程，特别是在具有重大影响力的场景中，它已经成为一项关键技术。尽管AI在受控环境下的预测能力令人印象深刻，但在各种关键场景中，它仍面临一系列实际障碍，阻碍了其在广泛应用中的使用。特别是，对于决策者而言，通常不清楚给定的AI系统在其下游应用中是否可信的预测。为了应对对更具透明度、韧性和可信度AI系统的需求，开发了一套工具，用于量化AI预测的不确定性，更广泛地说，使AI能够“自我评估”其预测的可靠性。在本论文中，我们将AI自我评估的方法按照几个关键维度进行分类，并提供了选择和设计适当方法的指南。

    arXiv:2408.01301v1 Announce Type: cross  Abstract: Artificial intelligence (AI) has revolutionized decision-making processes and systems throughout society and, in particular, has emerged as a significant technology in high-impact scenarios of national interest. Yet, despite AI's impressive predictive capabilities in controlled settings, it still suffers from a range of practical setbacks preventing its widespread use in various critical scenarios. In particular, it is generally unclear if a given AI system's predictions can be trusted by decision-makers in downstream applications. To address the need for more transparent, robust, and trustworthy AI systems, a suite of tools has been developed to quantify the uncertainty of AI predictions and, more generally, enable AI to "self-assess" the reliability of its predictions. In this manuscript, we categorize methods for AI self-assessment along several key dimensions and provide guidelines for selecting and designing the appropriate method
    
[^13]: 虚拟CAT：瑞士义务教育中算法思维评估工具

    The virtual CAT: A tool for algorithmic thinking assessment in Swiss compulsory education

    [https://arxiv.org/abs/2408.01263](https://arxiv.org/abs/2408.01263)

    本文介绍了一款评估瑞士义务教育中算法思维能力的虚拟CAT工具，它通过自动化的平台降低了人力成本并且提供了针对性的反馈。

    

    arXiv:2408.01263v1 公告类型：交叉  翻译：在当今数字时代，掌握算法思维（AT）技能不仅在计算机科学相关领域至关重要。这些能力使个人能够将复杂问题分解为更可管理的步骤，并创建一个行动序列来解决问题。为了应对教育环境中算法思维评估的需求，以及处理当前方法存在的局限性，本文介绍了一种名为虚拟Cross Array Task（CAT）的数字评估工具，它是对传统无插电评估活动的改进设计，旨在评估瑞士义务教育中的算法能力。这款工具提供了可扩展和自动化的评估方法，减少了人力参与并缓解了潜在的数据收集错误。该平台拥有基于手势的编程界面和基于视觉的积木编程接口，确保了对不同学习者的适用性，并支持多语言能力。为了评估虚拟CAT平台，我们进行了一次试点评估在瑞士排名前100的高中中，结果显示，该平台能够有效地识别学生的算法思维能力，并提供了针对性的反馈。

    arXiv:2408.01263v1 Announce Type: cross  Abstract: In today's digital era, holding algorithmic thinking (AT) skills is crucial, not only in computer science-related fields. These abilities enable individuals to break down complex problems into more manageable steps and create a sequence of actions to solve them. To address the increasing demand for AT assessments in educational settings and the limitations of current methods, this paper introduces the virtual Cross Array Task (CAT), a digital adaptation of an unplugged assessment activity designed to evaluate algorithmic skills in Swiss compulsory education. This tool offers scalable and automated assessment, reducing human involvement and mitigating potential data collection errors. The platform features gesture-based and visual block-based programming interfaces, ensuring its usability for diverse learners, further supported by multilingual capabilities. To evaluate the virtual CAT platform, we conducted a pilot evaluation in Switzer
    
[^14]: TrIM: 三角形输入运动同步阵列用于卷积神经网络 -- 第一部分：数据流和分析建模

    TrIM: Triangular Input Movement Systolic Array for Convolutional Neural Networks -- Part I: Dataflow and Analytical Modelling

    [https://arxiv.org/abs/2408.01254](https://arxiv.org/abs/2408.01254)

    TrIM 三角形输入运动同步阵列提出了一种新的架构，旨在通过特定数据流减少对大规模内存的访问次数，为卷积神经网络的复杂计算提供更高能效。

    

    arXiv:2408.01254v1 公告类型：新定标题：为了跟上高级AI模型日益复杂的计算需求和数据强度，新的计算范式正在被提出。这些范式旨在通过减少从处理核心到内存的数据传输成本来实现高能效，从而减轻冯诺依曼瓶颈，这是数据传输成本与处理核心到内存能耗相关的一种现象。卷积神经网络（CNNs）特别容易受到这种瓶颈的影响，因为它们需要管理大量数据。同步阵列（SA）是减轻数据传输成本的潜在架构，因为它们能够通过特定的数据流（如权重固定和排固定）减少对主内存的访问次数。这些PEs不断在特定数据流下交换和处理数据，从而减少了对大规模内存的访问次数。SA的硬件特殊化能够适应不同的工作负载，从矩阵乘法到其他类型的计算任务。

    arXiv:2408.01254v1 Announce Type: new  Abstract: In order to follow the ever-growing computational complexity and data intensity of state-of-the-art AI models, new computing paradigms are being proposed. These paradigms aim at achieving high energy efficiency, by mitigating the Von Neumann bottleneck that relates to the energy cost of moving data between the processing cores and the memory. Convolutional Neural Networks (CNNs) are particularly susceptible to this bottleneck, given the massive data they have to manage. Systolic Arrays (SAs) are promising architectures to mitigate the data transmission cost, thanks to high data utilization carried out by an array of Processing Elements (PEs). These PEs continuously exchange and process data locally based on specific dataflows (like weight stationary and row stationary), in turn reducing the number of memory accesses to the main memory. The hardware specialization of SAs can meet different workloads, ranging from matrix multiplications to
    
[^15]: 不确定性环境中的元推理：基于BAMDP框架的元推理方法

    Metareasoning in uncertain environments: a meta-BAMDP framework

    [https://arxiv.org/abs/2408.01253](https://arxiv.org/abs/2408.01253)

    本文提出了一种新的元推理框架，该框架在代理人不完全了解所面临的MDP的概率分布时，能够动态地优化推理过程的选择，提高了代理人在资源受限环境中的决策能力。

    

    arXiv:2408.01253v1 公告类型：新  翻译摘要：在决策制定场景中，可以认为“推理”是一种算法$P$，该算法选择一个动作$a^* \in \mathcal{A}$，旨在优化一些结果，如最大化马尔可夫决策过程（MDP）的价值函数。然而，执行$P$本身可能涉及到一些成本（时间、能量、有限的能力等），并且需要在考虑与执行选择在下的决策问题直接获得的实用价值。这样的成本需要在准确建模人类行为以及优化人工A计划时被考虑进去，因为所有物理系统都面临着资源限制。找到正确的$P$本身可以被看作是在推理过程$P$空间中进行优化的问题，通常被称作“元推理”。传统上，人类元推理模型假设代理知道底层MDP的转移和奖励分布。本文提出了一种新的元推理框架，该框架在代理人对所面临的MDP的一阶概率分布不完全了解的情况下，能够动态地优化推理过程的选择。该框架以贝叶斯马尔可夫决策过程(BAMDP)为基础，但去掉了代理人对MDP模型参数知识的前提假设，提出了\textit{meta-BAMDP}（元BAMDP）框架，并通过计算模型的优化为代理人提供了执行策略，该执行策略可以在不完全了解环境概率模型的情况下提高性能。此外，本文通过实验演示了该方法的有效性。

    arXiv:2408.01253v1 Announce Type: new  Abstract: In decision-making scenarios, \textit{reasoning} can be viewed as an algorithm $P$ that makes a choice of an action $a^* \in \mathcal{A}$, aiming to optimize some outcome such as maximizing the value function of a Markov decision process (MDP). However, executing $P$ itself may bear some costs (time, energy, limited capacity, etc.) and needs to be considered alongside explicit utility obtained by making the choice in the underlying decision problem. Such costs need to be taken into account in order to accurately model human behavior, as well as optimizing AI planning, as all physical systems are bound to face resource constraints. Finding the right $P$ can itself be framed as an optimization problem over the space of reasoning processes $P$, generally referred to as \textit{metareasoning}. Conventionally, human metareasoning models assume that the agent knows the transition and reward distributions of the underlying MDP. This paper gener
    
[^16]: 基于深度渐进强化学习的可变资源调度框架，用于IRS和UAV辅助的MEC系统

    Deep progressive reinforcement learning-based flexible resource scheduling framework for IRS and UAV-assisted MEC system

    [https://arxiv.org/abs/2408.01248](https://arxiv.org/abs/2408.01248)

    研究提出了一种基于深度渐进强化学习的可变资源调度框架，用于优化IRS和UAV辅助的MEC系统中的能耗，通过使用多任务代理和渐进时间调度器解决了混合整数非线性规划问题。

    

    arXiv:2408.01248v1 公告类型: 交叉 摘要：智能反射表面（IRS）和无人驾驶航空器（UAV）辅助的移动边缘计算（MEC）系统在临时和紧急场景中得到了广泛应用。我们的目标是通过共同优化UAV位置、IRS相位偏移、任务卸载和资源的分配来最小化MEC系统中的能耗。为此，我们提出了一个名为Flexible REsource Scheduling (FRES)的框架，通过采用一种新颖的深度渐进强化学习技术。该技术包括以下创新点：首先，我们提出了一个新型的多任务代理以解决混合整数非线性规划（MINLP）问题。多任务代理有两个输出头，分别用于不同的任务，其中一类头被用于带有整数变量的卸载决策，而另一类头则被用于带有连续变量的资源分配。其次，我们引入了一个渐进的时间调度器以优化任务学习过程。最终，通过逐步挖掘深度强化学习与风电耦合作用的内在逻辑，我们开发了一个新型的基于风电的MEC系统优化调度方法。

    arXiv:2408.01248v1 Announce Type: cross  Abstract: The intelligent reflection surface (IRS) and unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) system is widely used in temporary and emergency scenarios. Our goal is to minimize the energy consumption of the MEC system by jointly optimizing UAV locations, IRS phase shift, task offloading, and resource allocation with a variable number of UAVs. To this end, we propose a Flexible REsource Scheduling (FRES) framework by employing a novel deep progressive reinforcement learning which includes the following innovations: Firstly, a novel multi-task agent is presented to deal with the mixed integer nonlinear programming (MINLP) problem. The multi-task agent has two output heads designed for different tasks, in which a classified head is employed to make offloading decisions with integer variables while a fitting head is applied to solve resource allocation with continuous variables. Secondly, a progressive scheduler is intro
    
[^17]: 使用大型语言模型的高通量临床文本表型分析

    High-Throughput Phenotyping of Clinical Text Using Large Language Models

    [https://arxiv.org/abs/2408.01214](https://arxiv.org/abs/2408.01214)

    本研究证实了 GPT-4 在自动化临床文本表型分析方面超越了 GPT-3.5-Turbo，为精确医学提供了一种高效工具。

    

    arXiv:2408.01214v1 公告类型: 交叉  摘要: 高通量表型自动化自动将患者症状映射到标准化概念 ontology，这对于精确医学至关重要。这项研究评估了使用大型语言模型自动化在线孟德尔遗传（OMIM）数据库中临床总结表型的能力。鉴于它们丰富的表型数据，这些总结可以作为医生记录的替代品。我们进行了 GPT-4 和 GPT-3.5-Turbo 之间的性能对比。我们的结果显示，在识别、分类和标准化症状方面，GPT-4超过了 GPT-3.5-Turbo，实现了与人工注释者的一致性，与内部评分者的共识相当。尽管在症状标准化方面存在一些限制，但 GPT-4 的广泛预训练在跨多个表型任务实现高性能和普遍适用性方面取得了成功，同时避免了手动注释训练数据的需求。大型语言模型预计将成为自动化临床文本表型分析的主导方法。

    arXiv:2408.01214v1 Announce Type: cross  Abstract: High-throughput phenotyping automates the mapping of patient signs to standardized ontology concepts and is essential for precision medicine. This study evaluates the automation of phenotyping of clinical summaries from the Online Mendelian Inheritance in Man (OMIM) database using large language models. Due to their rich phenotype data, these summaries can be surrogates for physician notes. We conduct a performance comparison of GPT-4 and GPT-3.5-Turbo. Our results indicate that GPT-4 surpasses GPT-3.5-Turbo in identifying, categorizing, and normalizing signs, achieving concordance with manual annotators comparable to inter-rater agreement. Despite some limitations in sign normalization, the extensive pre-training of GPT-4 results in high performance and generalizability across several phenotyping tasks while obviating the need for manually annotated training data. Large language models are expected to be the dominant method for automa
    
[^18]: 多目标深度强化学习在自主系统中的优化

    Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems

    [https://arxiv.org/abs/2408.01188](https://arxiv.org/abs/2408.01188)

    本文采用了名为Deep W-Learning（DWN）的多目标强化学习技术，将其应用于新兴Web服务器示例，以在运行时找到最佳性能优化配置，并与两种单一目标优化实现（ε-贪婪算法和深度Q网络）进行了对比。

    

    arXiv:2408.01188v1 公告类型：新  摘要：在自主系统（AS）中，强化学习（RL）因其能在运行时学习而不需要环境模型或预定义动作而得到了广泛使用。然而，AS中RL的许多应用，例如基于Q学习的应用，只能优化一个目标，因此在具有多个目标的系统（如多目标强化学习（MORL）中，需要将多个目标在单个目标函数中以预先定义的权重结合。存在多种MORL技术，但它们大多数只在RL基准测试中应用，而不是在真实的自主系统中。本工作中，我们使用了名为Deep W-Learning（DWN）的多目标强化学习技术，并在诸如自适应服务器这样的新兴Web服务器示例中对其进行应用，以找到在运行时性能优化方面的理想配置。我们将DWN与两种单一目标优化实现进行了比较：ε-贪婪算法和深度Q网络。我们的初步评估显示，DW

    arXiv:2408.01188v1 Announce Type: new  Abstract: Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as it enables learning at runtime without the need for a model of the environment or predefined actions. However, most applications of RL in AS, such as those based on Q-learning, can only optimize one objective, making it necessary in multi-objective systems to combine multiple objectives in a single objective function with predefined weights. A number of Multi-Objective Reinforcement Learning (MORL) techniques exist but they have mostly been applied in RL benchmarks rather than real-world AS systems. In this work, we use a MORL technique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers exemplar, a self-adaptive server, to find the optimal configuration for runtime performance optimization. We compare DWN to two single-objective optimization implementations: {\epsilon}-greedy algorithm and Deep Q-Networks. Our initial evaluation shows that DW
    
[^19]: 使用元启发式策略优化 variational 量子电路的强化学习 Metaheuristic 方法

    Optimizing Variational Quantum Circuits Using Metaheuristic Strategies in Reinforcement Learning

    [https://arxiv.org/abs/2408.01187](https://arxiv.org/abs/2408.01187)

    本研究整合了多种元启发式优化算法（Particle Swarm Optimization, Ant Colony Optimization等）于量子强化学习中，展示了它们能够优化参数，并且在模拟退火和粒子群优化下获得了最佳效果。

    

    arXiv:2408.01187v1 公告类型：交叉 摘要：量子强化学习（QRL）在某些情况下相较于经典强化学习具有优势，例如简洁的状态空间表示和更快的收敛。然而，这些实际的好处需要进一步验证。QRL面临诸如解决方案景观平坦等挑战，传统的基于梯度的方法在这些情况下效率低下，这需要使用无梯度算法。本工作探讨将元启发式算法，如粒子群优化（PSO）、蚁群优化（ACO）、禁忌搜索（TS）、遗传算法（GA）、模拟退火（SA）和和谐搜索（HS），与QRL集成。这些算法在参数优化方面提供了灵活性和效率。在$5\times5$ MiniGrid强化学习环境中的评估显示，所有算法均达到了近似最优结果，其中模拟退火和粒子群优化表现最佳。在Cart Pole环境中，模拟退火和遗传算法表现良好。未来的研究将应用这些算法到量子电路优化中，以验证其在该领域的有效性。

    arXiv:2408.01187v1 Announce Type: cross  Abstract: Quantum Reinforcement Learning (QRL) offers potential advantages over classical Reinforcement Learning, such as compact state space representation and faster convergence in certain scenarios. However, practical benefits require further validation. QRL faces challenges like flat solution landscapes, where traditional gradient-based methods are inefficient, necessitating the use of gradient-free algorithms. This work explores the integration of metaheuristic algorithms -- Particle Swarm Optimization, Ant Colony Optimization, Tabu Search, Genetic Algorithm, Simulated Annealing, and Harmony Search -- into QRL. These algorithms provide flexibility and efficiency in parameter optimization. Evaluations in $5\times5$ MiniGrid Reinforcement Learning environments show that, all algorithms yield near-optimal results, with Simulated Annealing and Particle Swarm Optimization performing best. In the Cart Pole environment, Simulated Annealing, Geneti
    
[^20]: 论文标题：误导大型语言模型：漏洞、挑战与机遇

    Misinforming LLMs: vulnerabilities, challenges and opportunities

    [https://arxiv.org/abs/2408.01168](https://arxiv.org/abs/2408.01168)

    该论文探讨了大型语言模型在自然语言处理中的潜力与挑战，尤其关注了它们存在的误导性问题和在确保信息准确性的研究机会。

    

    论文摘要：arXiv:2408.01168v1 公告类型：交叉 摘要：尽管在自然语言处理领域取得了显著进展，但大型语言模型（LLMs）的内部工作机制仍常常被误解。尽管表现出连贯的回答和明显的推理行为，LLMs实际上依赖于词汇嵌入的统计模式，而不是真正的认知过程。本文认为，由于LLMs依赖于词汇嵌入向量序列模式的统计相关性，它们的内置机制存在根本的不信任问题。然而，对结合基于生成变换器的模型与事实基础和逻辑编程语言的研究可能会导致开发出可信赖的LLM，这些模型能够基于提供的事实生成语句并解释其自我推理过程。

    arXiv:2408.01168v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have made significant advances in natural language processing, but their underlying mechanisms are often misunderstood. Despite exhibiting coherent answers and apparent reasoning behaviors, LLMs rely on statistical patterns in word embeddings rather than true cognitive processes. This leads to vulnerabilities such as "hallucination" and misinformation. The paper argues that current LLM architectures are inherently untrustworthy due to their reliance on correlations of sequential patterns of word embedding vectors. However, ongoing research into combining generative transformer-based models with fact bases and logic programming languages may lead to the development of trustworthy LLMs capable of generating statements based on given truth and explaining their self-reasoning process.
    
[^21]: TCR-GPT: 结合自回归模型和强化学习的方法来生成T细胞受体库

    TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation

    [https://arxiv.org/abs/2408.01156](https://arxiv.org/abs/2408.01156)

    TCR-GPT模型通过使用自回归模型和强化学习结合的方法，提高了生成T细胞受体序列的准确性，并在人源化TCRs的序列生成中取得了良好的效果。

    

    arXiv:2408.01156v1 公告类型：交叉 摘要：T细胞受体（TCRs）在免疫系统中发挥着重要作用，通过识别并结合由感染或癌性细胞呈现的特定抗原。了解TCR的序列模式对于开发针对免疫治疗的策略和设计有效的疫苗至关重要。语言模型，如自回归转换器，提供了一种强大的解决方案，通过学习TCR库的潜在概率分布，从而生成新的TCR序列，这些序列继承了库中潜在的序列模式。在本文中，我们提出了TCR-GPT，一个基于仅含解码器的Transformer结构的经济模型，旨在揭示和复制TCR库中的序列模式。TCR-GPT在通过皮尔森相关系数测量的概率分布推断精度方面表现出色，其精确度达到了0.953。此外，通过利用强化学习，我们已经调整了TCR序列的分布，以保证在人源化TCRs（Hu-TCRs）的序列生成中推广自回归模型的学习效果。强化学习使得TCR-GPT能够针对特定的序列空间设计出更适合的模型，提高了生成的TCR序列和实际Hu-TCRs之间的接近度，并且能够在多维特征空间中生成更多样化的序列。实验表明，使用强化学习的TCR-GPT模型在模拟实验和真实TCR数据集上的性能都得到了显著提升。

    arXiv:2408.01156v1 Announce Type: cross  Abstract: T-cell receptors (TCRs) play a crucial role in the immune system by recognizing and binding to specific antigens presented by infected or cancerous cells. Understanding the sequence patterns of TCRs is essential for developing targeted immune therapies and designing effective vaccines. Language models, such as auto-regressive transformers, offer a powerful solution to this problem by learning the probability distributions of TCR repertoires, enabling the generation of new TCR sequences that inherit the underlying patterns of the repertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only transformer architecture, designed to uncover and replicate sequence patterns in TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring sequence probability distributions measured by Pearson correlation coefficient. Furthermore, by leveraging Reinforcement Learning(RL), we adapted the distribution of TCR sequences t
    
[^22]: DERA: 密集实体检索方法在知识图实体对齐中的应用

    DERA: Dense Entity Retrieval for Entity Alignment in Knowledge Graphs

    [https://arxiv.org/abs/2408.01154](https://arxiv.org/abs/2408.01154)

    这种新的密集实体检索方法利用语言模型统一编码跨知识图实体的各种信息特征，提高了实体对齐的准确性，促进了跨KG等效实体的快速检索。

    

    arXiv:2408.01154v1 公告类型: cross

    arXiv:2408.01154v1 Announce Type: cross  Abstract: Entity Alignment (EA) aims to match equivalent entities in different Knowledge Graphs (KGs), which is essential for knowledge fusion and integration. Recently, embedding-based EA has attracted significant attention and many approaches have been proposed. Early approaches primarily focus on learning entity embeddings from the structural features of KGs, defined by relation triples. Later methods incorporated entities' names and attributes as auxiliary information to enhance embeddings for EA. However, these approaches often used different techniques to encode structural and attribute information, limiting their interaction and mutual enhancement. In this work, we propose a dense entity retrieval framework for EA, leveraging language models to uniformly encode various features of entities and facilitate nearest entity search across KGs. Alignment candidates are first generated through entity retrieval, which are subsequently reranked to 
    
[^23]: 使用定理谱重要性分解解释图像模型的全局扰动鲁棒性

    Interpreting Global Perturbation Robustness of Image Models using Axiomatic Spectral Importance Decomposition

    [https://arxiv.org/abs/2408.01139](https://arxiv.org/abs/2408.01139)

    该研究提出了一种无模型的全局解释性方法，用于理解和评估图像模型在全球扰动下的鲁棒性。通过分析受扰自然图像的谱信噪比随频率的指数下降趋势，揭示了低频信号在模型鲁棒性中的正面作用，并发现高频率信号的贡献与模型的鲁棒性度量负相关。这些发现有助于设计更加鲁棒的模型结构。

    

    arXiv:2408.01139v1 公告类型: 交叉 摘要: 扰动鲁棒性评估了模型对各种扰动的脆弱性，包括数据污染和 adversarial攻击。理解扰动鲁棒性的机制对于全局解释性至关重要。我们提出了一种无模型的全局机制解释性方法，用于解释图像模型的扰动鲁棒性。这项研究受到两个关键因素的启发。首先，以前的全球解释性工作与鲁棒性基准（例如平均污染错误mCE）同时进行，并不是为了直接解释图像模型中扰动鲁棒性的工作机制。其次，我们注意到，受扰自然图像的谱信噪比（SNR）随频率指数下降。这种幂律类似的下降表明：低频信号通常比高频信号更鲁棒——然而，高分类精度并不能保证模型的鲁棒性。我们还进一步洞察到，模型的鲁棒性度量-mCE和高频信号的贡献有负相关性，这意味着在高频信号较小的图像区域中，即使存在高噪声水平，模型的鲁棒性通常也很高。这些发现揭示了高频率信号在模型鲁棒性中的负面作用，并为模型结构的设计提供了上下文。例如，即使对于轻度扰动，具有良好鲁棒性的模型也倾向于在低频信号更大的空间区域中保持更高的SNR值。最后，我们在多个图像模型上进行了广泛实验，展示了该方法的有效性和洞察力。总的来说，我们的工作扩展了对图像模型鲁棒性的全球解释性理解和评估方法，有助于推动后续的模型设计、理解和优化工作。下方是该论文的英文标题和摘要，请注意，对于以下的tldr和en_tldr部分，我会总结出一个中文和英文版的概要：

    arXiv:2408.01139v1 Announce Type: cross  Abstract: Perturbation robustness evaluates the vulnerabilities of models, arising from a variety of perturbations, such as data corruptions and adversarial attacks. Understanding the mechanisms of perturbation robustness is critical for global interpretability. We present a model-agnostic, global mechanistic interpretability method to interpret the perturbation robustness of image models. This research is motivated by two key aspects. First, previous global interpretability works, in tandem with robustness benchmarks, e.g. mean corruption error (mCE), are not designed to directly interpret the mechanisms of perturbation robustness within image models. Second, we notice that the spectral signal-to-noise ratios (SNR) of perturbed natural images exponentially decay over the frequency. This power-law-like decay implies that: Low-frequency signals are generally more robust than high-frequency signals -- yet high classification accuracy can not be ac
    
[^24]: Mamba架构综述

    A Survey of Mamba

    [https://arxiv.org/abs/2408.01129](https://arxiv.org/abs/2408.01129)

    Mamba架构以经典状态空间模型的灵感为基础，提出了一种新型解决方案，可以在保持序列长度相关近线性可扩展性的同时，提供与Transformer相当的建模能力，有望在人工智能领域带来新的发展。

    

    深度学习是一门至关重要的技术，已经在人工智能领域引发了一场显著的革命。作为最典型的架构，Transformer已经赋能了大量的先进模型，尤其是在包含数十亿参数的大型语言模型方面，它们已经成为深度学习领域的基石。尽管取得了显着成就，但Transformer仍然面临固有的局限性，特别是由于注意力计算的二次计算复杂性导致的耗时的推理过程。最近，一种名为Mamba的新型架构，借鉴了经典的状态空间模型，作为一种发展基础模型的潜在替代方案而受到关注，它在保持序列长度相关近线性可扩展性的同时，能够提供与Transformer相当的建模能力。这一发现激励了越来越多的研究积极探索Mamba在各种领域实现卓越表现的可能性。

    arXiv:2408.01129v1 Announce Type: cross  Abstract: Deep learning, as a vital technique, has sparked a notable revolution in artificial intelligence. As the most representative architecture, Transformers have empowered numerous advanced models, especially the large language models that comprise billions of parameters, becoming a cornerstone in deep learning. Despite the impressive achievements, Transformers still face inherent limitations, particularly the time-consuming inference resulting from the quadratic computation complexity of attention calculation. Recently, a novel architecture named Mamba, drawing inspiration from classical state space models, has emerged as a promising alternative for building foundation models, delivering comparable modeling abilities to Transformers while preserving near-linear scalability concerning sequence length. This has sparked an increasing number of studies actively exploring Mamba's potential to achieve impressive performance across diverse domain
    
[^25]: BioRAG: 基于RAG-LLM框架的生物学问题推理平台

    BioRAG: A RAG-LLM Framework for Biological Question Reasoning

    [https://arxiv.org/abs/2408.01107](https://arxiv.org/abs/2408.01107)

    BioRAG是一种采用RAG-LLM技术的问答系统，旨在解决生命科学研究领域中的知识仓库维护和信息检索难题。

    

    arXiv:2408.01107v1 公告类型：交叉  摘要：生命科学研究领域的问答系统，由于发现的速度加快、洞察力的演变以及知识实体之间的复杂相互作用，在维护一个全面的资料仓库和准确的信

    arXiv:2408.01107v1 Announce Type: cross  Abstract: The question-answering system for Life science research, which is characterized by the rapid pace of discovery, evolving insights, and complex interactions among knowledge entities, presents unique challenges in maintaining a comprehensive knowledge warehouse and accurate information retrieval. To address these issues, we introduce BioRAG, a novel Retrieval-Augmented Generation (RAG) with the Large Language Models (LLMs) framework. Our approach starts with parsing, indexing, and segmenting an extensive collection of 22 million scientific papers as the basic knowledge, followed by training a specialized embedding model tailored to this domain. Additionally, we enhance the vector retrieval process by incorporating a domain-specific knowledge hierarchy, which aids in modeling the intricate interrelationships among each query and context. For queries requiring the most current information, BioRAG deconstructs the question and employs an it
    
[^26]: 基于贡献的低秩适应性与预训练模型在真实图像修复中的应用

    Contribution-based Low-Rank Adaptation with Pre-training Model for Real Image Restoration

    [https://arxiv.org/abs/2408.01099](https://arxiv.org/abs/2408.01099)

    本文提出了一种高效参数调优方法CoLoRA，通过随机失真预训练（PROD）和贡献性低秩适应性，针对多个真实图像修复任务，大幅简化了模型的复杂性，并在精度与内存需求上超越了现有方法。

    

    arXiv:2408.01099v1 公告类型: 交叉  摘要: 最近，在自然语言处理和高层次计算机视觉中，借助掩码建模和提示调优，预训练模型和高效参数调优取得了显著的成功。然而，在低层次计算机视觉领域，对预训练模型的研究有限，尽管其在各种现实世界任务（如减轻AI边缘设备上新任务时的内存膨胀问题）中的重要性与收益备受关注，高效的小批量参数调优策略尚未被探索。这里，我们提出了一个新颖的有效参数调优方法，称为贡献性低秩适应性（CoLoRA），用于多个图像修复任务，以及一种有效的预训练方法，名为随机顺序失真（PROD）。与之前所有网络参数调优的工作不同，我们的CoLoRA通过利用LoRA（低秩适应性）针对每个新的视觉任务来有效地调优少量参数。我们采用一种贡献测量机制，通过分析网络的感知变化权重来指导网络参数的选定和优化，极大地简化了模型的复杂性，同时保持了高效的性能。我们证明，在多个真实世界图像修复任务上，通过PROD和CoLoRA的协同作用，我们的方法在精度和内存需求方面均优于现有的预训练和调优方法。我们的工作丰富了图像处理领域的预训练范式，并为AI边缘设备上的新任务集成提供了有效的方法。

    arXiv:2408.01099v1 Announce Type: cross  Abstract: Recently, pre-trained model and efficient parameter tuning have achieved remarkable success in natural language processing and high-level computer vision with the aid of masked modeling and prompt tuning. In low-level computer vision, however, there have been limited investigations on pre-trained models and even efficient fine-tuning strategy has not yet been explored despite its importance and benefit in various real-world tasks such as alleviating memory inflation issue when integrating new tasks on AI edge devices. Here, we propose a novel efficient parameter tuning approach dubbed contribution-based low-rank adaptation (CoLoRA) for multiple image restorations along with effective pre-training method with random order degradations (PROD). Unlike prior arts that tune all network parameters, our CoLoRA effectively fine-tunes small amount of parameters by leveraging LoRA (low-rank adaptation) for each new vision task with our contribut
    
[^27]: 论文标题翻译

    Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions

    [https://arxiv.org/abs/2408.01091](https://arxiv.org/abs/2408.01091)

    中文总结要点

    

    论文摘要翻译

    arXiv:2408.01091v1 Announce Type: new  Abstract: Large multimodal models (LMMs) excel in adhering to human instructions. However, self-contradictory instructions may arise due to the increasing trend of multimodal interaction and context length, which is challenging for language beginners and vulnerable populations. We introduce the Self-Contradictory Instructions benchmark to evaluate the capability of LMMs in recognizing conflicting commands. It comprises 20,000 conflicts, evenly distributed between language and vision paradigms. It is constructed by a novel automatic dataset creation framework, which expedites the process and enables us to encompass a wide range of instruction forms. Our comprehensive evaluation reveals current LMMs consistently struggle to identify multimodal instruction discordance due to a lack of self-awareness. Hence, we propose the Cognitive Awakening Prompting to inject cognition from external, largely enhancing dissonance detection. The dataset and code are 
    
[^28]: 适应性AI评估尺度：为英语学术用途的AI评估改进方案

    The EAP-AIAS: Adapting the AI Assessment Scale for English for Academic Purposes

    [https://arxiv.org/abs/2408.01075](https://arxiv.org/abs/2408.01075)

    本研究提议了一种适应性AI评价尺度，专门为英语学术用途设计，以适应人工智能的快速发展，并在评估中更有效地应用，确保评估的质量和一致性。

    

    arXiv:2408.01075v1 公告类型：交叉

    arXiv:2408.01075v1 Announce Type: cross  Abstract: The rapid advancement of Generative Artificial Intelligence (GenAI) presents both opportunities and challenges for English for Academic Purposes (EAP) instruction. This paper proposes an adaptation of the AI Assessment Scale (AIAS) specifically tailored for EAP contexts, termed the EAP-AIAS.   This framework aims to provide a structured approach for integrating GenAI tools into EAP assessment practices while maintaining academic integrity and supporting language development. The EAP-AIAS consists of five levels, ranging from "No AI" to "Full AI", each delineating appropriate GenAI usage in EAP tasks. We discuss the rationale behind this adaptation, considering the unique needs of language learners and the dual focus of EAP on language proficiency and academic acculturation.   This paper explores potential applications of the EAP-AIAS across various EAP assessment types, including writing tasks, presentations, and research projects. By 
    
[^29]: 自对弈方法在强化学习中的调查

    A Survey on Self-play Methods in Reinforcement Learning

    [https://arxiv.org/abs/2408.01072](https://arxiv.org/abs/2408.01072)

    自对弈强化学习的方法在帮助智能体通过与自身复制或历史版本的对弈中学习，其在不同场景中有广泛的应用，并提出了相关的开放问题和研究方向。

    

    这篇论文详细介绍了自对弈（Self-play）在强化学习领域中最新取得的重要进展。首先，本文介绍了自对弈的基本概念，包括多智能体强化学习框架和基本的博弈论概念。然后，本文提供了一个统一的自对弈算法框架，并将现有的自对弈算法归类到这个框架之下。此外，本文通过展示自对弈在不同场景中的应用，弥合了算法与实践之间的差距。最后，本文提出了自对弈面临的开放性问题和未来的研究方向。本文为理解自对弈在强化学习中的多层面特点提供了一个宝贵的指南。

    arXiv:2408.01072v1 Announce Type: new  Abstract: Self-play, characterized by agents' interactions with copies or past versions of itself, has recently gained prominence in reinforcement learning. This paper first clarifies the preliminaries of self-play, including the multi-agent reinforcement learning framework and basic game theory concepts. Then it provides a unified framework and classifies existing self-play algorithms within this framework. Moreover, the paper bridges the gap between the algorithms and their practical implications by illustrating the role of self-play in different scenarios. Finally, the survey highlights open challenges and future research directions in self-play. This paper is an essential guide map for understanding the multifaceted landscape of self-play in RL.
    
[^30]: 基于LLMs的软件系统自愈能力：应对运行时错误的适应性解决策略

    LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems

    [https://arxiv.org/abs/2408.01055](https://arxiv.org/abs/2408.01055)

    一种基于LLMs的新方法可以自适应地处理软件系统的运行时错误，提高系统的自我恢复能力。

    

    arXiv:2408.01055v1 公告类型：交叉 摘要：在软件系统的运行时，无法预料的错误可能会导致程序突然终止执行，从而引发严重后果，如数据丢失或系统崩溃。尽管开发阶段会尝试识别潜在错误，但此类预料之外的错误仍难以完全消除，因此，执行时采用缓解措施仍是减少其影响的关键。自动化的自愈技术，如重用现有的错误处理器，已被研究用于降低执行终止带来的损失。然而，现有方法的使用性受限于它们的预设启发式规则，它们在应对多样化的运行时错误时表现不佳。最近，大型语言模型（LLMs）的出现为解决这一问题开辟了新途径。受其卓越的能力启发，我们提出了一种利用LLMs来处理运行时错误的方法。

    arXiv:2408.01055v1 Announce Type: cross  Abstract: Unanticipated runtime errors, lacking predefined handlers, can abruptly terminate execution and lead to severe consequences, such as data loss or system crashes. Despite extensive efforts to identify potential errors during the development phase, such unanticipated errors remain a challenge to to be entirely eliminated, making the runtime mitigation measurements still indispensable to minimize their impact. Automated self-healing techniques, such as reusing existing handlers, have been investigated to reduce the loss coming through with the execution termination. However, the usability of existing methods is retained by their predefined heuristic rules and they fail to handle diverse runtime errors adaptively. Recently, the advent of Large Language Models (LLMs) has opened new avenues for addressing this problem. Inspired by their remarkable capabilities in understanding and generating code, we propose to deal with the runtime errors i
    
[^31]: 跨域环境中基于身体指令遵循的语义技能接地

    Semantic Skill Grounding for Embodied Instruction-Following in Cross-Domain Environments

    [https://arxiv.org/abs/2408.01024](https://arxiv.org/abs/2408.01024)

    本文提出了一个SemGro框架，通过迭代分解技能，使预训练的语言模型能够针对不同领域规划指令遵循任务。

    

    arXiv:2408.01024v1 新闻类型：新消息 摘要：在基于身体指令遵循（EIF）中，作为任务规划器整合预训练语言模型（LMs）的出现是一个重要的分支，任务在技能层级上被预训练技能和用户指令提示的语言模型所规划。然而，在不同领域中接地这些预训练技能仍然是一个挑战，因为它们与特定领域的知识紧密纠缠。为了解决这一挑战，我们提出了一个语义技能接地（SemGro）框架，该框架利用了语义技能的层次性。SemGro认识到了这些技能的广泛范围，从在不同领域都普遍适用的低语义技能到高度专门化和特定于某一领域的长期前景丰富语义技能。该框架采用了迭代的技能分解方法，从具有较高语义技能层次的更广泛范围开始，然后再逐步向下，将语义技能分解为更为细粒度的组成部分，以准确地规划出适应于特定领域的指令遵循任务。

    arXiv:2408.01024v1 Announce Type: new  Abstract: In embodied instruction-following (EIF), the integration of pretrained language models (LMs) as task planners emerges as a significant branch, where tasks are planned at the skill level by prompting LMs with pretrained skills and user instructions. However, grounding these pretrained skills in different domains remains challenging due to their intricate entanglement with the domain-specific knowledge. To address this challenge, we present a semantic skill grounding (SemGro) framework that leverages the hierarchical nature of semantic skills. SemGro recognizes the broad spectrum of these skills, ranging from short-horizon low-semantic skills that are universally applicable across domains to long-horizon rich-semantic skills that are highly specialized and tailored for particular domains. The framework employs an iterative skill decomposition approach, starting from the higher levels of semantic skill hierarchy and then moving downwards, s
    
[^32]: GNN-MolKAN: 结合KAN提升分子表示学习能力的GNNs

    GNN-MolKAN: Harnessing the Power of KAN to Advance Molecular Representation Learning with GNNs

    [https://arxiv.org/abs/2408.01018](https://arxiv.org/abs/2408.01018)

    该研究提出了一种结合KAN架构的GNNs，GNN-MolKAN和GNN-MolKAN+，以提高分子表示学习的性能，展现了其在预测不同分子特性任务中的优越性。

    

    arXiv:2408.01018v1 公告类型: 交叉 摘要: 分子性质预测和药物设计中有效的分子表征学习至关重要。然而，现有的方法在标注不足和架构设计不佳方面存在局限性。例如，图神经网络（GNNs）由于过度压缩而导致分子结构的重要细节丢失，从而影响了分子表征。在此工作中，我们提出了一种新的GNN类，即GNN-MolKAN及其增强变种GNN-MolKAN+，它们将人工智能+科学领域的Kolmogorov-Arnold Networks（KAN）架构融入GNNs，以解决这些挑战。此外，我们引入了自适应快速KAN（AdFastKAN），这是一种高级KAN，提供了增加的稳定性和速度，进一步提升了标准GNN的性能。值得注意的是，我们的方法具有三个关键优势：1) 卓越性能：GNN-MolKAN和GNN-MolKAN+展示了优越的预测能力，具有强大的泛化能力；2) 结构掌握：KAN结合了GNN的结构动态感知能力；3) 高效学习：AdFastKAN实现了快的训练过程和稳定的预测精度。通过实验验证，我们证明GNN-MolKAN和GNN-MolKAN+在多样化分子特性预测任务上表现出了优越的性能，表明了KAN框架在GNNs中的有效性。

    arXiv:2408.01018v1 Announce Type: cross  Abstract: Effective molecular representation learning is crucial for molecular property prediction and drug design. However, existing approaches struggle with limitations in insufficient annotations and suboptimal architecture design. For instance, Graph Neural Networks (GNNs) suffer from over-squashing, causing the loss of important structural details in molecules, thus impairing molecular representations. In this work, we propose a new class of GNNs, GNN-MolKAN and its augmented variant, GNN-MolKAN+, that integrate the Kolmogorov-Arnold Networks (KAN) architecture from AI + Science into GNNs to address these challenges. Additionally, we introduce Adaptive FastKAN (AdFastKAN), an advanced KAN that offers increased stability and speed, further enhancing the performance of standard GNNs. Notably, our approach holds three key benefits: 1) Superior Performance: GNN-MolKAN and GNN-MolKAN+ demonstrate superior prediction ability, robust generalizatio
    
[^33]: 道路交通图数据：基准测试与道路交通预测模型

    IBB Traffic Graph Data: Benchmarking and Road Traffic Prediction Model

    [https://arxiv.org/abs/2408.01016](https://arxiv.org/abs/2408.01016)

    本文介绍了一种新的IBB交通图数据集，以解决现有道路交通数据集在适用性和多样性方面的问题，并提出了一个预测模型，旨在提高智能交通系统的效率和安全性。

    

    引言: 道路交通堵塞预测是智能交通系统中的一个关键组成部分，因为它能使得交通管理具有前瞻性，提高郊区体验，减少环境影响，并整体提高安全和效率。虽然有多个公共数据集，尤其是在都市地区，但这些数据集可能并不适用于实际情况，因为数据量不够（即传感器和道路连接数量不足）以及一些外部因素，如目标地区的特性差异，如城市、高速公路以及数据收集位置等因素。为了解决这个问题，本文介绍了一个新的IBB交通图数据集，作为一种替代基准数据集，以减轻这些限制，并丰富具有新地理特征的文献。IBB交通图数据集涵盖了在2451个不同地点收集的传感器数据。此外，我们还提出了一个关于道路交通预测的新模型。

    arXiv:2408.01016v1 Announce Type: cross  Abstract: Road traffic congestion prediction is a crucial component of intelligent transportation systems, since it enables proactive traffic management, enhances suburban experience, reduces environmental impact, and improves overall safety and efficiency. Although there are several public datasets, especially for metropolitan areas, these datasets may not be applicable to practical scenarios due to insufficiency in the scale of data (i.e. number of sensors and road links) and several external factors like different characteristics of the target area such as urban, highways and the data collection location. To address this, this paper introduces a novel IBB Traffic graph dataset as an alternative benchmark dataset to mitigate these limitations and enrich the literature with new geographical characteristics. IBB Traffic graph dataset covers the sensor data collected at 2451 distinct locations. Moreover, we propose a novel Road Traffic Prediction
    
[^34]: 张量束低秩近似 (TT-LoRA): 加速 LLMs 以民主化人工智能

    Tensor Train Low-rank Approximation (TT-LoRA): Democratizing AI with Accelerated LLMs

    [https://arxiv.org/abs/2408.01008](https://arxiv.org/abs/2408.01008)

    本文提出了一种名为TT-LoRA的低秩张量束近似方法，旨在通过更快的LLMs微调加速人工智能民主化。

    

    arXiv:2408.01008v1 公告类型: 交叉  翻译摘要: 在最近几年中，大型语言模型 (LLMs) 在广泛的自然语言处理 (NLP) 任务中展示了惊人的能力，例如问答、情感分析、文本摘要和机器翻译。然而，LLMs日益复杂的需求巨大计算资源，阻碍了这些模型的更广泛研究和应用。为了解决这一问题，已经开发了各种参数高效的微调策略，如Low-Rank Approximation（LoRA）和Adapters。尽管这些方法具有潜力，但它们通常在可压缩性方面存在限制。具体来说，LoRA在现代大型LLM中越来越增多的可训练参数上难以有效扩展。此外，虽然Low-Rank Economic Tensor-Train Adaptation（LoRETTA）利用张量束分解，但它尚未实现对非常大模型进行压缩的必要水平。

    arXiv:2408.01008v1 Announce Type: cross  Abstract: In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities across a wide range of natural language processing (NLP) tasks, such as question-answering, sentiment analysis, text summarization, and machine translation. However, the ever-growing complexity of LLMs demands immense computational resources, hindering the broader research and application of these models. To address this, various parameter-efficient fine-tuning strategies, such as Low-Rank Approximation (LoRA) and Adapters, have been developed. Despite their potential, these methods often face limitations in compressibility. Specifically, LoRA struggles to scale effectively with the increasing number of trainable parameters in modern large scale LLMs. Additionally, Low-Rank Economic Tensor-Train Adaptation (LoRETTA), which utilizes tensor train decomposition, has not yet achieved the level of compression necessary for fine-tuning very large scale mo
    
[^35]: FBSDiff: 插拔式频率带替代式扩散特征变换的高可控制文本驱动图像翻译

    FBSDiff: Plug-and-Play Frequency Band Substitution of Diffusion Features for Highly Controllable Text-Driven Image Translation

    [https://arxiv.org/abs/2408.00998](https://arxiv.org/abs/2408.00998)

    本文提出了一种将预训练的文本到图像扩散模型高效地转换为图像到图像编辑工具的新型方法，使得用户可以根据文本描述灵活地控制图像内容。

    

    arXiv:2408.00998v1 公告类型: 新  摘要: 大规模文本到图像 diffusion 模型在生成人工智能和多模态技术的发展中是一个革命性的里程碑，它允许根据自然语言文本提示生成非凡的图像。然而，这类模型缺乏可控性的问题限制了它们在现实生活中的实际应用，因为注意力已经集中在利用参考图像来控制文本到图像的合成。由于参考图像与生成的图像之间的密切关系，这个问题也可以被看作是根据文本操纵（或者编辑）参考图像的任务，即文本驱动的图像到图像翻译。本文贡献了一种新颖、简练、高效的方法，该方法将预训练的大型文本到图像（T2I）扩散模型调整到图像到图像（I2I）范式中，实现高质量和多变的文本驱动图像编辑。

    arXiv:2408.00998v1 Announce Type: new  Abstract: Large-scale text-to-image diffusion models have been a revolutionary milestone in the evolution of generative AI and multimodal technology, allowing extraordinary image generation based on natural-language text prompts. However, the issue of lacking controllability of such models restricts their practical applicability for real-life content creation, for which attention has been focused on leveraging a reference image to control text-to-image synthesis. Due to the close correlation between the reference image and the generated image, this problem can also be regarded as the task of manipulating (or editing) the reference image as per the text, namely text-driven image-to-image translation. This paper contributes a novel, concise, and efficient approach that adapts the pre-trained large-scale text-to-image (T2I) diffusion model to the image-to-image (I2I) paradigm in a plug-and-play manner, realizing high-quality and versatile text-driven
    
[^36]: 一种在安全约束网格环境中实现无模型任务适应的安全探索策略

    A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments

    [https://arxiv.org/abs/2408.00997](https://arxiv.org/abs/2408.00997)

    我们的研究提出了一个无模型策略，确保机器人能够在遵守安全限制的同时，学习和适应新任务，这个方法对于处理复杂环境中的未知条件和障碍特别有利，如可能包括的障碍物。

    

    在这项研究中，我们提出了一个无模型策略，用于在安全约束的网格环境中进行探索，这种方法确保了同时探索环境并遵守约束条件。Our safety-aware exploration strategy allows agents to learn new tasks without compromising the environment's safety, thereby facilitating learning in practical environments. This approach is particularly advantageous for robotic navigation in complex environments that may include obstacles and unpredictable conditions.

    arXiv:2408.00997v1 Announce Type: new  Abstract: Training a model-free reinforcement learning agent requires allowing the agent to sufficiently explore the environment to search for an optimal policy. In safety-constrained environments, utilizing unsupervised exploration or a non-optimal policy may lead the agent to undesirable states, resulting in outcomes that are potentially costly or hazardous for both the agent and the environment. In this paper, we introduce a new exploration framework for navigating the grid environments that enables model-free agents to interact with the environment while adhering to safety constraints. Our framework includes a pre-training phase, during which the agent learns to identify potentially unsafe states based on both observable features and specified safety constraints in the environment. Subsequently, a binary classification model is trained to predict those unsafe states in new environments that exhibit similar dynamics. This trained classifier emp
    
[^37]: 《IncidentNet: 稀疏传感下的交通事件检测、定位和严重性估计》

    IncidentNet: Traffic Incident Detection, Localization and Severity Estimation with Sparse Sensing

    [https://arxiv.org/abs/2408.00996](https://arxiv.org/abs/2408.00996)

    IncidentNet是一种通过训练稀疏放置在城市的传感器收集数据的深度学习模型，用于检测、定位和评估交通事件的严重性。

    

    迄今为止，关于交通事件检测的研究主要依赖于大量的传感器覆盖，并且主要基于决策树和随机森林模型，这些模型在代表能力上有限，因此无法准确检测事件。本文介绍了IncidentNet——一种使用在城市环境中稀疏放置的传感器捕获的数据进行训练的深度学习模型，以分类、定位和估计交通事件的严重性。我们的模型建立在微观交通数据之上，该数据可以通过安装在交通交叉路口的摄像头收集。由于缺乏同时提供微观交通细节和交通事件细节的合成交通数据集，我们还在本文中提出了一个方法，该方法可以根据给定的宏观交通数据生成一个合成微观交通数据集。在使用IncidentNet技术时，检测出的事故率达到了98%，误报率低于7%，并且在197个测试案例中的准确率达到95%以上。

    arXiv:2408.00996v1 Announce Type: cross  Abstract: Prior art in traffic incident detection relies on high sensor coverage and is primarily based on decision-tree and random forest models that have limited representation capacity and, as a result, cannot detect incidents with high accuracy. This paper presents IncidentNet - a novel approach for classifying, localizing, and estimating the severity of traffic incidents using deep learning models trained on data captured from sparsely placed sensors in urban environments. Our model works on microscopic traffic data that can be collected using cameras installed at traffic intersections. Due to the unavailability of datasets that provide microscopic traffic details and traffic incident details simultaneously, we also present a methodology to generate a synthetic microscopic traffic dataset that matches given macroscopic traffic data. IncidentNet achieves a traffic incident detection rate of 98%, with false alarm rates of less than 7% in 197 
    
[^38]: ArchCode：将软件需求融入大型语言模型生成的代码中

    ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models

    [https://arxiv.org/abs/2408.00994](https://arxiv.org/abs/2408.00994)

    本文介绍了ARCHCODE框架，该框架利用大型语言模型通过在上下文中学习的方式，组织并推断软件需求，从而提升代码生成质量。

    

    arXiv:2408.00994v1 公告类型：交叉 摘要：本文旨在将大型语言模型（LLM）的代码生成能力扩展到能够自动处理从给定文本描述中给出的全面软件需求。这些需求包括功能性（即对输入执行预期行为）和非功能性要求（例如，时间/空间性能、鲁棒性、可维护性）。然而，文本描述要么可能冗长地表达要求，要么甚至可能省略一些要求。我们介绍ARCHCODE，一个全新的框架，它利用“在上下文中学习”的原理来组织从描述中观察到的需求，并从这些描述中推断出未表达的需求。ARCHCODE从给出的描述中生成需求，并对它们进行条件处理，以产生代码片段和测试用例。每个测试用例都针对一个要求，允许根据代码片段执行结果与要求的符合性对代码片段进行排名。公共基准测试结果表明，ARCHCODE在处理复杂软件需求和生成高质量代码方面优于现有的方法。未来的工作将集中于实现ARCHCODE在真实世界软件工程环境中的应用和评估。

    arXiv:2408.00994v1 Announce Type: cross  Abstract: This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g., time/space performance, robustness, maintainability) requirements. However, textual descriptions can either express requirements verbosely or may even omit some of them. We introduce ARCHCODE, a novel framework that leverages in-context learning to organize requirements observed in descriptions and to extrapolate unexpressed requirements from them. ARCHCODE generates requirements from given descriptions, conditioning them to produce code snippets and test cases. Each test case is tailored to one of the requirements, allowing for the ranking of code snippets based on the compliance of their execution results with the requirements. Public benchmar
    
[^39]: 具有恶意代理的multi-agent系统的弹性研究

    On the Resilience of Multi-Agent Systems with Malicious Agents

    [https://arxiv.org/abs/2408.00989](https://arxiv.org/abs/2408.00989)

    本文研究了面对恶意代理时multi-agent系统的弹性，并探讨了增加系统抵御能力的方法。

    

    arXiv:2408.00989v1 公告类型: 新摘要：多代理系统，依靠大型语言模型，在各种任务中展示了强大的能力，因为专家代理专注于特定的领域。然而，当代理被单独部署时，存在一个风险，即恶意用户可能会引入恶意代理，这些代理生成的结果是错误的或不相关的，以至于其他非专门代理难以识别。因此，本文探讨了两个基本问题：（1）在不同类型的多代理系统结构（例如A->B->C，A<->B<->C）下，面对恶意代理时，各种下游任务的弹性是多少？（2）我们如何能增加系统抵御恶意代理的能力？为了模拟恶意代理，我们设计了两种方法，AutoTransform和AutoInject，将任何代理转换成恶意代理，同时保持其功能完整性。我们在多种下游任务上进行了全面实验，包括自然语言处理、知识抽取和文本生成任务，并与真实世界数据集进行了比较分析，以评估系统在面对恶意代理时的表现。我们发现，尽管multi-agent系统在面对恶意代理时表现出一定程度的脆弱性，但通过适当的结构设计和防御策略的制定，系统的整体性能是可以得到增强的。我们的工作不仅揭示了multi-agent系统在面对恶意攻击时的抗性，也为构建更安全、更健壮的协作系统提供了新的见解和策略。

    arXiv:2408.00989v1 Announce Type: new  Abstract: Multi-agent systems, powered by large language models, have shown great abilities across various tasks due to the collaboration of expert agents, each focusing on a specific domain. However, when agents are deployed separately, there is a risk that malicious users may introduce malicious agents who generate incorrect or irrelevant results that are too stealthy to be identified by other non-specialized agents. Therefore, this paper investigates two essential questions: (1) What is the resilience of various multi-agent system structures (e.g., A$\rightarrow$B$\rightarrow$C, A$\leftrightarrow$B$\leftrightarrow$C) under malicious agents, on different downstream tasks? (2) How can we increase system resilience to defend against malicious agents? To simulate malicious agents, we devise two methods, AutoTransform and AutoInject, to transform any agent into a malicious one while preserving its functional integrity. We run comprehensive experimen
    
[^40]: 环境、社会、治理(ESG)和人工智能的集成：全面的责任AI评估框架

    Integrating ESG and AI: A Comprehensive Responsible AI Assessment Framework

    [https://arxiv.org/abs/2408.00965](https://arxiv.org/abs/2408.00965)

    本文介绍了一个新的ESG-AI框架，旨在帮助投资者评估和管理AI投资，同时推动公司的可持续性和盈利能力。

    

    arXiv:2408.00965v1 公告类型：新  摘要：人工智能（AI）技术在各个行业部门中得到了广泛的发展和应用。将环境、社会和治理（ESG）考虑因素与AI投资相结合，对于确保伦理和技术上的可持续发展至关重要。特别是从投资者的角度来看，这种整合不仅能够减轻风险，还能够通过与更广泛的全球目标保持一致，从而提升长期的价值创造。然而，学术界和工业界对这个领域的探讨相对较少。为了弥补这一差距，我们提出了一个全新的ESG-AI框架，这个框架是基于与28家公司合作经验中的洞察而开发的。该框架由三个关键组成部分组成。通过与业界实践者的合作，我们为这一整合提供了一个结构化的方法。ESG-AI框架概述了人工智能应用的环境和社会影响，帮助使用者，如投资者，去评估和管理AI投资的价值，同时推动公司的可持续性目标和盈利能力的发展。此外，我们设计了一个在线评估工具，以确保该框架的实用性和可扩展性。

    arXiv:2408.00965v1 Announce Type: new  Abstract: Artificial Intelligence (AI) is a widely developed and adopted technology across entire industry sectors. Integrating environmental, social, and governance (ESG) considerations with AI investments is crucial for ensuring ethical and sustainable technological advancement. Particularly from an investor perspective, this integration not only mitigates risks but also enhances long-term value creation by aligning AI initiatives with broader societal goals. Yet, this area has been less explored in both academia and industry. To bridge the gap, we introduce a novel ESG-AI framework, which is developed based on insights from engagements with 28 companies and comprises three key components. The framework provides a structured approach to this integration, developed in collaboration with industry practitioners. The ESG-AI framework provides an overview of the environmental and social impacts of AI applications, helping users such as investors asse
    
[^41]: PERSOMA个性化软提示适配器架构在个性化语言提示中的应用

    PERSOMA: PERsonalized SOft ProMpt Adapter Architecture for Personalized Language Prompting

    [https://arxiv.org/abs/2408.00960](https://arxiv.org/abs/2408.00960)

    PERSOMA是一种用于个性化语言提示的软提示适配器架构，能高效处理和个性化用户交互历史。

    

    论文介绍了一种名为PERSOMA的个性化软提示适配器架构，旨在大型语言模型中对用户的广泛交互历史进行准确和个性化的理解。与现有的大型语言模型个性化提示方法相比，PERSOMA提供了一种新的高效捕获用户历史的方式。论文通过使用用户交互的操作减少和压缩算法，将用户交互信息转化为特征丰富的软提示嵌入表示。此外，论文还通过各种评估方法验证了PERSOMA架构，包括判断各类参数压缩和调整方法的效率，如低秩注意力（LoRA）等方法。通过严格的测试后，结果表明PERSOMA在处理复杂和大量的用户交互历史方面优于现有基于嵌入和提示的方法。

    arXiv:2408.00960v1 Announce Type: cross  Abstract: Understanding the nuances of a user's extensive interaction history is key to building accurate and personalized natural language systems that can adapt to evolving user preferences. To address this, we introduce PERSOMA, Personalized Soft Prompt Adapter architecture. Unlike previous personalized prompting methods for large language models, PERSOMA offers a novel approach to efficiently capture user history. It achieves this by resampling and compressing interactions as free form text into expressive soft prompt embeddings, building upon recent research utilizing embedding representations as input for LLMs. We rigorously validate our approach by evaluating various adapter architectures, first-stage sampling strategies, parameter-efficient tuning techniques like LoRA, and other personalization methods. Our results demonstrate PERSOMA's superior ability to handle large and complex user histories compared to existing embedding-based and t
    
[^42]: 这里是翻译过的论文标题

    CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression

    [https://arxiv.org/abs/2408.00938](https://arxiv.org/abs/2408.00938)

    本研究提出了一种基于临床知识改进的扩散模型，用于更准确地预测特发性肺纤维化（IPF）的进展。

    

    这里是翻译过的论文摘要

    arXiv:2408.00938v1 Announce Type: cross  Abstract: The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly correlates with higher patient mortality rates. Early detection of IPF progression is critical for initiating timely treatment, which can effectively slow down the advancement of the disease. However, the current clinical criteria define disease progression requiring two CT scans with a one-year interval, presenting a dilemma: a disease progression is identified only after the disease has already progressed. To this end, in this paper, we develop a novel diffusion model to accurately predict the progression of IPF by generating patient's follow-up CT scan from the initial CT scan. Specifically, from the clinical prior knowledge, we tailor improvements to the traditional diffusion model and propose a Clinically-Informed Residual Diffusion model, called CIResDiff. The key innovations of CIResDiff include 1) performing the target region pre-registration to align the lung
    
[^43]: 论文标题：在GPU上实现高数据吞吐量的强化学习：一个领域无关的框架，用于数据驱动的科学研究

    Enabling High Data Throughput Reinforcement Learning on GPUs: A Domain Agnostic Framework for Data-Driven Scientific Research

    [https://arxiv.org/abs/2408.00930](https://arxiv.org/abs/2408.00930)

    我们介绍了一个名为WarpSci的框架，该框架能够显著提高在GPU上进行强化学习的性能，尤其适用于需要复杂环境模型数据的科学研究。

    

    论文摘要：我们介绍WarpSci，一个设计用于克服在具有大量高维观测或动作空间的复杂环境中应用强化学习时遇到的关键系统瓶颈的领域无关框架。值得注意的是，我们 framework eliminates the need for data transfer between the CPU and GPU，使单个或多个GPU上可以同时执行数千个模拟。这对于研究数据驱动的科学研究特别有利，因为在领域中复杂的模型环境至关重要。

    arXiv:2408.00930v1 Announce Type: cross  Abstract: We introduce WarpSci, a domain agnostic framework designed to overcome crucial system bottlenecks encountered in the application of reinforcement learning to intricate environments with vast datasets featuring high-dimensional observation or action spaces. Notably, our framework eliminates the need for data transfer between the CPU and GPU, enabling the concurrent execution of thousands of simulations on a single or multiple GPUs. This high data throughput architecture proves particularly advantageous for data-driven scientific research, where intricate environment models are commonly essential.
    
[^44]: 白皮书：利用GCG后缀的数据泄露简要探索

    WHITE PAPER: A Brief Exploration of Data Exfiltration using GCG Suffixes

    [https://arxiv.org/abs/2408.00925](https://arxiv.org/abs/2408.00925)

    本文揭示了一项新的数据泄露技术，即在利用生成语言模型协助时，通过注入恶意指令并使用GCG后缀提高数据泄露的成功率，尤其在企业环境中，这种攻击可能对业务造成约450万美元的损失。虽然存在风险，但通过管理和安全策略的改进，可以降低此类攻击的成功率。

    

    arXiv:2408.00925v1 公告类型：交叉  摘要：交叉提示注入攻击（XPIA）是一种有效的用于数据泄露的技术，近来在该领域得到了广泛的应用。在XPIA攻击中，攻击者能够在第三方数据中注入恶意指令，而这些数据很可能会被生成语言模型（LLM）在辅助用户时消费，用户成为受害者。XPIA通常被用作数据泄露的一种手段，估计一次平均数据泄露的成本对企业来说接近450万美元，这一成本包括了如企业凭证被篡改等不同类型的数据泄露。随着基于梯度的攻击，如GCG后缀攻击的兴起，使用GCG后缀的XPIA发生的概率令人担忧。在我作为Microsoft人工智能红队的工作中，我展示了在模拟的XPIA场景中使用GCG后缀配合注入漏洞的可行性攻击模型。结果表明，存在GCG后缀的情况下，成功数据泄露的概率几乎增加了20%，有些情况下甚至更高。然而，这种数据泄露的可能性并不意味着实际的成功率，因为除了技术因素外，还有管理和安全策略等非技术因素的影响。我们的研究旨在为数据保护提供新的视角和思考方向，同时也为防范此类攻击提供参考和建议。

    arXiv:2408.00925v1 Announce Type: cross  Abstract: The cross-prompt injection attack (XPIA) is an effective technique that can be used for data exfiltration, and that has seen increasing use. In this attack, the attacker injects a malicious instruction into third party data which an LLM is likely to consume when assisting a user, who is the victim. XPIA is often used as a means for data exfiltration, and the estimated cost of the average data breach for a business is nearly $4.5 million, which includes breaches such as compromised enterprise credentials. With the rise of gradient-based attacks such as the GCG suffix attack, the odds of an XPIA occurring which uses a GCG suffix are worryingly high. As part of my work in Microsoft's AI Red Team, I demonstrated a viable attack model using a GCG suffix paired with an injection in a simulated XPIA scenario. The results indicate that the presence of a GCG suffix can increase the odds of successful data exfiltration by nearly 20%, with some c
    
[^45]: 授予 GPT-4 许可证和机会：增强少样本事件检测的准确性和置信度估计

    Granting GPT-4 License and Opportunity: Enhancing Accuracy and Confidence Estimation for Few-Shot Event Detection

    [https://arxiv.org/abs/2408.00914](https://arxiv.org/abs/2408.00914)

    本研究通过在事件检测中使用GPT-4的少样本学习方法，实现了增强的准确性和置信度估计，通过为GPT-4提供的“许可证和机会”（L&O），实现了0.759 AUC的置信度指标。

    

    arXiv:2408.00914v1 公告类型：新  翻译：大型语言模型（LLM），如 GPT-4，在少样本学习环境中显示出足够的潜力，可以用于生成“银色”数据和新知识库的改进。通过迭代应用和审查，这样的工作流程变得更加有效。可靠的置信度估计是此类模型如 GPT-4的已报告弱点，而补偿的方法则需要大量的额外复杂性和计算资源。目前的研究探讨了 GPT-4在基于 BETTER 知识库的事件检测中的少样本学习有效置信度估计的方法。关键创新是将提供给 GPT-4的提示和任务扩展为提供一个允许猜测而不确定的许可证和量化并解释不确定性的机会（L&O）。这种方法无额外设备即可提高准确性，提供可用的置信度指标（0.759 AUC）。

    arXiv:2408.00914v1 Announce Type: new  Abstract: Large Language Models (LLMs) such as GPT-4 have shown enough promise in the few-shot learning context to suggest use in the generation of "silver" data and refinement of new ontologies through iterative application and review. Such workflows become more effective with reliable confidence estimation. Unfortunately, confidence estimation is a documented weakness of models such as GPT-4, and established methods to compensate require significant additional complexity and computation. The present effort explores methods for effective confidence estimation with GPT-4 with few-shot learning for event detection in the BETTER ontology as a vehicle. The key innovation is expanding the prompt and task presented to GPT-4 to provide License to speculate when unsure and Opportunity to quantify and explain its uncertainty (L&O). This approach improves accuracy and provides usable confidence measures (0.759 AUC) with no additional machinery.
    
[^46]: 使用多头图结构学习与梯度加权图注意力解释的静息状态EEG多头图结构学习帕金森病检测

    Parkinson's Disease Detection from Resting State EEG using Multi-Head Graph Structure Learning with Gradient Weighted Graph Attention Explanations

    [https://arxiv.org/abs/2408.00906](https://arxiv.org/abs/2408.00906)

    本文提出了一种基于静息状态EEG的新方法，使用多层感知机和梯度加权图注意力解释来检测帕金森病，旨在提高模型的可解释性和对复杂大脑连接的建模能力。

    

    arXiv:2408.00906v1 宣布类型: 交叉

    arXiv:2408.00906v1 Announce Type: cross  Abstract: Parkinson's disease (PD) is a debilitating neurodegenerative disease that has severe impacts on an individual's quality of life. Compared with structural and functional MRI-based biomarkers for the disease, electroencephalography (EEG) can provide more accessible alternatives for clinical insights. While deep learning (DL) techniques have provided excellent outcomes, many techniques fail to model spatial information and dynamic brain connectivity, and face challenges in robust feature learning, limited data sizes, and poor explainability. To address these issues, we proposed a novel graph neural network (GNN) technique for explainable PD detection using resting state EEG. Specifically, we employ structured global convolutions with contrastive learning to better model complex features with limited data, a novel multi-head graph structure learner to capture the non-Euclidean structure of EEG data, and a head-wise gradient-weighted graph 
    
[^47]: 时序知识图异常检测方法及其可解释性

    Online Detection of Anomalies in Temporal Knowledge Graphs with Interpretability

    [https://arxiv.org/abs/2408.00872](https://arxiv.org/abs/2408.00872)

    AnoT通过将时序知识图转换成规则图，提供了一种易理解和可解释的在线异常检测方法，它可以适应知识更新的模式变化和语义漂移。

    

    时序知识图（TKGs）对于捕捉实体之间的演变关系非常宝贵，但往往充斥着噪声，因此需要强大的异常检测机制。现有的动态图异常检测方法在捕捉TKGs中节点和边类的丰富语义方面遇到挑战，而TKG嵌入方法的可解释性不足，削弱了异常检测的可靠性。此外，这些方法在适应因知识更新而导致的模式变化和语义漂移方面也表现不佳。为了解决这些挑战，我们引入了AnoT，一种针对TKG的高效可解释性在线异常检测方法。AnoT首先将TKG总结为一种新的规则图，从而能够在TKGs中灵活地推断出复杂的模式。当新的知识出现时，AnoT将它映射到规则图中的一个节点上，并递归地遍历规则图来推导出异常。

    arXiv:2408.00872v1 Announce Type: new  Abstract: Temporal knowledge graphs (TKGs) are valuable resources for capturing evolving relationships among entities, yet they are often plagued by noise, necessitating robust anomaly detection mechanisms. Existing dynamic graph anomaly detection approaches struggle to capture the rich semantics introduced by node and edge categories within TKGs, while TKG embedding methods lack interpretability, undermining the credibility of anomaly detection. Moreover, these methods falter in adapting to pattern changes and semantic drifts resulting from knowledge updates. To tackle these challenges, we introduce AnoT, an efficient TKG summarization method tailored for interpretable online anomaly detection in TKGs. AnoT begins by summarizing a TKG into a novel rule graph, enabling flexible inference of complex patterns in TKGs. When new knowledge emerges, AnoT maps it onto a node in the rule graph and traverses the rule graph recursively to derive the anomaly
    
[^48]: UniMoT：具有离散令牌表示的统一分子-文本语言模型

    UniMoT: Unified Molecule-Text Language Model with Discrete Token Representation

    [https://arxiv.org/abs/2408.00863](https://arxiv.org/abs/2408.00863)

    UniMoT是一种统一的分子-文本语言模型，通过使用基于向量量化的tokenizer，它在自回归模型中将分子转换成序列的分子令牌，实现分子与文本的高效集成。

    

    arXiv:2408.00863v1 Announce Type: cross  摘要：大型语言模型（LLMs）在各种任务中的显著成功推动研究社区扩展其能力到分子应用。然而，大多数分子LLMs使用基于适配器的架构，这些架构不平等地对待分子和文本模态，缺乏对分子模态的监督信号。为了解决这些问题，我们介绍了UniMoT，一个统一分子-文本LLM，采用基于tokenizer的架构，将分子令牌扩展到LLM的词汇中。具体来说，我们引入了一个基于向量量化（Vector Quantization）的tokenizer，其采用Q-Former来弥合分子与文本模态之间的差距。该tokenizer将分子转换为具有因果依赖关系的分子令牌序列，封装了分子和文本的高层信息。装备了这个tokenizer，UniMoT可以将分子和文本模态统一到共享令牌表示和自回归模型中，从而在分子和文本之间实现真正的集成。

    arXiv:2408.00863v1 Announce Type: cross  Abstract: The remarkable success of Large Language Models (LLMs) across diverse tasks has driven the research community to extend their capabilities to molecular applications. However, most molecular LLMs employ adapter-based architectures that do not treat molecule and text modalities equally and lack a supervision signal for the molecule modality. To address these issues, we introduce UniMoT, a Unified Molecule-Text LLM adopting a tokenizer-based architecture that expands the vocabulary of LLM with molecule tokens. Specifically, we introduce a Vector Quantization-driven tokenizer that incorporates a Q-Former to bridge the modality gap between molecule and text. This tokenizer transforms molecules into sequences of molecule tokens with causal dependency, encapsulating high-level molecular and textual information. Equipped with this tokenizer, UniMoT can unify molecule and text modalities under a shared token representation and an autoregressive
    
[^49]: UlRe-NeRF: 使用神经渲染的3D超声成像，通过超声反射方向参数化

    UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization

    [https://arxiv.org/abs/2408.00860](https://arxiv.org/abs/2408.00860)

    该模型通过将超声反射方向参数化和谐波编码与神经渲染结合，生成接近真实物理的3D超声图像，提高了图像质量和处理复杂反射的能力。

    

    arXiv:2408.00860v1 公告类型：新提交  摘要：三维超声成像在医疗诊断中广泛使用，是一项关键技术。然而，传统的三维超声成像方法存在固定分辨率、存储效率低、上下文连接不足等问题，导致在处理复杂的图像异常和反射特性时表现不佳。最近，基于NeRF（神经辐射场）的技术在视角合成和三维重建方面取得了显著进步，但在高清晰度超声成像方面仍有研究缺口。为了解决这些问题，我们提出了一种新的模型UlRe-NeRF，它将隐式的神经网络和显式的超声体绘制功能集成到一个超声神经渲染架构中。该模型包含了反射方向参数化和谐波编码，使用方向性MLP模块生成视角依赖的高频反射强度估计，以及一个空间MLP模块来估计整个空间内的反射强度变化，从而提高图像的质量和真实性。通过这项技术，UlRe-NeRF能够提供接近真实物理的3D ultrasound渲染，并且具有更高效的存储和更优的处理能力，尤其是在处理复杂反射和透视问题时。实验结果表明，UlRe-NeRF在各种复杂场景中的表现优于现有技术，为超声成像领域提供了新的解决方案。

    arXiv:2408.00860v1 Announce Type: new  Abstract: Three-dimensional ultrasound imaging is a critical technology widely used in medical diagnostics. However, traditional 3D ultrasound imaging methods have limitations such as fixed resolution, low storage efficiency, and insufficient contextual connectivity, leading to poor performance in handling complex artifacts and reflection characteristics. Recently, techniques based on NeRF (Neural Radiance Fields) have made significant progress in view synthesis and 3D reconstruction, but there remains a research gap in high-quality ultrasound imaging. To address these issues, we propose a new model, UlRe-NeRF, which combines implicit neural networks and explicit ultrasound volume rendering into an ultrasound neural rendering architecture. This model incorporates reflection direction parameterization and harmonic encoding, using a directional MLP module to generate view-dependent high-frequency reflection intensity estimates, and a spatial MLP mod
    
[^50]: Y 社交：基于 LLMs 的社交媒体数字双胞胎

    Y Social: an LLM-powered Social Media Digital Twin

    [https://arxiv.org/abs/2408.00818](https://arxiv.org/abs/2408.00818)

    Y 社交是一个使用最新自然语言处理技术的社交媒体数字双胞胎，它能够模拟复杂的用户行为和在线平台的动态，为研究人员提供了宝贵的分析工具。

    

    我们介绍了一个新的数字双胞胎 Y，它旨在模拟一个在线社交平台。数字双胞胎是物理系统的虚拟复制品，用于进行高级分析和实验。在社交媒体的情况下，像 Y 这样的数字双胞胎提供了一种强大的工具，让研究人员能够模拟和理解复杂在线互动。Y 通过使用最先进的自然语言处理技术，可以复现复杂的用户行为，并准确地模拟用户互动、内容传播和网络动态。通过整合这些方面，Y 提供有关用户参与度、信息传播和平台政策影响的宝贵见解。此外，通过集成 LLMs，Y 能够生成复杂的文本内容和预测用户反应，有助于研究在线环境中的新兴现象。

    arXiv:2408.00818v1 Announce Type: new  Abstract: In this paper we introduce Y, a new-generation digital twin designed to replicate an online social media platform. Digital twins are virtual replicas of physical systems that allow for advanced analyses and experimentation. In the case of social media, a digital twin such as Y provides a powerful tool for researchers to simulate and understand complex online interactions. {\tt Y} leverages state-of-the-art Large Language Models (LLMs) to replicate sophisticated agent behaviors, enabling accurate simulations of user interactions, content dissemination, and network dynamics. By integrating these aspects, Y offers valuable insights into user engagement, information spread, and the impact of platform policies. Moreover, the integration of LLMs allows Y to generate nuanced textual content and predict user responses, facilitating the study of emergent phenomena in online environments.   To better characterize the proposed digital twin, in this
    
[^51]: 通过多目标深度强化学习方法适应性交通信号安全与效率改进

    Adaptive traffic signal safety and efficiency improvement by multi objective deep reinforcement learning approach

    [https://arxiv.org/abs/2408.00814](https://arxiv.org/abs/2408.00814)

    这项研究提出了一种新型的多目标深度强化学习方法，可以提高交通信号控制的安全性和效率，并减少碳排放，特别是在动态交通条件下性能更佳，显示了其广阔的实用前景。

    

    这项研究通过利用多目标深度强化学习技术提出了一种适应性交通信号控制（ATSC）的创新方法。该方案旨在提高路口控制策略的同时，同时解决安全性、效率和脱碳化三个目标。传统的ATSC方法通常优先考虑交通效率，并且在适应实时动态交通条件时往往遇到困难。为了解决这些问题，本研究提出了一种基于Dueling Double Deep Q Network（D3QN）框架的DRL-based ATSC算法。该算法在中国的长沙的一个模拟路口的表现被评估。值得注意的是，与传统的ATSC和单纯优化效率的ATSC算法相比，提出的ATSC算法通过实现交通事故减少了16%和二氧化碳排放减少了4%，突出了其优越性。此外，算法还能在变化多端的交通条件下保持稳定的性能，表明其有广泛的应用前景。

    arXiv:2408.00814v1 Announce Type: cross  Abstract: This research introduces an innovative method for adaptive traffic signal control (ATSC) through the utilization of multi-objective deep reinforcement learning (DRL) techniques. The proposed approach aims to enhance control strategies at intersections while simultaneously addressing safety, efficiency, and decarbonization objectives. Traditional ATSC methods typically prioritize traffic efficiency and often struggle to adapt to real-time dynamic traffic conditions. To address these challenges, the study suggests a DRL-based ATSC algorithm that incorporates the Dueling Double Deep Q Network (D3QN) framework. The performance of this algorithm is assessed using a simulated intersection in Changsha, China. Notably, the proposed ATSC algorithm surpasses both traditional ATSC and ATSC algorithms focused solely on efficiency optimization by achieving over a 16% reduction in traffic conflicts and a 4% decrease in carbon emissions. Regarding tr
    
[^52]: ChipExpert：开放源代码的集成电路设计专用大型语言模型

    ChipExpert: The Open-Source Integrated-Circuit-Design-Specific Large Language Model

    [https://arxiv.org/abs/2408.00804](https://arxiv.org/abs/2408.00804)

    ChipExpert是专门为集成电路设计领域设计的开放源代码大型语言模型，旨在解决该领域的专业知识和高门槛问题。

    

    arXiv:2408.00804v1 宣布类型：交叉  摘要：集成电路（IC）设计领域具有高度的专业性，为入门和研究开发带来了重大挑战。虽然大型语言模型（LLMs）在各种领域取得了显着的成功，但现有的LLMs往往无法满足学生、工程师和研究人员在IC设计领域的特定需求。因此，LLMs在IC设计领域中的潜力大部分仍未被开发。为了解决这些问题，我们介绍了ChipExpert，这是第一个针对IC设计领域的开放源代码教育型LLM。ChipExpert是在当前最佳开源基础模型（Llama-3 8B）上训练的。整个训练过程包括几个关键阶段，包括数据准备、继续预训练、指令指导的有监督微调和偏好对齐以及评估。在数据准备阶段，我们通过手动选择和人工注释创建了多个高质量的定制数据集。我们还包括了一个包含真实世界设计挑战的交互式问答数据集以及一个IC设计案例研究。在继续预训练阶段，我们使用Karel逻辑推理任务来集成IC设计的语言漫游能力。在指令指导的有监督微调阶段，我们开发了包含多个IC设计相关任务的精调数据集。在偏好对齐阶段，我们应用了偏置校正来提高ChipExpert在IC设计相关任务上的性能。最后，我们通过与工业领域的工程师合作进行了一系列的评估实验，以确保LLM能够准确地处理真实世界的IC设计问题。我们相信，通过开放源代码和定制化的LLM，将进一步促进IC设计领域的研究和教育。

    arXiv:2408.00804v1 Announce Type: cross  Abstract: The field of integrated circuit (IC) design is highly specialized, presenting significant barriers to entry and research and development challenges. Although large language models (LLMs) have achieved remarkable success in various domains, existing LLMs often fail to meet the specific needs of students, engineers, and researchers. Consequently, the potential of LLMs in the IC design domain remains largely unexplored. To address these issues, we introduce ChipExpert, the first open-source, instructional LLM specifically tailored for the IC design field. ChipExpert is trained on one of the current best open-source base model (Llama-3 8B). The entire training process encompasses several key stages, including data preparation, continue pre-training, instruction-guided supervised fine-tuning, preference alignment, and evaluation. In the data preparation stage, we construct multiple high-quality custom datasets through manual selection and d
    
[^53]: 元因分析在(微)服务中的全面调查：方法论、挑战和趋势

    A Comprehensive Survey on Root Cause Analysis in (Micro) Services: Methodologies, Challenges, and Trends

    [https://arxiv.org/abs/2408.00803](https://arxiv.org/abs/2408.00803)

    本论文调查了在微服务中识别和解决复杂依赖和传播性故障挑战的根本原因分析(RCA)技术，强调了快速恢复和维护系统稳定性的重要性。

    

    arXiv:2408.00803v1 公告类型：交叉  摘要：微服务中的复杂依赖关系和传播性故障特性，这些服务以其密集的网络互联特性为标志，在确定问题的根本原因方面提出了巨大的挑战。迅速识别和解决破坏性的问题对于确保快速恢复和维护系统稳定性至关重要。已经出现了一系列方法来应对这一挑战，这些方法主要集中在通过症状数据诊断故障。本调查旨在提供对微服务中元因分析(RCA)技术的全面、结构化回顾，探索包括度量、跟踪、日志和多模态数据在内的方法论。它深入探讨了微服务架构中的方法论、挑战和未来趋势。位于人工智能和自动化进步的最前沿，它为未来的研究方向提供了指导。

    arXiv:2408.00803v1 Announce Type: cross  Abstract: The complex dependencies and propagative faults inherent in microservices, characterized by a dense network of interconnected services, pose significant challenges in identifying the underlying causes of issues. Prompt identification and resolution of disruptive problems are crucial to ensure rapid recovery and maintain system stability. Numerous methodologies have emerged to address this challenge, primarily focusing on diagnosing failures through symptomatic data. This survey aims to provide a comprehensive, structured review of root cause analysis (RCA) techniques within microservices, exploring methodologies that include metrics, traces, logs, and multi-model data. It delves deeper into the methodologies, challenges, and future trends within microservices architectures. Positioned at the forefront of AI and automation advancements, it offers guidance for future research directions.
    
[^54]: 利用LLM推理增强个性化推荐系统

    Leveraging LLM Reasoning Enhances Personalized Recommender Systems

    [https://arxiv.org/abs/2408.00802](https://arxiv.org/abs/2408.00802)

    本研究利用LLM推理增强个性化推荐系统，证明了在零射程和微调设置中使用LLM推理能够提高任务质量。我们还提出了RecSAVER方法，这是一种自动评价LLM推理响应质量的工具。

    

    arXiv:2408.00802v1 通告类型：交叉  翻译：最近的技术进步显示了大语言模型(LLM)在执行推理任务方面的潜力，特别是在CoT(Chain-of-Thought，思想链)提示方面的应用。虽然像算术推理这样的任务涉及明确的、明确的答案和逻辑推理，LLM推理在推荐系统(RecSys)中的应用是一个未得到充分探索的领域。我们的研究探讨了几方面的问题，以更好地理解RecSys中的推理，并展示了在零射程和微调设置中使用LLM推理是如何提高任务质量的。此外，我们还提出了RecSAVER（推荐系统自动验证和评价推理），这是一种自动评估LLM推理响应质量的方法，无需使用经 curated 黄金参考或人类评分器。我们展示了

    arXiv:2408.00802v1 Announce Type: cross  Abstract: Recent advancements have showcased the potential of Large Language Models (LLMs) in executing reasoning tasks, particularly facilitated by Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve clear, definitive answers and logical chains of thought, the application of LLM reasoning in recommendation systems (RecSys) presents a distinct challenge. RecSys tasks revolve around subjectivity and personalized preferences, an under-explored domain in utilizing LLMs' reasoning capabilities. Our study explores several aspects to better understand reasoning for RecSys and demonstrate how task quality improves by utilizing LLM reasoning in both zero-shot and finetuning settings. Additionally, we propose RecSAVER (Recommender Systems Automatic Verification and Evaluation of Reasoning) to automatically assess the quality of LLM reasoning responses without the requirement of curated gold references or human raters. We show 
    
[^55]: 使用大型语言模型和领域特定标准的大语言模型对话式本体交互

    Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards

    [https://arxiv.org/abs/2408.00800](https://arxiv.org/abs/2408.00800)

    本研究提出了一个使用大型语言模型和领域特定标准的大语言模型对话式本体交互概念，能够将用户提问准确转化为SPARQL查询，有效防止了虚假信息的产生。

    

    本贡献介绍了一种概念，它使用大型语言模型（LLMs）和聊天机器人界面来增强本体论的SPARQL查询生成，从而为正式知识提供直观的访问途径。用户通过自然语言输入提问，系统将这些提问转换成准确的SPARQL查询，这些查询严格查询本体论的内容，防止由LLM带来的虚假信息或虚构内容。为了提高结果的质量和准确性，将来自领域特定标准的额外文本信息整合到本体论中，以便对它的概念和关系进行精确描述。一项实验研究评估了生成的SPARQL查询的准确性，揭示了使用LLMs查询本体论的显著优势，并强调了未来研究的重点领域。

    arXiv:2408.00800v1 Announce Type: cross  Abstract: The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An experimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research.
    
[^56]: Golden-Retriever: 高保真能动性检索增强生成在工业知识库中的应用

    Golden-Retriever: High-Fidelity Agentic Retrieval Augmented Generation for Industrial Knowledge Base

    [https://arxiv.org/abs/2408.00798](https://arxiv.org/abs/2408.00798)

    一种名为Golden-Retriever的系统被设计用来增强工业知识库的检索效率，通过推敲式的查询增强和明确的上下文解释，提升了RAG框架的检索准确性。

    

    arXiv:2408.00798v1 公告类型: 交叉 摘要: 本文介绍了Golden-Retriever，旨在高效地导航庞大的工业知识库，克服了通用语言模型微调和基于检索的生成(RAG)框架在特定领域术语和上下文解释方面的传统挑战。Golden-Retriever在文档检索前实施了一种基于反思的查询增强步骤，该步骤涉及识别输入问题中的术语、基于上下文澄清其意义，并在增强查询之前列出所有术语和缩写。我们的方法特别涉及从输入问题中提取和列出所有的术语和缩写、确定与之相符的上下文以及从预定义的术语典中为每项寻求扩展的定义和描述。这种全面的增强确保了RAG框架通过提供清晰的上下文和解释迷惑情境，能够检索到最相关的文档，从而显著提高了检索的准确性。在三个开放源代码的大语言模型上进行的评估，使用了一个特定领域的问答数据集。我们的方法在控制样本集上的搜索准确性得分上获得了明显优势，尤其是在军事和工业语言应用方面，这是因为在监控数据集中，查询弱的领域感被直接转化为增qq强问题对原始查询的良好响应。整体上，Golden-Retriever在数量较多的样本集上也获得了最高性能，实验结果再次验证了我们的方法在工业知识检索和问答方面的有效性以及它在持续纳入新发现的领域术语方面的扩展性。

    arXiv:2408.00798v1 Announce Type: cross  Abstract: This paper introduces Golden-Retriever, designed to efficiently navigate vast industrial knowledge bases, overcoming challenges in traditional LLM fine-tuning and RAG frameworks with domain-specific jargon and context interpretation. Golden-Retriever incorporates a reflection-based question augmentation step before document retrieval, which involves identifying jargon, clarifying its meaning based on context, and augmenting the question accordingly. Specifically, our method extracts and lists all jargon and abbreviations in the input question, determines the context against a pre-defined list, and queries a jargon dictionary for extended definitions and descriptions. This comprehensive augmentation ensures the RAG framework retrieves the most relevant documents by providing clear context and resolving ambiguities, significantly improving retrieval accuracy. Evaluations using three open-source LLMs on a domain-specific question-answer d
    
[^57]: CCSRP: 通过协作共进化法实现突触神经网络稳健修剪

    CCSRP: Robust Pruning of Spiking Neural Networks through Cooperative Coevolution

    [https://arxiv.org/abs/2408.00794](https://arxiv.org/abs/2408.00794)

    通过协作共进化，本研究提出了一种稳健的SNN剪枝方法，旨在在不牺牲准确性与鲁棒性的前提下，减少计算资源需求。

    

    arXiv:2408.00794v1 宣布类型：交叉 摘要：脉冲神经网络（SNNs）在各种动态视觉任务中显示了潜力，但那些适合实际部署的通常缺乏在资源受限和关键安全环境中所需的紧凑性和鲁棒性。先前的工作主要集中在通过网络剪枝和对抗性训练等策略来提高人工神经网络的紧凑性或鲁棒性，而对于SNNs的类似方法研究甚少。稳健修剪突触神经网络的目标是减少计算开销同时保持准确性及鲁棒性。现有的稳健修剪方法通常需要专家知识和反复试验来确定合适的剪枝标准或辅助模块，因此限制了它们更广泛的适用性。同时，进化算法（EAs）已经被应用来自动化人工神经网络的剪枝，获得了显著的成果，但超出了剪枝标准或辅助模块的选择自动化。

    arXiv:2408.00794v1 Announce Type: cross  Abstract: Spiking neural networks (SNNs) have shown promise in various dynamic visual tasks, yet those ready for practical deployment often lack the compactness and robustness essential in resource-limited and safety-critical settings. Prior research has predominantly concentrated on enhancing the compactness or robustness of artificial neural networks through strategies like network pruning and adversarial training, with little exploration into similar methodologies for SNNs. Robust pruning of SNNs aims to reduce computational overhead while preserving both accuracy and robustness. Current robust pruning approaches generally necessitate expert knowledge and iterative experimentation to establish suitable pruning criteria or auxiliary modules, thus constraining their broader application. Concurrently, evolutionary algorithms (EAs) have been employed to automate the pruning of artificial neural networks, delivering remarkable outcomes yet overloo
    
[^58]: 使用神经网络加速遗传算法改进预灾规划的航空机动性

    Improving Air Mobility for Pre-Disaster Planning with Neural Network Accelerated Genetic Algorithm

    [https://arxiv.org/abs/2408.00790](https://arxiv.org/abs/2408.00790)

    本研究提出了一种新的遗传算法框架，通过神经网络加速机场运营计划的优化，以应对天气灾害的紧急疏散需求，即使是在数据有限的情况下也能有效提高疏散效率。

    

    arXiv:2408.00790v1 公告类型：交叉 摘要：天气灾害相关的紧急操作对航空机动性造成了巨大的挑战，尤其是在影响逐渐临近的时候，尤其是在影响逐渐临近的时候，尤其是在影响逐渐临近的时候，对飞机和机场操作尤其如此。我们提出了一种调整机场运营计划的优化框架，以应对这种预灾情况。首先，我们从多个机场汇总会运营数据，然后确定最多撤离航班的数量，以最大限度地提高受影响机场的发出能力，同时不阻碍常规航空交通。我们提出了一个新型的神经网络（NN）加速遗传算法（GA）用于疏散规划。我们的实验表明，整合虽然提供了与较小计算开销的相似结果。我们发现，在不缩小种群规模的情况下，使用神经网络能够提高遗传算法的效率，甚至在模型在来自不同机场的数据上进行训练后也同样有效。

    arXiv:2408.00790v1 Announce Type: cross  Abstract: Weather disaster related emergency operations pose a great challenge to air mobility in both aircraft and airport operations, especially when the impact is gradually approaching. We propose an optimized framework for adjusting airport operational schedules for such pre-disaster scenarios. We first, aggregate operational data from multiple airports and then determine the optimal count of evacuation flights to maximize the impacted airport's outgoing capacity without impeding regular air traffic. We then propose a novel Neural Network (NN) accelerated Genetic Algorithm(GA) for evacuation planning. Our experiments show that integration yielded comparable results but with smaller computational overhead. We find that the utilization of a NN enhances the efficiency of a GA, facilitating more rapid convergence even when operating with a reduced population size. This effectiveness persists even when the model is trained on data from airports d
    
[^59]: 是否信任：机器学习的信仰飞跃

    Whether to trust: the ML leap of faith

    [https://arxiv.org/abs/2408.00786](https://arxiv.org/abs/2408.00786)

    本文提出了一种创新方法，通过辨识和测量用户信任机器学习时的信仰飞跃，直接在机器学习中构建内在信任。

    

    arXiv:2408.00786v1 公告类型：交叉  翻译摘要：对于可信赖的人工智能采纳来说，信任至关重要。信任通常被理解为一种态度，但我们无法准确测量它，也不能对其进行管理。我们将对整个系统的信任与机器学习（ML）及其组成部件的信任混为一谈；因此，大多数用户在信任机器学习时所做的信仰飞跃往往不被理解。当前构建信任的努力解释了ML的过程，这对非ML专家来说可能难以理解，因为这个过程很复杂，而且解释与他们自己未表达的思维模型无关。我们提出了一种创新的方法，直接在ML中构建内在信任，通过辨识和测量用户信任ML时的信仰飞跃（Leap of Faith，LoF）。我们的LoF矩阵识别出ML模型与用户自身思维模型的匹配情况。通过将用户的原始数据和目标函数同时输入到ML模型中以及一个经过专家验证的规则为基础的AI模型中，我们可以严格但实际地识别这种匹配。这种匹配是基于对输入数据的内部逻辑一致性的审查，并使用专家确定的规则作为校准点。通过将用户的反馈与这些校准点进行比较，我们可以推断出用户对ML模型的信任程度。正如我们所定义的，信任意味着在没有充分了解模型内部工作原理的情况下，用户愿意接受模型输出作为决策依据。

    arXiv:2408.00786v1 Announce Type: cross  Abstract: Human trust is critical for trustworthy AI adoption. Trust is commonly understood as an attitude, but we cannot accurately measure this, nor manage it. We conflate trust in the overall system, ML, and ML's component parts; so most users do not understand the leap of faith they take when they trust ML. Current efforts to build trust explain ML's process, which can be hard for non-ML experts to comprehend because it is complex, and explanations are unrelated to their own (unarticulated) mental models. We propose an innovative way of directly building intrinsic trust in ML, by discerning and measuring the Leap of Faith (LoF) taken when a user trusts ML. Our LoF matrix identifies where an ML model aligns to a user's own mental model. This match is rigorously yet practically identified by feeding the user's data and objective function both into an ML model and an expert-validated rules-based AI model, a verified point of reference that can 
    
[^60]: 深度分析通过知识驱动的大型语言模型进行情绪识别

    In-Depth Analysis of Emotion Recognition through Knowledge-Based Large Language Models

    [https://arxiv.org/abs/2408.00780](https://arxiv.org/abs/2408.00780)

    本研究提出了一种结合情绪识别方法和贝叶斯线索整合的方法，利用大型语言模型获得的情境知识来提高在社交情境中分析面部表情的准确性，并在囚徒困境这一社会任务中得到了验证。

    

    arXiv:2408.00780v1 公告类型：交叉 摘要：社交情境中的情绪识别是一项复杂的工作，它需要整合面部表情和情境上下文的信息。尽管自动情绪识别的传统方法专注于脱情境的信号，但最近的研究强调了情境在塑造情绪感知中的重要性。本文对新兴的社会情境下的情绪识别这一领域做出了贡献，通过心理学的情绪感知理论来指导自动方法的设计。我们提出了一个结合了情绪识别方法和贝叶斯线索整合（BCI）的方法，以整合面部表情的脱情境信息和通过大型语言模型获得的情境知识。我们在囚徒困境这一社会任务的情境下测试了这个方法。我们的结果在各种主观情感评估测试中对BCI提供了明确的支撑。

    arXiv:2408.00780v1 Announce Type: cross  Abstract: Emotion recognition in social situations is a complex task that requires integrating information from both facial expressions and the situational context. While traditional approaches to automatic emotion recognition have focused on decontextualized signals, recent research emphasizes the importance of context in shaping emotion perceptions. This paper contributes to the emerging field of context-based emotion recognition by leveraging psychological theories of human emotion perception to inform the design of automated methods. We propose an approach that combines emotion recognition methods with Bayesian Cue Integration (BCI) to integrate emotion inferences from decontextualized facial expressions and contextual knowledge inferred via Large-language Models. We test this approach in the context of interpreting facial expressions during a social task, the prisoner's dilemma. Our results provide clear support for BCI across a range of au
    
[^61]: 前端扩散：通过抽象到详细任务过渡探索意图驱动的用户界面

    Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions

    [https://arxiv.org/abs/2408.00778](https://arxiv.org/abs/2408.00778)

    本文提出Frontend Diffusion工具，旨在通过用户的草图和端到端语言模型实现从抽象意图到详细网页的生成过程。

    

    arXiv:2408.00778v1 公告类型：交叉

    arXiv:2408.00778v1 Announce Type: cross  Abstract: The emergence of Generative AI is catalyzing a paradigm shift in user interfaces from command-based to intent-based outcome specification. In this paper, we explore abstract-to-detailed task transitions in the context of frontend code generation as a step towards intent-based user interfaces, aiming to bridge the gap between abstract user intentions and concrete implementations. We introduce Frontend Diffusion, an end-to-end LLM-powered tool that generates high-quality websites from user sketches. The system employs a three-stage task transition process: sketching, writing, and coding. We demonstrate the potential of task transitions to reduce human intervention and communication costs in complex tasks. Our work also opens avenues for exploring similar approaches in other domains, potentially extending to more complex, interdependent tasks such as video production.
    
[^62]: 通过自然语言处理和统计分析解码人工智能和人类作者的写作：揭示的语言微妙差异

    Decoding AI and Human Authorship: Nuances Revealed Through NLP and Statistical Analysis

    [https://arxiv.org/abs/2408.00769](https://arxiv.org/abs/2408.00769)

    该研究揭示了人工智能与人“更高的总字数、复杂性和多样性”撰写者在语言表达上的微妙差异，并突出展示了AI在特定语言模式和句子结构上的独特一致性。

    

    arXiv:2408.00769v1 公告类型：交叉 摘要：这项研究探讨了由人工智能和人类撰写的文本之间的微妙差异，旨在阐明人工智能和人类如何表达语言。通过全面的数据统计分析，研究调查了文本中的各种语言特征、创造力和潜在的人类和AI撰写的文本中的偏差。这项研究的重要性在于它对理解AI的创造能力和其对文学、交流和社会框架的影响做出了贡献。通过精心策划的数据集，包含跨越各种主题和流派的500K篇论文，这些论文是由大型语言模型生成的，或由人类撰写，该研究揭示了语言表达的深层次以及AI和人类文本创作的认知过程。分析发现，人类撰写的论文通常在总单词数上比AI生成的要多，并且展现了更高的复杂性和多样性。此外，研究还指出，AI在某些特定的语言模式和句式使用上表现出一致性，这与人类的写作风格存在差异。这些发现有助于我们更好地理解人工智能在文学创作中的作用，以及它在未来可能对人类写作方式产生的变革。论文的结论强调了进一步研究AI写作特性和人类认知过程之间的差异的必要性。

    arXiv:2408.00769v1 Announce Type: cross  Abstract: This research explores the nuanced differences in texts produced by AI and those written by humans, aiming to elucidate how language is expressed differently by AI and humans. Through comprehensive statistical data analysis, the study investigates various linguistic traits, patterns of creativity, and potential biases inherent in human-written and AI- generated texts. The significance of this research lies in its contribution to understanding AI's creative capabilities and its impact on literature, communication, and societal frameworks. By examining a meticulously curated dataset comprising 500K essays spanning diverse topics and genres, generated by LLMs, or written by humans, the study uncovers the deeper layers of linguistic expression and provides insights into the cognitive processes underlying both AI and human-driven textual compositions. The analysis revealed that human-authored essays tend to have a higher total word count on
    
[^63]: 使用空间 filling curves 对比光流和深度学习实现计算高效的交通事件检测

    Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves

    [https://arxiv.org/abs/2408.00768](https://arxiv.org/abs/2408.00768)

    本文提出了一种结合光流、深度学习和空间填满曲线的框架，实现了对车辆前向摄像头捕获的视频数据中交通事件的实时、高效检测。该框架有助于为驾驶员或自动驾驶车辆提供实时反馈，识别前方道路潜在的威胁或突发事件，提高驾驶情况感知，并可能提高安全性。

    

    我们面临着在视频、雷达和激光雷达等交通数据中识别事件和收集数据的挑战，这对评价感知系统的性能至关重要。这类数据通常是无结构的、多模态的、时间序列的，且缺乏元数据或注释。本文比较了光流和深度学习在视频数据（来自车辆前向摄像头）中实现计算高效的交通事件检测的能力。我们的方法是利用车辆周围光流场的干扰来发现潜在的事件，而另一种方法是通过训练深度学习模型预测驾驶员的视线，以预测潜在事件的位置。我们将这些结果输送到空间填满曲线上，以降低维度并实现计算上的效率。我们通过标准的实验，针对在不同场景下检测事件的有效性，验证了本概念的效力。计算效率的评估取决于算法的执行时间，总内存消耗以及空间解构的时间。结果表明，本概念所展示的算法可以比传统的基于光流的方法更快地找到事件，并且能够在达到良好的检测精度时，更快地完成计算密集型操作。Our approach is designed to serve as an early warning or an auxiliary system that can provide real-time feedback to drivers or autonomous vehicles by identifying potential hazards or sudden events in the road ahead, improving situational awareness and potentially enhancing safety. In summary, this paper presents a novel framework for computationally efficient traffic event detection, which relies on optical flow, deep learning, and space-filling curves, offering a promising solution for the autonomous driving industry to achieve real-time event detection with minimal computational resources.

    arXiv:2408.00768v1 Announce Type: new  Abstract: Gathering data and identifying events in various traffic situations remains an essential challenge for the systematic evaluation of a perception system's performance. Analyzing large-scale, typically unstructured, multi-modal, time series data obtained from video, radar, and LiDAR is computationally demanding, particularly when meta-information or annotations are missing. We compare Optical Flow (OF) and Deep Learning (DL) to feed computationally efficient event detection via space-filling curves on video data from a forward-facing, in-vehicle camera. Our first approach leverages unexpected disturbances in the OF field from vehicle surroundings; the second approach is a DL model trained on human visual attention to predict a driver's gaze to spot potential event locations. We feed these results to a space-filling curve to reduce dimensionality and achieve computationally efficient event retrieval. We systematically evaluate our concept b
    
[^64]: SentenceVAE：通过下一个句子预测为大型语言模型提供更快、更长和更准确的推理

    SentenceVAE: Faster, Longer and More Accurate Inference with Next-sentence Prediction for Large Language Models

    [https://arxiv.org/abs/2408.00655](https://arxiv.org/abs/2408.00655)

    SentenceVAE是一种创新的模型，它通过将大型语言模型的推理过程改为由句子逐个处理的策略，大幅提高了这些模型的推理速度和准确性。

    

    arXiv:2408.00655v2 公告类型：替换  摘要：现代大型语言模型（LLM）主要依靠下一个token预测方法进行推理，这严重阻碍了它们的处理速度。在这项研究中，我们提出了一种新的推理方法，称为下一个句子预测，旨在提高LLM的推理效率。我们介绍了句式变分自动编码器（SentenceVAE），这是一个由句式编码器和句式解码器组成的tiny模型。编码器能够有效地将句子中的信息压缩成一个单一的代币，而解码器重建这个压缩的数据，使其恢复到原始的句子形式。通过将SentenceVAE集成到LLM的输入和输出层中，我们开发了句子级别的LLM（Sentence-level LLMs, SLLMs），这些模型采用了一种按句子处理的推理方法，显著提高了推理速度。SentenceVAE还通过将文本分割成句子，保持了原始语义内容的完整性，因此提高了推理的准确性和流畅性。

    arXiv:2408.00655v2 Announce Type: replace  Abstract: Contemporary large language models (LLMs) primarily rely on next-token prediction method for inference, which significantly impedes their processing speed. In this paper, we introduce a novel inference methodology termed next-sentence prediction, aimed at enhancing the inference efficiency of LLMs. We present Sentence Variational Autoencoder (SentenceVAE), a tiny model consisting of a Sentence Encoder and a Sentence Decoder. The encoder effectively condenses the information within a sentence into a singular token, while the decoder reconstructs this compressed data back into its original sentential form. By integrating SentenceVAE into the input and output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a sentence-by-sentence inference approach, markedly accelerating inference speeds. SentenceVAE also maintains the integrity of the original semantic content by segmenting the text into sentences, thereby improving a
    
[^65]: 基于多视图数据融合的 conformal 轨迹预测在合作驾驶中的应用

    Conformal Trajectory Prediction with Multi-View Data Integration in Cooperative Driving

    [https://arxiv.org/abs/2408.00374](https://arxiv.org/abs/2408.00374)

    V2INet 提出了一个创新的端到端训练框架，用于结合多角度信息进行轨迹预测，以克服单一视角的局限性，提高校正后的多模态轨迹预测的性能。

    

    arXiv:2408.00374v2 Announce Type: replace-cross 摘要: 目前关于轨迹预测的研究主要依赖于车载传感器收集的数据。随着连接的快速发展，如车对车（V2V）和车对基础设施（V2I）通信，通过无线网络收集的有价值的信息变得可用。多视图信息的集成有潜力克服仅从单一视角收集数据的内在局限性，如遮挡和有限视野。在本工作中，我们介绍了 V2INet，一个新颖的轨迹预测框架，旨在通过扩展现有单一视图模型来建模多视图数据。与以前的方法不同，我们的模型支持端到端训练，增强了模型的灵活性和性能。此外，预测的多模态轨迹得到了校正，以：

    arXiv:2408.00374v2 Announce Type: replace-cross  Abstract: Current research on trajectory prediction primarily relies on data collected by onboard sensors of an ego vehicle. With the rapid advancement in connected technologies, such as vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communication, valuable information from alternate views becomes accessible via wireless networks. The integration of information from alternative views has the potential to overcome the inherent limitations associated with a single viewpoint, such as occlusions and limited field of view. In this work, we introduce V2INet, a novel trajectory prediction framework designed to model multi-view data by extending existing single-view models. Unlike previous approaches where the multi-view data is manually fused or formulated as a separate training stage, our model supports end-to-end training, enhancing both flexibility and performance. Moreover, the predicted multimodal trajectories are calibrated 
    
[^66]: Gemma 2: 提高实用规模开放语言模型的性能

    Gemma 2: Improving Open Language Models at a Practical Size

    [https://arxiv.org/abs/2408.00118](https://arxiv.org/abs/2408.00118)

    Gemma 2是Gemma系列中新型轻量级开放模型，通过改进Transformer架构和应用蒸馏知识培训，在20亿和90亿参数规模上表现最佳。

    

    arXiv:2408.00118v2 公告类型: 替换交叉摘要：在本工作中，我们介绍了Gemma 2，Gemma家族的一个新的轻量级、最先进的开源模型系列，参数规模从20亿到270亿不等。在本版本中，我们向Transformer架构应用了几项已知的技术改进，如布雷特吉等人（2020a）提出的本地-全局注意力交叉和埃辛等人（2023）提出的组查询注意力。我们还使用蒸馏知识（Hinton et al.，2015）而不是接下来预测的方式训练了2亿和90亿参数的模型。结果模型在它们的规模上提供了最佳的性能，甚至为比它们大2-3倍的模型提供了竞争性的替代方案。我们将所有模型发布给了社区。

    arXiv:2408.00118v2 Announce Type: replace-cross  Abstract: In this work, we introduce Gemma 2, a new addition to the Gemma family of lightweight, state-of-the-art open models, ranging in scale from 2 billion to 27 billion parameters. In this new version, we apply several known technical modifications to the Transformer architecture, such as interleaving local-global attentions (Beltagy et al., 2020a) and group-query attention (Ainslie et al., 2023). We also train the 2B and 9B models with knowledge distillation (Hinton et al., 2015) instead of next token prediction. The resulting models deliver the best performance for their size, and even offer competitive alternatives to models that are 2-3 times bigger. We release all our models to the community.
    
[^67]: 研究用户原型以及在评分网上的讨论

    Characterizing User Archetypes and Discussions on Scored.co

    [https://arxiv.org/abs/2407.21753](https://arxiv.org/abs/2407.21753)

    本研究开发了一个多维框架来分析极右翼社交平台“评分网”上的用户类型和互动，揭示了平台用户特征、活跃度、讨论内容和社区成员的行为

    

    arXiv:2407.21753v1 公告类型：交叉  摘要：近年来，社交媒体平台的普及极大地改变了个人互动、组织和分享信息的方式。在这种背景下，我们见证了互动规模和复杂性的急剧增加，同时对一些边缘社交平台的研究却少之又少。在本研究中，我们提出了一个多维框架，用于在关注度不高的极右翼平台“评分网”上研究节点和超边。我们的方法整合了对更高阶互动的可能性研究，得益于超网络表示，并考虑了节点特征，如用户活跃度、情感和毒性，旨在定义不同类型的用户原型并了解其在网络中的作用。利用评分网的大量数据，我们分析了这些原型随时间的变化，并探讨了它们之间的互动及其影响力。通过我们的方法，我们揭示了该平台上的用户特征、活跃度、讨论内容和社区成员的行为，为相关领域提供了深刻的见解

    arXiv:2407.21753v1 Announce Type: cross  Abstract: In recent years, the proliferation of social platforms has drastically transformed the way individuals interact, organize, and share information. In this scenario, we experience an unprecedented increase in the scale and complexity of interactions and, at the same time, little to no research about some fringe social platforms. In this paper, we present a multi-dimensional framework for characterizing nodes and hyperedges in social hypernetworks, with a focus on the understudied alt-right platform Scored.co. Our approach integrates the possibility of studying higher-order interactions, thanks to the hypernetwork representation, and various node features such as user activity, sentiment, and toxicity, with the aim to define distinct user archetypes and understand their roles within the network. Utilizing a comprehensive dataset from Scored.co, we analyze the dynamics of these archetypes over time and explore their interactions and influe
    
[^68]: 加拿大非营利性融入领域面临的新来者面临的整合作用广义用途LLM的社会和伦理风险

    Social and Ethical Risks Posed by General-Purpose LLMs for Settling Newcomers in Canada

    [https://arxiv.org/abs/2407.20240](https://arxiv.org/abs/2407.20240)

    本文讨论了加拿大非营利性融入领域面临的新来者面临的生成AI潜在风险，并建议加强相关研究与开发以促进AI教育和定制化LLM技术与服务提供者相应地对接。

    

    arXiv:2407.20240v2  通告类型：替換交叉链接

    arXiv:2407.20240v2 Announce Type: replace-cross  Abstract: The non-profit settlement sector in Canada supports newcomers in achieving successful integration. This sector faces increasing operational pressures amidst rising immigration targets, which highlights a need for enhanced efficiency and innovation, potentially through reliable AI solutions. The ad-hoc use of general-purpose generative AI, such as ChatGPT, might become a common practice among newcomers and service providers to address this need. However, these tools are not tailored for the settlement domain and can have detrimental implications for immigrants and refugees. We explore the risks that these tools might pose on newcomers to first, warn against the unguarded use of generative AI, and second, to incentivize further research and development in creating AI literacy programs as well as customized LLMs that are aligned with the preferences of the impacted communities. Crucially, such technologies should be designed to in
    
[^69]: 论文标题 ： 《通过自我推理改进检索增强的语言模型》

    Improving Retrieval Augmented Language Model with Self-Reasoning

    [https://arxiv.org/abs/2407.19813](https://arxiv.org/abs/2407.19813)

    本文提出了一种自我推理框架，旨在改进检索增强的语言模型的可靠性和可追溯性，通过在生成过程中整合外部知识，减少无帮助或误导性响应的产生，并改善模型的透明度和可信度。

    

    

    arXiv:2407.19813v2 Announce Type: replace-cross  Abstract: The Retrieval-Augmented Language Model (RALM) has shown remarkable performance on knowledge-intensive tasks by incorporating external knowledge during inference, which mitigates the factual hallucinations inherited in large language models (LLMs). Despite these advancements, challenges persist in the implementation of RALMs, particularly concerning their reliability and traceability. To be specific, the irrelevant document retrieval may result in unhelpful response generation or even deteriorate the performance of LLMs, while the lack of proper citations in generated outputs complicates efforts to verify the trustworthiness of the models. To this end, we propose a novel self-reasoning framework aimed at improving the reliability and traceability of RALMs, whose core idea is to leverage reasoning trajectories generated by the LLM itself. The framework involves constructing self-reason trajectories with three processes: a relevan
    
[^70]: "一个好的机器人总是知道其局限性": 通过因子化的自我自信量度评估自主系统的决策能力

    "A Good Bot Always Knows Its Limitations": Assessing Autonomous System Decision-making Competencies through Factorized Machine Self-confidence

    [https://arxiv.org/abs/2407.19631](https://arxiv.org/abs/2407.19631)

    通过创建自评估系统能力的新框架，科学家们寻求提高自主系统的决策透明度和可靠性。

    

    arXiv:2407.19631v2 宣布类型: 替换跨栏摘要: 智能机器如何评估其在完成任务方面的能力？这个问题对于在不确定性下算法性 reasoning 的自主系统来说是焦点。在这里，提出智能机器的自我自信——一种基于对世界的状态、自己的知识和执行任务的能力的自我评估，是一种计算不可行的有用能力指标。本文提出了一种计算框架，称为因子化的自我自信（Factorized Machine Self-confidence, FaMSeC），为算法决策过程提供了一个全面、工程导向的描述，包括：结果评估、求解器质量、模型质量、对齐质量和过去的经验。在FaMSeC中，自我自信指标是从层次构建的，这些指标不仅能够告知系统内部的知识和能力，也能在跨系统之间进行自我沟通，进而提高了系统的决策质量的沟通和教育，并对于设计和构建更加可信和可靠的自主系统具有重要意义。

    arXiv:2407.19631v2 Announce Type: replace-cross  Abstract: How can intelligent machines assess their competencies in completing tasks? This question has come into focus for autonomous systems that algorithmically reason and make decisions under uncertainty. It is argued here that machine self-confidence - a form of meta-reasoning based on self-assessments of an agent's knowledge about the state of the world and itself, as well as its ability to reason about and execute tasks - leads to many eminently computable and useful competency indicators for such agents. This paper presents a culmination of work on this concept in the form of a computational framework called Factorized Machine Self-confidence (FaMSeC), which provides a holistic engineering-focused description of factors driving an algorithmic decision-making process, including: outcome assessment, solver quality, model quality, alignment quality, and past experience. In FaMSeC, self confidence indicators are derived from hierarch
    
[^71]: LLMs' Understanding of Natural Language Revealed

    LLMs' Understanding of Natural Language Revealed

    [https://arxiv.org/abs/2407.19630](https://arxiv.org/abs/2407.19630)

    本文揭示了LLMs语言理解能力的夸大。虽然LLMs能够生成连贯的语言，但其对语言的理解能力并未得到充分测试。Abstract中的操作表明，评估LLMs的语言理解能力需要辨识语言的语法结构并执行逻辑推理。

    

    arXiv:2407.19630v2 公告类型：替换 摘要：大规模语言模型（LLMs）是一项大规模的数据驱动倒置工程实验成果，旨在从底部向上对语言进行大规模的数据驱动反向工程。尽管LLMs在许多下游自然语言处理任务中显示出它们的效用，但大量的研究表明，LLMs在执行需要对符号变量进行量化和操作的任务方面是无能为力的，例如计划和问题解决。具体来说，我们在本文档中将重点测试LLMs的语言理解能力，这是它们的专长。正如我们将要展示的那样，LLMs的语言理解能力已经被广泛地夸大了。虽然LLMs已经被证明能够生成类似人类的连贯语言（因为这就是它们的设计方式），但它们的语言理解能力尚未被正确测试。特别是，我们认为应该通过执行一个操作来测试LLMs的语言理解能力，这个操作需要能够辨识和理解语言的语法结构，同时也能执行逻辑推理。

    arXiv:2407.19630v2 Announce Type: replace  Abstract: Large language models (LLMs) are the result of a massive experiment in bottom-up, data-driven reverse engineering of language at scale. Despite their utility in a number of downstream NLP tasks, ample research has shown that LLMs are incapable of performing reasoning in tasks that require quantification over and the manipulation of symbolic variables (e.g., planning and problem solving); see for example [25][26]. In this document, however, we will focus on testing LLMs for their language understanding capabilities, their supposed forte. As we will show here, the language understanding capabilities of LLMs have been widely exaggerated. While LLMs have proven to generate human-like coherent language (since that's how they were designed), their language understanding capabilities have not been properly tested. In particular, we believe that the language understanding capabilities of LLMs should be tested by performing an operation that 
    
[^72]: 与AI从业者和AI合规专家共同设计的AI影响评估报告模板

    Co-designing an AI Impact Assessment Report Template with AI Practitioners and AI Compliance Experts

    [https://arxiv.org/abs/2407.17374](https://arxiv.org/abs/2407.17374)

    本研究提出了一个基于欧盟AI法案和NIST框架的AI影响评估报告模板，并通过用户研究验证了其有效性。

    

    在AI监管日益发展的背景下，对于公司而言，进行影响评估并通过全面的报告文档其合规性至关重要。然而，目前报告往往缺乏对法规的深入理解，且通常只关注AI系统相关的隐私方面，而忽略了这些系统在实际使用中的广泛应用。此外，目前还没有系统地设计并评估这些报告，同时考虑AI从业者和AI合规专家的意见。为了填补这一空白，我们与14位AI从业者和6位AI合规专家经过反复的协同设计和评估，提出了一个基于欧盟AI法案、NIST的AI风险管理框架和ISO 42001 AI管理系统的AI影响评估报告模板。我们通过为一家大型科技公司的基于AI的会议伴侣生产一个影响评估报告，评估了该模板的效果。在该公司的8位AI从业者和具有相同背景的用户研究中，我们对报告的结构、内容和实用性进行了测试。用户对报告的结构和内容给予了积极评价，并且认为报告的实用性较高。这些结果为将来的影响评估报告设计提供了宝贵的反馈，并强调了与AI执法者和合规专家的合作对于确保报告的完整性和相关性的重要性。

    arXiv:2407.17374v2 Announce Type: replace-cross  Abstract: In the evolving landscape of AI regulation, it is crucial for companies to conduct impact assessments and document their compliance through comprehensive reports. However, current reports lack grounding in regulations and often focus on specific aspects like privacy in relation to AI systems, without addressing the real-world uses of these systems. Moreover, there is no systematic effort to design and evaluate these reports with both AI practitioners and AI compliance experts. To address this gap, we conducted an iterative co-design process with 14 AI practitioners and 6 AI compliance experts and proposed a template for impact assessment reports grounded in the EU AI Act, NIST's AI Risk Management Framework, and ISO 42001 AI Management System. We evaluated the template by producing an impact assessment report for an AI-based meeting companion at a major tech company. A user study with 8 AI practitioners from the same company an
    
[^73]: 跨客户端变异性自适应联邦学习方法 CCVA-FL：应用于基于医学影像的数据集

    CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging

    [https://arxiv.org/abs/2407.11652](https://arxiv.org/abs/2407.11652)

    本文提出了一种名为“跨客户端变异性自适应联邦学习”（CCVA-FL）的方法，通过生成合成医学图像解决医疗图像数据中的跨客户端变异问题，从而提高联邦学习的性能。

    

    arXiv:2407.11652v3 公告类型：替换

    arXiv:2407.11652v3 Announce Type: replace  Abstract: Federated Learning (FL) offers a privacy-preserving approach to train models on decentralized data. Its potential in healthcare is significant, but challenges arise due to cross-client variations in medical image data, exacerbated by limited annotations. This paper introduces Cross-Client Variations Adaptive Federated Learning (CCVA-FL) to address these issues. CCVA-FL aims to minimize cross-client variations by transforming images into a common feature space. It involves expert annotation of a subset of images from each client, followed by the selection of a client with the least data complexity as the target. Synthetic medical images are then generated using Scalable Diffusion Models with Transformers (DiT) based on the target client's annotated images. These synthetic images, capturing diversity and representing the original data, are shared with other clients. Each client then translates its local images into the target image spa
    
[^74]: LoRA 大规模语言模型低秩适应性综述

    A Survey on LoRA of Large Language Models

    [https://arxiv.org/abs/2407.11046](https://arxiv.org/abs/2407.11046)

    这篇综述详细介绍了LoRA技术，它通过更新低秩矩阵来提高大规模语言模型的性能，并探讨了其在提升计算效率和保护数据隐私方面的应用。

    

    arXiv:2407.11046v2 公告类型: 替换交叉 摘要: 低秩适应性(LoRA)，这是一种在下游任务上通过更新密集型神经网络层与可插拔的低秩矩阵来进行的最有效的参数精简微调范式。此外，它还具有在跨任务泛化以及在确保隐私方面的显着优势。因此，LoRA最近受到了大量的关注，与它相关的工作数量呈指数级增长。对LoRA的当前进展进行全面概述变得尤为必要。本文从以下几个方面对LoRA的发展进行分类和综述：(1) 下游适应改进变体，这些变体提高了LoRA在下游任务上的表现；(2) 跨任务泛化方法，这些方法混合了多个LoRA插件以实现跨任务泛化；(3) 效率改进方法，这些方法提高了LoRA的计算效率；(4) 数据隐私保护方法，这些方法在联邦学习中使用LoRA；(5) 应用。此外，这篇综述还讨论了LoRA研究的未来方向和对未来工作的期望。

    arXiv:2407.11046v2 Announce Type: replace-cross  Abstract: Low-Rank Adaptation~(LoRA), which updates the dense neural network layers with pluggable low-rank matrices, is one of the best performed parameter efficient fine-tuning paradigms. Furthermore, it has significant advantages in cross-task generalization and privacy-preserving. Hence, LoRA has gained much attention recently, and the number of related literature demonstrates exponential growth. It is necessary to conduct a comprehensive overview of the current progress on LoRA. This survey categorizes and reviews the progress from the perspectives of (1) downstream adaptation improving variants that improve LoRA's performance on downstream tasks; (2) cross-task generalization methods that mix multiple LoRA plugins to achieve cross-task generalization; (3) efficiency-improving methods that boost the computation-efficiency of LoRA; (4) data privacy-preserving methods that use LoRA in federated learning; (5) application. Besides, this
    
[^75]: D-Rax: 域特定放射学助手，通过多模态数据和专家模型预测提升

    D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions

    [https://arxiv.org/abs/2407.02604](https://arxiv.org/abs/2407.02604)

    D-Rax 是一个新的域特定放射学助手，能够通过结合多模态数据和专家模型预测，更精确地帮助放射科医生处理胸部X光片。

    

    arXiv:2407.02604v2 公告类型：替换 摘要：大型视觉语言模型（VLMs）从研究领域发展到了适用于各种用途的程度，这在医学图像和数据的多模态分析中表现尤为突出。尽管目前的VLMs能够在多模态数据领域提供广泛的适用性，并可用于帮助解决医学中的问题，但由于该领域本身存在的一些挑战，如模型的不确定性、错误的预测和建议等，VLMs在临床上的应用仍然受限。在本研究中，我们提出并设计了一个以胸部X光片（CXR）为重点的域特定、会话式放射学助手——D-Rax。通过结合领域专家的见解和多模态技术的先进性，D-Rax能够准确且高效地解读CXR图像，从而为放射科医生提供一条全新的自然语言接口，并有助于提高放射学报告的精确性和完整性。目前我们正在逐步完善D-Rax的功能，并计划进行更多临床实验，以评估其对医疗实践的潜在影响。

    arXiv:2407.02604v2 Announce Type: replace  Abstract: Large vision language models (VLMs) have progressed incredibly from research to applicability for general-purpose use cases. LLaVA-Med, a pioneering large language and vision assistant for biomedicine, can perform multi-modal biomedical image and data analysis to provide a natural language interface for radiologists. While it is highly generalizable and works with multi-modal data, it is currently limited by well-known challenges that exist in the large language model space. Hallucinations and imprecision in responses can lead to misdiagnosis which currently hinder the clinical adaptability of VLMs. To create precise, user-friendly models in healthcare, we propose D-Rax -- a domain-specific, conversational, radiologic assistance tool that can be used to gain insights about a particular radiologic image. In this study, we enhance the conversational analysis of chest X-ray (CXR) images to support radiological reporting, offering compre
    
[^76]: 具有安全约束的离线多 agent 强化学习的扩散模型

    Diffusion Models for Offline Multi-agent Reinforcement Learning with Safety Constraints

    [https://arxiv.org/abs/2407.00741](https://arxiv.org/abs/2407.00741)

    本文提出了一种在离线多智能体强化学习中整合扩散模型的创新方法，该方法通过风险管理和协同动作建模提高了多个代理行动的安全性。框架基于集成就地、分布式执行的架构，并利用扩散模型进行预测轨迹生成。我们的方法在DSRL基准测试中实现了与命令和控制相比的性能提升，并能更有效地应对复杂的动态环境。

    

    arXiv:2407.00741v5 公告类型：替换 摘要：在多 agent 强化学习（MARL）的最新进展中，其应用已扩展到各种具有安全风险的场景。然而，大多数方法都侧重于在线学习，这在实际部署中可能会带来重大风险。为了解决这一挑战，我们介绍了一种创新的框架，将扩散模型整合到 MARL 范式中。这种方法通过风险缓解和协同动作建模显著提高了多个代理的行动安全性。我们的框架基于集成就地、分布式执行（CTDE）架构，并增加了预测轨迹生成的扩散模型。此外，我们还引入了一种特定的算法以确保操作安全性。我们对DSRL基准进行了评估，实验结果表明，我们的模型不仅严格遵守严格的安全限制，而且还实现了与命令和控制相比的性能提升。通过上下文预测和行为规划，我们的方法不仅能够提高智能体的集体性能，还能够更有效地应对复杂的动态环境。

    arXiv:2407.00741v5 Announce Type: replace  Abstract: In recent advancements in Multi-agent Reinforcement Learning (MARL), its application has extended to various safety-critical scenarios. However, most methods focus on online learning, which presents substantial risks when deployed in real-world settings. Addressing this challenge, we introduce an innovative framework integrating diffusion models within the MARL paradigm. This approach notably enhances the safety of actions taken by multiple agents through risk mitigation while modeling coordinated action. Our framework is grounded in the Centralized Training with Decentralized Execution (CTDE) architecture, augmented by a Diffusion Model for prediction trajectory generation. Additionally, we incorporate a specialized algorithm to further ensure operational safety. We evaluate our model against baselines on the DSRL benchmark. Experiment results demonstrate that our model not only adheres to stringent safety constraints but also achie
    
[^77]: Chat AI: 一种无缝支持Slurm的HPC服务解决方案

    Chat AI: A Seamless Slurm-Native Solution for HPC-Based Services

    [https://arxiv.org/abs/2407.00110](https://arxiv.org/abs/2407.00110)

    该论文提出了一种架构，能够在HPC集群上运行实时AI应用的托管和云VM服务，同时保证用户数据的隐私和安全，避免了存储用户数据而不经用户同意的情况。

    

    arXiv:2407.00110v2 公告类型：替换交叉文摘：大型语言模型（LLM）的广泛应用已促使人们迫切需要一个高效、安全、私密的托管基础设施，这不仅允许研究人员运行开源或自定义的精调LLM，而且确保用户的数据不会在没有用户同意的情况下被存储。虽然配备了先进GPU的高性能计算（HPC）系统非常适合训练LLM，但它们的批次调度范式并不是为了支持实时AI应用的托管而设计的。另一方面，云系统非常适合提供Web服务，但通常缺乏访问HPC集群的计算能力，尤其是昂贵且稀缺的高端GPU，这些GPU对于获得最佳推理性能是必需的。我们提出了一个架构，并在云VM上运行了一个Web服务，该服务具有安全访问基于HPC系统的可扩展后端的能力，该后端运行着多种LLM模型。此外，该架构实现了安全的数据访问，用户数据不会被未经授权的访问。

    arXiv:2407.00110v2 Announce Type: replace-cross  Abstract: The widespread adoption of large language models (LLMs) has created a pressing need for an efficient, secure and private serving infrastructure, which allows researchers to run open source or custom fine-tuned LLMs and ensures users that their data remains private and is not stored without their consent. While high-performance computing (HPC) systems equipped with state-of-the-art GPUs are well-suited for training LLMs, their batch scheduling paradigm is not designed to support real-time serving of AI applications. Cloud systems, on the other hand, are well suited for web services but commonly lack access to the computational power of HPC clusters, especially expensive and scarce high-end GPUs, which are required for optimal inference speed. We propose an architecture with an implementation consisting of a web service that runs on a cloud VM with secure access to a scalable backend running a multitude of LLM models on HPC syste
    
[^78]: 使用多变量变换器增强太阳能驾驶员预报

    Enhancing Solar Driver Forecasting with Multivariate Transformers

    [https://arxiv.org/abs/2406.15847](https://arxiv.org/abs/2406.15847)

    本文提出了一种使用自定义损失函数对高、低太阳能活动水平进行平衡的时间序列Transformer模型，实现了SET数据集上太阳能驱动器的准确预报，尤其是在高峰期间。

    

    arXiv:2406.15847v2 公告类型：替换交叉  翻译摘要：在本工作中，我们采用时间序列Transformer（PatchTST）开发了一个全面的框架，用于F10.7、S10.7、M10.7和Y10.7太阳能驱动器的预报。为了确保对太阳能活动的低和高水平有平等的代表性，我们建立了一个自定义的损失函数，根据太阳能驱动器历史分布与训练集之间的距离来加权样本。太阳能驱动器预报框架包括一个18天的回看窗口，并能预测未来6天的值。当本模型在与Space Environment Technologies（SET）数据集进行基准测试时，我们模型提供的预测在几乎所有情况下标准均方误差都更低，特别是在太阳能活动高峰期，预测精度有所提升。所有代码都可从Github的https://github.com/ARCLab-MIT/sw-driver-forecaster获取。

    arXiv:2406.15847v2 Announce Type: replace-cross  Abstract: In this work, we develop a comprehensive framework for F10.7, S10.7, M10.7, and Y10.7 solar driver forecasting with a time series Transformer (PatchTST). To ensure an equal representation of high and low levels of solar activity, we construct a custom loss function to weight samples based on the distance between the solar driver's historical distribution and the training set. The solar driver forecasting framework includes an 18-day lookback window and forecasts 6 days into the future. When benchmarked against the Space Environment Technologies (SET) dataset, our model consistently produces forecasts with a lower standard mean error in nearly all cases, with improved prediction accuracy during periods of high solar activity. All the code is available on Github https://github.com/ARCLab-MIT/sw-driver-forecaster.
    
[^79]: 现实对话：面向面对面对话的口语对话模型

    Let's Go Real Talk: Spoken Dialogue Model for Face-to-Face Conversation

    [https://arxiv.org/abs/2406.07867](https://arxiv.org/abs/2406.07867)

    我们介绍了一个新型的面向面对面对话的口语对话模型，该模型能够处理音频-视觉言语输入并产生相应的回应。这是创建不依赖中间文本虚拟助手的第一步。我们新引入了MultiDialog，这是首个大规模的多模态口语对话语料库，含约340小时的9,000多个对话的平行音频-视觉记录，这些记录是基于开放域对话数据集TopicalChat录制的。

    

    在本文中，我们介绍了一种新型的面向面对面对话的口语对话模型。该模型处理用户的音频-视觉言语输入，并产生音频-视觉言语作为回应，标志着朝着创建不依赖中间文本的虚拟助手迈出了第一步。为此，我们新引入了MultiDialog，这是首个大规模的多模态（即声音和视觉）口语对话语料库，含约340小时的9,000多个对话的平行音频-视觉记录，它们是基于开放域对话数据集TopicalChat录制的。MultiDialog包含了对话伙伴根据给定脚本进行角色扮演并进行情感标注的音频-视频对话记录，我们期待这些记录将为多模态合成研究开辟新的机会。我们的面向面对面对话的口语对话模型结合了经过文本预训练的大型语言模型，并将其适应到音频-视觉口语对话领域，通过将语音-文本联合预训练纳入模型之中。

    arXiv:2406.07867v2 Announce Type: replace  Abstract: In this paper, we introduce a novel Face-to-Face spoken dialogue model. It processes audio-visual speech from user input and generates audio-visual speech as the response, marking the initial step towards creating an avatar chatbot system without relying on intermediate text. To this end, we newly introduce MultiDialog, the first large-scale multimodal (i.e., audio and visual) spoken dialogue corpus containing 340 hours of approximately 9,000 dialogues, recorded based on the open domain dialogue dataset, TopicalChat. The MultiDialog contains parallel audio-visual recordings of conversation partners acting according to the given script with emotion annotations, which we expect to open up research opportunities in multimodal synthesis. Our Face-to-Face spoken dialogue model incorporates a textually pretrained large language model and adapts it into the audio-visual spoken dialogue domain by incorporating speech-text joint pretraining. 
    
[^80]: 使用上下文化Vendi分数指引改进生成的图像的地理多样性

    Improving Geo-diversity of Generated Images with Contextualized Vendi Score Guidance

    [https://arxiv.org/abs/2406.04551](https://arxiv.org/abs/2406.04551)

    该研究提出了一种称为上下文化Vendi分数指引的方法，旨在提高生成图像的地理多样性，使特定地区的图像表现与现实世界相符。

    

    arXiv:2406.04551v2 公告类型：替换

    arXiv:2406.04551v2 Announce Type: replace  Abstract: With the growing popularity of text-to-image generative models, there has been increasing focus on understanding their risks and biases. Recent work has found that state-of-the-art models struggle to depict everyday objects with the true diversity of the real world and have notable gaps between geographic regions. In this work, we aim to increase the diversity of generated images of common objects such that per-region variations are representative of the real world. We introduce an inference time intervention, contextualized Vendi Score Guidance (c-VSG), that guides the backwards steps of latent diffusion models to increase the diversity of a sample as compared to a "memory bank" of previously generated images while constraining the amount of variation within that of an exemplar set of real-world contextualizing images. We evaluate c-VSG with two geographically representative datasets and find that it substantially increases the dive
    
[^81]: RepCNN: 微小模型为唤醒词检测

    RepCNN: Micro-sized, Mighty Models for Wakeword Detection

    [https://arxiv.org/abs/2406.02652](https://arxiv.org/abs/2406.02652)

    本文提出了RepCNN模型，这是一种轻量级的卷积模型，通过重新架构和重新参数化技术，在保持低内存和计算开销的同时，显著提高了唤醒词检测的准确性。

    

    arXiv:2406.02652v2 公告类型：替换交叉  摘要：始终运行的机器学习模型需要极低的存储和计算开销。它们的限制性参数数量限制了模型学习的能力，以及传统训练算法找到最佳参数的有效性。在这里，我们展示了一个小型的卷积模型可以通过首先将其计算重新构成为一种更大型且分支更多的架构来进行更好的训练。然后，在进行推理时，我们将训练过的模型重新参数化为单分支形式，参数更少，以便具有更低的内存足迹和计算成本。使用这种技术，我们展示了我们的始终在线唤醒词检测模型RepCNN，在推理过程中提供了很好的性能平衡。与具有相同运行时的单分支卷积模型相比，RepCNN重新参数化的模型准确度提高了43%。同时，RepCNN在准确性方面达到了复杂架构如BC-ResNet的水平，但参数数量少了一半。

    arXiv:2406.02652v2 Announce Type: replace-cross  Abstract: Always-on machine learning models require a very low memory and compute footprint. Their restricted parameter count limits the model's capacity to learn, and the effectiveness of the usual training algorithms to find the best parameters. Here we show that a small convolutional model can be better trained by first refactoring its computation into a larger redundant multi-branched architecture. Then, for inference, we algebraically re-parameterize the trained model into the single-branched form with fewer parameters for a lower memory footprint and compute cost. Using this technique, we show that our always-on wake-word detector model, RepCNN, provides a good trade-off between latency and accuracy during inference. RepCNN re-parameterized models are 43% more accurate than a uni-branch convolutional model while having the same runtime. RepCNN also meets the accuracy of complex architectures like BC-ResNet, while having 2x lesser p
    
[^82]: 逆凹效用强化学习是逆游戏理论

    Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory

    [https://arxiv.org/abs/2405.19024](https://arxiv.org/abs/2405.19024)

    这篇论文提出了一个新的统一框架，能够解决逆凹效用强化学习问题，即使在凹效用设置中也能够确保可行奖励函数的识别。

    

    arXiv:2405.19024v3 公告类型：替换-交叉  摘要：我们考虑具有凹效用的逆强化学习问题。凹效用强化学习（CURL）是标准RL目标的一般化，它使用了状态的占用度量凹函数，而不是线性函数。CURL因其能够代表许多重要应用实例，包括标准的RL例如模仿学习、纯探索、受限MDP、离线RL、人造行为规范化RL等而最近受到了关注。逆强化学习是一种强大的范式，它专注于恢复一个未知的行为奖励函数，它能够为观察到的行为提供合理的解释。到目前为止，关于逆强化学习的理论研究已经取得了一些进展，其中问题被形式化为识别可行的奖励函数集合。然而，对于CURL问题的逆强化学习尚未被考虑。在这篇论文中，我们展示了大多数标准的IRL研究方法都可以应用于逆凹效用强化学习问题，并且提供了一个新的统一框架来解决此类问题，即使在凹效用设置中也能够确保可行奖励函数的识别。

    arXiv:2405.19024v3 Announce Type: replace-cross  Abstract: We consider inverse reinforcement learning problems with concave utilities. Concave Utility Reinforcement Learning (CURL) is a generalisation of the standard RL objective, which employs a concave function of the state occupancy measure, rather than a linear function. CURL has garnered recent attention for its ability to represent instances of many important applications including the standard RL such as imitation learning, pure exploration, constrained MDPs, offline RL, human-regularized RL, and others. Inverse reinforcement learning is a powerful paradigm that focuses on recovering an unknown reward function that can rationalize the observed behaviour of an agent. There has been recent theoretical advances in inverse RL where the problem is formulated as identifying the set of feasible reward functions. However, inverse RL for CURL problems has not been considered previously. In this paper we show that most of the standard IRL
    
[^83]: 使用大型语言模型获取信息丰富的文本评估

    Eliciting Informative Text Evaluations with Large Language Models

    [https://arxiv.org/abs/2405.15077](https://arxiv.org/abs/2405.15077)

    本文提出了一种使用大型语言模型提高信息丰富文本评估机制的效力的方法，旨在扩大同行预测机制的应用范围。

    

    摘要：同行预测机制以有保证的保证激励高质量的反馈。然而，现有的方法只适用于相当简单的报告，如多项选择或标量数字。我们的目的是将这些技术扩展到文本报告的大领域，利用大型语言模型最近的发展。这大大扩展了同行预测机制的适用范围，因为文本反馈在大量反馈渠道中很常见：同行评审、电子商务顾客评价和社会媒体上的评论。我们介绍两种机制，即生成性同行预测机制（GPPM）和生成性概要同行预测机制（GSPPM）。这些机制利用LLM作为预测器，从一个人的报告中映射到对她的同伴报告的预测。从理论上讲，我们证明当LLM的预测足够准确时，我们的机制可以激励高强度的努力并说实话，

    arXiv:2405.15077v3 Announce Type: replace-cross  Abstract: Peer prediction mechanisms motivate high-quality feedback with provable guarantees. However, current methods only apply to rather simple reports, like multiple-choice or scalar numbers. We aim to broaden these techniques to the larger domain of text-based reports, drawing on the recent developments in large language models. This vastly increases the applicability of peer prediction mechanisms as textual feedback is the norm in a large variety of feedback channels: peer reviews, e-commerce customer reviews, and comments on social media.   We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM) and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms utilize LLMs as predictors, mapping from one agent's report to a prediction of her peer's report. Theoretically, we show that when the LLM prediction is sufficiently accurate, our mechanisms can incentivize high effort and truth-telling as 
    
[^84]: 多物理神经网络绑图法用于多变异性时间序列

    Bond Graphs for multi-physics informed Neural Networks for multi-variate time series

    [https://arxiv.org/abs/2405.13586](https://arxiv.org/abs/2405.13586)

    这项研究提出了一种结合绑定图和消息传递图神经网络的神经网络体系结构，旨在为多物理和复杂多域现象任务提供多信息输出的深度学习模型。

    

    arXiv:2405.13586v2 公告类型：替换-交叉引用

    arXiv:2405.13586v2 Announce Type: replace-cross  Abstract: In the trend of hybrid Artificial Intelligence techniques, Physical-Informed Machine Learning has seen a growing interest. It operates mainly by imposing data, learning, or architecture bias with simulation data, Partial Differential Equations, or equivariance and invariance properties. While it has shown great success on tasks involving one physical domain, such as fluid dynamics, existing methods are not adapted to tasks with complex multi-physical and multi-domain phenomena. In addition, it is mainly formulated as an end-to-end learning scheme. To address these challenges, we propose to leverage Bond Graphs, a multi-physics modeling approach, together with Message Passing Graph Neural Networks. We propose a Neural Bond graph Encoder (NBgE) producing multi-physics-informed representations that can be fed into any task-specific model. It provides a unified way to integrate both data and architecture biases in deep learning. Ou
    
[^85]: 新的基于事件嵌入新闻文章的方法

    A Novel Method for News Article Event-Based Embedding

    [https://arxiv.org/abs/2405.13071](https://arxiv.org/abs/2405.13071)

    本文提出了一种新方法，优化了新闻文章的嵌入生成，该方法专注于文章中提到的实体和主题，并对它们与特定事件的历史联系进行优化，提高了主题识别的准确性，并有助于减少媒体偏见。

    

    arXiv:2405.13071v2 公告类型：替换交叉  翻译摘要：新闻文章的嵌入是多个领域的重要工具，例如媒体偏见检测、识别虚假新闻和制作新闻推荐。然而，现有的新闻嵌入方法并未优化以捕捉新闻事件的隐性上下文。大多数嵌入方法依赖于全文本信息，忽视了时间相关的嵌入生成。在本文中，我们提出了一种新的轻量级方法，该方法通过专注于文章中提到的实体和主题以及它们与特定事件的历史联系来优化新闻嵌入的生成。我们建议的方法由三个阶段组成。首先，我们从给定的新闻文章中处理和提取事件、实体和主题。其次，我们通过在当前和历史数据上训练分时段的GloVe模型来为主题和实体生成周期性的时间嵌入。最后，我们结合两种不同的方法来拼接生成的新新闻嵌入：平滑倒数频率，以及主题和实体的基于时间的关键词嵌入。我们展示了这种方法在提高新闻主题识别和相似新闻文章搜索方面的有效性，并通过实验验证了其在多媒体环境下减少媒体偏见的潜力。

    arXiv:2405.13071v2 Announce Type: replace-cross  Abstract: Embedding news articles is a crucial tool for multiple fields, such as media bias detection, identifying fake news, and making news recommendations. However, existing news embedding methods are not optimized to capture the latent context of news events. Most embedding methods rely on full-text information and neglect time-relevant embedding generation. In this paper, we propose a novel lightweight method that optimizes news embedding generation by focusing on entities and themes mentioned in articles and their historical connections to specific events. We suggest a method composed of three stages. First, we process and extract events, entities, and themes from the given news articles. Second, we generate periodic time embeddings for themes and entities by training time-separated GloVe models on current and historical data. Lastly, we concatenate the news embeddings generated by two distinct approaches: Smooth Inverse Frequency 
    
[^86]: 电影推荐系统前的用户信念数据集：收集在线推荐系统的前选择数据

    The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online Recommender Systems

    [https://arxiv.org/abs/2405.11053](https://arxiv.org/abs/2405.11053)

    本文介绍了一种收集用户对未经历电影的信念的方法，并实现了一个结合用户评分、信念和推荐的丰富数据集。

    

    arXiv:2405.11053v3 公告类型：替换-交叉

    arXiv:2405.11053v3 Announce Type: replace-cross  Abstract: An increasingly important aspect of designing recommender systems involves considering how recommendations will influence consumer choices. This paper addresses this issue by introducing a method for collecting user beliefs about un-experienced items - a critical predictor of choice behavior. We implemented this method on the MovieLens platform, resulting in a rich dataset that combines user ratings, beliefs, and observed recommendations. We document challenges to such data collection, including selection bias in response and limited coverage of the product space. This unique resource empowers researchers to delve deeper into user behavior and analyze user choices absent recommendations, measure the effectiveness of recommendations, and prototype algorithms that leverage user belief data, ultimately leading to more impactful recommender systems. The dataset can be found at https://grouplens.org/datasets/movielens/ml_belief_2024
    
[^87]: FloorSet --- 一个带有真实世界SoC设计约束的VLSI布局规划数据集

    FloorSet -- a VLSI Floorplanning Dataset with Design Constraints of Real-World SoCs

    [https://arxiv.org/abs/2405.05480](https://arxiv.org/abs/2405.05480)

    FloorSet是一个包含带有真实世界SoC设计约束的VLSI布局规划数据的合成数据集，旨在为机器学习方法提供一个更接近真实世界情况的挑战。

    

    arXiv:2405.05480v4 宣布类型：替换交叉  摘要：对于系统级芯片（SoCs）及其子系统，布局规划是一个重要的和非同小可的物理设计流程步骤。它代表了一个困难的组合优化问题。一个典型的带有120个分区的大型SoC产生了大约10E250的搜索空间。随着新的机器学习（ML）方法出现以解决这些问题，对于一个能够涵盖大量训练数据并且更好地反映真实世界约束和目标的现代基准的需求正在增长。为了满足这一需求，我们推出了FloorSet ——两个全面的合成固定轮廓布局设计数据集，它们反映了真实SoC的分布。每个数据集都有100万训练样本和100个测试样本，其中每个样本都是一种合成布局。FloorSet-Prime包含了全边接矩形分区的布局和接近最优的走线长度。一个简化版的数据集通过去除空闲区域和简化斜向连接来减少内存消耗，同时保持高性能。FloorSet-Duo则进一步丰富了对真实世界SoC中常见复杂度的模拟，包括不对称分区、孤立分区和不规则形状。FloorSet的发布标志着布局规划领域的新基准开始，为学习算法提供了一个真实世界的挑战，同时也是理论研究和工业实际的双重机遇。

    arXiv:2405.05480v4 Announce Type: replace-cross  Abstract: Floorplanning for systems-on-a-chip (SoCs) and its sub-systems is a crucial and non-trivial step of the physical design flow. It represents a difficult combinatorial optimization problem. A typical large scale SoC with 120 partitions generates a search-space of nearly 10E250. As novel machine learning (ML) approaches emerge to tackle such problems, there is a growing need for a modern benchmark that comprises a large training dataset and performance metrics that better reflect real-world constraints and objectives compared to existing benchmarks. To address this need, we present FloorSet -- two comprehensive datasets of synthetic fixed-outline floorplan layouts that reflect the distribution of real SoCs. Each dataset has 1M training samples and 100 test samples where each sample is a synthetic floor-plan. FloorSet-Prime comprises fully-abutted rectilinear partitions and near-optimal wire-length. A simplified dataset that reflec
    
[^88]: 不要浪费您的宝贵时间：早期停止交叉验证

    Don't Waste Your Time: Early Stopping Cross-Validation

    [https://arxiv.org/abs/2405.03389](https://arxiv.org/abs/2405.03389)

    通过早期停止交叉验证的过程，研究人员减少了模型选择中不必要的计算成本，同时保持或提高了性能，这对于在有限的时间预算内有效进行模型选择至关重要。

    

    arXiv:2405.03389v2 Announce Type: 替换样本摘要：在表数据自动化机器学习系统中，标准的机器学习技术通常采用交叉验证；确保测量的性能能够推广到未见过的数据，或者随后的集合学习不会过拟合。然而，与留出验证相比，使用k-折交叉验证显著增加了验证单个配置的计算成本。虽然确保了更好的泛化能力，并且由此增强了性能，但额外的成本往往超过了在时间预算内进行有效模型选择的能力。我们的目标是使带有交叉验证的模型选择更加有效。因此，我们研究了在模型选择过程中对交叉验证进行早期停顿的影响。我们调查了在两类算法（多层感知机和随机森林）和36个分类数据集上对随机搜索的早期停顿的影响。此外，我们还分析了在考虑3-、5-和10-折交叉验证时，折叠数量对早期停顿的影响。此外，我们还研究了性能指标的敏感性，以确定何时停止交叉验证最有效。实验结果表明，在模型选择过程中采用早期停顿的交叉验证是可行的，它可以显著减少训练时间和成本，同时保持或提高性能。

    arXiv:2405.03389v2 Announce Type: replace-cross  Abstract: State-of-the-art automated machine learning systems for tabular data often employ cross-validation; ensuring that measured performances generalize to unseen data, or that subsequent ensembling does not overfit. However, using k-fold cross-validation instead of holdout validation drastically increases the computational cost of validating a single configuration. While ensuring better generalization and, by extension, better performance, the additional cost is often prohibitive for effective model selection within a time budget. We aim to make model selection with cross-validation more effective. Therefore, we study early stopping the process of cross-validation during model selection. We investigate the impact of early stopping on random search for two algorithms, MLP and random forest, across 36 classification datasets. We further analyze the impact of the number of folds by considering 3-, 5-, and 10-folds. In addition, we inve
    
[^89]: 大型语言模型事件推理的综合评价

    A Comprehensive Evaluation on Event Reasoning of Large Language Models

    [https://arxiv.org/abs/2404.17513](https://arxiv.org/abs/2404.17513)

    本文评估了大型语言模型在不同关系和推理范式上的事件推理能力，发现虽然模型有完成事件推理的能力，但总体表现并不令人满意，同时也发现模型在事件推理能力上的不均衡性。

    

    arXiv:2404.17513v2 公告类型：替换交叉  摘要：事件推理是许多应用的基础能力。它需要事件模式知识进行全局推理，并且需要处理各种事件之间的关系和推理范式。LLM在不同关系和推理范式上完成事件推理的能力仍然未知。为了减轻这一差距，我们对LLM的事件推理能力进行了全面评估。我们引入了一个新的基准EV2用于评估事件推理。EV2包含两个层次的评价，即模式和实例，并且在关系和推理范式方面是全面的。我们在EV2上进行了广泛的实验。我们发现LLM有完成事件推理的能力，但它们的性能远未达到满意。我们还注意到LLM在事件推理能力方面的不平衡。此外，LLM具有事件模式知识，尽管它们在人类如何进行事件推理方面并不一致。

    arXiv:2404.17513v2 Announce Type: replace-cross  Abstract: Event reasoning is a fundamental ability that underlies many applications. It requires event schema knowledge to perform global reasoning and needs to deal with the diversity of the inter-event relations and the reasoning paradigms. How well LLMs accomplish event reasoning on various relations and reasoning paradigms remains unknown. To mitigate this disparity, we comprehensively evaluate the abilities of event reasoning of LLMs. We introduce a novel benchmark EV2 for EValuation of EVent reasoning. EV2 consists of two levels of evaluation of schema and instance and is comprehensive in relations and reasoning paradigms. We conduct extensive experiments on EV2. We find that LLMs have abilities to accomplish event reasoning but their performances are far from satisfactory. We also notice the imbalance of event reasoning abilities in LLMs. Besides, LLMs have event schema knowledge, however, they're not aligned with humans on how to
    
[^90]: 突破瓶颈：神经调制神经网络中从奖励驱动学习到奖励 agnostic 的领域自适应学习演化过渡

    Breaching the Bottleneck: Evolutionary Transition from Reward-Driven Learning to Reward-Agnostic Domain-Adapted Learning in Neuromodulated Neural Nets

    [https://arxiv.org/abs/2404.12631](https://arxiv.org/abs/2404.12631)

    论文讨论了如何在生物智能中突破信息瓶颈，让机器学习能像生物智能一样高效地从多样非奖励刺激信息中学习。

    

    arXiv:2404.12631v2 公告类型：替换交叉引用 摘要：高级生物智能能够高效地从刺激信息的丰富流中学习，即使在行为质量反馈稀缺或完全缺失的情况下也是如此。这种学习利用了对任务领域的一些隐含假设。我们把这种学习称为领域自适应学习（Domain-Adapted Learning, DAL）。相比之下，人工智能学习算法依赖于从行为质量的外部明确提供指标来获得适应性行为。这种做法设立了一个信息瓶颈，阻碍了对多样非奖励刺激信息的认知，限制了学习效率。我们考虑这样一个问题：生物进化是如何绕过这个瓶颈来产生DAL的？我们提出物种首先进化出从奖励信号中学习的本领，虽然效率低下（有瓶颈）但却具有广泛的适应性。从那里，通过逐渐积累的非奖励信息的纳入学习过程可以逐渐进行，因此这些信息可以用来引导学习。

    arXiv:2404.12631v2 Announce Type: replace-cross  Abstract: Advanced biological intelligence learns efficiently from an information-rich stream of stimulus information, even when feedback on behaviour quality is sparse or absent. Such learning exploits implicit assumptions about task domains. We refer to such learning as Domain-Adapted Learning (DAL). In contrast, AI learning algorithms rely on explicit externally provided measures of behaviour quality to acquire fit behaviour. This imposes an information bottleneck that precludes learning from diverse non-reward stimulus information, limiting learning efficiency. We consider the question of how biological evolution circumvents this bottleneck to produce DAL. We propose that species first evolve the ability to learn from reward signals, providing inefficient (bottlenecked) but broad adaptivity. From there, integration of non-reward information into the learning process can proceed via gradual accumulation of biases induced by such infor
    
[^91]: 深度强化学习在旅游采购问题中的应用

    Deep Reinforcement Learning for Traveling Purchaser Problems

    [https://arxiv.org/abs/2404.02476](https://arxiv.org/abs/2404.02476)

    我们提出了一种新方法，利用深度强化学习将旅行采购问题中的路线构建和采购计划分开处理，并从全局视角优化解决方案。我们的方法是高效的，能够为旅游采购问题提供有效解决方案。

    

    arXiv:2404.02476v3 公告类型：替换交叉 摘要：旅行采购问题（TPP）是一个具有广泛应用的重要组合优化问题。由于路线构建和采购计划之间存在耦合，现有关于TPPs的工作通常同时解决路线和采购计划，这虽然导致了解高计算成本的确切方法和设计复杂但性能有限的启发式方法。与此形成鲜明对比的是，我们提出了一种基于深度强化学习（DRL）的新方法，该方法将路线构建和采购计划分开处理，并在全局视角下评估和优化解决方案。我们方法的关键组成部分包括用于TPPs的双边图表示，以捕获市场与产品之间的关系，以及一个政策网络，它从双边图中提取信息，并使用这些信息来顺序构建路线。我们框架的一个显著优点是我们能够以较少的处理时间为起点，在路线上的所有商店位置空间中随机初始化一个点，并使用强化学习算法的精髓来优化路径，从而为旅游采购问题的有效解决方案提供了一种新途径。设计了专门的双边图表示。我们的方法在多阶段旅行采购问题上进行了测试并获得了良好的结果。

    arXiv:2404.02476v3 Announce Type: replace-cross  Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficient
    
[^92]: DASA: 自适应延迟的多代理随机逼近

    DASA: Delay-Adaptive Multi-Agent Stochastic Approximation

    [https://arxiv.org/abs/2403.17247](https://arxiv.org/abs/2403.17247)

    DASA算法是针对多代理随机逼近问题设计的，能够在处理延迟和异步通信的延迟环境中实现快速收敛。

    

    arXiv:2403.17247v3 通告类型：替换交叉  翻译摘要：我们考虑这样一个场景，其中N个代理试图通过并行行动并与中央服务器通信来加速一个共同的随机逼近(SA)问题。我们假设向上游传输到服务器的时间是异步的，并且可能是不变的延迟。为了减轻延迟和落后的影响，同时实现分布式计算的好处，我们提出了\texttt{DASA}，它是基于混合时间和平均延迟的自适应算法，适用于多代理随机逼近。我们为\texttt{DASA}提供了有限时间的分析，假设代理的随机观测过程是独立的马尔可夫链。显著地推进了现有的结果，\texttt{DASA}是第一个与其收敛速度仅取决于混合时间和平均延迟相关的算法，同时实现了在Markovian抽样下的N倍加速收敛。我们的工作对于各种SA应用具有重要意义，并且当处理延迟和异步环境时，其算法性能不会受到显著影响。

    arXiv:2403.17247v3 Announce Type: replace-cross  Abstract: We consider a setting in which $N$ agents aim to speedup a common Stochastic Approximation (SA) problem by acting in parallel and communicating with a central server. We assume that the up-link transmissions to the server are subject to asynchronous and potentially unbounded time-varying delays. To mitigate the effect of delays and stragglers while reaping the benefits of distributed computation, we propose \texttt{DASA}, a Delay-Adaptive algorithm for multi-agent Stochastic Approximation. We provide a finite-time analysis of \texttt{DASA} assuming that the agents' stochastic observation processes are independent Markov chains. Significantly advancing existing results, \texttt{DASA} is the first algorithm whose convergence rate depends only on the mixing time $\tau_{mix}$ and on the average delay $\tau_{avg}$ while jointly achieving an $N$-fold convergence speedup under Markovian sampling. Our work is relevant for various SA ap
    
[^93]: 无人航空系统系统级自动测试系统

    Automated System-level Testing of Unmanned Aerial Systems

    [https://arxiv.org/abs/2403.15857](https://arxiv.org/abs/2403.15857)

    该论文提出了一种基于模型的测试和人工智能技术的自动化系统级测试方法，为无人航空系统的有效测试提供了可行的解决方案，提高了测试效率和准确性。

    

    arXiv:2403.15857v2 公告类型：替换交叉摘要：无人航空系统（UAS）依赖于各种航空电子系统，这些系统对于安全性和任务执行至关重要。国际安全标准的重大要求是对航空电子软件系统进行严格的系统级测试。当前工业做法是手动创建测试场景，使用模拟器手动/自动执行这些场景，并手动评估结果。测试场景通常包括设置特定飞行或环境条件，并在这些条件下对受测系统进行测试。为此目的的现有技术方法也要求手动创建测试场景并进行评估。在本论文中，我们提出了一种自动化无人航空系统系统级测试的新方法。提出的AITester方法利用基于模型的测试和人工智能（AI）技术来自动生成、执行和评估各种测试场景。测试场景通过AI技术可以动态生成，并模拟和评估系统中不同组件的性能，从而提高了测试的覆盖率和可靠度。此外，AITester还利用机器学习算法来分析和优化测试案例，从而在短时间内发现并隔离系统潜在的错误和问题。AITester能够显著降低测试成本并提高UAS系统测试的效率和准确性。

    arXiv:2403.15857v2 Announce Type: replace-cross  Abstract: Unmanned aerial systems (UAS) rely on various avionics systems that are safety-critical and mission-critical. A major requirement of international safety standards is to perform rigorous system-level testing of avionics software systems. The current industrial practice is to manually create test scenarios, manually/automatically execute these scenarios using simulators, and manually evaluate outcomes. The test scenarios typically consist of setting certain flight or environment conditions and testing the system under test in these settings. The state-of-the-art approaches for this purpose also require manual test scenario development and evaluation. In this paper, we propose a novel approach to automate the system-level testing of the UAS. The proposed approach (AITester) utilizes model-based testing and artificial intelligence (AI) techniques to automatically generate, execute, and evaluate various test scenarios. The test sce
    
[^94]: 一种优化框架，用于确保将多视角一致性应用到3D网格的纹理化

    An Optimization Framework to Enforce Multi-View Consistency for Texturing 3D Meshes

    [https://arxiv.org/abs/2403.15559](https://arxiv.org/abs/2403.15559)

    本文提出了一种四阶段的优化框架，用于通过非刚性对齐和MRF问题解决，确保多视角纹理化处理，以达到高效的3D网格多视角纹理化处理

    

    arXiv:2403.15559v2 公告类型：替换交叉  翻译摘要：在预训练的文本到图像模型的基础上，对3D网格进行纹理化时，一个基本的问题是如何确保多视角的一致性。现有技术方法通常使用扩散模型来聚合多视角输入，其中常见的问题是在聚合步骤中由于平均操作引起的模糊性，或者局部特征的不一致性。本文介绍了一种优化框架，该框架分为四个阶段来实现多视角的一致性。特别是，第一阶段使用MV一致的扩散过程从预定义的多视角集生成一个2D纹理的过完备集合。第二阶段选择一个子集的视图，这些视图在覆盖下的3D模型中是相互一致的，我们展示了如何通过解决半正定规划来达到这个目标。第三阶段执行非刚性对齐，以在重叠区域对选定的视图进行对齐。第四阶段解决一个MRF问题，它用于一致一致性评估的重建问题，并且通过采分选采样来细化视角选择。整体框架进行迭代优化，直到达到满意的性能，实现了高效的3D网格多视角纹理化处理

    arXiv:2403.15559v2 Announce Type: replace-cross  Abstract: A fundamental problem in the texturing of 3D meshes using pre-trained text-to-image models is to ensure multi-view consistency. State-of-the-art approaches typically use diffusion models to aggregate multi-view inputs, where common issues are the blurriness caused by the averaging operation in the aggregation step or inconsistencies in local features. This paper introduces an optimization framework that proceeds in four stages to achieve multi-view consistency. Specifically, the first stage generates an over-complete set of 2D textures from a predefined set of viewpoints using an MV-consistent diffusion process. The second stage selects a subset of views that are mutually consistent while covering the underlying 3D model. We show how to achieve this goal by solving semi-definite programs. The third stage performs non-rigid alignment to align the selected views across overlapping regions. The fourth stage solves an MRF problem t
    
[^95]: 基于多标准方法从解释集合中选择集成的解释方法中的解释

    A multi-criteria approach for selecting an explanation from the set of counterfactuals produced by an ensemble of explainers

    [https://arxiv.org/abs/2403.13940](https://arxiv.org/abs/2403.13940)

    在一组反事实解释中，由多种集成解释方法生成，本文提出了一种多标准方法，通过考虑多个质量标准，减少冲突，并为用户提供易于理解的指导，从而选择最合适的一个。

    

    arXiv:2403.13940v2 公告类型: 替换交叉摘要: 反事实广泛用于通过提供获得更受欢迎预测的替代方案来解释机器学习模型的预测。它们可以通过各种方法生成，这些方法优化不同的甚至是冲突的质量标准，并产生截然不同的解决方案。然而，选择最合适的解释方法和生成反事实中的一个并非易事。而不是迫使用户测试多种不同的解释方法和分析冲突的解决方案，本文我们提出了一种多阶段集成方法，该方法基于多标准分析选择单个体化反事实。它提供了一个在多个流行质量标准上得分很好的妥协解决方案。这种方法利用了支配关系和理想点决策支持方法，该方法从帕累托前沿中选择一个反事实。进行的研究表明，该方法可以更全面地考虑反事实的解释质量，尤其是当考虑多个标准时，它能够减少多准则问题中的冲突，并提供用户易于理解的信息，从而在他们进行解释选择时提供指导。

    arXiv:2403.13940v2 Announce Type: replace-cross  Abstract: Counterfactuals are widely used to explain ML model predictions by providing alternative scenarios for obtaining the more desired predictions. They can be generated by a variety of methods that optimize different, sometimes conflicting, quality measures and produce quite different solutions. However, choosing the most appropriate explanation method and one of the generated counterfactuals is not an easy task. Instead of forcing the user to test many different explanation methods and analysing conflicting solutions, in this paper, we propose to use a multi-stage ensemble approach that will select single counterfactual based on the multiple-criteria analysis. It offers a compromise solution that scores well on several popular quality measures. This approach exploits the dominance relation and the ideal point decision aid method, which selects one counterfactual from the Pareto front. The conducted experiments demonstrated that th
    
[^96]: 自然语言处理预训练-微调范式教程

    A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing

    [https://arxiv.org/abs/2403.02504](https://arxiv.org/abs/2403.02504)

    论文介绍了自然语言处理领域中预训练-微调范式的重要性和优势，该范式通过使用大型预训练语言模型，可以在特定任务上进行微调和微调，以相对较小的标注数据集获得接近从零开始的性能，并且提供丰富的上下文表示和语言理解能力。

    

    arXiv:2403.02504v3 新闻类型：替换-交叉  摘要：由于自然语言充当表达思想和情感的主要渠道，文本分析已成为心理学研究中的重要技术。它使从自然语言中提取出宝贵见解成为可能，支持诸如评估个性特征、监测心理健康和人际沟通中的情感分析等努力。在文本分析中，现有的研究通常会采用手动编码，这是一种耗时的方法，使用预先构建的词典，这种方法通常无法涵盖所有可能的情况，或者从头开始训练模型，这需要大量的标记数据。在本教程中，我们介绍预训练-微调范式。预训练-微调范式代表了文本分析和自然语言处理中的一个根本变革方法。这种范式通过使用大型预训练语言模型而与众不同，显示出在负责多种不同任务时的高效率和通用性。通过在特定任务上进行微调和微调，这些模型能够以相对较小的标注数据集获得几乎与从头开始训练时相同的性能水平。此外，预训练模型为研究者提供了丰富的上下文表示和语言理解能力，而无需每个新任务都需要从头开始学习。

    arXiv:2403.02504v3 Announce Type: replace-cross  Abstract: Given that natural language serves as the primary conduit for expressing thoughts and emotions, text analysis has become a key technique in psychological research. It enables the extraction of valuable insights from natural language, facilitating endeavors like personality traits assessment, mental health monitoring, and sentiment analysis in interpersonal communications. In text analysis, existing studies often resort to either human coding, which is time-consuming, using pre-built dictionaries, which often fails to cover all possible scenarios, or training models from scratch, which requires large amounts of labeled data. In this tutorial, we introduce the pretrain-finetune paradigm. The pretrain-finetune paradigm represents a transformative approach in text analysis and natural language processing. This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in f
    
[^97]: 论文标题: 有效的路由学习到大型语言模型

    Routoo: Learning to Route to Large Language Models Effectively

    [https://arxiv.org/abs/2401.13979](https://arxiv.org/abs/2401.13979)

    论文创新：开发了一种名为“Routoo”的建筑，旨在根据性能、成本和效率来优化大型语言模型的选择，以提高特定提示的响应质量。

    

    论文摘要: arXiv:2401.13979v2 公告类型: 替换跨学科摘要: 开发基础大型语言模型(LLM)的成本正在变得越来越高，效率也越来越低。此外，闭源和大型的开源模型通常提供更好的响应质量，但代价更高，不如小规模模型。在这篇论文中，我们介绍了一个名为“Routoo”的建筑设计，旨在根据性能、成本和效率来优化特定提示的LLM选择。Routoo包括两个关键组件：一个性能预测器和一个成本自适应解码器。性能预测器是一个轻量级的LLM，它不需要执行和评估就能估计各种底层LLM的性能。成本自适应解码器根据这些预测和其他约束（如成本和延迟）选择最合适的模型。我们使用MMLU基准对57个学科领域中的开源模型进行了评估。我们的结果表明，Routoo在匹配MMLU基准点方面与开源模型的性能相当。

    arXiv:2401.13979v2 Announce Type: replace-cross  Abstract: Developing foundational large language models (LLMs) is becoming increasingly costly and inefficient. Also, closed-source and larger open-source models generally offer better response quality but come with higher inference costs than smaller models. In this paper, we introduce Routoo, an architecture designed to optimize the selection of LLMs for specific prompts based on performance, cost, and efficiency. Routoo consists of two key components: a performance predictor and a cost-aware decoding. The performance predictor is a lightweight LLM that estimates the performance of various underlying LLMs without needing to execute and evaluate them. The cost-aware decoding then selects the most suitable model based on these predictions and other constraints like cost and latency. We evaluated Routoo using the MMLU benchmark across 57 domains employing open-source models. Our results show that Routoo matches the performance of the Mixt
    
[^98]: 可微树搜索网络

    Differentiable Tree Search Network

    [https://arxiv.org/abs/2401.11660](https://arxiv.org/abs/2401.11660)

    D-TSN利用可微树搜索优化策略性能，适用于在复杂任务中进行高效和准确的行动决策。

    

    arXiv:2401.11660v2 发布公告类型：替换交叉引用摘要：在有限的训练数据下进行决策制定的问题中，使用深度神经网络近似的策略函数往往表现出较低的性能。另一种方法是从有限的资料中学习世界模型，并在线搜索中确定动作。然而，由于学习的世界模型不准确，错误会累积，导致性能不佳。虽然如TreeQN的方法试图通过在神经网络架构中引入算法的偏见来解决问题，但这些偏见的强度往往不够强，不足以解决复杂的问题。在本文中，我们介绍了一种名为可微树搜索网络（D-TSN）的全新神经网络架构，该架构通过在最佳第一在线搜索算法的结构中嵌入算法结构来显著加强偏见。D-TSN使用预测的世界模型进行完全的可微树搜索，这允许对搜索过程进行优化，从而显著提高策略性能。我们在多种复杂的跟踪任务和策略学习任务中表示了D-TSN的有效性，展示了在缺乏充分的训练数据的情况下，我们的方法如何在包含复杂感知和规划特性的随机任务中实现高效和准确的动作决策。

    arXiv:2401.11660v2 Announce Type: replace-cross  Abstract: In decision-making problems with limited training data, policy functions approximated using deep neural networks often exhibit suboptimal performance. An alternative approach involves learning a world model from the limited data and determining actions through online search. However, the performance is adversely affected by compounding errors arising from inaccuracies in the learned world model. While methods like TreeQN have attempted to address these inaccuracies by incorporating algorithmic inductive biases into the neural network architectures, the biases they introduce are often weak and insufficient for complex decision-making tasks. In this work, we introduce Differentiable Tree Search Network (D-TSN), a novel neural network architecture that significantly strengthens the inductive bias by embedding the algorithmic structure of a best-first online search algorithm. D-TSN employs a learned world model to conduct a fully d
    
[^99]: MERA：一种全面的俄语LLM评估

    MERA: A Comprehensive LLM Evaluation in Russian

    [https://arxiv.org/abs/2401.04531](https://arxiv.org/abs/2401.04531)

    MERA是一个用于评估面向俄语语言的基础模型的新指令基准，它包括21个评估任务，旨在更好地理解这些模型的能力、局限性和风险。

    

    arXiv:2401.04531v3 公告类型：替换交叉  翻译摘要：在过去几年中，人工智能研究中最显著的进步之一是在于基础模型（FMs）的崛起，尤其是语言模型（LMs）的发展。随着模型规模的增加，LMs在可量化的方面取得了进步，并在定性特征上有所新发展。然而，尽管研究人员给予了关注，并且LM的应用迅速增长，但我们对这些模型的能力、局限性和相关风险的理解仍需要进一步加深。为了解决这些问题，我们推出了一个开放的Multimodal Evaluation of Russian-language Architectures（MERA），这是一个旨在评估面向俄语语言的基础模型的新指令基准。该基准包括21个评估任务，涵盖了11个技能领域的生成模型，并且设计成为一个黑盒测试，以确保排除数据泄漏。该论文介绍了一种评估FM和LM的方法论，尤其是在零样本和few-shot固定指令设置中。

    arXiv:2401.04531v3 Announce Type: replace-cross  Abstract: Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). As the models' size increases, LMs demonstrate enhancements in measurable aspects and the development of new qualitative features. However, despite researchers' attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce an open Multimodal Evaluation of Russian-language Architectures (MERA), a new instruction benchmark for evaluating foundation models oriented towards the Russian language. The benchmark encompasses 21 evaluation tasks for generative models in 11 skill domains and is designed as a black-box test to ensure the exclusion of data leakage. The paper introduces a methodology to evaluate FMs and LMs in zero- and few-shot fixed instruction settin
    
[^100]: 使用OCL和搜索方法的高效MC/DC测试数据生成

    Efficient Test Data Generation for MC/DC with OCL and Search

    [https://arxiv.org/abs/2401.03469](https://arxiv.org/abs/2401.03469)

    本文提出了一种基于模型的有效方法，利用启发式方法和案例推理来提高基于OCL的MC/DC测试数据生成效率。

    

    arXiv:2401.03469v3 新闻类型：替换交叉  翻译摘要：航空电子软件系统的系统级测试需要符合国际安全标准如DO-178C的要求。航空电子工业的一个重要考虑是按照安全标准推荐的准则自动生成测试数据。DO-178C推荐的准则之一是改进的条件/决策覆盖率(MC/DC)准则。当前基于模型的测试数据生成方法使用用例约束语言(OCL)编写的约束，并应用搜索技术来生成测试数据。这些方法要么不支持MC/DC准则，要么在使用大型航空电子系统时遇到性能问题。在本文中，我们提出了一种在基于模型的测试中自动生成MC/DC测试数据的有效方法。我们开发了一种策略，该策略利用基于案例的推理(CBR)和设计用于解决MC/DC定制OCL的缩减范围启发式方法。

    arXiv:2401.03469v3 Announce Type: replace-cross  Abstract: System-level testing of avionics software systems requires compliance with different international safety standards such as DO-178C. An important consideration of the avionics industry is automated test data generation according to the criteria suggested by safety standards. One of the recommended criteria by DO-178C is the modified condition/decision coverage (MC/DC) criterion. The current model-based test data generation approaches use constraints written in Object Constraint Language (OCL), and apply search techniques to generate test data. These approaches either do not support MC/DC criterion or suffer from performance issues while generating test data for large-scale avionics systems. In this paper, we propose an effective way to automate MC/DC test data generation during model-based testing. We develop a strategy that utilizes case-based reasoning (CBR) and range reduction heuristics designed to solve MC/DC-tailored OCL 
    
[^101]: 非参数策略测试

    Nonparametric Strategy Test

    [https://arxiv.org/abs/2312.10695](https://arxiv.org/abs/2312.10695)

    我们提出了一种非参数统计检验，用于评估代理人是否遵循给定的混合策略。通过卡方拟合优度检验和广义沃尔德-沃尔夫瓦兹位移检验相结合的方式，以确保代理人的行为模式符合预期。

    

    我们提出了一种非参数统计检验，用于确定在重复的战略形式游戏中，根据代理人行动样本的情况下，一个代理人是否遵循给定的混合策略。这涉及到两部分内容：确定代理商的纯策略频率是否足够接近目标频率，以及确定在不同游戏回合中选择的纯策略是否独立。我们的集成测试通过应用卡方拟合优度检验来确定第一部分，通过应用广义的沃尔德-沃尔夫瓦兹位移检验来确定第二部分。两者的结果通过Bonferroni校正相结合，为给定的显著性水平$\alpha$提供一个完整的测试。我们将该测试应用于公开的人类石头-剪刀-布游戏数据。该数据包括500名人类玩家的50次回合游戏。我们使用零假设测试，该假设是参与者遵循给定的混合策略。

    arXiv:2312.10695v4 Announce Type: replace-cross  Abstract: We present a nonparametric statistical test for determining whether an agent is following a given mixed strategy in a repeated strategic-form game given samples of the agent's play. This involves two components: determining whether the agent's frequencies of pure strategies are sufficiently close to the target frequencies, and determining whether the pure strategies selected are independent between different game iterations. Our integrated test involves applying a chi-squared goodness of fit test for the first component and a generalized Wald-Wolfowitz runs test for the second component. The results from both tests are combined using Bonferroni correction to produce a complete test for a given significance level $\alpha.$ We applied the test to publicly available data of human rock-paper-scissors play. The data consists of 50 iterations of play for 500 human players. We test with a null hypothesis that the players are following
    
[^102]: 时间转移学习在粗粒度咨询自治下的交通优化

    Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy

    [https://arxiv.org/abs/2312.09436](https://arxiv.org/abs/2312.09436)

    本文提出了一种时间转移学习方法，用来提高咨询自治下的交通效率。这种方法通过在特定的车流量和速度条件下训练策略，然后将其应用于实际交通场景，即使在缺乏完全自动驾驶车辆的情况下，也能有效提高交通流量的通过率并减少事故发生率。

    

    arXiv:2312.09436v2 公告类型：替换

    arXiv:2312.09436v2 Announce Type: replace  Abstract: The recent development of connected and automated vehicle (CAV) technologies has spurred investigations to optimize dense urban traffic to maximize vehicle speed and throughput. This paper explores advisory autonomy, in which real-time driving advisories are issued to the human drivers, thus achieving near-term performance of automated vehicles. Due to the complexity of traffic systems, recent studies of coordinating CAVs have resorted to leveraging deep reinforcement learning (RL). Coarse-grained advisory is formalized as zero-order holds, and we consider a range of hold duration from 0.1 to 40 seconds. However, despite the similarity of the higher frequency tasks on CAVs, a direct application of deep RL fails to be generalized to advisory autonomy tasks. To overcome this, we utilize zero-shot transfer, training policies on a set of source tasks--specific traffic scenarios with designated hold durations--and then evaluating the effi
    
[^103]: 论文标题：大型语言模型训练数据管理概览

    Data Management For Training Large Language Models: A Survey

    [https://arxiv.org/abs/2312.01700](https://arxiv.org/abs/2312.01700)

    本论文提供了大型语言模型数据管理策略的全面概述，重点关注了如何通过优化训练数据来提升模型的训练效率和性能。

    

    arXiv:2312.01700v3 公告类型：替换交叉

    arXiv:2312.01700v3 Announce Type: replace-cross  Abstract: Data plays a fundamental role in training Large Language Models (LLMs). Efficient data management, particularly in formulating a well-suited training dataset, is significant for enhancing model performance and improving training efficiency during pretraining and supervised fine-tuning stages. Despite the considerable importance of data management, the underlying mechanism of current prominent practices are still unknown. Consequently, the exploration of data management has attracted more and more attention among the research community. This survey aims to provide a comprehensive overview of current research in data management within both the pretraining and supervised fine-tuning stages of LLMs, covering various aspects of data management strategy design. Looking into the future, we extrapolate existing challenges and outline promising directions for development in this field. Therefore, this survey serves as a guiding resource
    
[^104]: 这里是一个针对动态手势生成的全新框架，用于驾驶情景

    SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios

    [https://arxiv.org/abs/2309.04421](https://arxiv.org/abs/2309.04421)

    我们提出了一个使用虚拟3D模型的全新框架，该框架使用Unreal Engine生成现实的手势动作，通过节省时间和努力，为驾驶情景中的动态手势生成提供了更高效的方法。

    

    arXiv:2309.04421v2 公告类型：替换 摘要：在汽车领域创建一个多样化的手势动作数据库可能会很艰难且耗时。为了解决这一挑战，我们提出了使用由虚拟3D模型生成的合成手势数据的构想。我们的框架使用虚幻引擎生成现实的手势动作，提供自定义选项并降低过度拟合的危险。我们还生成了多种变体，包括手势速度、表现力和手形，以提高泛化能力。此外，我们还模拟了不同位置的摄像头和类型的摄像头，如RGB、红外和深度摄像头，而不会增加获取这些摄像头的额外时间和成本。实验结果表明，我们提出的框架“SynthoGestures（https://github.com/amrgomaaelhady/SynthoGestures）”提高了手势识别精度，并可以代替或补充真实手势的数据集。通过节省时间，我们为驾驶情景中的动态手势生成提供了更高效的方法。

    arXiv:2309.04421v2 Announce Type: replace  Abstract: Creating a diverse and comprehensive dataset of hand gestures for dynamic human-machine interfaces in the automotive domain can be challenging and time-consuming. To overcome this challenge, we propose using synthetic gesture datasets generated by virtual 3D models. Our framework utilizes Unreal Engine to synthesize realistic hand gestures, offering customization options and reducing the risk of overfitting. Multiple variants, including gesture speed, performance, and hand shape, are generated to improve generalizability. In addition, we simulate different camera locations and types, such as RGB, infrared, and depth cameras, without incurring additional time and cost to obtain these cameras. Experimental results demonstrate that our proposed framework, SynthoGestures (https://github.com/amrgomaaelhady/SynthoGestures), improves gesture recognition accuracy and can replace or augment real-hand datasets. By saving time and effort in the
    
[^105]: 规则基础的错误检测和修正以实现运动轨迹分类的操作化

    Rule-Based Error Detection and Correction to Operationalize Movement Trajectory Classification

    [https://arxiv.org/abs/2308.14250](https://arxiv.org/abs/2308.14250)

    本文提出了一套规则基础的错误检测和修正方法，大幅度提高了运动轨迹分类模型的性能，特别是在应对数据分布变化时。

    

    arXiv:2308.14250v3 宣布类型：替换交叉  翻译摘要：运动轨迹的分类在交通运输领域有许多应用，是大规模运动轨迹生成和异常检测的关键组成部分，对于灾难或其他外部冲击后的安全应用至关重要。然而，目前的先进技术（SOTA）依赖于监督深度学习，当轨迹分布发生变化时，这会造成挑战。我们提供了一个神经符号规则基础框架，用于这些模型的错误检测和修正，以集成到我们的运动轨迹平台上。我们对几个最近的高级技术模型提供了实验，展示了高度准确的错误检测能力，以及对变化测试分布的准确度改进，以及对基线用例的准确度改进，以及对算法开发具有理论属性的实验套件。尤其是在显示了F1评分在测试时的绩效之后，我们从新的SOTA模型中选择了六个最具代表性的模型进行比较，并对实际测试数据的性能进行了验证。我们的规则基础错误检测和修正方法在所有六个模型中实现的F1评分平均提高了5.45个百分点，表明了其在应对变化数据分布和提高模型准确度方面的有效性。在新的SOTA模型中，我们的方法实现了最强的性能改进，达到了21.62%的平均提升。我们的work通过在复杂、未经训练的数据上显示出色的性能，为运动轨迹错误检测和修正提供了强有力的证据，并且证实了神经符号规则基础方法的实用性和优越性。

    arXiv:2308.14250v3 Announce Type: replace-cross  Abstract: Classification of movement trajectories has many applications in transportation and is a key component for large-scale movement trajectory generation and anomaly detection which has key safety applications in the aftermath of a disaster or other external shock. However, the current state-of-the-art (SOTA) are based on supervised deep learning - which leads to challenges when the distribution of trajectories changes due to such a shock. We provide a neuro-symbolic rule-based framework to conduct error correction and detection of these models to integrate into our movement trajectory platform. We provide a suite of experiments on several recent SOTA models where we show highly accurate error detection, the ability to improve accuracy with a changing test distribution, and accuracy improvement for the base use case in addition to a suite of theoretical properties that informed algorithm development. Specifically, we show an F1 sco
    
[^106]: 语言模型中的算术：从记忆到计算

    Arithmetic with Language Models: from Memorization to Computation

    [https://arxiv.org/abs/2308.01154](https://arxiv.org/abs/2308.01154)

    本文研究了大型语言模型的算术计算能力，发现它们能够通过一种“编码-回归-解码”机制进行泛化计算。

    

    arXiv:2308.01154v4 公告类型：替换 摘要：对最近的大型语言模型的涌现计算和问题求解能力的更好理解对进一步改进它们并拓宽其应用范围至关重要。本文研究了一种语言模型，它在训练中用来预测下一个词，是如何执行算术计算的，这种计算能够超出训练数据范围。二进制加法和乘法构成了一个很好的测试平台，因为它们只需要非常小的词汇量，并且在输入/输出 discontinuities方面表现出相关性，使得对新的数据运行平滑的输入插值无效。我们成功地训练了一个轻量级语言模型，让它学会了这些任务，并进行了多项实验，以研究该模型扩展的能力和内部信息处理。我们的发现支持这样的假设：语言模型在工作时作为一个编码-回归-解码机，其中计算在值空间中发生，一旦输入被编码，语言模型就可以对算术计算进行预测和解码。

    arXiv:2308.01154v4 Announce Type: replace  Abstract: A better understanding of the emergent computation and problem-solving capabilities of recent large language models is of paramount importance to further improve them and broaden their applicability. This work investigates how a language model, trained to predict the next token, can perform arithmetic computations generalizing beyond training data. Binary addition and multiplication constitute a good testbed for this purpose, since they require a very small vocabulary and exhibit relevant input/output discontinuities making smooth input interpolation ineffective for novel data. We successfully trained a light language model to learn these tasks and ran a number of experiments to investigate the extrapolation capabilities and internal information processing. Our findings support the hypothesis that the language model works as an Encoding-Regression-Decoding machine where the computation takes place in the value space once the input to
    
[^107]: SRAN: 结构感知循环网络用于空间时间 disaggregation

    SARN: Structurally-Aware Recurrent Network for Spatio-Temporal Disaggregation

    [https://arxiv.org/abs/2306.07292](https://arxiv.org/abs/2306.07292)

    本文提出了一种称为SARN的模型，该模型整合了结构感知空间注意层和GRU模型，能够准确地从低分辨率空间聚合数据重建到高分辨率的不规则分区。

    

    arXiv:2306.07292v4 发布公告类型: replace-cross

    arXiv:2306.07292v4 Announce Type: replace-cross  Abstract: Open data is frequently released spatially aggregated, usually to comply with privacy policies. But coarse, heterogeneous aggregations complicate learning and integration for downstream AI/ML systems. In this work, we consider models to disaggregate spatio-temporal data from a low-resolution, irregular partition (e.g., census tract) to a high-resolution, irregular partition (e.g., city block). We propose an overarching model named the Structurally-Aware Recurrent Network (SARN), which integrates structurally-aware spatial attention (SASA) layers into the Gated Recurrent Unit (GRU) model. The spatial attention layers capture spatial interactions among regions, while the gated recurrent module captures the temporal dependencies. Each SASA layer calculates both global and structural attention -- global attention facilitates comprehensive interactions between different geographic levels, while structural attention leverages the con
    
[^108]: 多链思维元推理问答系统

    Answering Questions by Meta-Reasoning over Multiple Chains of Thought

    [https://arxiv.org/abs/2304.13007](https://arxiv.org/abs/2304.13007)

    我们介绍了一种名为“Multi-Chain Reasoning”（MCR）的新方法，它通过元推理多个思想链来改进多跳问答系统的性能，同时提升最终答案的统一解释性。

    

    arXiv:2304.13007v4 新闻类型：替换交叉  翻译摘要：现代的多跳问答系统（QA）通常将问题分解为一系列推理步骤，称为“思想链”（CoT），然后达到最终答案。通常，多个链被抽样，通过最终答案的投票机制进行聚合，但是本身放弃了对中间步骤的考虑。尽管这种方法提高了性能，但它没有考虑不同链之间中间步骤之间的关系，也没有为预测的答案提供统一的解释。我们提出了“多链推理”（MCR）方法，该方法促使大型语言模型进行元推理多思想链，而不是对它们的答案进行聚合。MCR检查不同的推理链，在它们之间混合信息，并在生成解释并预测答案时选择最具相关性的事实。MCR在7个多跳QA数据集上超过了强大的基线。此外，我们的分析表明强基线通常在问题的第一个线索上表现良好，但对于后续线索的要求越来越严格——与该直觉相配合。Developer Testing for Mobile Apps: A Case Study on EValuating Security Features

    arXiv:2304.13007v4 Announce Type: replace-cross  Abstract: Modern systems for multi-hop question answering (QA) typically break questions into a sequence of reasoning steps, termed chain-of-thought (CoT), before arriving at a final answer. Often, multiple chains are sampled and aggregated through a voting mechanism over the final answers, but the intermediate steps themselves are discarded. While such approaches improve performance, they do not consider the relations between intermediate steps across chains and do not provide a unified explanation for the predicted answer. We introduce Multi-Chain Reasoning (MCR), an approach which prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them and selects the most relevant facts in generating an explanation and predicting the answer. MCR outperforms strong baselines on 7 multi-hop QA datasets. Moreover, our anal
    
[^109]: 通过贝叶斯网络建模评估 rubrics：一种务实的approach

    Modelling Assessment Rubrics through Bayesian Networks: a Pragmatic Approach

    [https://arxiv.org/abs/2209.05467](https://arxiv.org/abs/2209.05467)

    本文提出了一种直接从评估 rubric中获取学习者模型的方法，该方法基于贝叶斯网络，通过逻辑门简化参数获取，以自动化智能教学系统中的技能测试。

    

    arXiv:2209.05467v3 宣布类型：替换交叉 摘要：智能教学系统中的学习者技能自动评估是一项基本任务。评估 rubric通常有效地描述了相关技能水平和资质。本文介绍了一种直接从某些层次（部分）顺序定义评估 rubric中技能的方法，以创建一个学习者模型。该模型基于贝叶斯网络，并利用不确定性逻辑门（常称为“混淆门”）来减少模型的参数数量，以便通过专家简化参数的获取，并在智能教学系统中进行实时推断。我们说明了该方法是如何应用于自动化对计算机思维技能的测试任务的评估的。从评估 rubric中简化模型的获取方式，为快速自动化多种任务评估提供了可能性。

    arXiv:2209.05467v3 Announce Type: replace-cross  Abstract: Automatic assessment of learner competencies is a fundamental task in intelligent tutoring systems. An assessment rubric typically and effectively describes relevant competencies and competence levels. This paper presents an approach to deriving a learner model directly from an assessment rubric defining some (partial) ordering of competence levels. The model is based on Bayesian networks and exploits logical gates with uncertainty (often referred to as noisy gates) to reduce the number of parameters of the model, so to simplify their elicitation by experts and allow real-time inference in intelligent tutoring systems. We illustrate how the approach can be applied to automatize the human assessment of an activity developed for testing computational thinking skills. The simple elicitation of the model starting from the assessment rubric opens up the possibility of quickly automating the assessment of several tasks, making them m
    

