# 摘要

| Ref | Title | Summary |
| --- | --- | --- |
| [^1] | [Self-Taught Evaluators](https://arxiv.org/abs/2408.02666) | 本文提出了一种使用合成数据自教方法，无需人类注释，大幅度提升了Llama3-70B-Instruct模型的性能，并在RewardBench上取得了显著的改进。 |
| [^2] | [SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models](https://arxiv.org/abs/2408.02632) | SEAS框架通过自我演化对抗优化，提高了大型语言模型在红队演练中的安全性和鲁棒性。 |
| [^3] | [Backward explanations via redefinition of predicates](https://arxiv.org/abs/2408.02606) | 本文提出了一种新的逆向解释方法，可以在不牺牲分数质量的情况下为RL代理在环境中的长序列交互提供解释。 |
| [^4] | [Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection](https://arxiv.org/abs/2408.02595) | 本文提出了一种新框架来检测多模态讽刺，该框架利用图文描述来捕捉和检测讽刺，并提高了模型处理图文不匹配的能力。 |
| [^5] | [Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization](https://arxiv.org/abs/2408.02584) | 本文研究了如何通过微调大型语言模型来提高基于属性的摘要的质量，并将在特定领域摘要数据集上的实验结果与实际性能提升进行了评估。 |
| [^6] | [Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition](https://arxiv.org/abs/2408.02582) | 本文提出了一种针对难以涉足的口音语音识别的公平性系统，通过改进的聚类和数据挖掘方法显著提高了非典型口音的语音识别性能。 |
| [^7] | [Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information](https://arxiv.org/abs/2408.02559) | 在“挂戟丹”多玩家合作游戏中，研究探讨了LLM代理如何基于心智理论适应应对不同对手策略，尽管促进了良好合作，但性能仍然受到特定对手策略和游戏动态的影响，展现出了改进LLM推理能力以解决信息不完美挑战的潜力。 |
| [^8] | [The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces](https://arxiv.org/abs/2408.02547) | 本文提出了一种基于功能性肌肉网络的手势感知模型，通过高效地提取时频特征和时间序列分析技术，显著提升了手势识别的分类性能，相对于现有的方法具有更优越的性能。 |
| [^9] | [Counterfactual Shapley Values for Explaining Reinforcement Learning](https://arxiv.org/abs/2408.02529) | 这里是中文总结出的一句话要点 |
| [^10] | [Single-tap Latency Reduction with Single- or Double- tap Prediction](https://arxiv.org/abs/2408.02525) | 本文提出了一种新的机器学习方法PredicTaps，可以在单击或双击出现之前预测检测到的点击是单击还是双击的第一接触点，从而显著减少了用户在触摸屏设备上的单击延迟。 |
| [^11] | [A First Look at License Compliance Capability of LLMs in Code Generation](https://arxiv.org/abs/2408.02487) | 研究评估了大型语言模型对受版权保护代码生成的许可证合规性，并提出了评估基准LiCoEval。 |
| [^12] | [From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future](https://arxiv.org/abs/2408.02479) | 这篇论文调查了大型语言模型在软件工程中的应用，以及基于大型语言模型的代理（可能具有人工通用智能潜力）的优势和挑战。 |
| [^13] | [An investigation into the causes of race bias in AI-based cine CMR segmentation](https://arxiv.org/abs/2408.02462) | 该研究发现AI在基于电影的心脏磁共振图像分割中存在种族偏见，并探讨了可能的原因，以便在未来改进模型以消除这些偏见的影响。 |
| [^14] | [Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach](https://arxiv.org/abs/2408.02456) | 本文提出了GATH，一种用于增强异构知识图完备性的新型基于GAT的方法。通过整合两个独立的注意力模型来预测缺失实体，并采用自适应采样策略以提高模型对重要节点和边相关性的学习能力。 |
| [^15] | [Long Input Benchmark for Russian Analysis](https://arxiv.org/abs/2408.02439) | LIBRA是一套专门用于评估LLM对俄罗斯长文本理解能力的基准，涉及21个数据集和不同的复杂度等级。 |
| [^16] | [PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy](https://arxiv.org/abs/2408.02412) | 论文的主要贡献是将通用DRAM数据映射策略引入深度学习中，以提高深度神经网络的性能和能效，为加速器的设计提供了新方法。 |
| [^17] | [Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models](https://arxiv.org/abs/2408.02408) | 论文提出 MCGF 多天气跨视角地理定位框架，通过使用去噪扩散模型动态适应未知天气条件，并采用联合优化方法提升跨视角地理定位的准确性。 |
| [^18] | [Operationalizing Contextual Integrity in Privacy-Conscious Assistants](https://arxiv.org/abs/2408.02373) | 本文提出了一种通过将上下文完整性框架应用于信息流，以指导信息共享助手的行为，实现用户隐私的合规性。 |
| [^19] | [Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding](https://arxiv.org/abs/2408.02361) | 本文提出了一种使用有约束的思考链解码技术来提高对话系统中的关系提取的准确性，通过训练模型学习更具体的信息，减少了对手动构建本体的需求。 |
| [^20] | [Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction](https://arxiv.org/abs/2408.02337) | 本文介绍了一种现代的半自动化方法，用于创建针对低资源语言的KBQA、MRC和IR数据集，并推出了首个波兰语KBQA数据集PUGG，结合大型语言模型和波兰语知识图谱，显著提升了问答系统的效率和准确性。 |
| [^21] | [Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning](https://arxiv.org/abs/2408.02295) | 研究提出了一种鲁棒的强化学习框架，通过广义高斯误差模型改进了数据的误差和不确定性估计。 |
| [^22] | [Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost](https://arxiv.org/abs/2408.02280) | 本文提出了一种面向硬件的集成选择方法，该方法将推理时间整合到后验集成中，以在预测准确性和推理效率之间取得平衡。我们的方法可以在保持高预测精度的同时提高集成功率，适合部署在资源有限或成本敏感的生产环境中。 |
| [^23] | [DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting](https://arxiv.org/abs/2408.02279) | 本研究提出了一种名为 DRFormer 的多尺度 Transformer 模型，创新性地使用动态 Tokenizer 和动态稀疏学习算法来捕捉时间序列数据的多样 receptive field 和稀疏模式。该模型能够构建层级化的 receptive field，并有效抽取不同时间尺度的信息，显著提升了长期时间序列预测任务中的性能。 |
| [^24] | [Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes](https://arxiv.org/abs/2408.02275) | 本系统利用几何代数与大型语言模型结合，实现了3D场景中对象精确重新定位，无需专业训练数据，仅通过自然语言指令即可操作。 |
| [^25] | [A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction](https://arxiv.org/abs/2408.02233) | 本论文提出了一个结合多源异构外源知识的方法，用于法律指控的预测，特别是通过法律知识库、对话式LLM和与之相关的法律文献，增强了预测模型。 |
| [^26] | [SpecRover: Code Intent Extraction via LLMs](https://arxiv.org/abs/2408.02232) | 此处是中文摘要的小结 |
| [^27] | [Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation](https://arxiv.org/abs/2408.02213) | 大语言模型能够有效协助Database管理员对数据库性能进行优化。 |
| [^28] | [Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems](https://arxiv.org/abs/2408.02205) | 该论文提出的护栏分类系统旨在确保基础模型系统在运行时的安全性。 |
| [^29] | [SelfBC: Self Behavior Cloning for Offline Reinforcement Learning](https://arxiv.org/abs/2408.02165) | 本文提出了SelfBC方法，它通过集成自我约束机制到off-policy方法中，在离线强化学习中学习非保守策略，避免了策略崩溃，并且理论和实验结果证明了其有效性。 |
| [^30] | [Generative Retrieval with Few-shot Indexing](https://arxiv.org/abs/2408.02152) | 论文提出了一种新的基于少样本索引的生成检索框架，它通过提示LLM创建文档标识符银行，并在检索过程中限制模型产生的docid，以提高检索性能。 |
| [^31] | [VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces](https://arxiv.org/abs/2408.02140) | VidModEx方法使用SHAP增强了合成数据生成，提高了图像和视频分类模型的性能，在多个高维数据集上取得了显著的提升。 |
| [^32] | [Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study](https://arxiv.org/abs/2408.02117) | 我们的研究展示了在模拟环境中，考虑价值并产生正当理由的代理能够提高冲突解决率、社交体验、隐私保护以及灵活性。 |
| [^33] | [Dise\~no de sonido para producciones audiovisuales e historias sonoras en el aula. Hacia una docencia creativa mediante el uso de herramientas inteligentes](https://arxiv.org/abs/2408.02113) | 本研究通过智能工具进行创新教学，探索了音频视觉作品声音设计的教学方法，强调了项目式学习在提升学生音频技术实践能力中的作用，同时突出了创建包容性和互动性的学习环境的重要性，以及教师对学生个性化支持与指导的必要性。 |
| [^34] | [KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving](https://arxiv.org/abs/2408.02088) | 本文提出了RCBEV-KAN算法，一种融合摄像头、激光雷达和毫米波雷达数据的全新算法，旨在提高自动驾驶车辆的3D物体检测精度。 |
| [^35] | [Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models](https://arxiv.org/abs/2408.02085) | 本研究综述了评估与选择用于语言模型指令训练的数据方法的现有文献，揭示了不同评估方法的实际应用及未来研究的可能性，旨在为最优的数据驱动训练提供有价值的见解和策略。 |
| [^36] | [Case-based reasoning approach for diagnostic screening of children with developmental delays](https://arxiv.org/abs/2408.02073) | 本文提出了一种基于案例推理的儿童发展迟缓诊断筛查方法，旨在早发现、早干预，减少医疗和社会成本，并提高治疗效果。 |
| [^37] | [ParkingE2E: Camera-based End-to-end Parking Network, from Images to Planning](https://arxiv.org/abs/2408.02061) | 通过模仿学习，本文提出了一个端到端的方法，能够从图像中直接规划出停车路径，该方法在真实世界中展现出良好的适用性和性能。 |
| [^38] | [3D Single-object Tracking in Point Clouds with High Temporal Variation](https://arxiv.org/abs/2408.02049) | 我们提出了HVTrack框架，用于处理点云中具有高时序变化的三维单对象跟踪问题，通过相对姿态感知记忆模块、基扩张特征交叉注意力模块和上下文点引导自注意力模块来解决挑战。 |
| [^39] | [Latency-Aware Resource Allocation for Mobile Edge Generation and Computing via Deep Reinforcement Learning](https://arxiv.org/abs/2408.02047) | 本文提出了一种基于深度强化学习的算法，用于解决移动边缘生成计算系统中通信、计算和AI生成内容资源的联合分配问题，以降低用户的服务延迟。 |
| [^40] | [Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages](https://arxiv.org/abs/2408.02044) | 本研究微调了几种大型语言模型，用于分析Twitter/X上的东欧V4国家语言中有关俄罗斯和乌克兰军事冲突的情感信息，并比较了它们的性能。 |
| [^41] | [Mining Path Association Rules in Large Property Graphs (with Appendix)](https://arxiv.org/abs/2408.02029) | 本文研究了大型的属性图中带标签的路径关联规则挖掘问题，并提出了一个高效且可扩展的算法PIONEER，该算法利用路径的抗单调性进行有效剪枝，并通过近似技术和并行化实现可扩展的路径关联规则挖掘。 |
| [^42] | [Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association](https://arxiv.org/abs/2408.02025) | 本文提出了一种基于对比学习的算法，用于解决多语言环境中面部与声音识别面临的复杂问题，特别是在无法面对面识别的情况下。 |
| [^43] | [Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease](https://arxiv.org/abs/2408.02018) | 本文通过使用条件变分AutoEncoder，构建了一个能在个体基础上进行MRI时间序列预测的模型，从而提高了阿尔茨海默病诊断的特异性。 |
| [^44] | [MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots](https://arxiv.org/abs/2408.01988) | 本文提出MetaWearS方法，通过元学习减少便携式系统初始数据集的需求，并使用原型更新机制简化更新过程。 |
| [^45] | [DeMansia: Mamba Never Forgets Any Tokens](https://arxiv.org/abs/2408.01986) | 这里是被总结出的中文要点 |
| [^46] | [SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning](https://arxiv.org/abs/2408.01970) | SR-CIS通过结合小模型快速推理和慢速决策的大模型，并通过CA-OAD机制实现高效协作，提供了一种新的内存与推理解耦的机制，以解决当前深度学习模型在面对人类记忆和学习机制时的挑战。 |
| [^47] | [ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science](https://arxiv.org/abs/2408.01966) | ML-EAT是一种量度语言技术固有偏见的工具，采用多层次方法进行可解释和透明的分析。 |
| [^48] | [Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification](https://arxiv.org/abs/2408.01964) | 本文讨论了分布式系统在网络安全中的应用，并提出了相应的安全策略。 |
| [^49] | [The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations](https://arxiv.org/abs/2408.01962) | 本研究探讨了开放生成模型对以人为本的数据科学工作，特别是事实核查组织的具体影响，并分析了这些组织在数据科学流程中使用开放模型的动机及其对AI生成社会影响的潜在影响。 |
| [^50] | [Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study](https://arxiv.org/abs/2408.01961) | 论文发现英尼两种语言的AI倾向将青少年描绘成社会问题的一部分，而青少年自己更希望被展示出作为成长中个体所面临的正常挑战。 |
| [^51] | [Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI](https://arxiv.org/abs/2408.01959) | 研究揭示了43个CLIP视觉语言模型在面部印象偏见方面的学习情况，证明了社会一致性会中介模型反映的人类偏见程度，并且在数据集大规模训练下，模型更倾向于准确形成那些依赖于不可见属性的印象。 |
| [^52] | [Visual Grounding for Object-Level Generalization in Reinforcement Learning](https://arxiv.org/abs/2408.01942) | 这项研究通过视觉对齐和基于VLM的内在奖励函数，提升了在强化学习中指导代理进行未见过新对象的零样本概括的效率。 |
| [^53] | [Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference](https://arxiv.org/abs/2408.01935) | 本文定义了语言模型用于自然语言推理时的决策和复合风险，并通过实验框架评估了这两种风险，揭示了LLMs在复杂推理和频繁错误报告方面的局限性，为提高语言模型的可靠性提供了洞察。 |
| [^54] | [Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration](https://arxiv.org/abs/2408.01880) | 本文提出了一种名为FULORA的代理双人知识图推理模型，该模型利用层次强化学习中的高效指引-探索策略来克服多跳推理中的奖励稀疏和训练难题。通过高级代理提供阶段指引，低级代理能够快速收敛到最佳策略，并且在多个知识图推理任务中展现出优越性能。 |
| [^55] | [Safe Semi-Supervised Contrastive Learning Using In-Distribution Data as Positive Examples](https://arxiv.org/abs/2408.01872) |  |
| [^56] | [ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features](https://arxiv.org/abs/2408.01808) | 本文提出了一种新型的基于 linguistic feature 的黑盒语音识别模型攻击方法，该方法能够生成成本低且能抵抗模型更新的敌意音频样本，以成功欺骗 ASR 系统。 |
| [^57] | [Review of Cloud Service Composition for Intelligent Manufacturing](https://arxiv.org/abs/2408.01795) | 本文综述了智能制造业中云服务优化的研究进展，并提出了统一的优化指标体系，旨在支持智能制造平台的可持续发展。 |
| [^58] | [Advancing Green AI: Efficient and Accurate Lightweight CNNs for Rice Leaf Disease Identification](https://arxiv.org/abs/2408.01752) | 本次研究专注于建立轻量级CNN模型，如ShuffleNet、MobileNetV2和EfficientNet-B0，用于实现对水稻叶片病害的高效和准确识别。通过结合局部绝对差异操作、空间金字塔池化和改进的全连接层，该模型能够显著提高病害识别的准确率。 |
| [^59] | [LAM3D: Leveraging Attention for Monocular 3D Object Detection](https://arxiv.org/abs/2408.01739) | 本文提出了一种名为 LAM3D 的框架，它通过在 Pyramid Vision Transformer v2 的基础上增加2D/3D检测机制，有效利用自注意力机制进行单目3D目标检测，并在KITTI 3D对象检测基准上展示了其优越性能。 |
| [^60] | [Can LLMs predict the convergence of Stochastic Gradient Descent?](https://arxiv.org/abs/2408.01736) | 论文展示了大型语言模型在预测随机梯度下降收敛到局部最小值方面的出色性能。 |
| [^61] | [Landmark-guided Diffusion Model for High-fidelity and Temporally Coherent Talking Head Generation](https://arxiv.org/abs/2408.01732) | 我们提出了一个两阶段扩散模型，使用音频同步面部特征点，并在此基础上生成高质量、同步且时间一致的说话人头像视频，解决了当前模型在图像质量和唇形同步方面的不足。 |
| [^62] | [Joint Universal Adversarial Perturbations with Interpretations](https://arxiv.org/abs/2408.01715) | 论文提出了一种新的研究课题，探讨是否存在能够被良性样本检测的通用对抗性扰动，并将其用于对抗性防御策略。 |
| [^63] | [Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers](https://arxiv.org/abs/2408.01705) | 本文提出了一种名为 "Downstream Transfer Attack (DTA) 的创新方法，该方法利用预训练的视觉变换器模型的缺陷，转移到下游任务上进行有针对性的攻击。通过个性化的攻击策略，DTA能够在多个计算机视觉任务中有效运作。 |
| [^64] | [Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data](https://arxiv.org/abs/2408.01700) | 论文提出了一个结合知识图谱和大型语言模型的方法，用于提取和验证航空制造文档中的高度复杂和低产量产品的测试数据。 |
| [^65] | [Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization](https://arxiv.org/abs/2408.01697) | 该论文提出了一种基于信息瓶颈理论的不变图学习方法，旨在提高图神经网络在分布外数据上的性能。通过实验证明，该方法能有效地提取不变特征，优化图学习中的特征表示，同时保持对原分布数据的良好泛化能力。 |
| [^66] | [IDNet: A Novel Dataset for Identity Document Analysis and Fraud Detection](https://arxiv.org/abs/2408.01690) | 本研究引入了一个新的数据集IDNet，旨在促进隐私保护的欺诈检测技术的进步。 |
| [^67] | [Controllable Unlearning for Image-to-Image Generative Models via $\varepsilon$-Constrained Optimization](https://arxiv.org/abs/2408.01689) | 本文提出了一种使用ε控制因子调节图像到图像生成模型去学习程度的方法，旨在平衡去学习和模型性能，保护用户数据安全。 |
| [^68] | [SAT3D: Image-driven Semantic Attribute Transfer in 3D](https://arxiv.org/abs/2408.01664) | 这项研究提出了一种新的方法，可以基于参考图像在3D环境中实现更准确的语义属性转移，解决了以往方法在语义属性编辑方面的局限性。 |
| [^69] | [Positive-Unlabeled Constraint Learning (PUCL) for Inferring Nonlinear Continuous Constraints Functions from Expert Demonstrations](https://arxiv.org/abs/2408.01622) | 本论文提出了一个名为PUCL的新算法，用于从专家演示中推断未知连续约束函数，无需事先了解约束参数化和环境模型。算法通过训练策略从可行和不可行路径中提取信息，逐步优化约束函数。 |
| [^70] | [Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment](https://arxiv.org/abs/2408.01614) | 本研究提出了“心理分析师”，一种基于OpenAI GPT-4的定制模型，优化用于心理健康障碍的预筛查。该模型通过DSM-5、PHQ-8详细数据描述和大量训练数据的使用，在识别心理困扰方面表现出色，并显示出在预测PHQ-8评分方面的精确度。通过验证结果显示，该模型在改善心理健康支持和服务方面显示出巨大的潜力。 |
| [^71] | [Trustworthy Machine Learning under Social and Adversarial Data Sources](https://arxiv.org/abs/2408.01596) | 本文探讨了在社会和对抗性数据源影响下如何确保机器学习系统的输出仍然是可信赖的，提出了全新的理论框架和技术。 |
| [^72] | [Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference](https://arxiv.org/abs/2408.01582) | 本文提出了一种利用高斯扩散模型结合Conformal方法，对大规模随机对照试验中的个体治疗效应进行高效估计的新方法。通过探索预测数据的模式和理论优势，该方法能够处理大规模数据和不同的干预方案，并对治疗效应进行精确估计。 |
| [^73] | [Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging](https://arxiv.org/abs/2408.01554) | 该研究提出使用新型光学触觉传感器和机器学习算法，结合七自由度机器人和个性化、增材制造的胃癌肿瘤假体，进行胃息肉诊断。 |
| [^74] | [Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization](https://arxiv.org/abs/2408.01532) | 本文提出了一种基于RNN的音频-视觉深度伪造检测和定位的新框架，通过跨模态注意力和上下文信息的学习，提高检测准确性并定位伪造图像的不自然区域。 |
| [^75] | [Analyzing LLMs' Capabilities to Establish Implicit User Sentiment of Software Desirability](https://arxiv.org/abs/2408.01527) | 这里是中文摘要的总结 |
| [^76] | [Gradient flow in parameter space is equivalent to linear interpolation in output space](https://arxiv.org/abs/2408.01517) | 该论文证明参数空间的梯度流可通过重新参数化等效于输出空间的线性插值，并且在参数雅可比矩阵满秩的条件下，全局最小值可达。 |
| [^77] | [LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models](https://arxiv.org/abs/2408.01460) | 本地价值基准是一个针对大型语言模型评估其与澳大利亚价值观一致性的可扩展型框架，帮助世界各地的监管机构制定适合自己的评估标准。 |
| [^78] | [AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools](https://arxiv.org/abs/2408.01459) | 该研究通过使用ChatGPT-4等大型语言模型，发现代理式AI技术可能有助于辨别校园欺凌与玩笑，为学生的心理安全提供有效支持。 |
| [^79] | [Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance](https://arxiv.org/abs/2408.01458) | 本文批评了人工智能领域的公众调查，指出这些调查容易受到西方知识和价值观的影响，并建议在全球化的背景下设计更敏感的调查方法。 |
| [^80] | [Amman City, Jordan: Toward a Sustainable City from the Ground Up](https://arxiv.org/abs/2408.01454) | 安曼智慧城市项目介绍了如何通过创新技术改善市民生活质量和城市环境。 |
| [^81] | [Reporting and Analysing the Environmental Impact of Language Models on the Example of Commonsense Question Answering with External Knowledge](https://arxiv.org/abs/2408.01453) | 本文研究了语言模型在常识问答中应用的环境影响，强调了减少人工智能任务对环境影响的重要性。 |
| [^82] | [Estimating Environmental Cost Throughout Model's Adaptive Life Cycle](https://arxiv.org/abs/2408.01446) | 本文提出了一种预测指数PreIndex，用来估计在模型适应性生命周期的再培训过程中，从当前数据分布到新数据分布的变化中，所涉及的环境成本（如碳排放和能源消耗）。 |
| [^83] | [SUSTechGAN: Image Generation for Object Recognition in Adverse Conditions of Autonomous Driving](https://arxiv.org/abs/2408.01430) | 深圳科技大学提出的GAN模型增强了在不利条件下自动驾驶车辆对象识别的能力，通过生成图像增加了训练数据的多样性。 |
| [^84] | [Transferable Adversarial Facial Images for Privacy Protection](https://arxiv.org/abs/2408.01428) | 本文提出了一种新的面部隐私保护方案，能在保持高视觉质量的同时提高转移能力。通过直接塑造整个面部空间，而不是仅利用妆容信息等一种特征来整合对抗性噪声，该方案能够在黑盒场景中生成自然且高度可转移的对抗性面部图像。 |
| [^85] | [Siamese Transformer Networks for Few-shot Image Classification](https://arxiv.org/abs/2408.01427) | 本研究提出了基于Siamese Transformer的网络，通过提取全局和局部特征，结合了Euclidean distance measure，在少样本图像分类任务中取得了显著提升。 |
| [^86] | [Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions](https://arxiv.org/abs/2408.01091) | 中文总结要点 |
| [^87] | [CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression](https://arxiv.org/abs/2408.00938) | 本研究提出了一种基于临床知识改进的扩散模型，用于更准确地预测特发性肺纤维化（IPF）的进展。 |
| [^88] | [UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization](https://arxiv.org/abs/2408.00860) | 该模型通过将超声反射方向参数化和谐波编码与神经渲染结合，生成接近真实物理的3D超声图像，提高了图像质量和处理复杂反射的能力。 |
| [^89] | [Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models](https://arxiv.org/abs/2408.00230) | 文章探讨了文本到图像扩散模型在处理文字与图像概念映射时存在的问题，并提出了一种基于大型语言模型的解决方案，有效提高了模型对文字提示的响应一致性。 |
| [^90] | [Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)](https://arxiv.org/abs/2408.00108) | 本文提出了AA-CBR-P（基于偏好的抽象论证案例基于推理），它允许用户根据特定偏好对案例进行排序，并证明了模型在遵循这些偏好时进行预测的能力。这种方法在评估头颅肿瘤患者不同评估方法的有效性上得到了实验验证。 |
| [^91] | [Implementing Streaming algorithm and k-means clusters to RAG](https://arxiv.org/abs/2407.21300) | 论文提出了一种结合流算法和K-means聚类的RAG改进方案，以高效更新索引并缩短查询时间，同时节省内存资源。|> |
| [^92] | [Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection](https://arxiv.org/abs/2407.20708) | 设计了一种采用整数值训练和脉冲驱动推理的新型SNN，在对象检测任务上取得了比传统ANNs更好的性能，同时实现了高能效和实时检测能力。 |
| [^93] | [AOTree: Aspect Order Tree-based Model for Explainable Recommendation](https://arxiv.org/abs/2407.19937) | AOTree模型通过捕获用户评论中的方面顺序，为可解释的推荐系统提供了一种新的方法。 |
| [^94] | [VersusDebias: Universal Zero-Shot Debiasing for Text-to-Image Models via SLM-Based Prompt Engineering and Generative Adversary](https://arxiv.org/abs/2407.19524) | 我们提出了一种通用的文本到图像模型偏激消除框架VersusDebias，使用小语言模型和生成对手机制来减少偏激想象的影响，并通过提示工程生成无偏的提示。 |
| [^95] | [Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning](https://arxiv.org/abs/2407.19393) | 这里是中文总结出的一句话要点 |
| [^96] | [Be More Real: Travel Diary Generation Using LLM Agents and Individual Profiles](https://arxiv.org/abs/2407.18932) | 该研究引入了一种基于LLM代理的工作框架，通过提取个体的流动性模式和推理生成轨迹，实现了更真实的城市级旅行日记生成，并考虑了不同的个人特征。 |
| [^97] | [PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning](https://arxiv.org/abs/2407.18569) | 该方法通过结合模仿学习和深度强化学习，提高个性化驾驶规划的性能，尤其是在大量数据支持和泛化能力方面。 |
| [^98] | [Automated Explanation Selection for Scientific Discovery](https://arxiv.org/abs/2407.17454) | 这篇论文提出了一种结合机器学习和自动化推理的科学发现循环，用于生成和选择解释，并引入了新的解释选择标准。 |
| [^99] | [Analyzing the Polysemy Evolution using Semantic Cells](https://arxiv.org/abs/2407.16110) | 本文通过分析“春天”一词在不同语境中的4种含义，揭示了词汇多义性的演化是由语义单元的修改所引起的，并且这一过程是随时间逐渐发生的。 |
| [^100] | [A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model](https://arxiv.org/abs/2407.15362) | 文章提出了一种全新的网络结构，通过整合病理切片图像、病理报告和基因表达谱的多模态数据，训练出一个能够理解病理切片全局特征的模型，并在多种下游任务上取得了优于单一模态模型的性能。 |
| [^101] | [Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval](https://arxiv.org/abs/2407.10805) | Think-on-Graph 2.0 是一种改进的 RAG 框架，通过将问题与知识图对齐，促进深度推理和提高 LLM 结果的准确性和可靠性。 |
| [^102] | [ISMRNN: An Implicitly Segmented RNN Method with Mamba for Long-Term Time Series Forecasting](https://arxiv.org/abs/2407.10768) | 本文提出了一种改进的RNN模型ISMRNN，通过隐式分割和时间序列特异性Mamba解码器的结合，有效解决了传统RNN模型在处理长期依赖和信息丢失方面的局限性，提高了长时期时间序列预测的性能，尤其是在股票价格、比特币价格和能源消耗等数据集上的长期预测方面。 |
| [^103] | [Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning](https://arxiv.org/abs/2407.09281) | 本文通过比较大型语言模型与认知实例学习模型在预测人类行为决策方面的表现，发现大型语言模型在快速适应反馈方面表现出色，而认知实例学习模型则在处理延迟反馈方面更为有效。 |
| [^104] | [The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective](https://arxiv.org/abs/2407.08583) | 论文讨论了多模态大型语言模型与数据协同发展的关系，表明两者在模型性能和数据质量提升中起到相互促进的作用。 |
| [^105] | [Bridging Smoothness and Approximation: Theoretical Insights into Over-Smoothing in Graph Neural Networks](https://arxiv.org/abs/2407.01281) | 这项研究通过建立理论框架评估了图卷积网络逼近目标函数的限度，揭示了过度平滑现象的本质，并提出了新的视角来理解该问题。 |
| [^106] | [Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models](https://arxiv.org/abs/2407.00569) | 中文摘要提炼的要点 |
| [^107] | [InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection](https://arxiv.org/abs/2406.16464) | InterCLIP-MEP 框架使用交互式 CLIP 和增强的记忆预测器改进了对社交媒体上多模态 sarcasm 的检测效果。 |
| [^108] | [Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue](https://arxiv.org/abs/2406.06399) | 文章研究了大型语言模型在对话生成任务中的局限性，对比了在context学习与微调等不同适应技术在不同对话类型中的性能差异。 |
| [^109] | [Opinion-Guided Reinforcement Learning](https://arxiv.org/abs/2405.17287) | 本文提出了一种通过观点指导强化学习的方法，通过模型的提供者，我们可以更有效的优化强化学习代理在不同的环境和不确定性条件下的表现，同时对于在人工和人类指导下的经济效率都取得了积极的结果。 |
| [^110] | [Doubly-Dynamic ISAC Precoding for Vehicular Networks: A Constrained Deep Reinforcement Learning (CDRL) Approach](https://arxiv.org/abs/2405.14347) | 本文提出了一种基于约束深度强化学习的双重动态ISAC预编码策略，旨在提高车载网络中的通信效率，尤其是在动态变化的环境中。 |
| [^111] | [VR-GPT: Visual Language Model for Intelligent Virtual Reality Applications](https://arxiv.org/abs/2405.11537) | 文章提出了一种将视觉语言模型应用在VR环境中来提升用户交互和任务效率的创新方法，通过unity引擎和自研的VLM，实现了无需视觉文本指令的实时、直观用户交互。使用语音识别和文本转语音技术，有效提升了用户完成复杂任务的效率和舒适度。 |
| [^112] | [Dynamic In-context Learning with Conversational Models for Data Extraction and Materials Property Prediction](https://arxiv.org/abs/2405.10448) | 此工具是一种结合了对话型大型语言模型的开源提取工具，能够高效、准确地从科学文献中提取材料属性数据，已经在二维材料的厚度等关键参数上取得了超过95%的性能。 |
| [^113] | [Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification](https://arxiv.org/abs/2405.00156) | 利用Jax框架加速量子模拟，适用于长尾胸部X线多标签分类的高效混合量子迁移学习。 |
| [^114] | [N-Agent Ad Hoc Teamwork](https://arxiv.org/abs/2404.10740) | 该论文研究了在动态变化队友数量和类型的环境中，N个自治代理如何进行合作的问题，并提出了相应的理论和算法以解决这一挑战。 |
| [^115] | [OpenBias: Open-set Bias Detection in Text-to-Image Generative Models](https://arxiv.org/abs/2404.07990) | 本文提出OpenBias，一个检测文本到图像生成模型中开放集偏见的系统，无需预先定义的偏差集合，利用大型语言模型和视觉问答模型来识别和量化这些模型可能存在的偏差，解决了现有方法无法处理开放集偏差的问题，提供定量证据。 |
| [^116] | [Reinforcement Learning with Generalizable Gaussian Splatting](https://arxiv.org/abs/2404.07950) | 我们提出了一种基于可泛化高斯点积的强化学习方法，该方法在不同的环境中提供了更清晰和泛化的场景表示，并通过直接使用形状函数和概率分布去除了“黑箱”效应，使得方法更易于理解和可视化。 |
| [^117] | [Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers](https://arxiv.org/abs/2404.07220) | 论文提出了“混合RAG”方法，通过结合语义搜索技术和混合查询策略，改善了RAG系统的准确性，并在多个IR和生成式问答数据集上取得了突破性成果。 |
| [^118] | [Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs](https://arxiv.org/abs/2404.04264) | LGOT通过结合大型语言模型与知识图谱，解决了逻辑查询中的误导性问题及知识图的不完整性问题，提升了问答系统准确性。 |
| [^119] | [Offline Imitation of Badminton Player Behavior via Experiential Contexts and Brownian Motion](https://arxiv.org/abs/2403.12406) | 该研究提出了一种新的层次离线模仿学习模型RallyNet，旨在模仿羽毛球比赛中球员的行为决策过程。 |
| [^120] | [Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization](https://arxiv.org/abs/2403.10967) | 该研究通过改进Dreamer V3的世界模型，提出了一种新的情境重复状态空间模型（cRSSM），这种模型能够通过包含情境信息来实现更好的零样本泛化能力。该方法在两个不同的CARL基准任务上取得了更好的结果，并且在两个额外的数据集上也验证了其泛化性能的提升。 |
| [^121] | [Dissecting Deep RL with High Update Ratios: Combatting Value Divergence](https://arxiv.org/abs/2403.05996) | 研究表明，在强化学习中，当梯度更新次数远远超过环境样本时，通过对抗值函数分歧，算法能够保持学习能力，避免了优先偏见的出现。 |
| [^122] | [Aligning Large Language Models for Controllable Recommendations](https://arxiv.org/abs/2403.05063) | 我们提出了一种通过强化学习对语言模型进行微调和适应以提高它们遵循推荐系统和人类意图的能力的方法。 |
| [^123] | [PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering](https://arxiv.org/abs/2403.05053) | 研究提出了一种新的渐进式组合扩散方法，专注于图像合成中的前景生成，并通过改进的注意力引导策略显著提高了合成速度和质量。 |
| [^124] | [Class-incremental Learning for Time Series: Benchmark and Evaluation](https://arxiv.org/abs/2402.12035) | 这项研究为时间序列增量学习问题提供了一个全面的评估框架，并指出了当前算法的局限性。 |
| [^125] | [Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap](https://arxiv.org/abs/2402.06046) | 事故表明自动驾驶汽车在实际交通中存在风险，尤其是对紧急情况的识别和响应存在不足。 |
| [^126] | [Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding](https://arxiv.org/abs/2312.16477) | 本文提出了一种基于知识蒸馏的压缩方法，用于减少3D形状识别中视图级别方法的参数数量，同时保持性能。通过设计一种名为GMViT的高性能大型模型，以及引入空间自编码器增强特征表示，该方法在一个名为DeCoV的策略下实现了在图像分类任务上的较好性能。 |
| [^127] | [Robust Survival Analysis with Adversarial Regularization](https://arxiv.org/abs/2312.16019) | 本文提出了一种使用对抗性正则化的鲁棒生存分析方法，通过神经网络验证技术提高了生存模型在面对数据集不确定性时的性能。 |
| [^128] | [Exploiting Novel GPT-4 APIs](https://arxiv.org/abs/2312.14302) | 本研究对新型 GPT-4 APIs 的新功能进行了利用，发现即使是微调模型也可以移除其核心保护措施，并且能够进行函数调用和知识检索的劫持。 |
| [^129] | [Reliable Academic Conference Question Answering: A Study Based on Large Language Model](https://arxiv.org/abs/2310.13028) | 该研究开发了一个ConferenceQA数据集，并通过组织学术会议数据和问题-答案对标注，提高了大型语言模型在学术问题解答方面的可靠性和时效性。 |
| [^130] | [Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review](https://arxiv.org/abs/2310.03392) | 该研究系统性综述了在关键安全行业中人类与人工智能交互的研究，指出了目前研究中的局限性与挑战，并提出了改善该领域的研究最佳实践。 |
| [^131] | [Time-Series Classification in Smart Manufacturing Systems: An Experimental Evaluation of State-of-the-Art Machine Learning Algorithms](https://arxiv.org/abs/2310.02812) | 本研究通过实证评估了先进的机器学习算法在智能制造系统中的时间序列分类任务中的表现，发现了经典机器学习算法和深度学习算法在处理制造业复杂场景时的优越性能，并为制造业的时间序列分析提供了决策支持。 |
| [^132] | [On CNF formulas irredundant with respect to unit clause propagation](https://arxiv.org/abs/2309.01750) | 本文证明了对于某个特定形式的对称确定性霍恩函数，存在一个非冗余CNF公式，它相较于最小的大约$n^2$倍，这表明了在移除变量时可能存在的非冗余性问题。 |
| [^133] | [Large AI Model Empowered Multimodal Semantic Communications](https://arxiv.org/abs/2309.01249) | 本文提出了一种基于大型AI模型的大型AI模型-强化型多模态语义通信（LAM-MSC）框架，该框架利用多模态语言模型（MLM）和大型语言模型（LLM）进行多模态数据转换，以保持语义一致性，并进行个性化语义提取或恢复。 |
| [^134] | [LAMBO: Large AI Model Empowered Edge Intelligence](https://arxiv.org/abs/2308.15078) | LAMBO框架采用大型AI模型，通过输入嵌入和AED模型，结合ACE学习进行预训练，解决了边缘智能中异构约束、感知不全等问题，并提高了模型的泛化能力。 |
| [^135] | [Leveraging Language Model Capabilities for Sound Event Detection](https://arxiv.org/abs/2308.11530) | 本文提出了一种采用预训练的声学和语言模型，结合使用多模态表示学习，以构建一个更有效地进行声事件检测的框架。 |
| [^136] | [Inductive Meta-path Learning for Schema-complex Heterogeneous Information Networks](https://arxiv.org/abs/2307.03937) | 本文提出了一种名为SchemaWalk的算法，用于在复杂异构信息网络中学习元路径，该算法无需枚举所有路径实例即可高效地进行学习。 |
| [^137] | [Large AI Model-Based Semantic Communications](https://arxiv.org/abs/2307.03492) | 文章提出了一种基于大型AI模型的语义通信框架，通过SKB将图像分割成语义段，然后通过ASI对这些段进行加权整合，实现更高效的语义通信。 |
| [^138] | [The Cultivated Practices of Text-to-Image Generation](https://arxiv.org/abs/2306.11393) | 在《人工智造 · 影像印记》一章中，作者描述了文本到图像生成技术的里程碑式发展以及在其中扮演关键角色的“催生工程”。文章提醒我们需要对这种共创生态系统可能带来的影响进行深入思考。 |
| [^139] | [A Review on Knowledge Graphs for Healthcare: Resources, Applications, and Promises](https://arxiv.org/abs/2306.04802) | 这篇论文综述了医疗保健知识图谱的发展，强调了大型语言模型在构建更准确和全面的知识图谱中的应用，并讨论了可信的生成内容和模型评估的潜在改进。 |
| [^140] | [Markov Decision Processes under External Temporal Processes](https://arxiv.org/abs/2305.16056) | 这篇论文研究了在不断变化的外部时间过程影响下的马尔可夫决策过程，并提出了一种策略迭代算法来处理这个问题，同时分析了解决方案的样本复杂性和性能。 |
| [^141] | [Should We Attend More or Less? Modulating Attention for Fairness](https://arxiv.org/abs/2305.13088) | 这项研究提出了一种通过调整注意力权重来提高自然语言处理模型公平性的方法，该方法在模型训练后实施，对模型性能影响很小。 |
| [^142] | [Emergent Representations of Program Semantics in Language Models Trained on Programs](https://arxiv.org/abs/2305.11169) | 即使未曾直接训练过，AI模型也在阅读代码的过程中学习到了程序语义表示 |
| [^143] | [Context-dependent communication under environmental constraints](https://arxiv.org/abs/2305.05821) | 论文研究了在环境约束下，情境依赖通信如何从一种情境信号模型中产生，并探讨了发送者和接收者如何利用认知能力克服环境限制，实现有效沟通。 |
| [^144] | [Vision Learners Meet Web Image-Text Pairs](https://arxiv.org/abs/2301.07088) | 新型视觉学习者MUG通过自监督学习，在网络图像文本配对数据上进行预训练，旨在改进视觉表示。 |
| [^145] | [A Look at Value-Based Decision-Time vs. Background Planning Methods Across Different Settings](https://arxiv.org/abs/2206.08442) | 本研究比较了不同环境中基于价值的决策时刻规划和背景规划方法的有效性，并在理论上和实验中验证了哪一种方法在改进代理行为方面表现更好。 |
| [^146] | [Confidence-aware Self-Semantic Distillation on Knowledge Graph Embedding](https://arxiv.org/abs/2206.02963) | 本文提出了一种基于自语义蒸馏的知识图嵌入方法，该方法利用自我知识蒸馏增强KGE在低维空间中的性能，无需预训练的高维模型，且操作简单。 |

# 详细

[^1]: 自教裁判

    Self-Taught Evaluators

    [https://arxiv.org/abs/2408.02666](https://arxiv.org/abs/2408.02666)

    本文提出了一种使用合成数据自教方法，无需人类注释，大幅度提升了Llama3-70B-Instruct模型的性能，并在RewardBench上取得了显著的改进。

    

    arXiv:2408.02666v1 公告类型：交叉 摘要：基于模型的评估是成功模型开发的核心——作为训练的奖励模型，以及作为人类评估的替代品。为了训练这样的裁判，传统的做法是收集大量人类对模型响应的偏好判断，这既耗时又耗力，因为随着时间的推移，数据也会变得过时。在这个工作中，我们提出了一种旨在不使用人类注释改善裁判的策略，仅使用合成训练数据。从未标注的指令开始，我们的迭代自改进方案生成对比性的模型输出，并训练一个基于LLM的裁判，以便生成推理轨迹和最终判断，在每个新迭代中使用改进的预测进行重复训练。我们的自教裁判不需要任何标注的偏好数据，就可以将一个强大的LLM（Llama3-70B-Instruct）的性能从75.4提高到88.3（加入多数投票，则为88.7）在RewardBench上。这超过了常用LLM评判工具的表现，有潜力节省成本并应对模型不断进步所带来的挑战。

    arXiv:2408.02666v1 Announce Type: cross  Abstract: Model-based evaluation is at the heart of successful model development -- as a reward model for training, and as a replacement for human evaluation. To train such evaluators, the standard approach is to collect a large amount of human preference judgments over model responses, which is costly and the data becomes stale as models improve. In this work, we present an approach that aims to im-prove evaluators without human annotations, using synthetic training data only. Starting from unlabeled instructions, our iterative self-improvement scheme generates contrasting model outputs and trains an LLM-as-a-Judge to produce reasoning traces and final judgments, repeating this training at each new iteration using the improved predictions. Without any labeled preference data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct) from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms commonly used LLM jud
    
[^2]: SEAS：大型语言模型自我演化对抗安全优化

    SEAS: Self-Evolving Adversarial Safety Optimization for Large Language Models

    [https://arxiv.org/abs/2408.02632](https://arxiv.org/abs/2408.02632)

    SEAS框架通过自我演化对抗优化，提高了大型语言模型在红队演练中的安全性和鲁棒性。

    

    arXiv:2408.02632v1 预告类型：交叉  译文摘要：随着大型语言模型(LLMs)在能力和影响力方面的不断进步，确保其安全和防止有害输出变得至关重要。一种解决这些问题的 promising（有希望的）方法是训练模型自动生成用于红队演练的对抗性提示。然而，LLMs漏洞的演变微妙性挑战了当前对抗性方法的有效性，这些方法难以专门针对并探索这些模型的弱点。为了应对这些挑战，我们提出了“SEAS：自我演化对抗安全优化”（Self-Evolving Adversarial Safety Optimization）优化框架，它通过利用模型自身生成的数据来增强安全性。SEAS通过三个迭代的阶段：初始化、攻击和对抗性优化，来改进红队和目标模型以提高鲁棒性和安全性。本框架通过自我完善，使得模型更加安全和可靠。

    arXiv:2408.02632v1 Announce Type: cross  Abstract: As large language models (LLMs) continue to advance in capability and influence, ensuring their security and preventing harmful outputs has become crucial. A promising approach to address these concerns involves training models to automatically generate adversarial prompts for red teaming. However, the evolving subtlety of vulnerabilities in LLMs challenges the effectiveness of current adversarial methods, which struggle to specifically target and explore the weaknesses of these models. To tackle these challenges, we introduce the $\mathbf{S}\text{elf-}\mathbf{E}\text{volving }\mathbf{A}\text{dversarial }\mathbf{S}\text{afety }\mathbf{(SEAS)}$ optimization framework, which enhances security by leveraging data generated by the model itself. SEAS operates through three iterative stages: Initialization, Attack, and Adversarial Optimization, refining both the Red Team and Target models to improve robustness and safety. This framework reduc
    
[^3]: 通过重新定义谓词的逆向解释

    Backward explanations via redefinition of predicates

    [https://arxiv.org/abs/2408.02606](https://arxiv.org/abs/2408.02606)

    本文提出了一种新的逆向解释方法，可以在不牺牲分数质量的情况下为RL代理在环境中的长序列交互提供解释。

    

    arXiv:2408.02606v1 通告类型： 新 摘要： 基于谓词的历史解释（HXP）研究了一个强化学习（RL）代理在环境中的序列交互行为（历史），并通过任意谓词来观察其行为。为此，为历史中的每个动作计算一个动作重要性分数。解释的组成部分是向用户显示最重要的动作。由于计算动作重要性分数是一组#W[1] hardness问题，对于长历史，我们需要近似分数，以牺牲分数质量为代价。因此，我们提出了一种新的HXP方法，称为反向HXP，能够在不近似分数的情况下为这些历史提供解释。实验展示出了B-HXP方法描述长历史的能力。

    arXiv:2408.02606v1 Announce Type: new  Abstract: History eXplanation based on Predicates (HXP), studies the behavior of a Reinforcement Learning (RL) agent in a sequence of agent's interactions with the environment (a history), through the prism of an arbitrary predicate. To this end, an action importance score is computed for each action in the history. The explanation consists in displaying the most important actions to the user. As the calculation of an action's importance is #W[1]-hard, it is necessary for long histories to approximate the scores, at the expense of their quality. We therefore propose a new HXP method, called Backward-HXP, to provide explanations for these histories without having to approximate scores. Experiments show the ability of B-HXP to summarise long histories.
    
[^4]: 利用图文描述提取多模态讽刺检测中增强的多层级跨模态语义不匹配表示法，通过注意力机制进行视觉语义建模

    Modelling Visual Semantics via Image Captioning to extract Enhanced Multi-Level Cross-Modal Semantic Incongruity Representation with Attention for Multimodal Sarcasm Detection

    [https://arxiv.org/abs/2408.02595](https://arxiv.org/abs/2408.02595)

    本文提出了一种新框架来检测多模态讽刺，该框架利用图文描述来捕捉和检测讽刺，并提高了模型处理图文不匹配的能力。

    

    arXiv:2408.02595v1 公告类型：新  摘要：讽刺是一种讽刺，以其固有的字面解读与意图内涵之间的差异为特征。尽管文本讽刺检测已经受到了广泛的探讨，但在一些情况下，仅凭文本输入可能不足以解读讽刺。为了在社交媒体数据中有效地识别讽刺，必须包含额外的情境线索，如图片。本研究提出了一个用于多模态讽刺检测的全新框架，它能够处理输入三元组。这些三元组中的两个组成元素是输入文本及其关联的图片，如数据集中所提供。此外，还引入了一种补充模态，即描述性的图片描述。引入这种视觉语义表示的动机是为了更准确地捕获文本与视觉内容之间的分歧，这对于讽刺检测任务来说是根本的。该研究的主要挑战在于如何更加敏感地捕捉图文之间的语义不匹配，以及如何通过引人注意机制来增强文本模块的表达能力。通过在Facebook和Instagram上分享的图片和图文帖子中加入描述性图片描述，该系统展示了如何通过多层级语义表示来捕捉讽刺的语义不匹配，并提出了一种有效的方法来检测其中的讽刺。

    arXiv:2408.02595v1 Announce Type: new  Abstract: Sarcasm is a type of irony, characterized by an inherent mismatch between the literal interpretation and the intended connotation. Though sarcasm detection in text has been extensively studied, there are situations in which textual input alone might be insufficient to perceive sarcasm. The inclusion of additional contextual cues, such as images, is essential to recognize sarcasm in social media data effectively. This study presents a novel framework for multimodal sarcasm detection that can process input triplets. Two components of these triplets comprise the input text and its associated image, as provided in the datasets. Additionally, a supplementary modality is introduced in the form of descriptive image captions. The motivation behind incorporating this visual semantic representation is to more accurately capture the discrepancies between the textual and visual content, which are fundamental to the sarcasm detection task. The primar
    
[^5]: 利用LLMs的力量：针对高质量基于属性的摘要的高质量微调方法

    Leveraging the Power of LLMs: A Fine-Tuning Approach for High-Quality Aspect-Based Summarization

    [https://arxiv.org/abs/2408.02584](https://arxiv.org/abs/2408.02584)

    本文研究了如何通过微调大型语言模型来提高基于属性的摘要的质量，并将在特定领域摘要数据集上的实验结果与实际性能提升进行了评估。

    

    arXiv:2408.02584v1 公告类型：交叉  摘要：信息数字化时代的不断增长迫切需要高效的方法，以便用户从长篇文章中提取关键洞察。基于属性的摘要提供了一种针对性的方法，生成重点关注特定方面在文件内的摘要。尽管基于属性的摘要研究在总结领域取得了进步，但我们仍在不断寻求更好的模型性能。鉴于大型语言模型（LLMs）在自然语言处理领域的不同任务中展示了潜在的革命性发展，特别是在总结问题中，本文探讨了LLMs在基于属性的摘要任务上的微调潜力。我们评估了公开源基础LLMs，如Llama2、Mistral、Gemma和Aya的微调对一个公开可用的特定领域基于属性的摘要数据集的影响。我们的假设是这种方法将使这些模型能够有效地识别和提取与属性的相关内容，并且在实际摘要任务中显著提高性能。

    arXiv:2408.02584v1 Announce Type: cross  Abstract: The ever-increasing volume of digital information necessitates efficient methods for users to extract key insights from lengthy documents. Aspect-based summarization offers a targeted approach, generating summaries focused on specific aspects within a document. Despite advancements in aspect-based summarization research, there is a continuous quest for improved model performance. Given that large language models (LLMs) have demonstrated the potential to revolutionize diverse tasks within natural language processing, particularly in the problem of summarization, this paper explores the potential of fine-tuning LLMs for the aspect-based summarization task. We evaluate the impact of fine-tuning open-source foundation LLMs, including Llama2, Mistral, Gemma and Aya, on a publicly available domain-specific aspect based summary dataset. We hypothesize that this approach will enable these models to effectively identify and extract aspect-relat
    
[^6]: 带有押韵的语音聚类和挖掘对包容性和公平性语音识别的重要性

    Clustering and Mining Accented Speech for Inclusive and Fair Speech Recognition

    [https://arxiv.org/abs/2408.02582](https://arxiv.org/abs/2408.02582)

    本文提出了一种针对难以涉足的口音语音识别的公平性系统，通过改进的聚类和数据挖掘方法显著提高了非典型口音的语音识别性能。

    

    arXiv:2408.02582v1 公告类型: 跨学科摘要: 现代自动语音识别(ASR)系统通常是在超过数万小时语音数据的训练下取得的巨大成功。然而，这样的数据分布通常倾向于平衡或者典型语音模式。因此，这些系统在典型口音以外的非典型口音的语音识别上表现不佳。在本研究中提出了倾斜语音聚类和挖掘方法来打造针对难以涉足的口音语音识别的公平系统。对于口音识别，我们应用了三种方法来克服数据量小或不平衡的监督口音数据：监督或无监督的数据预训练、分布稳健优化(DRO)及无监督的聚类方法。这三种方法对于校正小规模和不平衡口音语音的口音识别模型表现有显著提升。我们通过提出的方法在印度口音语音上对ASR进行微调并取得了显著的提升，这表明了监督和无监督的数据挖掘方法对于提高识别泛化性能的重要性。

    arXiv:2408.02582v1 Announce Type: cross  Abstract: Modern automatic speech recognition (ASR) systems are typically trained on more than tens of thousands hours of speech data, which is one of the main factors for their great success. However, the distribution of such data is typically biased towards common accents or typical speech patterns. As a result, those systems often poorly perform on atypical accented speech. In this paper, we present accent clustering and mining schemes for fair speech recognition systems which can perform equally well on under-represented accented speech. For accent recognition, we applied three schemes to overcome limited size of supervised accent data: supervised or unsupervised pre-training, distributionally robust optimization (DRO) and unsupervised clustering. Three schemes can significantly improve the accent recognition model especially for unbalanced and small accented speech. Fine-tuning ASR on the mined Indian accent speech using the proposed superv
    
[^7]: 基于心智理论的LLM代理评估与增强：在“挂戟丹”多玩家合作游戏中对不完美信息的处理

    Evaluating and Enhancing LLMs Agent based on Theory of Mind in Guandan: A Multi-Player Cooperative Game under Imperfect Information

    [https://arxiv.org/abs/2408.02559](https://arxiv.org/abs/2408.02559)

    在“挂戟丹”多玩家合作游戏中，研究探讨了LLM代理如何基于心智理论适应应对不同对手策略，尽管促进了良好合作，但性能仍然受到特定对手策略和游戏动态的影响，展现出了改进LLM推理能力以解决信息不完美挑战的潜力。

    

    arXiv:2408.02559v1 公告类型：交叉 摘要：大型语言模型（LLMs）在处理带有不完美信息的简单游戏中取得了成功，并能够在复杂的、带有不完美信息的环境中实现多代理协调，尤其是在非英语环境中，它们在实际与他人合作对抗代理的能力仍需进一步探索。本研究探讨了开源和基于API的LLMs在复杂的、需要在不完美信息环境中进行合作的文本游戏中的适用性，并将它们的性能与使用其他类型代理的现有基准进行比较。我们提出了一种心智理论（ToM）规划技术，允许LLM代理通过仅使用游戏规则、当前状态和历史上下文作为输入来适应对抗各种对手的策略。我们引入了一个外部工具来解决这种扑克游戏中动态和广泛的行动空间所面临的挑战。我们的结果表明，虽然LLM代理能够仅凭常识而成功，但他们的性能仍然依赖于具体的对手策略和游戏 dynamics，这表明了改进LLM推理和应对不完美信息挑战的潜在空间。这是研究人机合作问题的第一个研究，未来工作将集中在进一步提高LLM的性能和扩展到其他具有不同维度的多玩家文本游戏。

    arXiv:2408.02559v1 Announce Type: cross  Abstract: Large language models (LLMs) have shown success in handling simple games with imperfect information and enabling multi-agent coordination, but their ability to facilitate practical collaboration against other agents in complex, imperfect information environments, especially in a non-English environment, still needs to be explored. This study investigates the applicability of knowledge acquired by open-source and API-based LLMs to sophisticated text-based games requiring agent collaboration under imperfect information, comparing their performance to established baselines using other types of agents. We propose a Theory of Mind (ToM) planning technique that allows LLM agents to adapt their strategy against various adversaries using only game rules, current state, and historical context as input. An external tool was incorporated to mitigate the challenge of dynamic and extensive action spaces in this card game. Our results show that alth
    
[^8]: 功能性肌肉网络在提升手势感知精度中的作用对人类机器界面

    The Role of Functional Muscle Networks in Improving Hand Gesture Perception for Human-Machine Interfaces

    [https://arxiv.org/abs/2408.02547](https://arxiv.org/abs/2408.02547)

    本文提出了一种基于功能性肌肉网络的手势感知模型，通过高效地提取时频特征和时间序列分析技术，显著提升了手势识别的分类性能，相对于现有的方法具有更优越的性能。

    

    arXiv:2408.02547v1 公告类型：新摘要：准确的手势感知模型对于各种机器人应用的发展至关重要，它直接影响到神经机器人学和互动机器人的能力。最近，表面肌电图（sEMG）因其丰富的信息上下文和与先进机器学习方法及可穿戴系统的兼容性而被探索，用以提高各种基于sEMG的神经机器人感知模型的性能，同时确保其对于使用sEMG的神经机器人的鲁棒性。文献中提出了许多提高性能的方法，这些方法虽然确保了模型的高效性，但在实际应用中往往需要较强的计算能力、大规模的数据集和可扩展性较低的解决方案。本文通过提出从肌肉同步而非肌肉个体激活中解码信息的方法，来解决上述挑战。我们对功能性肌肉网络背后的肌肉同步进行了一定程度的理解，提出一种基于一致性功能肌肉网络的手势感知模型。我们还研究了肌肉间的同步和肌肉连接互联的图网络作为手部神经解码器。我们的模型利用高效的时频特征和时间序列分析技术，在分类性能方面实现了突显的提升。通过在多个手势识别任务上的实验验证，我们的模型相对现有方法显示出更优越的性能。

    arXiv:2408.02547v1 Announce Type: new  Abstract: Developing accurate hand gesture perception models is critical for various robotic applications, enabling effective communication between humans and machines and directly impacting neurorobotics and interactive robots. Recently, surface electromyography (sEMG) has been explored for its rich informational context and accessibility when combined with advanced machine learning approaches and wearable systems. The literature presents numerous approaches to boost performance while ensuring robustness for neurorobots using sEMG, often resulting in models requiring high processing power, large datasets, and less scalable solutions. This paper addresses this challenge by proposing the decoding of muscle synchronization rather than individual muscle activation. We study coherence-based functional muscle networks as the core of our perception model, proposing that functional synchronization between muscles and the graph-based network of muscle con
    
[^9]: 这里是翻译过的论文标题

    Counterfactual Shapley Values for Explaining Reinforcement Learning

    [https://arxiv.org/abs/2408.02529](https://arxiv.org/abs/2408.02529)

    这里是中文总结出的一句话要点

    

    这里是翻译过的论文摘要

    arXiv:2408.02529v1 Announce Type: new  Abstract: This paper introduces a novel approach Counterfactual Shapley Values (CSV), which enhances explainability in reinforcement learning (RL) by integrating counterfactual analysis with Shapley Values. The approach aims to quantify and compare the contributions of different state dimensions to various action choices. To more accurately analyze these impacts, we introduce new characteristic value functions, the ``Counterfactual Difference Characteristic Value" and the ``Average Counterfactual Difference Characteristic Value." These functions help calculate the Shapley values to evaluate the differences in contributions between optimal and non-optimal actions. Experiments across several RL domains, such as GridWorld, FrozenLake, and Taxi, demonstrate the effectiveness of the CSV method. The results show that this method not only improves transparency in complex RL systems but also quantifies the differences across various decisions.
    
[^10]: 单击延迟减少与单击或双击预测

    Single-tap Latency Reduction with Single- or Double- tap Prediction

    [https://arxiv.org/abs/2408.02525](https://arxiv.org/abs/2408.02525)

    本文提出了一种新的机器学习方法PredicTaps，可以在单击或双击出现之前预测检测到的点击是单击还是双击的第一接触点，从而显著减少了用户在触摸屏设备上的单击延迟。

    

    arXiv:2408.02525v1 公告类型：交叉  摘要：智能手机、平板电脑和笔记本电脑（触控板）上广泛使用触摸表面，单击和双击是最基本的也是最常用的操作。单或双击的检测导致单击延迟问题，这在触控输入的敏感性方面形成了一个性能瓶颈。为了减少单击延迟，我们提出了一种新的基于机器学习的点击预测方法，称为PredicTaps。我们的方法无需等待传统的数百毫秒，就能预测检测到的点击是单击还是双击的第一接触点。我们提出了三个评估和一个用户评估，展示了它在各种点击情况下的广泛适用性和在不同形式因子的触摸板和平板电脑上的可用性（触摸板和平板电脑）。结果表明，PredicTaps在不降低可用性的情况下，将笔记本电脑的单击延迟从150-500毫秒降低到12毫秒，将智能手机的单击延迟降低到17.6毫秒。

    arXiv:2408.02525v1 Announce Type: cross  Abstract: Touch surfaces are widely utilized for smartphones, tablet PCs, and laptops (touchpad), and single and double taps are the most basic and common operations on them. The detection of single or double taps causes the single-tap latency problem, which creates a bottleneck in terms of the sensitivity of touch inputs. To reduce the single-tap latency, we propose a novel machine-learning-based tap prediction method called PredicTaps. Our method predicts whether a detected tap is a single tap or the first contact of a double tap without having to wait for the hundreds of milliseconds conventionally required. We present three evaluations and one user evaluation that demonstrate its broad applicability and usability for various tap situations on two form factors (touchpad and smartphone). The results showed PredicTaps reduces the single-tap latency from 150-500 ms to 12 ms on laptops and to 17.6 ms on smartphones without reducing usability.
    
[^11]: 大型语言模型（LLM）代码生成功能的许可证合规性初探

    A First Look at License Compliance Capability of LLMs in Code Generation

    [https://arxiv.org/abs/2408.02487](https://arxiv.org/abs/2408.02487)

    研究评估了大型语言模型对受版权保护代码生成的许可证合规性，并提出了评估基准LiCoEval。

    

    arXiv:2408.02487v1 宣布类型：交叉

    arXiv:2408.02487v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have revolutionized code generation, leading to widespread adoption of AI coding tools by developers. However, LLMs can generate license-protected code without providing the necessary license information, leading to potential intellectual property violations during software production. This paper addresses the critical, yet underexplored, issue of license compliance in LLM-generated code by establishing a benchmark to evaluate the ability of LLMs to provide accurate license information for their generated code. To establish this benchmark, we conduct an empirical study to identify a reasonable standard for "striking similarity" that excludes the possibility of independent creation, indicating a copy relationship between the LLM output and certain open-source code. Based on this standard, we propose an evaluation benchmark LiCoEval, to evaluate the license compliance capabilities of LLMs. 
    
[^12]: 从大型语言模型到基于大型语言模型的软件工程代理：当前挑战和未来调查

    From LLMs to LLM-based Agents for Software Engineering: A Survey of Current, Challenges and Future

    [https://arxiv.org/abs/2408.02479](https://arxiv.org/abs/2408.02479)

    这篇论文调查了大型语言模型在软件工程中的应用，以及基于大型语言模型的代理（可能具有人工通用智能潜力）的优势和挑战。

    

    arXiv:2408.02479v1 公告类型：交叉  摘要：随着大型语言模型（LLMs）的兴起，研究人员越来越多地探索其在各个垂直领域的应用，例如软件工程。LLMs已在包括代码生成和漏洞检测在内的领域取得显著成功。然而，它们也表现出许多限制和不足。LLM-based代理是一种新技术，具有成为人工通用智能（AGI）的潜力，它将LLM作为核心进行决策和行动，解决了LLM缺乏自主性和自我改进的一些固有局限性。尽管许多研究和小结探讨了在软件工程中使用LLM的可能性，但它们缺乏对LLM和基于LLM的代理之间区别的明确区分。该领域仍然处于其统一标准和基准测试的早期阶段，这些标准和测试旨在确定一个LLM解决方案是否可以被认可为一个在它的领域中的LLM-based代理。在这项调查中，我们广泛地研究了当前的问题以及未来发展的挑战，并探讨了对LLM-based代理在软件工程中的应用的展望。

    arXiv:2408.02479v1 Announce Type: cross  Abstract: With the rise of large language models (LLMs), researchers are increasingly exploring their applications in var ious vertical domains, such as software engineering. LLMs have achieved remarkable success in areas including code generation and vulnerability detection. However, they also exhibit numerous limitations and shortcomings. LLM-based agents, a novel tech nology with the potential for Artificial General Intelligence (AGI), combine LLMs as the core for decision-making and action-taking, addressing some of the inherent limitations of LLMs such as lack of autonomy and self-improvement. Despite numerous studies and surveys exploring the possibility of using LLMs in software engineering, it lacks a clear distinction between LLMs and LLM based agents. It is still in its early stage for a unified standard and benchmarking to qualify an LLM solution as an LLM-based agent in its domain. In this survey, we broadly investigate the current p
    
[^13]: 关于AI基于电影CMR分割中的种族偏见调查

    An investigation into the causes of race bias in AI-based cine CMR segmentation

    [https://arxiv.org/abs/2408.02462](https://arxiv.org/abs/2408.02462)

    该研究发现AI在基于电影的心脏磁共振图像分割中存在种族偏见，并探讨了可能的原因，以便在未来改进模型以消除这些偏见的影响。

    

    arXiv:2408.02462v1 Announce Type: cross 摘要：人工智能（AI）方法正在越来越多地用于自动分割电影心脏磁共振（CMR）成像。然而，这些方法已经被证明存在种族偏见，即它们根据用于训练AI模型的数据的平衡（不平衡）水平表现出不同的性能。在本文中，我们调查了这种偏见的来源，寻求理解其根本原因，以便有效地加以缓解。我们在英国生物银行收集的黑人和白人受者的短轴电影CMR图像上进行了分类和分割实验，并应用了AI可解释性方法来理解结果。在分类实验中，我们从图像中独自预测种族，发现准确率很高，但从 ground truth 分割中预测的准确率较低，这表明种族之间的分布差异，这通常是导致AI模型性能差异的关键因素。ent 10.17632/ngpcgbvrb.2.

    arXiv:2408.02462v1 Announce Type: cross  Abstract: Artificial intelligence (AI) methods are being used increasingly for the automated segmentation of cine cardiac magnetic resonance (CMR) imaging. However, these methods have been shown to be subject to race bias, i.e. they exhibit different levels of performance for different races depending on the (im)balance of the data used to train the AI model. In this paper we investigate the source of this bias, seeking to understand its root cause(s) so that it can be effectively mitigated. We perform a series of classification and segmentation experiments on short-axis cine CMR images acquired from Black and White subjects from the UK Biobank and apply AI interpretability methods to understand the results. In the classification experiments, we found that race can be predicted with high accuracy from the images alone, but less accurately from ground truth segmentations, suggesting that the distributional shift between races, which is often the 
    
[^14]: 使用新颖的GAT（Graph Attention Network）方法增强异构知识图 completion

    Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach

    [https://arxiv.org/abs/2408.02456](https://arxiv.org/abs/2408.02456)

    本文提出了GATH，一种用于增强异构知识图完备性的新型基于GAT的方法。通过整合两个独立的注意力模型来预测缺失实体，并采用自适应采样策略以提高模型对重要节点和边相关性的学习能力。

    

    知识图（KG）在提高搜索结果和推荐系统的效率中起到了重要作用。随着KG大小的迅速增长，它们变得不准确且不完整。这个问题可以通过知识图 completion方法来解决，其中基于GAT的方法因其卓越的性能而脱颖而出。然而，现有的基于GAT的知识图 completion方法在处理异构知识图时经常遭受过拟合问题，这主要是因为样本数量不平衡。此外，这些方法在预测共享同一路径和头部（尾部）实体的尾（头）实体方面的表现不佳。为了解决这些问题，我们提出了GATH（Graph Attention Transformation for Heterogeneous KGs），一种专为异构KG设计的新颖基于GAT的方法。GATH包含两个单独的注意力网络模块，它们协同工作来预测缺失实体。我们还引入了一种自适应采样策略，在不同的实体中自动调整难易程度，以便网络能够更好地学习重要节点和边的相关性。通过在多个基准异构KG数据集上的广泛实验，我们证明了GATH在提高异构KG的完备性方面的有效性和优越性能。

    arXiv:2408.02456v1 Announce Type: cross  Abstract: Knowledge graphs (KGs) play a vital role in enhancing search results and recommendation systems. With the rapid increase in the size of the KGs, they are becoming inaccuracy and incomplete. This problem can be solved by the knowledge graph completion methods, of which graph attention network (GAT)-based methods stand out since their superior performance. However, existing GAT-based knowledge graph completion methods often suffer from overfitting issues when dealing with heterogeneous knowledge graphs, primarily due to the unbalanced number of samples. Additionally, these methods demonstrate poor performance in predicting the tail (head) entity that shares the same relation and head (tail) entity with others. To solve these problems, we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH incorporates two separate attention network modules that work synergistically to predict the missing entities. We also introduc
    
[^15]: 长输入基准分析俄罗斯语言表现

    Long Input Benchmark for Russian Analysis

    [https://arxiv.org/abs/2408.02439](https://arxiv.org/abs/2408.02439)

    LIBRA是一套专门用于评估LLM对俄罗斯长文本理解能力的基准，涉及21个数据集和不同的复杂度等级。

    

    arXiv:2408.02439v1 公告类型：交叉  摘要：自然语言处理（NLP）领域的最新进展促进了大型语言模型（LLM）的发展，这些模型能够解决大量的任务。它们应用的关键方面之一是它们能够处理长文本文档和处理长序列的标记。这创造了对长情境理解评估的需求。为了满足俄罗斯语言的需求，我们提出了一项长输入基准（LIBRA），它包括21个适应化的数据集，以深入研究LLM对长文本的理解。测试被分为四个复杂度组，并允许在各种上下文长度上评估模型，上下文长度从4k直到128k个标记。我们为LIBRA提供了开源数据集、代码库和公共排行榜，以指引未来的研究。

    arXiv:2408.02439v1 Announce Type: cross  Abstract: Recent advancements in Natural Language Processing (NLP) have fostered the development of Large Language Models (LLMs) that can solve an immense variety of tasks. One of the key aspects of their application is their ability to work with long text documents and to process long sequences of tokens. This has created a demand for proper evaluation of long-context understanding. To address this need for the Russian language, we propose LIBRA (Long Input Benchmark for Russian Analysis), which comprises 21 adapted datasets to study the LLM's abilities to understand long texts thoroughly. The tests are divided into four complexity groups and allow the evaluation of models across various context lengths ranging from 4k up to 128k tokens. We provide the open-source datasets, codebase, and public leaderboard for LIBRA to guide forthcoming research.
    
[^16]: 论文标题：PENDRAM：通过泛化DRAM数据映射策略实现深度神经网络的高性能和能效处理

    PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy

    [https://arxiv.org/abs/2408.02412](https://arxiv.org/abs/2408.02412)

    论文的主要贡献是将通用DRAM数据映射策略引入深度学习中，以提高深度神经网络的性能和能效，为加速器的设计提供了新方法。

    

    论文摘要：卷积神经网络（CNNs）是深度神经网络（DNNs）中的一种流行类型，已经被证明是解决机器学习任务的关键。为了提高CNN推理的性能和能效，专用的硬件加速器变得越来越流行。然而，CNN加速器仍然面临性能和能效问题，因为离散内存（DRAM）的访问延迟和能耗很高，这对于那些对延迟和能源有严格限制的嵌入式应用程序尤其重要。此外，不同的DRAM架构有不同的访问延迟和能耗特征，这使得为高能效和高性能CNN加速器优化它们变得复杂。为了解决这个问题，我们提出了PENDRAM，一种新的设计空间探索方法，它通过泛化DRAM数据映射策略为CNN加速提供了高性能和能效。尤其是，它通过泛化DRAM数据映射策略为CNN加速提供了高性能和能效。这种方法允许在不牺牲性能和能效的情况下实现DRAM的高效访问，从而为各种类似的任务提供了坚实的基础，包括但不限于图像和视频处理。

    arXiv:2408.02412v1 Announce Type: cross  Abstract: Convolutional Neural Networks (CNNs), a prominent type of Deep Neural Networks (DNNs), have emerged as a state-of-the-art solution for solving machine learning tasks. To improve the performance and energy efficiency of CNN inference, the employment of specialized hardware accelerators is prevalent. However, CNN accelerators still face performance- and energy-efficiency challenges due to high off-chip memory (DRAM) access latency and energy, which are especially crucial for latency- and energy-constrained embedded applications. Moreover, different DRAM architectures have different profiles of access latency and energy, thus making it challenging to optimize them for high performance and energy-efficient CNN accelerators. To address this, we present PENDRAM, a novel design space exploration methodology that enables high-performance and energy-efficient CNN acceleration through a generalized DRAM data mapping policy. Specifically, it expl
    
[^17]: 使用去噪扩散模型进行多天气跨视角地理定位

    Multi-weather Cross-view Geo-localization Using Denoising Diffusion Models

    [https://arxiv.org/abs/2408.02408](https://arxiv.org/abs/2408.02408)

    论文提出 MCGF 多天气跨视角地理定位框架，通过使用去噪扩散模型动态适应未知天气条件，并采用联合优化方法提升跨视角地理定位的准确性。

    

    arXiv:2408.02408v1 公告类型: 新 Abstract: 跨视角地理定位在无GNSS信号的环境中旨在通过匹配无人机拍摄的图像与大量带有地理标签的卫星图像来确定未知位置。最近的研究表明，在特定天气条件下学习区分性图像表示可以显著提高性能。然而，不常见极端天气条件的频繁出现阻碍了进步。本文介绍了一个名为MCGF的多天气跨视角地理定位框架，它旨在使用去噪扩散模型动态适应未知天气条件。MCGF为图像恢复和地理定位建立了联合优化。为了图像恢复，MCGF引入了一个共享编码器和轻量级去噪模块来帮助主干消除与特定天气有关的信息。对于地理定位，MCGF使用EVA-02作为主干来提取特征，并使用交叉熵损失进行定位和天气调整。

    arXiv:2408.02408v1 Announce Type: new  Abstract: Cross-view geo-localization in GNSS-denied environments aims to determine an unknown location by matching drone-view images with the correct geo-tagged satellite-view images from a large gallery. Recent research shows that learning discriminative image representations under specific weather conditions can significantly enhance performance. However, the frequent occurrence of unseen extreme weather conditions hinders progress. This paper introduces MCGF, a Multi-weather Cross-view Geo-localization Framework designed to dynamically adapt to unseen weather conditions. MCGF establishes a joint optimization between image restoration and geo-localization using denoising diffusion models. For image restoration, MCGF incorporates a shared encoder and a lightweight restoration module to help the backbone eliminate weather-specific information. For geo-localization, MCGF uses EVA-02 as a backbone for feature extraction, with cross-entropy loss for
    
[^18]: 《在隐私意识驱动的助手操作上下文完整性》

    Operationalizing Contextual Integrity in Privacy-Conscious Assistants

    [https://arxiv.org/abs/2408.02373](https://arxiv.org/abs/2408.02373)

    本文提出了一种通过将上下文完整性框架应用于信息流，以指导信息共享助手的行为，实现用户隐私的合规性。

    

    arXiv:2408.02373v1 公告类型：新发布 概要：高级人工智能助手结合了前沿的自然语言模型和工具访问权限，能够在无需用户监督的情况下自动执行复杂的任务。然而，助手有访问用户信息（如电子邮件和文档）的能力，这提高了隐私担忧。为了引导信息共享助手的行为符合隐私期望，本文提出了一种将“上下文完整性”（CI）框架应用于信息流，该框架认为隐私是根据特定上下文适当的信息流动。特别是，我们设计并评估了多种指导助手信息共享行为的CI合规策略。我们的评估基于一个由合成数据和人工注释组成的新的表单填写基准，结果显示，提示前沿的自然语言模型执行CI基础的推理，能够实现更好的合规性。

    arXiv:2408.02373v1 Announce Type: new  Abstract: Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields stron
    
[^19]: 通过有约束的思考链解码进行会话本体关系提取

    Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding

    [https://arxiv.org/abs/2408.02361](https://arxiv.org/abs/2408.02361)

    本文提出了一种使用有约束的思考链解码技术来提高对话系统中的关系提取的准确性，通过训练模型学习更具体的信息，减少了对手动构建本体的需求。

    

    arXiv:2408.02361v1 公告类型: 交叉 摘要: 领域领先的任务导向对话系统大多依赖于任务特定的本体以满足用户查询。像客户服务录音这样的任务导向对话数据的大多数，都没有本体和标注。这样的本体通常是通过手动构建的，这限制了专用系统的应用。对话本体构造是一种自动化该过程的方法，通常包括两步：术语提取和关系提取。在本文工作中，我们专注于跨学习环境中的关系提取。为了提高泛化能力，我们提出了对大型语言模型解码机制的扩展。我们采纳了最近为推理问题开发的思想链(CoT)解码技术，将其应用于生成式关系提取。在这里，我们在解码空间中生成多个分支，并根据信心阈值选择关系。通过约束解码器至本体术语的定义，我们训练模型学习更具体的信息，并将负样的生成预防到了最优解中。实验结果表明，与基线模型相比，我们的方法能够更好地提取对话和相关关系，从而降低了对手动构建本体的需求，对构建动态调整的用户服务系统有着积极的意义。

    arXiv:2408.02361v1 Announce Type: cross  Abstract: State-of-the-art task-oriented dialogue systems typically rely on task-specific ontologies for fulfilling user queries. The majority of task-oriented dialogue data, such as customer service recordings, comes without ontology and annotation. Such ontologies are normally built manually, limiting the application of specialised systems. Dialogue ontology construction is an approach for automating that process and typically consists of two steps: term extraction and relation extraction. In this work, we focus on relation extraction in a transfer learning set-up. To improve the generalisation, we propose an extension to the decoding mechanism of large language models. We adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning problems, to generative relation extraction. Here, we generate multiple branches in the decoding space and select the relations based on a confidence threshold. By constraining the decoding to ontology t
    
[^20]: 开发 PUGG 对于波兰语：针对 KBQA、MRC 和 IR 数据集构建的现代方法

    Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction

    [https://arxiv.org/abs/2408.02337](https://arxiv.org/abs/2408.02337)

    本文介绍了一种现代的半自动化方法，用于创建针对低资源语言的KBQA、MRC和IR数据集，并推出了首个波兰语KBQA数据集PUGG，结合大型语言模型和波兰语知识图谱，显著提升了问答系统的效率和准确性。

    

    arXiv:2408.02337v1 宣布类型：新  摘要：人工智能和自然语言处理领域的进步已经彻底改变了机器与人类之间的语言互动，问答系统（QA）在这一过程中扮演了核心角色。知识基质问答（KBQA）任务，利用结构化知识图（KG），允许处理大量知识密集型的问题。但是，对于低资源语言的KBQA数据集存在着显著的差距。许多现有数据集的构建管道过时且在人力资源方面效率低下，并不利用现代辅助工具，如大型语言模型（LLM）来减少工作量。为了解决这个问题，我们设计并实现了专门针对低资源环境的现代半自动化数据集构建方法，涵盖了KBQA、机器阅读理解（MRC）和信息检索（IR）等任务。我们执行了这个管道，并推出了PUGG数据集，这是首个波兰语KBQA数据集，通过结合LLM技术和波兰语知识图谱，显著提升了问答系统的效率和准确性，为波兰语的低资源环境带来了期望的改进。

    arXiv:2408.02337v1 Announce Type: new  Abstract: Advancements in AI and natural language processing have revolutionized machine-human language interactions, with question answering (QA) systems playing a pivotal role. The knowledge base question answering (KBQA) task, utilizing structured knowledge graphs (KG), allows for handling extensive knowledge-intensive questions. However, a significant gap exists in KBQA datasets, especially for low-resource languages. Many existing construction pipelines for these datasets are outdated and inefficient in human labor, and modern assisting tools like Large Language Models (LLM) are not utilized to reduce the workload. To address this, we have designed and implemented a modern, semi-automated approach for creating datasets, encompassing tasks such as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR), tailored explicitly for low-resource environments. We executed this pipeline and introduced the PUGG dataset, the first Poli
    
[^21]: 关于鲁棒强化学习的广义高斯TD误差模型

    Generalized Gaussian Temporal Difference Error For Uncertainty-aware Reinforcement Learning

    [https://arxiv.org/abs/2408.02295](https://arxiv.org/abs/2408.02295)

    研究提出了一种鲁棒的强化学习框架，通过广义高斯误差模型改进了数据的误差和不确定性估计。

    

    我们提出了一个在深度强化学习中基于广义高斯误差模型的新框架，适用于离散和连续的控制设置。我们的框架改进了对误差分布的灵活建模，通过包含更高阶的统计量（特别是峰度），提高了数据相关的噪声估计，即，误差的不确定性。我们研究了广义高斯分布的形状参数对误差不确定性的影响，并提供了闭合形式的表达式，这表明了不确定性与形状参数之间的关系。

    arXiv:2408.02295v1 Announce Type: cross  Abstract: Conventional uncertainty-aware temporal difference (TD) learning methods often rely on simplistic assumptions, typically including a zero-mean Gaussian distribution for TD errors. Such oversimplification can lead to inaccurate error representations and compromised uncertainty estimation. In this paper, we introduce a novel framework for generalized Gaussian error modeling in deep reinforcement learning, applicable to both discrete and continuous control settings. Our framework enhances the flexibility of error distribution modeling by incorporating higher-order moments, particularly kurtosis, thereby improving the estimation and mitigation of data-dependent noise, i.e., aleatoric uncertainty. We examine the influence of the shape parameter of the generalized Gaussian distribution (GGD) on aleatoric uncertainty and provide a closed-form expression that demonstrates an inverse relationship between uncertainty and the shape parameter. Add
    
[^22]: 硬件自适应集成选择方法以平衡预测准确性和成本

    Hardware Aware Ensemble Selection for Balancing Predictive Accuracy and Cost

    [https://arxiv.org/abs/2408.02280](https://arxiv.org/abs/2408.02280)

    本文提出了一种面向硬件的集成选择方法，该方法将推理时间整合到后验集成中，以在预测准确性和推理效率之间取得平衡。我们的方法可以在保持高预测精度的同时提高集成功率，适合部署在资源有限或成本敏感的生产环境中。

    

    arXiv:2408.02280v1 公告类型: 交叉  翻译摘要: 自动机器学习 (AutoML) 在简化机器学习模型部署方面发挥了巨大作用，它自动化了从数据预处理到模型选择再到集成的一系列任务。针对表格数据的AutoML系统通常采用后验集成方法，该方法通过结合多个模型来提高预测准确性。这通常会导致更长的推理时间，这在实际部署中是一个主要限制。为了解决这个问题，我们提出了一种面向硬件的集成选择方法，该方法将推理时间整合到后验集成中。通过利用现有的集成选择框架，该框架采用质量多样性优化，我们的方法对候选集合的预测准确性和硬件效率进行了评估。这种双重焦点使人们能够从准确性和效率的帕累托前沿中进行选择。我们的评估使用合集能够根据服务器硬件和机器学习任务的细节，在预测精度、集成大小和推理时间之间取得权衡。这种方法验证了在保持高预测精度同时提高集成功率的潜力，适合部署在资源有限或成本敏感的生产环境中。

    arXiv:2408.02280v1 Announce Type: cross  Abstract: Automated Machine Learning (AutoML) significantly simplifies the deployment of machine learning models by automating tasks from data preprocessing to model selection to ensembling. AutoML systems for tabular data often employ post hoc ensembling, where multiple models are combined to improve predictive accuracy. This typically results in longer inference times, a major limitation in practical deployments. Addressing this, we introduce a hardware-aware ensemble selection approach that integrates inference time into post hoc ensembling. By leveraging an existing framework for ensemble selection with quality diversity optimization, our method evaluates ensemble candidates for their predictive accuracy and hardware efficiency. This dual focus allows for a balanced consideration of accuracy and operational efficiency. Thus, our approach enables practitioners to choose from a Pareto front of accurate and efficient ensembles. Our evaluation u
    
[^23]: DRFormer：利用多样 receptive field 的多尺度 Transformer 长时序预测

    DRFormer: Multi-Scale Transformer Utilizing Diverse Receptive Fields for Long Time-Series Forecasting

    [https://arxiv.org/abs/2408.02279](https://arxiv.org/abs/2408.02279)

    本研究提出了一种名为 DRFormer 的多尺度 Transformer 模型，创新性地使用动态 Tokenizer 和动态稀疏学习算法来捕捉时间序列数据的多样 receptive field 和稀疏模式。该模型能够构建层级化的 receptive field，并有效抽取不同时间尺度的信息，显著提升了长期时间序列预测任务中的性能。

    

    arXiv:2408.02279v1 Announce Type: cross  摘要：长时序预测（LTSF）在金融、交通预测等诸多领域得到了广泛应用。近期，基于片段的 Transformer 模型作为一种前景的解决方案受到关注，它将数据分为底层片段，作为输入的键。然而，现有的方法主要依赖于预先设定的片段长度，这需要行业专家的知识，并且在捕捉不同尺度的数据特征方面面临挑战。此外，时间序列数据在不同的时间尺度上表现出不同的变化和波动模式，这传统方法难以有效建模。在本文中，我们提出了一种以动态学习算法为指导的动态 Tokenizer，用于捕捉时间序列数据中的多样 receptive field 和稀疏模式。为了建立层级化的 receptive field，我们开发了一种多尺度 Transformer 模型，结合了多尺度序列抽取，能够捕捉多尺度特征。模型可以有效地抽取不同时间尺度的信息，从而在长期预测任务中获得更好性能。

    arXiv:2408.02279v1 Announce Type: cross  Abstract: Long-term time series forecasting (LTSF) has been widely applied in finance, traffic prediction, and other domains. Recently, patch-based transformers have emerged as a promising approach, segmenting data into sub-level patches that serve as input tokens. However, existing methods mostly rely on predetermined patch lengths, necessitating expert knowledge and posing challenges in capturing diverse characteristics across various scales. Moreover, time series data exhibit diverse variations and fluctuations across different temporal scales, which traditional approaches struggle to model effectively. In this paper, we propose a dynamic tokenizer with a dynamic sparse learning algorithm to capture diverse receptive fields and sparse patterns of time series data. In order to build hierarchical receptive fields, we develop a multi-scale Transformer model, coupled with multi-scale sequence extraction, capable of capturing multi-resolution feat
    
[^24]: 几何代数与大型语言模型的结合：3D交互型可控场景中分离网格的指令驱动转换

    Geometric Algebra Meets Large Language Models: Instruction-Based Transformations of Separate Meshes in 3D, Interactive and Controllable Scenes

    [https://arxiv.org/abs/2408.02275](https://arxiv.org/abs/2408.02275)

    本系统利用几何代数与大型语言模型结合，实现了3D场景中对象精确重新定位，无需专业训练数据，仅通过自然语言指令即可操作。

    

    这篇论文介绍了一种新型的大语言模型(LLMs)与康式几何代数(CGA)的集成，它旨在革新可控3D场景编辑，特别是对象重新定位任务，这些任务通常需要复杂的手动流程和专业技能。这些传统的技艺通常依赖于大量的训练数据集或缺乏对精确编辑的正式语言描述。我们的系统“shenlong”使用CGA作为强大的正式语言，精确地建模了进行精确对象重新定位所需的空间变换。借助预训练LLMs的无监督学习能力，“shenlong”可以将自然语言指令翻译成CGA操作，并将这些操作应用于场景中，从而在三维场景中实现精确的空间变换，而无需专门的数据预训练。在现实的模拟环境中实施后，“shenlong”确保了与现有系统的兼容性。

    arXiv:2408.02275v1 Announce Type: new  Abstract: This paper introduces a novel integration of Large Language Models (LLMs) with Conformal Geometric Algebra (CGA) to revolutionize controllable 3D scene editing, particularly for object repositioning tasks, which traditionally requires intricate manual processes and specialized expertise. These conventional methods typically suffer from reliance on large training datasets or lack a formalized language for precise edits. Utilizing CGA as a robust formal language, our system, shenlong, precisely models spatial transformations necessary for accurate object repositioning. Leveraging the zero-shot learning capabilities of pre-trained LLMs, shenlong translates natural language instructions into CGA operations which are then applied to the scene, facilitating exact spatial transformations within 3D scenes without the need for specialized pre-training. Implemented in a realistic simulation environment, shenlong ensures compatibility with existing
    
[^25]: 多源异构知识注入的提示学习方法用于法律指控预测

    A Multi-Source Heterogeneous Knowledge Injected Prompt Learning Method for Legal Charge Prediction

    [https://arxiv.org/abs/2408.02233](https://arxiv.org/abs/2408.02233)

    本论文提出了一个结合多源异构外源知识的方法，用于法律指控的预测，特别是通过法律知识库、对话式LLM和与之相关的法律文献，增强了预测模型。

    

    法律指控预测是法律人工智能中的一个重要任务，它旨在为案件描述准确地分配指控标签，吸引了大量的 recent 兴趣。现有的方法主要使用各种神经网络结构直接建模案件描述，未能有效地利用多源外部知识。我们提出了一种基于提示学习框架的方法，该方法同时利用了法律知识库、对话式LLM和相关法律文章的多源异构外部知识。具体来说，我们通过法律知识库与案件描述中的知识片段进行匹配，并通过硬提示模板将它们封装到输入中。此外，我们通过对比学习检索与给定案件描述相关联的法律文章，并通过对话式LLM获得案件描述中的事实元素。我们通过软提示词汇的嵌入向量融合来完成这项工作。

    arXiv:2408.02233v1 Announce Type: cross  Abstract: Legal charge prediction, an essential task in legal AI, seeks to assign accurate charge labels to case descriptions, attracting significant recent interest. Existing methods primarily employ diverse neural network structures for modeling case descriptions directly, failing to effectively leverage multi-source external knowledge. We propose a prompt learning framework-based method that simultaneously leverages multi-source heterogeneous external knowledge from a legal knowledge base, a conversational LLM, and related legal articles. Specifically, we match knowledge snippets in case descriptions via the legal knowledge base and encapsulate them into the input through a hard prompt template. Additionally, we retrieve legal articles related to a given case description through contrastive learning, and then obtain factual elements within the case description through a conversational LLM. We fuse the embedding vectors of soft prompt tokens w
    
[^26]: 论文标题翻译

    SpecRover: Code Intent Extraction via LLMs

    [https://arxiv.org/abs/2408.02232](https://arxiv.org/abs/2408.02232)

    此处是中文摘要的小结

    

    Paper abstract translated

    arXiv:2408.02232v1 Announce Type: cross  Abstract: Autonomous program improvement typically involves automatically producing bug fixes and feature additions. Such program improvement can be accomplished by a combination of large language model (LLM) and program analysis capabilities, in the form of an LLM agent. Since program repair or program improvement typically requires a specification of intended behavior - specification inference can be useful for producing high quality program patches. In this work, we examine efficient and low-cost workflows for iterative specification inference within an LLM agent. Given a GitHub issue to be resolved in a software project, our goal is to conduct iterative code search accompanied by specification inference - thereby inferring intent from both the project structure and behavior. The intent thus captured is examined by a reviewer agent with the goal of vetting the patches as well as providing a measure of confidence in the vetted patches. Our app
    
[^27]: 大语言模型能否有效地进行数据库摇杆调整？全面实验评估

    Is Large Language Model Good at Database Knob Tuning? A Comprehensive Experimental Evaluation

    [https://arxiv.org/abs/2408.02213](https://arxiv.org/abs/2408.02213)

    大语言模型能够有效协助Database管理员对数据库性能进行优化。

    

    arXiv:2408.02213v1 公告类型：交叉  摘要：数据库优化通过调整摇杆来增强数据库性能，摇杆调整扮演了重要角色。然而，传统的调整方法大多遵循“尝试-收集-调整”的过程，证明了其低效且特定于数据库。此外，这些方法往往不透明，使得数据库管理员（DBA）难以理解背后的决策过程。  大型语言模型（LLM），如GPT-4和Claude-3，已经在复杂的自然语言任务中表现出色，然而它们在数据库摇杆调整方面的潜力尚未得到充分探索。本研究利用LLM作为有经验的DBA进行摇杆调整任务，通过精心设计的提示。我们识别出系统调谐的三项关键子任务：摇杆修剪、模型初始化和摇杆建议，并对每项子任务提出了LLM驱动的解决方案来取代传统的方法。  我们开展了广泛的实验，将LLM驱动的方法与传统方法在不同数据库系统上的性能进行了比较，并通过实际应用验证了LLM方法的有效性，显示出LLM在数据库调优中的巨大潜力。

    arXiv:2408.02213v1 Announce Type: cross  Abstract: Knob tuning plays a crucial role in optimizing databases by adjusting knobs to enhance database performance. However, traditional tuning methods often follow a Try-Collect-Adjust approach, proving inefficient and database-specific. Moreover, these methods are often opaque, making it challenging for DBAs to grasp the underlying decision-making process.   The emergence of large language models (LLMs) like GPT-4 and Claude-3 has excelled in complex natural language tasks, yet their potential in database knob tuning remains largely unexplored. This study harnesses LLMs as experienced DBAs for knob-tuning tasks with carefully designed prompts. We identify three key subtasks in the tuning system: knob pruning, model initialization, and knob recommendation, proposing LLM-driven solutions to replace conventional methods for each subtask.   We conduct extensive experiments to compare LLM-driven approaches against traditional methods across the 
    
[^28]: 朝向安全设计的AI：基于基础模型的系统中的运行时护栏分类

    Towards AI-Safety-by-Design: A Taxonomy of Runtime Guardrails in Foundation Model based Systems

    [https://arxiv.org/abs/2408.02205](https://arxiv.org/abs/2408.02205)

    该论文提出的护栏分类系统旨在确保基础模型系统在运行时的安全性。

    

    论文讨论了基础模型（FM）在现代应用中的广泛应用和安全性的问题。论文提出了一种分类系统，系统地将运行时护栏作为一种技术手段来确保FM系统的安全性。我们还讨论了设计护栏时应考虑的软件特性和从软件架构角度确保这些特性的方法。

    arXiv:2408.02205v1 Announce Type: cross  Abstract: The rapid advancement and widespread deployment of foundation model (FM) based systems have revolutionized numerous applications across various domains. However, the fast-growing capabilities and autonomy have also raised significant concerns about responsible AI and AI safety. Recently, there have been increasing attention toward implementing guardrails to ensure the runtime behavior of FM-based systems is safe and responsible. Given the early stage of FMs and their applications (such as agents), the design of guardrails have not yet been systematically studied. It remains underexplored which software qualities should be considered when designing guardrails and how these qualities can be ensured from a software architecture perspective. Therefore, in this paper, we present a taxonomy for guardrails to classify and compare the characteristics and design options of guardrails. Our taxonomy is organized into three main categories: the mo
    
[^29]: SelfBC: 自我行为克隆在离线强化学习中的应用

    SelfBC: Self Behavior Cloning for Offline Reinforcement Learning

    [https://arxiv.org/abs/2408.02165](https://arxiv.org/abs/2408.02165)

    本文提出了SelfBC方法，它通过集成自我约束机制到off-policy方法中，在离线强化学习中学习非保守策略，避免了策略崩溃，并且理论和实验结果证明了其有效性。

    

    arXiv:2408.02165v1 公告类型：交叉  摘要：在离线强化学习中，策略约束方法使用额外的正则化技术来限制学习策略与离线数据集之间的差异。然而，这些方法往往导致过于保守的策略，模仿行为策略，从而限制了它们的性能。我们研究了这一局限性，并将这一局限性归因于传统约束的静态性质。在本文中，我们提出了一种新的动态策略约束，它限制了以前学习策略生成指数平滑平均samples的学习策略。通过将这种自我约束机制集成到off-policy方法中，我们的方法在离线环境中促进了非保守策略的学习，同时避免了策略崩溃。理论结果表明，我们的方法导致了一个几乎单调改进的参考策略。在D4RL MuJoCo领域的广泛实验中，我们证明了SelfBC的有效性。

    arXiv:2408.02165v1 Announce Type: cross  Abstract: Policy constraint methods in offline reinforcement learning employ additional regularization techniques to constrain the discrepancy between the learned policy and the offline dataset. However, these methods tend to result in overly conservative policies that resemble the behavior policy, thus limiting their performance. We investigate this limitation and attribute it to the static nature of traditional constraints. In this paper, we propose a novel dynamic policy constraint that restricts the learned policy on the samples generated by the exponential moving average of previously learned policies. By integrating this self-constraint mechanism into off-policy methods, our method facilitates the learning of non-conservative policies while avoiding policy collapse in the offline setting. Theoretical results show that our approach results in a nearly monotonically improved reference policy. Extensive experiments on the D4RL MuJoCo domain d
    
[^30]: 基于少样本索引的生成检索

    Generative Retrieval with Few-shot Indexing

    [https://arxiv.org/abs/2408.02152](https://arxiv.org/abs/2408.02152)

    论文提出了一种新的基于少样本索引的生成检索框架，它通过提示LLM创建文档标识符银行，并在检索过程中限制模型产生的docid，以提高检索性能。

    

    arXiv:2408.02152v1 公告类型：交叉摘要：现有的生成检索（GR）方法依赖于基于训练的数据库索引方法，即对模型进行微调，以记住查询与其相关文档标识符（docid）之间的关联。基于训练的索引有三个局限性：训练成本高、大型语言模型（LLM）预训练知识的利用率不足以及动态文档集合上的适应性问题。为了解决这些问题，我们提出了一种新的基于少样本索引的生成检索框架（Few-Shot GR）。它具有一种新的少样本索引过程，在过程中，我们将整个文档集合中的所有文档提供给LLM进行提示，最终创建一个包含所有文档的文档标识符银行。在检索过程中，我们将查询提供给相同的LLM，并限制其产生的文档标识符位于在索引期间创建的文档标识符银行之内，然后将生成的docid映射回其对应的文档。Few-Shot GR依赖于对LLM进行提示，而无需要求其进行训练

    arXiv:2408.02152v1 Announce Type: cross  Abstract: Existing generative retrieval (GR) approaches rely on training-based indexing, i.e., fine-tuning a model to memorise the associations between a query and the document identifier (docid) of a relevant document. Training-based indexing has three limitations: high training overhead, under-utilization of the pre-trained knowledge of large language models (LLMs), and challenges in adapting to a dynamic document corpus. To address the above issues, we propose a novel few-shot indexing-based GR framework (Few-Shot GR). It has a novel few-shot indexing process, where we prompt an LLM to generate docids for all documents in a corpus, ultimately creating a docid bank for the entire corpus. During retrieval, we feed a query to the same LLM and constrain it to generate a docid within the docid bank created during indexing, and then map the generated docid back to its corresponding document. Few-Shot GR relies solely on prompting an LLM without req
    
[^31]: VidModEx: 一种可解释且高效的黑色盒子模型提取方法，适用于高维空间

    VidModEx: Interpretable and Efficient Black Box Model Extraction for High-Dimensional Spaces

    [https://arxiv.org/abs/2408.02140](https://arxiv.org/abs/2408.02140)

    VidModEx方法使用SHAP增强了合成数据生成，提高了图像和视频分类模型的性能，在多个高维数据集上取得了显著的提升。

    

    arXiv:2408.02140v1 宣布类型：新  摘要：在黑箱模型提取领域，依赖于软标签或替代数据集的传统方法在扩展到高维输入空间和处理大量相关联的类别的复杂性方面遇到了挑战。在这项工作中，我们介绍了一种新的方法，该方法利用SHAP（SHapley Additive exPlanations）来增强合成数据生成。SHAP量化了每个输入特征对受害者模型的输出所做的个体贡献，这有助于优化一个基于能量的生成对抗网络以达到一个理想的输出。这种方法显著提升了性能，在图像分类模型上的准确度提升了16.45%，并且将这种方法扩展到了视频分类模型，在UCF11、UCF101、Kinetics 400、Kinetics 600和Something-Something V2等难以挑战的数据集上，平均提升了26.11%，最高提升了33.36%。我们进一步展示了这种方法的有效性和其实际实用性。

    arXiv:2408.02140v1 Announce Type: new  Abstract: In the domain of black-box model extraction, conventional methods reliant on soft labels or surrogate datasets struggle with scaling to high-dimensional input spaces and managing the complexity of an extensive array of interrelated classes. In this work, we present a novel approach that utilizes SHAP (SHapley Additive exPlanations) to enhance synthetic data generation. SHAP quantifies the individual contributions of each input feature towards the victim model's output, facilitating the optimization of an energy-based GAN towards a desirable output. This method significantly boosts performance, achieving a 16.45% increase in the accuracy of image classification models and extending to video classification models with an average improvement of 26.11% and a maximum of 33.36% on challenging datasets such as UCF11, UCF101, Kinetics 400, Kinetics 600, and Something-Something V2. We further demonstrate the effectiveness and practical utility of
    
[^32]: 基于价值的正当理由改善社交体验：一项多Agent模拟研究

    Value-Based Rationales Improve Social Experience: A Multiagent Simulation Study

    [https://arxiv.org/abs/2408.02117](https://arxiv.org/abs/2408.02117)

    我们的研究展示了在模拟环境中，考虑价值并产生正当理由的代理能够提高冲突解决率、社交体验、隐私保护以及灵活性。

    

    我们提出了Exanna框架，该框架允许代理在其决策过程中考虑自身的价值以及他人的价值。在提供行为正当理由并评估他人正当理由的过程中，Exanna代理会考虑到价值因素。通过多Agent模拟，我们展示了在决策过程中考虑价值并产生正当理由，特别是对于违反常规的行为，能够导致（1）更高的冲突解决率，（2）更好的社交体验，（3）更高的隐私保护，以及（4）更高的灵活性。

    arXiv:2408.02117v1 Announce Type: cross  Abstract: We propose Exanna, a framework to realize agents that incorporate values in decision making. An Exannaagent considers the values of itself and others when providing rationales for its actions and evaluating the rationales provided by others. Via multiagent simulation, we demonstrate that considering values in decision making and producing rationales, especially for norm-deviating actions, leads to (1) higher conflict resolution, (2) better social experience, (3) higher privacy, and (4) higher flexibility.
    
[^33]: 音频视觉作品声音设计的教学设计探索：通过智能工具实现创新教学

    Dise\~no de sonido para producciones audiovisuales e historias sonoras en el aula. Hacia una docencia creativa mediante el uso de herramientas inteligentes

    [https://arxiv.org/abs/2408.02113](https://arxiv.org/abs/2408.02113)

    本研究通过智能工具进行创新教学，探索了音频视觉作品声音设计的教学方法，强调了项目式学习在提升学生音频技术实践能力中的作用，同时突出了创建包容性和互动性的学习环境的重要性，以及教师对学生个性化支持与指导的必要性。

    

    arXiv:2408.02113v1 公告类型：交叉 Abstract: 本研究旨在分享传授音频视觉作品声音设计的教学经验，并与不同项目下的学生进行比较。本研究的目的并非对不同类型的教学进行比较，而更侧重于分析在不同年级学习该课程的不同学生的个性化问题。对于很大一部分学生来说，音频世界可能非常有趣，无论是那些具有创造性和技术倾向的学生。音乐创作和制作、音频与图像的同步、配音等学科通常对学生很有吸引力，但由于其极高的技术复杂性，它们有时可能成为入门的一个非常高的门槛，特别是对于不熟悉音频编辑软件的学生来说，他们可能需要几周甚至几个月的时间来熟练使用这些软件，而这些软件并非总对学生用户特别直观。通过采用项目式学习（PBL）方法论的学习可以显著提高学生的专业实践能力，有效的学习策略和资源能够使学生在较短的时间内掌握专业知识，从而推动学习效率的提升。此外，构建一个包容和互动的课堂环境对于鼓励学生在实践中勇于尝试和犯错至关重要，教师需要根据学生的实际情况提供个性化的支持和指导。对于高校教师来说，了解学生的学习偏好和学习风格对于设计有效教学方法和策略至关重要。

    arXiv:2408.02113v1 Announce Type: cross  Abstract: This study aims to share a teaching experience teaching sound design for audiovisual productions and compares different projects tackled by students. It is not intended to be a comparative analysis of different types of teaching but rather an analysis of different problems observed in different profiles of students of the subject who study it in different grades. The world of audio can be very interesting for a large part of the students, both those with creative and technical inclinations. Musical creation and production, synchronization with images, dubbing, etc. They are disciplines that are generally interesting but can have a very high barrier to entry due to their great technical complexity. Sometimes it can take weeks or even months for the uninitiated to begin to use audio editing programs with the necessary ease, which are not always particularly intuitive for students. Learning through the use of PBL methodologies generates, 
    
[^34]: KAN-RCBEV深度：基于自动驾驶的多模态融合算法

    KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving

    [https://arxiv.org/abs/2408.02088](https://arxiv.org/abs/2408.02088)

    本文提出了RCBEV-KAN算法，一种融合摄像头、激光雷达和毫米波雷达数据的全新算法，旨在提高自动驾驶车辆的3D物体检测精度。

    

    arXiv:2408.02088v1 声明类型：交叉  摘要：自动驾驶中的准确三维物体检测因为遮挡、物体规模的变化以及复杂的城市环境而极具挑战。本文介绍了一种名为RCBEV-KAN的创新算法，该算法旨在通过融合来自摄像头、激光雷达和毫米波雷达的多模态传感器数据来提高三维物体检测的准确性。我们的创新鸟瞰视图(BEV)基

    arXiv:2408.02088v1 Announce Type: cross  Abstract: Accurate 3D object detection in autonomous driving is critical yet challenging due to occlusions, varying object scales, and complex urban environments. This paper introduces the RCBEV-KAN algorithm, a pioneering method designed to enhance 3D object detection by fusing multimodal sensor data from cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View (BEV)-based approach, utilizing a Transformer architecture, significantly boosts detection precision and efficiency by seamlessly integrating diverse data sources, improving spatial relationship handling, and optimizing computational processes. Experimental results show that the RCBEV-KAN model demonstrates superior performance across most detection categories, achieving higher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score (0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8% faster). These results indicate that RCBEV-KAN i
    
[^35]: 标题：释放数据巨浪的力量：用于语言模型指令训练的数据评价与选择综合调查

    Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models

    [https://arxiv.org/abs/2408.02085](https://arxiv.org/abs/2408.02085)

    本研究综述了评估与选择用于语言模型指令训练的数据方法的现有文献，揭示了不同评估方法的实际应用及未来研究的可能性，旨在为最优的数据驱动训练提供有价值的见解和策略。

    

    摘要：arXiv:2408.02085v1 公告类型：新文摘要：指令训练在使大型语言模型（LLMs）与人类喜好保持一致方面扮演着关键角色。尽管存在大量的开放式指令数据集，但盲目地在所有现有指令上训练一个LLM可能并不理想且不实用。为了确定最有利的训练数据点，自然语言处理（NLP）和深度学习领域已经提出了数据评估和选择的方法。然而，在指令训练的背景下，仍然存在一个知识差距，即哪些数据评估指标可以应用，以及它们是如何融入选择机制的。为了填补这一空白，我们提出了对用于指令训练的LLMs的数据评估和选择现有文献的全面回顾。我们系统地对所有适用的方法进行了分类，并将其分为基于质量的、基于多样性的和基于重要性的三类，其中细化了精细粒度的分类体系。对于每种的评估方法和它们的实际应用，我们都进行了详细的分析和对比。此外，我们还发现了未来研究可能的空白领域，提出了未来研究的方向。通过对现有方法和新兴技术的综合评估，我们相信可以为指导语言模型的最优数据驱动训练提供有价值的见解和策略。

    arXiv:2408.02085v1 Announce Type: new  Abstract: Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each
    
[^36]: 基于案例推理的儿童发展迟缓诊断筛查方法

    Case-based reasoning approach for diagnostic screening of children with developmental delays

    [https://arxiv.org/abs/2408.02073](https://arxiv.org/abs/2408.02073)

    本文提出了一种基于案例推理的儿童发展迟缓诊断筛查方法，旨在早发现、早干预，减少医疗和社会成本，并提高治疗效果。

    

    根据世界卫生组织的数据，全球约有6%至9%的人口患有发展迟缓。基于中国安徽省淮北市2023年新生儿的数量（94,420），我们估计每年有大约7,500例（疑似发展迟缓病例）的疑虑病例。对这些儿童进行早期识别并进行适当的早期干预，可以显著减少医疗资源的浪费和社会成本。国际研究指出，发展迟缓儿童的最佳干预期是六岁前，最好是在三岁半之前。研究表明，接受早期干预的发展迟缓儿童症状明显改善，甚至有些儿童可能完全康复。本研究采用了一种结合CNN-Trans的混合模型进行案例推理。

    arXiv:2408.02073v1 Announce Type: new  Abstract: According to the World Health Organization, the population of children with developmental delays constitutes approximately 6% to 9% of the total population. Based on the number of newborns in Huaibei, Anhui Province, China, in 2023 (94,420), it is estimated that there are about 7,500 cases (suspected cases of developmental delays) of suspicious cases annually. Early identification and appropriate early intervention for these children can significantly reduce the wastage of medical resources and societal costs. International research indicates that the optimal period for intervention in children with developmental delays is before the age of six, with the golden treatment period being before three and a half years of age. Studies have shown that children with developmental delays who receive early intervention exhibit significant improvement in symptoms; some may even fully recover. This research adopts a hybrid model combining a CNN-Tran
    
[^37]: 停车场网络：相机为基础的端到端泊车，从图像到规划

    ParkingE2E: Camera-based End-to-end Parking Network, from Images to Planning

    [https://arxiv.org/abs/2408.02061](https://arxiv.org/abs/2408.02061)

    通过模仿学习，本文提出了一个端到端的方法，能够从图像中直接规划出停车路径，该方法在真实世界中展现出良好的适用性和性能。

    

    arXiv:2408.02061v1 宣布类型：交叉 摘要：自动驾驶泊车是智能驾驶领域的一个关键任务。传统的泊车算法通常基于规则设计。然而，由于算法设计的复杂性，这些方法在复杂的停车场景中不太有效。相比之下，基于神经网络的方

    arXiv:2408.02061v1 Announce Type: cross  Abstract: Autonomous parking is a crucial task in the intelligent driving field. Traditional parking algorithms are usually implemented using rule-based schemes. However, these methods are less effective in complex parking scenarios due to the intricate design of the algorithms. In contrast, neural-network-based methods tend to be more intuitive and versatile than the rule-based methods. By collecting a large number of expert parking trajectory data and emulating human strategy via learning-based methods, the parking task can be effectively addressed. In this paper, we employ imitation learning to perform end-to-end planning from RGB images to path planning by imitating human driving trajectories. The proposed end-to-end approach utilizes a target query encoder to fuse images and target features, and a transformer-based decoder to autoregressively predict future waypoints. We conducted extensive experiments in real-world scenarios, and the resul
    
[^38]: 点云中三维单对象跟踪方法

    3D Single-object Tracking in Point Clouds with High Temporal Variation

    [https://arxiv.org/abs/2408.02049](https://arxiv.org/abs/2408.02049)

    我们提出了HVTrack框架，用于处理点云中具有高时序变化的三维单对象跟踪问题，通过相对姿态感知记忆模块、基扩张特征交叉注意力模块和上下文点引导自注意力模块来解决挑战。

    

    arXiv:2408.02049v1 公告类型：新  摘要：三维单对象跟踪（3D SOT）的关键挑战是点云的高时序变化。现有的方法依赖于一个假设，即点云的形状变化和对象在相邻帧之间的运动是平滑的，无法应对高时序变化的数据。本文提出了一个新的框架，用于处理点云中具有高时序变化的三维单对象跟踪问题，称为HVTrack。HVTrack提出了三个新的组件来处理高时序变化场景中的挑战：1）相对姿态感知记忆模块，用于处理时序变化的点云形状；2）基扩张特征交叉注意力模块，用于处理在扩展的搜索区域内与对象相似的干扰；3）上下文点引导自注意力模块，用于抑制背景噪声。我们通过在KITTI-HV数据集上设置不同的帧间隔来进行采样，构建了一个具有高时序变化的数据集。

    arXiv:2408.02049v1 Announce Type: new  Abstract: The high temporal variation of the point clouds is the key challenge of 3D single-object tracking (3D SOT). Existing approaches rely on the assumption that the shape variation of the point clouds and the motion of the objects across neighboring frames are smooth, failing to cope with high temporal variation data. In this paper, we present a novel framework for 3D SOT in point clouds with high temporal variation, called HVTrack. HVTrack proposes three novel components to tackle the challenges in the high temporal variation scenario: 1) A Relative-Pose-Aware Memory module to handle temporal point cloud shape variations; 2) a Base-Expansion Feature Cross-Attention module to deal with similar object distractions in expanded search areas; 3) a Contextual Point Guided Self-Attention module for suppressing heavy background noise. We construct a dataset with high temporal variation (KITTI-HV) by setting different frame intervals for sampling in 
    
[^39]: 通过深度强化学习实现的移动边缘生成计算的感知性资源分配

    Latency-Aware Resource Allocation for Mobile Edge Generation and Computing via Deep Reinforcement Learning

    [https://arxiv.org/abs/2408.02047](https://arxiv.org/abs/2408.02047)

    本文提出了一种基于深度强化学习的算法，用于解决移动边缘生成计算系统中通信、计算和AI生成内容资源的联合分配问题，以降低用户的服务延迟。

    

    arXiv:2408.02047v1 公告类型：交叉 摘要：最近，移动边缘计算（MEC）和生成人工智能（GAI）技术的结合催生了一个新的领域，即移动边缘生成计算（MEGC），它为移动用户提供异构服务，如任务计算和内容生成。在这篇短文中，我们研究了MEGC系统中通信、计算和AI生成内容资源分配的联合问题。首先，我们制定了一个优化问题，以提高移动用户的服务质量。由于优化变量的强烈关联，我们提出了一个基于深度强化学习的算法来解决这个问题。数值结果表明，与两个基线算法相比，所提出的算法可以实现更低的延迟。

    arXiv:2408.02047v1 Announce Type: cross  Abstract: Recently, the integration of mobile edge computing (MEC) and generative artificial intelligence (GAI) technology has given rise to a new area called mobile edge generation and computing (MEGC), which offers mobile users heterogeneous services such as task computing and content generation. In this letter, we investigate the joint communication, computation, and the AIGC resource allocation problem in an MEGC system. A latency minimization problem is first formulated to enhance the quality of service for mobile users. Due to the strong coupling of the optimization variables, we propose a new deep reinforcement learning-based algorithm to solve it efficiently. Numerical results demonstrate that the proposed algorithm can achieve lower latency than two baseline algorithms.
    
[^40]: 多语言语言模型在Twitter/X情感分析中的微调：对V4国家东欧四国外语的情感分析研究

    Fine-tuning multilingual language models in Twitter/X sentiment analysis: a study on Eastern-European V4 languages

    [https://arxiv.org/abs/2408.02044](https://arxiv.org/abs/2408.02044)

    本研究微调了几种大型语言模型，用于分析Twitter/X上的东欧V4国家语言中有关俄罗斯和乌克兰军事冲突的情感信息，并比较了它们的性能。

    

    arXiv:2408.02044v1 公告类型：交叉

    arXiv:2408.02044v1 Announce Type: cross  Abstract: The aspect-based sentiment analysis (ABSA) is a standard NLP task with numerous approaches and benchmarks, where large language models (LLM) represent the current state-of-the-art. We focus on ABSA subtasks based on Twitter/X data in underrepresented languages. On such narrow tasks, small tuned language models can often outperform universal large ones, providing available and cheap solutions.   We fine-tune several LLMs (BERT, BERTweet, Llama2, Llama3, Mistral) for classification of sentiment towards Russia and Ukraine in the context of the ongoing military conflict. The training/testing dataset was obtained from the academic API from Twitter/X during 2023, narrowed to the languages of the V4 countries (Czech Republic, Slovakia, Poland, Hungary). Then we measure their performance under a variety of settings including translations, sentiment targets, in-context learning and more, using GPT4 as a reference model. We document several inte
    
[^41]: 如何在大型的属性图中挖掘带标签的路径关联规则？

    Mining Path Association Rules in Large Property Graphs (with Appendix)

    [https://arxiv.org/abs/2408.02029](https://arxiv.org/abs/2408.02029)

    本文研究了大型的属性图中带标签的路径关联规则挖掘问题，并提出了一个高效且可扩展的算法PIONEER，该算法利用路径的抗单调性进行有效剪枝，并通过近似技术和并行化实现可扩展的路径关联规则挖掘。

    

    在arXiv:2408.02029v1的公告类型为交叉参考的文献中，我们讨论了如何从小数据集到大数据集的转换。通过现场经验，我们证明了大规模的时间序列数据集是可行的、成本效益很高的，并且对于预测来说是可用的。我们还使用医学成像研究来探索使用多数据源整合数据的方法。通过DINEOF-2.0软件，我们分析了30名患者的纵向医疗影像数据集，并成功地检测了阿尔茨海默病相关的体积变化。结果表明，头骨处方对抗波的校正是有益的，并且未来可以推广到其他类型和严重程度的阿尔茨海默病。

    arXiv:2408.02029v1 Announce Type: cross  Abstract: How can we mine frequent path regularities from a graph with edge labels and vertex attributes? The task of association rule mining successfully discovers regular patterns in item sets and substructures. Still, to our best knowledge, this concept has not yet been extended to path patterns in large property graphs. In this paper, we introduce the problem of path association rule mining (PARM). Applied to any \emph{reachability path} between two vertices within a large graph, PARM discovers regular ways in which path patterns, identified by vertex attributes and edge labels, co-occur with each other. We develop an efficient and scalable algorithm PIONEER that exploits an anti-monotonicity property to effectively prune the search space. Further, we devise approximation techniques and employ parallelization to achieve scalable path association rule mining. Our experimental study using real-world graph data verifies the significance of path
    
[^42]: 基于对比学习的方法对于多语言的声音与面部识别

    Contrastive Learning-based Chaining-Cluster for Multilingual Voice-Face Association

    [https://arxiv.org/abs/2408.02025](https://arxiv.org/abs/2408.02025)

    本文提出了一种基于对比学习的算法，用于解决多语言环境中面部与声音识别面临的复杂问题，特别是在无法面对面识别的情况下。

    

    arXiv:2408.02025v1 公告类型: cross 摘要: 最近，在多语言环境中研究一个人脸与声音的固有联系已经成为一个引人注目的领域。本文介绍的是我们为2024年FAME（Face-Voice Association in Multilingual Environments）挑战赛提出的创新解决方案，重点是使用基于对比学习的方法来提高多语言环境中面部与声音的关联。这项任务涉及在跨语言环境下建立视觉和听觉模态信号的生物识别关系，以及建模在不同语言中的语音节奏之间的相互依赖关系，同时处理数据中的内在和外在可变性。为了处理这些不简单的挑战，我们的方法采用了监督的交叉对比学习（SCC）来建立多语言情景中的声音与面孔的坚固关联。随后，我们特别设计了一个基于链式集群的后续处理步骤，以减轻问题的复杂性并提高算法的性能。

    arXiv:2408.02025v1 Announce Type: cross  Abstract: The innate correlation between a person's face and voice has recently emerged as a compelling area of study, especially within the context of multilingual environments. This paper introduces our novel solution to the Face-Voice Association in Multilingual Environments (FAME) 2024 challenge, focusing on a contrastive learning-based chaining-cluster method to enhance face-voice association. This task involves the challenges of building biometric relations between auditory and visual modality cues and modelling the prosody interdependence between different languages while addressing both intrinsic and extrinsic variability present in the data. To handle these non-trivial challenges, our method employs supervised cross-contrastive (SCC) learning to establish robust associations between voices and faces in multi-language scenarios. Following this, we have specifically designed a chaining-cluster-based post-processing step to mitigate the im
    
[^43]: 个体化多时间线MRI轨迹预测用于阿尔茨海默病

    Individualized multi-horizon MRI trajectory prediction for Alzheimer's Disease

    [https://arxiv.org/abs/2408.02018](https://arxiv.org/abs/2408.02018)

    本文通过使用条件变分AutoEncoder，构建了一个能在个体基础上进行MRI时间序列预测的模型，从而提高了阿尔茨海默病诊断的特异性。

    

    神经退行性改变通过磁共振成像（MRI）来测量，这是诊断阿尔茨海默病（AD）的一种潜在生物标志物，但其普遍认为不如淀粉样蛋白或tau生物标志物特异性。由于不同个体之间脑解剖结构的差异很大，我们假设利用MRI时间序列可以帮助提高特异性，即将每个患者视为其自身的基线。在这里，我们转向条件变分 Autoencoder 来生成个体化的MRI预测，这些预测基于患者的年龄、疾病状态和之前的扫描。使用阿尔茨海默病神经影像倡议（ADNI）的连续成像数据，我们训练了一个新的架构，以构建一个潜在空间分布，可以从该分布中抽样生成解剖结构变化的未来预测。这使我们可以超出数据集的范围进行外推，并对未来的MRI进行预测，最多可达10年。我们在一个保留的数据集中评估了模型，该数据集从未被用来训练或微调过模型。

    arXiv:2408.02018v1 Announce Type: new  Abstract: Neurodegeneration as measured through magnetic resonance imaging (MRI) is recognized as a potential biomarker for diagnosing Alzheimer's disease (AD), but is generally considered less specific than amyloid or tau based biomarkers. Due to a large amount of variability in brain anatomy between different individuals, we hypothesize that leveraging MRI time series can help improve specificity, by treating each patient as their own baseline. Here we turn to conditional variational autoencoders to generate individualized MRI predictions given the subject's age, disease status and one previous scan. Using serial imaging data from the Alzheimer's Disease Neuroimaging Initiative, we train a novel architecture to build a latent space distribution which can be sampled from to generate future predictions of changing anatomy. This enables us to extrapolate beyond the dataset and predict MRIs up to 10 years. We evaluated the model on a held-out set fr
    
[^44]: MetaWearS: 一种仅需少量快照的便携式系统生命周期快捷方式

    MetaWearS: A Shortcut in Wearable Systems Lifecycle with Only a Few Shots

    [https://arxiv.org/abs/2408.01988](https://arxiv.org/abs/2408.01988)

    本文提出MetaWearS方法，通过元学习减少便携式系统初始数据集的需求，并使用原型更新机制简化更新过程。

    

    便携式系统能够提供连续的健康监测功能，并有可能在早期发现潜在的健康问题。然而，便携式系统的生命周期面临着一系列挑战。首先，对于新的便携式设备，有效的模型训练需要来自各种主题的大量标记数据，这些数据直接由便携式设备收集。其次，后继的模型更新需要进一步的大量标记数据来进行重新培训。最后，频繁地在便携式设备上更新模型可能会减少在长期数据监控中的电池寿命。为了解决这些问题，在本文中，我们提出了一种MetaWearS方法，这是一种元学习方法，可以减少所需的初始数据收集量。此外，我们的方法结合了一种原型更新机制，通过修改类原型而不是重新培训整个模型，简化了更新过程。我们在两个实际案例研究中探讨了MetaWearS的性能，即癫痫发作检测和智能手势识别。

    arXiv:2408.01988v1 Announce Type: cross  Abstract: Wearable systems provide continuous health monitoring and can lead to early detection of potential health issues. However, the lifecycle of wearable systems faces several challenges. First, effective model training for new wearable devices requires substantial labeled data from various subjects collected directly by the wearable. Second, subsequent model updates require further extensive labeled data for retraining. Finally, frequent model updating on the wearable device can decrease the battery life in long-term data monitoring. Addressing these challenges, in this paper, we propose MetaWearS, a meta-learning method to reduce the amount of initial data collection required. Moreover, our approach incorporates a prototypical updating mechanism, simplifying the update process by modifying the class prototype rather than retraining the entire model. We explore the performance of MetaWearS in two case studies, namely, the detection of epil
    
[^45]: 这里是被翻译过的论文标题

    DeMansia: Mamba Never Forgets Any Tokens

    [https://arxiv.org/abs/2408.01986](https://arxiv.org/abs/2408.01986)

    这里是被总结出的中文要点

    

    这里是被翻译过的论文摘要

    arXiv:2408.01986v1 Announce Type: cross  Abstract: This paper examines the mathematical foundations of transformer architectures, highlighting their limitations particularly in handling long sequences. We explore prerequisite models such as Mamba, Vision Mamba (ViM), and LV-ViT that pave the way for our proposed architecture, DeMansia. DeMansia integrates state space models with token labeling techniques to enhance performance in image classification tasks, efficiently addressing the computational challenges posed by traditional transformers. The architecture, benchmark, and comparisons with contemporary models demonstrate DeMansia's effectiveness. The implementation of this paper is available on GitHub at https://github.com/catalpaaa/DeMansia
    
[^46]: SR-CIS: 自我反思增量系统与解耦记忆与推理

    SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning

    [https://arxiv.org/abs/2408.01970](https://arxiv.org/abs/2408.01970)

    SR-CIS通过结合小模型快速推理和慢速决策的大模型，并通过CA-OAD机制实现高效协作，提供了一种新的内存与推理解耦的机制，以解决当前深度学习模型在面对人类记忆和学习机制时的挑战。

    

    arXiv:2408.01970v1 公告类型：交叉  摘要：人类快速学习新知识同时保留旧记忆的能力为当前的深度学习模型提出了严峻的挑战。为了解决这个问题，我们借鉴了人类记忆和学习的机制，并提出了自反式互补增量系统（SR-CIS）。SR-CIS由解构化的互补推断模块（CIM）和互补记忆模块（CMM）组成，其中CIM通过置信度自适应在线异常检测（CA-OAD）机制实现快速推断和慢速决策的小模型，而CIM则由Confidence-Aware Online Anomaly Detection（CA-OAD）机制实现快速推断和慢速决策的大模型。CMM由任务特定的短期记忆（STM）区域和通用的长期记忆（LTM）区域组成。通过设定任务特定的低秩自适应（LoRA）和相关原型权重和偏差，它为参数和表示记忆建立了外部存储实例，从而解构了记忆模块与推理模块，并实现了记忆的解耦。

    arXiv:2408.01970v1 Announce Type: cross  Abstract: The ability of humans to rapidly learn new knowledge while retaining old memories poses a significant challenge for current deep learning models. To handle this challenge, we draw inspiration from human memory and learning mechanisms and propose the Self-Reflective Complementary Incremental System (SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and Complementary Memory Module (CMM), SR-CIS features a small model for fast inference and a large model for slow deliberation in CIM, enabled by the Confidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient collaboration. CMM consists of task-specific Short-Term Memory (STM) region and a universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank Adaptive (LoRA) and corresponding prototype weights and biases, it instantiates external storage for parameter and representation memory, thus deconstructing the memory module from the infere
    
[^47]: ML-EAT：社会科学研究中的多层次嵌入关联测试，以可解释和透明的语言技术

    ML-EAT: A Multilevel Embedding Association Test for Interpretable and Transparent Social Science

    [https://arxiv.org/abs/2408.01966](https://arxiv.org/abs/2408.01966)

    ML-EAT是一种量度语言技术固有偏见的工具，采用多层次方法进行可解释和透明的分析。

    

    本文介绍了一种多层次嵌入关联测试（ML-EAT）方法，旨在对社会科学研究中语言技术的固有偏见进行可解释和透明的度量。ML-EAT通过量化三个不同层次的偏差——两个目标概念与两个属性概念之间的差异化关联；两个属性概念中每个目标概念的个体效应大小；以及每个个体目标概念与每个个体属性概念之间的关联——解决了传统EAT测量的模糊性和易理解性问题。使用ML-EAT，本文定义了一个EAT模式 taxonomy，描述了一个嵌入关联测试的九种可能结果，每种结果都与一个独特的EAT-Map相关联，这是一个新型的四象限可视化工具，用于解释ML-EAT。对静态和历时单词嵌入以及GPT-2语言模型的实证分析显示，ML-EAT能够揭示嵌入细节和泛化性能的差异。

    arXiv:2408.01966v1 Announce Type: cross  Abstract: This research introduces the Multilevel Embedding Association Test (ML-EAT), a method designed for interpretable and transparent measurement of intrinsic bias in language technologies. The ML-EAT addresses issues of ambiguity and difficulty in interpreting the traditional EAT measurement by quantifying bias at three levels of increasing granularity: the differential association between two target concepts with two attribute concepts; the individual effect size of each target concept with two attribute concepts; and the association between each individual target concept and each individual attribute concept. Using the ML-EAT, this research defines a taxonomy of EAT patterns describing the nine possible outcomes of an embedding association test, each of which is associated with a unique EAT-Map, a novel four-quadrant visualization for interpreting the ML-EAT. Empirical analysis of static and diachronic word embeddings, GPT-2 language mod
    
[^48]: 中文摘要：什么是基于分布式系统的网络安全策略？

    Top K Enhanced Reinforcement Learning Attacks on Heterogeneous Graph Node Classification

    [https://arxiv.org/abs/2408.01964](https://arxiv.org/abs/2408.01964)

    本文讨论了分布式系统在网络安全中的应用，并提出了相应的安全策略。

    

    arXiv:2408.01964v1 公告类型：交叉  摘要：分布式系统因其具有的高度可靠性、可用性和灵活性而被广泛应用于现代网络安全策略中。本文旨在讨论和分析分布式系统在网络安全中的应用，并提出相应的安全策略，以确保系统不受攻击和保护数据安全。作者将首先介绍分布式系统的基本概念和特点，然后详细探讨其在网络安全中的应用实例，并提出一些可能的安全威胁和防范措施。

    arXiv:2408.01964v1 Announce Type: cross  Abstract: Graph Neural Networks (GNNs) have attracted substantial interest due to their exceptional performance on graph-based data. However, their robustness, especially on heterogeneous graphs, remains underexplored, particularly against adversarial attacks. This paper proposes HeteroKRLAttack, a targeted evasion black-box attack method for heterogeneous graphs. By integrating reinforcement learning with a Top-K algorithm to reduce the action space, our method efficiently identifies effective attack strategies to disrupt node classification tasks. We validate the effectiveness of HeteroKRLAttack through experiments on multiple heterogeneous graph datasets, showing significant reductions in classification accuracy compared to baseline methods. An ablation study underscores the critical role of the Top-K algorithm in enhancing attack performance. Our findings highlight potential vulnerabilities in current models and provide guidance for future d
    
[^49]: 开放生成模型在以人为本的数据科学工作中的影响：基于事实核查组织的案例研究

    The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations

    [https://arxiv.org/abs/2408.01962](https://arxiv.org/abs/2408.01962)

    本研究探讨了开放生成模型对以人为本的数据科学工作，特别是事实核查组织的具体影响，并分析了这些组织在数据科学流程中使用开放模型的动机及其对AI生成社会影响的潜在影响。

    

    arXiv:2408.01962v1 公告类型：交叉 摘要：呼吁在学术研究中使用开放的生成语言模型，强调了科学研究可重复性和透明性的需求。然而，生成性AI的影响远不止于学术界，因为企业和公共利益组织也开始将这些模型融入到他们的数据科学流中。我们扩大了这个视角，包括开放模型对组织的影</p>

    arXiv:2408.01962v1 Announce Type: cross  Abstract: Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an int
    
[^50]: 《人工智能中青少年代表性的偏差：跨语言跨文化研究》

    Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study

    [https://arxiv.org/abs/2408.01961](https://arxiv.org/abs/2408.01961)

    论文发现英尼两种语言的AI倾向将青少年描绘成社会问题的一部分，而青少年自己更希望被展示出作为成长中个体所面临的正常挑战。

    

    本文研究了新闻媒体对青少年的常见描绘，这些描绘往往带有夸大和负面色彩，将青少年视作对社会构成风险，同时也需要社会保护的群体。随着人工智能开始承担部分传统媒体的功能，本文探讨了技术是如何反映对青少年的描绘以及对他们的潜在偏见。论文将注意力集中于两种不同语言背景中的青少年群体：美国和尼泊尔。研究结果显示，静态词嵌入（SWEs）和生成语言模型（GLMs）在描述青少年时存在着偏见。在英语语言的SWEs中，青少年与社会上的一些问题相挂钩。在预训练的GloVe SWEs中，与青少年最为相关的1000个单词中，超过50%与这些社会问题相关。在使用GPT2-XL和LLaMA-2-7B GLMs进行的语言生成任务中，超过30%的输出涉及到社会问题，例如暴力、药物滥用、心理健康问题以及性禁忌等。尼泊尔语的模型同样显示出了类似的现象。通过对青少年群体自身的视角进行分析，特别强调了青少年希望得到更积极、平衡的描绘。

    arXiv:2408.01961v1 Announce Type: cross  Abstract: Popular and news media often portray teenagers with sensationalism, as both a risk to society and at risk from society. As AI begins to absorb some of the epistemic functions of traditional media, we study how teenagers in two countries speaking two languages: 1) are depicted by AI, and 2) how they would prefer to be depicted. Specifically, we study the biases about teenagers learned by static word embeddings (SWEs) and generative language models (GLMs), comparing these with the perspectives of adolescents living in the U.S. and Nepal. We find English-language SWEs associate teenagers with societal problems, and more than 50% of the 1,000 words most associated with teenagers in the pretrained GloVe SWE reflect such problems. Given prompts about teenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss societal problems, most commonly violence, but also drug use, mental illness, and sexual taboo. Nepali models, while n
    
[^51]: 数据集大小和社会一致性中介面部印象偏见的视觉语言AI

    Dataset Scale and Societal Consistency Mediate Facial Impression Bias in Vision-Language AI

    [https://arxiv.org/abs/2408.01959](https://arxiv.org/abs/2408.01959)

    研究揭示了43个CLIP视觉语言模型在面部印象偏见方面的学习情况，证明了社会一致性会中介模型反映的人类偏见程度，并且在数据集大规模训练下，模型更倾向于准确形成那些依赖于不可见属性的印象。

    

    arXiv:2408.01959v1公告类型：新摘要：能够将图像与文本关联的多模态AI模型在包括自动图像字幕在内的多个领域具有巨大潜力，甚至对盲人和低视力用户的安全访问应用程序也有帮助。然而，对偏见的不确定性在某些情况下限制了它们的采用和可用性。在本文中，我们对43个CLIP视觉语言模型进行了研究，以确定它们是否像人类一样学习面部印象偏见，并且我们首次发现，这些偏见在三种类型的CLIP模型家族中得到体现。我们还首次展示了，一个偏见的程度在社会中共享，预测了它在CLIP模型中反映的程度的程度。在仅对最大数据集进行训练的模型中，人类似的面部印象才会出现，这表明与未经审核的文化的更好匹配对于复制越来越微妙的社交偏见是必要的。此外，我们还发现，当对图像的某些不可见属性（如可信赖性和性取向）形成印象时，只有在大数据集上下文中基于模型的训练才更加准确。这可能意味着在生成与社会偏好高度一致的文本描述方面，视觉语言模型正在远离对现实数据集的简单映射，并开始学习如何了解和模仿人类的社会形态知觉。这对于理解模型的感知能力和揭示这些偏见对决策制定的潜在影响至关重要。

    arXiv:2408.01959v1 Announce Type: new  Abstract: Multimodal AI models capable of associating images and text hold promise for numerous domains, ranging from automated image captioning to accessibility applications for blind and low-vision users. However, uncertainty about bias has in some cases limited their adoption and availability. In the present work, we study 43 CLIP vision-language models to determine whether they learn human-like facial impression biases, and we find evidence that such biases are reflected across three distinct CLIP model families. We show for the first time that the the degree to which a bias is shared across a society predicts the degree to which it is reflected in a CLIP model. Human-like impressions of visually unobservable attributes, like trustworthiness and sexuality, emerge only in models trained on the largest dataset, indicating that a better fit to uncurated cultural data results in the reproduction of increasingly subtle social biases. Moreover, we u
    
[^52]: 基于视觉的强化学习中对象级别概括的实现

    Visual Grounding for Object-Level Generalization in Reinforcement Learning

    [https://arxiv.org/abs/2408.01942](https://arxiv.org/abs/2408.01942)

    这项研究通过视觉对齐和基于VLM的内在奖励函数，提升了在强化学习中指导代理进行未见过新对象的零样本概括的效率。

    

    在这项工作中，我们研究了指导基于自然语言指令的代理进行概括的问题。为了解决这个问题，我们利用了一种视觉语言模型（VLM）来进行视觉对齐，并将这种视觉语言知识转移到强化学习（RL）中，使得代理能够在未见过的新对象和指令上进行零样本概括。通过视觉对齐，我们获得了指示指令中目标对象的具体置信图。基于该图，我们提出了两种将VLM知识转移到RL中的方法。首先，我们提出了基于置信图的对象对齐内在奖励函数，以更有效地引导代理接近目标对象。其次，置信图为代理的策略提供了一个更加统一和可访问的任务表示，相对于语言嵌入。这种表示能力使得代理能够通过更有效的途径处理未见过的新对象和指令。

    arXiv:2408.01942v1 Announce Type: new  Abstract: Generalization is a pivotal challenge for agents following natural language instructions. To approach this goal, we leverage a vision-language model (VLM) for visual grounding and transfer its vision-language knowledge into reinforcement learning (RL) for object-centric tasks, which makes the agent capable of zero-shot generalization to unseen objects and instructions. By visual grounding, we obtain an object-grounded confidence map for the target object indicated in the instruction. Based on this map, we introduce two routes to transfer VLM knowledge into RL. Firstly, we propose an object-grounded intrinsic reward function derived from the confidence map to more effectively guide the agent towards the target object. Secondly, the confidence map offers a more unified, accessible task representation for the agent's policy, compared to language embeddings. This enables the agent to process unseen objects and instructions through comprehens
    
[^53]: 论文标题: 定义和评估在自然语言推理中被应用的语言模型的决策和复合风险

    Defining and Evaluating Decision and Composite Risk in Language Models Applied to Natural Language Inference

    [https://arxiv.org/abs/2408.01935](https://arxiv.org/abs/2408.01935)

    本文定义了语言模型用于自然语言推理时的决策和复合风险，并通过实验框架评估了这两种风险，揭示了LLMs在复杂推理和频繁错误报告方面的局限性，为提高语言模型的可靠性提供了洞察。

    

    论文摘要: 尽管像ChatGPT这样的大型语言模型(LLMs)表现出色，但它们也被认为存在重要的风险。其中一种风险来自于模板的信心错误放置，无论是过于自信还是缺乏自信，这在模型对语义推理的判断中尤为明显。虽然前者已被广泛研究，但后者缺乏研究，导致了对基于信心错误放置的模型全面风险的理解存在不对称性。本研究通过定义两种风险类型（决策风险和复合风险），并提出了一个实验框架，包括两级推理架构和相应的度量指标来测量在分类和生成性LLMs中的风险。第一级依赖于一个决策规则，它决定了底层语言模型是否应该避免做出推理。如果模型不回避，第二级(它将应用于模型回避的情况)就是模型的推理。在四个不同的场景中进行的详细实验展示了该框架的有效性，并揭示了LLMs在复杂推理和频繁错误报告方面的局限。此外，我们的工作为开发更可靠的语言模型，并在使用这些模型进行自动推理时减少事故风险提供了宝贵的见解。

    arXiv:2408.01935v1 Announce Type: cross  Abstract: Despite their impressive performance, large language models (LLMs) such as ChatGPT are known to pose important risks. One such set of risks arises from misplaced confidence, whether over-confidence or under-confidence, that the models have in their inference. While the former is well studied, the latter is not, leading to an asymmetry in understanding the comprehensive risk of the model based on misplaced confidence. In this paper, we address this asymmetry by defining two types of risk (decision and composite risk), and proposing an experimental framework consisting of a two-level inference architecture and appropriate metrics for measuring such risks in both discriminative and generative LLMs. The first level relies on a decision rule that determines whether the underlying language model should abstain from inference. The second level (which applies if the model does not abstain) is the model's inference. Detailed experiments on four
    
[^54]: 《双人赛跑在图表上：通过有效指引-探索的代理双人知识图推理》

    Walk Wisely on Graph: Knowledge Graph Reasoning with Dual Agents via Efficient Guidance-Exploration

    [https://arxiv.org/abs/2408.01880](https://arxiv.org/abs/2408.01880)

    本文提出了一种名为FULORA的代理双人知识图推理模型，该模型利用层次强化学习中的高效指引-探索策略来克服多跳推理中的奖励稀疏和训练难题。通过高级代理提供阶段指引，低级代理能够快速收敛到最佳策略，并且在多个知识图推理任务中展现出优越性能。

    

    最近几年，多跳推理在知识图（KG）推理领域得到了广泛的研究，原因在于其有效性和可解释性。然而，由于奖励稀疏，先前的大多跳推理方法存在两个主要缺陷。首先，代理在早期阶段难以学会有效的、稳健的政策。其次，这些方法通常在一些特定的数据集上表现不佳，如稀疏知识图，在这些数据集中，代理需要走过长路径进行推理。为了解决这些问题，我们提出了一个基于层次强化学习（HRL）的代理双人知识图推理模型，名为FULORA。FULORA通过高效指引-探索的双人代理来应对上述推理挑战。高级代理在简化后的知识图上行走，为低级代理在原始知识图上的行走提供阶段引导。在这个框架中，低级代理优化一个价值，以便选择适当的边缘来导航知识图以到达目标实体。在这种方式中，高级代理通过提供阶段性指引来增强低级代理的经验积累，使得低级代理可以从高级代理的指导下快速收敛到最佳策略，而无需代理从头开始在原始知识图上进行探索。这一过程有效地加速了推理学习过程，提升了代理在许多不同类型知识图上的推理性能。试验结果表明，与现有方法相比，FULORA在错误率和其他效果指标上均表现出优越性能，尤其是在稀疏和大规模知识图推理任务中。

    arXiv:2408.01880v1 Announce Type: new  Abstract: Recent years, multi-hop reasoning has been widely studied for knowledge graph (KG) reasoning due to its efficacy and interpretability. However, previous multi-hop reasoning approaches are subject to two primary shortcomings. First, agents struggle to learn effective and robust policies at the early phase due to sparse rewards. Second, these approaches often falter on specific datasets like sparse knowledge graphs, where agents are required to traverse lengthy reasoning paths. To address these problems, we propose a multi-hop reasoning model with dual agents based on hierarchical reinforcement learning (HRL), which is named FULORA. FULORA tackles the above reasoning challenges by eFficient GUidance-ExpLORAtion between dual agents. The high-level agent walks on the simplified knowledge graph to provide stage-wise hints for the low-level agent walking on the original knowledge graph. In this framework, the low-level agent optimizes a value 
    
[^55]: 使用与正样本相同的内分布数据实现安全的半监督对比学习

    Safe Semi-Supervised Contrastive Learning Using In-Distribution Data as Positive Examples

    [https://arxiv.org/abs/2408.01872](https://arxiv.org/abs/2408.01872)

    

    

    arXiv:2408.01872v1 公告类型：跨领域 摘要：当只有少量的标签可用时，半监督学习方法在解决许多实际问题方面显示出良好的结果。现有方法假设标注和未标注数据的类分布相等；然而，当未标注数据中存在出分布（OOD）数据时，它们的表现会显著下降。以往的安全半监督学习研究已经通过基于标注数据的策略有效降低了出分布数据的负面影响。然而，即使这些研究能够有效地筛选出不必要的出分布数据，他们也可能会失去数据之间共享的基本信息，而不管其类别如何。为此，我们提出了将自监督对比学习方法应用于充分利用大量未标注数据的策略。我们还提出了一个带有系数调度比例的对比损失函数，以聚合作为锚定的标注负样本，从而确保所有数据在对比学习过程中的代表性，避免因过滤出分布数据而损失基本信息。

    arXiv:2408.01872v1 Announce Type: cross  Abstract: Semi-supervised learning methods have shown promising results in solving many practical problems when only a few labels are available. The existing methods assume that the class distributions of labeled and unlabeled data are equal; however, their performances are significantly degraded in class distribution mismatch scenarios where out-of-distribution (OOD) data exist in the unlabeled data. Previous safe semi-supervised learning studies have addressed this problem by making OOD data less likely to affect training based on labeled data. However, even if the studies effectively filter out the unnecessary OOD data, they can lose the basic information that all data share regardless of class. To this end, we propose to apply a self-supervised contrastive learning approach to fully exploit a large amount of unlabeled data. We also propose a contrastive loss function with coefficient schedule to aggregate as an anchor the labeled negative ex
    
[^56]: ALIF: 低成本基于 adversarial audio 攻击的黑盒语音平台使用 linguistics features

    ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features

    [https://arxiv.org/abs/2408.01808](https://arxiv.org/abs/2408.01808)

    本文提出了一种新型的基于 linguistic feature 的黑盒语音识别模型攻击方法，该方法能够生成成本低且能抵抗模型更新的敌意音频样本，以成功欺骗 ASR 系统。

    

    arXiv:2408.01808v1 公告类型: 交叉  这是 arXiv 上一个预印本的摘要翻译。原文是研究中发现 adversarial examples (AE) 对声音控制智能设备构成严重威胁。最近的研究提出了仅需要自动语音识别 (ASR) 系统最终转录的黑盒攻击。但是，这些攻击通常需要对 ASR 进行很多查询，这导致了巨大的成本。此外，基于 AE 的敌意音频样本容易受到 ASR 更新的影响。在本文中，我们确定了这些限制的根本原因，即无法直接在深度学习 (DL) 模型决策边界上构造 AE 攻击样本。基于这一观察，我们提出了 ALIF，即第一个基于黑盒 adversarial linguistic feature 的攻击管道。我们利用文本到语音 (TTS) 和 ASR 模型之间的互逆过程在 linguistic embedding 空间中生成扰动，其中决策边界存在。基于 ALIF 管道，我们能够生成仅需要几步查询便能欺骗 ASR 的低成本音频样本。此外，由于我们将攻击在 linguistic feature 空间中进行，这些样本能够很好地抵抗 ASR 更新，展示了我们的方法在现实世界中的潜在应用价值。

    arXiv:2408.01808v1 Announce Type: cross  Abstract: Extensive research has revealed that adversarial examples (AE) pose a significant threat to voice-controllable smart devices. Recent studies have proposed black-box adversarial attacks that require only the final transcription from an automatic speech recognition (ASR) system. However, these attacks typically involve many queries to the ASR, resulting in substantial costs. Moreover, AE-based adversarial audio samples are susceptible to ASR updates. In this paper, we identify the root cause of these limitations, namely the inability to construct AE attack samples directly around the decision boundary of deep learning (DL) models. Building on this observation, we propose ALIF, the first black-box adversarial linguistic feature-based attack pipeline. We leverage the reciprocal process of text-to-speech (TTS) and ASR models to generate perturbations in the linguistic embedding space where the decision boundary resides. Based on the ALIF pi
    
[^57]: 智能制造业的云服务组合综述

    Review of Cloud Service Composition for Intelligent Manufacturing

    [https://arxiv.org/abs/2408.01795](https://arxiv.org/abs/2408.01795)

    本文综述了智能制造业中云服务优化的研究进展，并提出了统一的优化指标体系，旨在支持智能制造平台的可持续发展。

    

    arXiv:2408.01795v1 公告类型：新 Abstract: 智能制造业是一种使用先进技术，如物联网、大数据和人工智能的新模型，以提高制造生产的效率和质量。作为推动制造业转型和升级的重要支持，云服务优化已经引起了研究者的关注。近年来，该领域取得了显著的研究成果。为了智能制造平台的可持续发展，本文总结了智能制造业的云服务优化过程。此外，为了解决现有研究中分散的优化指标和非统一/非标准定义的问题，我们从智能制造平台可持续发展的迫切需求出发，定义了11个考虑三方参与者主体的优化指标，以满足不同需求，实现资源的高效利用和可持续发展。

    arXiv:2408.01795v1 Announce Type: new  Abstract: Intelligent manufacturing is a new model that uses advanced technologies such as the Internet of Things, big data, and artificial intelligence to improve the efficiency and quality of manufacturing production. As an important support to promote the transformation and upgrading of the manufacturing industry, cloud service optimization has received the attention of researchers. In recent years, remarkable research results have been achieved in this field. For the sustainability of intelligent manufacturing platforms, in this paper we summarize the process of cloud service optimization for intelligent manufacturing. Further, to address the problems of dispersed optimization indicators and nonuniform/unstandardized definitions in the existing research, 11 optimization indicators that take into account three-party participant subjects are defined from the urgent requirements of the sustainable development of intelligent manufacturing platform
    
[^58]: 提升绿色AI: 为水稻叶片病害识别设计的有效和高精度的轻量级CNN

    Advancing Green AI: Efficient and Accurate Lightweight CNNs for Rice Leaf Disease Identification

    [https://arxiv.org/abs/2408.01752](https://arxiv.org/abs/2408.01752)

    本次研究专注于建立轻量级CNN模型，如ShuffleNet、MobileNetV2和EfficientNet-B0，用于实现对水稻叶片病害的高效和准确识别。通过结合局部绝对差异操作、空间金字塔池化和改进的全连接层，该模型能够显著提高病害识别的准确率。

    

    论文摘要：水稻是全球一半以上人口的主要食物来源，其产量对于全球粮食安全至关重要。然而，水稻栽培经常受到多种疾病的侵扰，这些疾病可以严重降低产量和品质。因此，早期和准确地检测水稻疾病对于防止疾病蔓延和减轻作物损失至关重要。在本次研究中，我们探索了三种适用于移动设备的长短期记忆网络模型，即ShuffleNet、MobileNetV2和EfficientNet-B0，用于水稻叶片病害分类。选择这些模型是因为它们与移动设备兼容，与其他CNN模型相比，它们需要的计算能力和内存较少。为了提高这三款模型的性能，我们在全连接层之间添加了两个全连接层，并使用了一个防止模型过拟合的dropout层。我们使用早停方法来防止模型发生过拟合。研究结果显示，最佳性能来自……（由于内容整合中英文摘要较长，建议在生成摘要时进行适当的精简）

    arXiv:2408.01752v1 Announce Type: new  Abstract: Rice plays a vital role as a primary food source for over half of the world's population, and its production is critical for global food security. Nevertheless, rice cultivation is frequently affected by various diseases that can severely decrease yield and quality. Therefore, early and accurate detection of rice diseases is necessary to prevent their spread and minimize crop losses. In this research, we explore three mobile-compatible CNN architectures, namely ShuffleNet, MobileNetV2, and EfficientNet-B0, for rice leaf disease classification. These models are selected due to their compatibility with mobile devices, as they demand less computational power and memory compared to other CNN models. To enhance the performance of the three models, we added two fully connected layers separated by a dropout layer. We used early stop creation to prevent the model from being overfiting. The results of the study showed that the best performance wa
    
[^59]: LAM3D：利用注意力的单目3D目标检测

    LAM3D: Leveraging Attention for Monocular 3D Object Detection

    [https://arxiv.org/abs/2408.01739](https://arxiv.org/abs/2408.01739)

    本文提出了一种名为 LAM3D 的框架，它通过在 Pyramid Vision Transformer v2 的基础上增加2D/3D检测机制，有效利用自注意力机制进行单目3D目标检测，并在KITTI 3D对象检测基准上展示了其优越性能。

    

    arXiv:2408.01739v1 公告类型：交叉  摘要：自从自注意力机制的引入和Transformer架构在计算机视觉任务中的采纳以来，基于 Vision Transformer 的架构在该领域获得了大量的关注，被用于包括图像分类、目标检测和图像分割等任务。然而，高效地将注意力机制应用于单目3D目标检测任务中仍然是一个悬而未决的问题。在本文中，我们提出了 LAM3D，这是一个用于利用自注意力机制进行单目3D目标检测的框架。为此，所提出的方法建立在 Pyramid Vision Transformer v2 (PVTv2) 作为特征提取的骨干上，以及对2D/3D检测机器的使用。我们在KITTI 3D 目标检测基准上评估了所提出的方法，证明了所提出解决方案在自动驾驶领域的适用性，并超越了参考方法的表现。此外，由于使用了 s

    arXiv:2408.01739v1 Announce Type: cross  Abstract: Since the introduction of the self-attention mechanism and the adoption of the Transformer architecture for Computer Vision tasks, the Vision Transformer-based architectures gained a lot of popularity in the field, being used for tasks such as image classification, object detection and image segmentation. However, efficiently leveraging the attention mechanism in vision transformers for the Monocular 3D Object Detection task remains an open question. In this paper, we present LAM3D, a framework that Leverages self-Attention mechanism for Monocular 3D object Detection. To do so, the proposed method is built upon a Pyramid Vision Transformer v2 (PVTv2) as feature extraction backbone and 2D/3D detection machinery. We evaluate the proposed method on the KITTI 3D Object Detection Benchmark, proving the applicability of the proposed solution in the autonomous driving domain and outperforming reference methods. Moreover, due to the usage of s
    
[^60]: 能用大语言模型预测随机梯度下降的收敛性吗？

    Can LLMs predict the convergence of Stochastic Gradient Descent?

    [https://arxiv.org/abs/2408.01736](https://arxiv.org/abs/2408.01736)

    论文展示了大型语言模型在预测随机梯度下降收敛到局部最小值方面的出色性能。

    

    arXiv:2408.01736v1 公告类型：交叉  摘要：大型语言模型因其在一系列广泛任务中表现出色而闻名。其令人惊讶的一个例子是最近发现的大语言模型理解满足马尔可夫性质的动力系统 governing 原则的能力。在这篇论文中，我们希望通过研究随机梯度下降在凸和非凸优化中的动力学进一步探索这一方向。通过利用随机梯度下降与马尔可夫链之间的理论联系，我们展示了对于之前未见过的起始点，大语言模型在预测 SGD 收敛到的局部最小值方面表现出了惊人的零样本性能。在更广泛的层面上，我们问询了大语言模型是否有潜力用于执行实践中使用的更大深度学习模型的零样本随机试验。

    arXiv:2408.01736v1 Announce Type: cross  Abstract: Large-language models are notoriously famous for their impressive performance across a wide range of tasks. One surprising example of such impressive performance is a recently identified capacity of LLMs to understand the governing principles of dynamical systems satisfying the Markovian property. In this paper, we seek to explore this direction further by studying the dynamics of stochastic gradient descent in convex and non-convex optimization. By leveraging the theoretical link between the SGD and Markov chains, we show a remarkable zero-shot performance of LLMs in predicting the local minima to which SGD converges for previously unseen starting points. On a more general level, we inquire about the possibility of using LLMs to perform zero-shot randomized trials for larger deep learning models used in practice.
    
[^61]: 基于特征引导的扩散模型用于高保真度和时间一致性说话人头像生成

    Landmark-guided Diffusion Model for High-fidelity and Temporally Coherent Talking Head Generation

    [https://arxiv.org/abs/2408.01732](https://arxiv.org/abs/2408.01732)

    我们提出了一个两阶段扩散模型，使用音频同步面部特征点，并在此基础上生成高质量、同步且时间一致的说话人头像视频，解决了当前模型在图像质量和唇形同步方面的不足。

    

    arXiv:2408.01732v1 公告类型：新  翻译摘要：音频驱动的说话人头像生成是一项重要的但具有挑战性的任务，适用于包括虚拟头像、电影制作和在线会议在内的各种领域。然而，现有的基于GAN的方法过分强调生成与语音同步的唇形，而忽略了生成的帧的视觉质量，而基于扩散的方法则过分强调生成高质量的帧，忽视了唇形匹配，导致嘴部运动出现抖动。为了解决上述问题，我们引入了一种两阶段基于扩散的模型。第一阶段涉及根据给定的语音生成同步的面部特征点。在第二阶段，这些生成的特征点作为条件在去噪过程中使用，旨在优化嘴部抖动问题并生成高保真度、同步和在时间上一致的说话人头像视频。广泛的实验证明，我们的模型达到了最佳性能。

    arXiv:2408.01732v1 Announce Type: new  Abstract: Audio-driven talking head generation is a significant and challenging task applicable to various fields such as virtual avatars, film production, and online conferences. However, the existing GAN-based models emphasize generating well-synchronized lip shapes but overlook the visual quality of generated frames, while diffusion-based models prioritize generating high-quality frames but neglect lip shape matching, resulting in jittery mouth movements. To address the aforementioned problems, we introduce a two-stage diffusion-based model. The first stage involves generating synchronized facial landmarks based on the given speech. In the second stage, these generated landmarks serve as a condition in the denoising process, aiming to optimize mouth jitter issues and generate high-fidelity, well-synchronized, and temporally coherent talking head videos. Extensive experiments demonstrate that our model yields the best performance.
    
[^62]: 联合通用对抗性扰动及其解释

    Joint Universal Adversarial Perturbations with Interpretations

    [https://arxiv.org/abs/2408.01715](https://arxiv.org/abs/2408.01715)

    论文提出了一种新的研究课题，探讨是否存在能够被良性样本检测的通用对抗性扰动，并将其用于对抗性防御策略。

    

    arXiv:2408.01715v1 公告类型：交叉

    arXiv:2408.01715v1 Announce Type: cross  Abstract: Deep neural networks (DNNs) have significantly boosted the performance of many challenging tasks. Despite the great development, DNNs have also exposed their vulnerability. Recent studies have shown that adversaries can manipulate the predictions of DNNs by adding a universal adversarial perturbation (UAP) to benign samples. On the other hand, increasing efforts have been made to help users understand and explain the inner working of DNNs by highlighting the most informative parts (i.e., attribution maps) of samples with respect to their predictions. Moreover, we first empirically find that such attribution maps between benign and adversarial examples have a significant discrepancy, which has the potential to detect universal adversarial perturbations for defending against adversarial attacks. This finding motivates us to further investigate a new research problem: whether there exist universal adversarial perturbations that are able t
    
[^63]: 下游转移攻击：预训练视觉变换器模型的下游任务攻击

    Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers

    [https://arxiv.org/abs/2408.01705](https://arxiv.org/abs/2408.01705)

    本文提出了一种名为 "Downstream Transfer Attack (DTA) 的创新方法，该方法利用预训练的视觉变换器模型的缺陷，转移到下游任务上进行有针对性的攻击。通过个性化的攻击策略，DTA能够在多个计算机视觉任务中有效运作。

    

    arXiv:2408.01705v1 公告类型：交叉  摘要：随着视觉变换器（ViT）和自监督学习（SSL）技术的发展，预训练的大型ViT已成为计算机视觉应用的新型基础模型。然而，研究表明，就像卷积神经网络（CNN）一样，ViT也容易受到 adversarial 攻击，这种攻击可以通过输入的小干扰欺骗模型做出错误的预测。本文研究了从预训练的ViT模型到下游任务的转移易感性。我们专注于 \emph{样本-wise} 转移攻击，并提出了一种名为 \emph{Downstream Transfer Attack (DTA)}  的攻击方法。对于给定的测试图像，DTA利用预训练的ViT模型来制作 adversarial 示例，然后将该 adversarial 示例应用于攻击一个在下游数据集上微调过的模型版本。在攻击过程中，DTA识别并利用模型中最脆弱的层，从而实现攻击的个性化定制。我们证明了DTA 能够在多个下游任务上有效地转移攻击，包括目标检测、图像分类和语义分割等。实验结果表明，DTA 与传统的梯度基于 adversar 攻击相比，能够提高攻击的准确性并减少所需的 adversarial 示例数量。此工作的进一步研究可能会揭示基于 ViT 的模型在新的应用场景中的安全性和鲁棒性问题，并促进安全模型的设计和部署。

    arXiv:2408.01705v1 Announce Type: cross  Abstract: With the advancement of vision transformers (ViTs) and self-supervised learning (SSL) techniques, pre-trained large ViTs have become the new foundation models for computer vision applications. However, studies have shown that, like convolutional neural networks (CNNs), ViTs are also susceptible to adversarial attacks, where subtle perturbations in the input can fool the model into making false predictions. This paper studies the transferability of such an adversarial vulnerability from a pre-trained ViT model to downstream tasks. We focus on \emph{sample-wise} transfer attacks and propose a novel attack method termed \emph{Downstream Transfer Attack (DTA)}. For a given test image, DTA leverages a pre-trained ViT model to craft the adversarial example and then applies the adversarial example to attack a fine-tuned version of the model on a downstream dataset. During the attack, DTA identifies and exploits the most vulnerable layers of t
    
[^64]: 论文标题: 《将大型语言模型与知识图谱集成，用于提取和验证文本测试数据》

    Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data

    [https://arxiv.org/abs/2408.01700](https://arxiv.org/abs/2408.01700)

    论文提出了一个结合知识图谱和大型语言模型的方法，用于提取和验证航空制造文档中的高度复杂和低产量产品的测试数据。

    

    摘要: arXiv:2408.01700v1 公告类型: 新  摘要: 像Thales Alenia Space这样的航空制造公司，设计、开发、集成、验证和验证的产品具有高度复杂性和低产量。它们仔细地记录了每个产品的每个阶段，但跨产品的分析由于文档数据的多样性和非结构化性质而具有挑战性。在本文中，我们提出了一种混合方法论，该方法结合了知识图谱(KGs)与大型语言模型(LLMs)，用于提取和验证这些文档中的数据。我们针对与卫星电子板相关的测试数据进行案例研究。为此，我们扩展了Semantic Sensor Network本体。我们将报告的元数据存储在一个KG中，而实际测试结果则存储在可由虚拟知识图谱访问的parquet格式中。验证过程通过基于LLM的方法来管理。我们还进行了一次基准测试研究，以评估该方法的性能

    arXiv:2408.01700v1 Announce Type: new  Abstract: Aerospace manufacturing companies, such as Thales Alenia Space, design, develop, integrate, verify, and validate products characterized by high complexity and low volume. They carefully document all phases for each product but analyses across products are challenging due to the heterogeneity and unstructured nature of the data in documents. In this paper, we propose a hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with Large Language Models (LLMs) to extract and validate data contained in these documents. We consider a case study focused on test data related to electronic boards for satellites. To do so, we extend the Semantic Sensor Network ontology. We store the metadata of the reports in a KG, while the actual test results are stored in parquet accessible via a Virtual Knowledge Graph. The validation process is managed using an LLM-based approach. We also conduct a benchmarking study to evaluate the performanc
    
[^65]: 不变图学习与信息瓶颈用于过分布外泛化

    Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization

    [https://arxiv.org/abs/2408.01697](https://arxiv.org/abs/2408.01697)

    该论文提出了一种基于信息瓶颈理论的不变图学习方法，旨在提高图神经网络在分布外数据上的性能。通过实验证明，该方法能有效地提取不变特征，优化图学习中的特征表示，同时保持对原分布数据的良好泛化能力。

    

    arXiv:2408.01697v1 公告类型：交叉摘要：图过分布外（OOD）泛化仍然是图学习中的主要挑战，因为图神经网络（GNNs）在分布偏移情况下常常遭受严重的表现度下降。不变学习，旨在提取跨多种分布的恒定特征，在OOD泛化问题上最近取得了一定成功。尽管不变学习在欧几里得数据（例如图像）上的OOD问题中取得了一些成功，但对于图数据的研究仍然受到了图数据复杂性的限制。现有的一些研究，如数据增强或因果干预，在处理图的过程中经常破坏了不变性，或者由于缺乏对因果部分的监督信号而存在可靠性问题。本工作中，我们提出了一个称为基于信息瓶颈理论的不变图学习（InfoIGL）的框架，旨在提取图的恒定特征并增强其分布外泛化能力。我们的框架通过信息瓶颈理论在数据与特征之间建立了有效的信息流，确保了不变性的提取和最优特征表示的学习。通过在多个图数据集上的实验，我们证明了InfoIGL能够有效地提高GNN在OOD数据上的性能，同时保持了对原始分布数据的良好泛化能力。 This framework not only ensures the effective extraction of invariant features but also optimizes the feature representations for graph learning, which is crucial for OOD generalization. Multiple experiments on various graph datasets demonstrate that InfoIGL significantly enhances the performance of GNNs in OOD tasks while maintaining good generalization abilities for the original distribution data.

    arXiv:2408.01697v1 Announce Type: cross  Abstract: Graph out-of-distribution (OOD) generalization remains a major challenge in graph learning since graph neural networks (GNNs) often suffer from severe performance degradation under distribution shifts. Invariant learning, aiming to extract invariant features across varied distributions, has recently emerged as a promising approach for OOD generation. Despite the great success of invariant learning in OOD problems for Euclidean data (i.e., images), the exploration within graph data remains constrained by the complex nature of graphs. Existing studies, such as data augmentation or causal intervention, either suffer from disruptions to invariance during the graph manipulation process or face reliability issues due to a lack of supervised signals for causal parts. In this work, we propose a novel framework, called Invariant Graph Learning based on Information bottleneck theory (InfoIGL), to extract the invariant features of graphs and enha
    
[^66]: IDNet: 一个用于身份文档分析和欺诈检测的新型数据集

    IDNet: A Novel Dataset for Identity Document Analysis and Fraud Detection

    [https://arxiv.org/abs/2408.01690](https://arxiv.org/abs/2408.01690)

    本研究引入了一个新的数据集IDNet，旨在促进隐私保护的欺诈检测技术的进步。

    

    arXiv:2408.01690v1 公告类型: 新  翻译摘要: 在在线平台上挫败身份盗窃并加强安全，有效进行欺诈检测和对政府发行的身份文档(如护照、驾驶执照和身份证)的分析至关重要。训练准确的身份文档欺诈检测和分析工具依赖于大量身份文档数据集的可用性。然而，目前可公开获得的用于身份文档分析的基准数据集，包括MIDV-500、MIDV-2020和FMIDV，在多个方面存在缺陷：它们提供的样本数量有限，涉及的欺诈模式不足，而且很少包括对关键个人身份识别字段(如肖像图像)的更改，这限制了其在训练模型方面的实用性，这些模型能够检测真实生活中的欺诈行为，同时保护隐私。  为了回应这些不足，我们的研究引入了一个新的基准数据集——IDNet，旨在推进隐私保护的欺诈检测技术的进步。

    arXiv:2408.01690v1 Announce Type: new  Abstract: Effective fraud detection and analysis of government-issued identity documents, such as passports, driver's licenses, and identity cards, are essential in thwarting identity theft and bolstering security on online platforms. The training of accurate fraud detection and analysis tools depends on the availability of extensive identity document datasets. However, current publicly available benchmark datasets for identity document analysis, including MIDV-500, MIDV-2020, and FMIDV, fall short in several respects: they offer a limited number of samples, cover insufficient varieties of fraud patterns, and seldom include alterations in critical personal identifying fields like portrait images, limiting their utility in training models capable of detecting realistic frauds while preserving privacy.   In response to these shortcomings, our research introduces a new benchmark dataset, IDNet, designed to advance privacy-preserving fraud detection e
    
[^67]: 使用ε约束优化方法的图像到图像生成模型的可控制遗忘

    Controllable Unlearning for Image-to-Image Generative Models via $\varepsilon$-Constrained Optimization

    [https://arxiv.org/abs/2408.01689](https://arxiv.org/abs/2408.01689)

    本文提出了一种使用ε控制因子调节图像到图像生成模型去学习程度的方法，旨在平衡去学习和模型性能，保护用户数据安全。

    

    虽然生成模型在近年来取得了显著的进步，但也引发了对隐私泄露和偏见等问题的担忧。机器去学习作为一种可行的解决方案，旨在从模型中移除特定的训练数据，例如含有私人信息和偏见的训练数据。在本文中，我们研究了Image-to-Image（I2I）生成模型中的机器去学习问题。以往的研究主要将这个问题视为一个单一目标优化问题，仅提供一种解决方案，这忽视了用户对去学习和模型效用之间的多样化期待。为了解决这个问题，我们提出了一种可控制去学习的框架，它使用控制系数ε来控制这种取舍。我们将I2I生成模型去学习的問題重新表述为一个ε约束优化问题，并使用一种基于梯度的方法来解决这个问题，以找到针对遗忘的优化的解决方案，同时能够保持模型的新鲜度和优越性。我们期望这种方法能够有效地应用于需要频繁更新模型的场景，如图形设计、自然语言处理和视觉内容创建等，以保护用户的数据安全和隐私。

    arXiv:2408.01689v1 Announce Type: cross  Abstract: While generative models have made significant advancements in recent years, they also raise concerns such as privacy breaches and biases. Machine unlearning has emerged as a viable solution, aiming to remove specific training data, e.g., containing private information and bias, from models. In this paper, we study the machine unlearning problem in Image-to-Image (I2I) generative models. Previous studies mainly treat it as a single objective optimization problem, offering a solitary solution, thereby neglecting the varied user expectations towards the trade-off between complete unlearning and model utility. To address this issue, we propose a controllable unlearning framework that uses a control coefficient $\varepsilon$ to control the trade-off. We reformulate the I2I generative model unlearning problem into a $\varepsilon$-constrained optimization problem and solve it with a gradient-based method to find optimal solutions for unlearni
    
[^68]: SAT3D:基于图像的3D语义属性转移

    SAT3D: Image-driven Semantic Attribute Transfer in 3D

    [https://arxiv.org/abs/2408.01664](https://arxiv.org/abs/2408.01664)

    这项研究提出了一种新的方法，可以基于参考图像在3D环境中实现更准确的语义属性转移，解决了以往方法在语义属性编辑方面的局限性。

    

    arXiv:2408.01664v1 Announce Type: 新的摘要: 基于GAN的图像编辑任务旨在在生成模型的潜在空间中对图像属性进行操作。大多数以前的2D和3D感知方法主要关注从参考图像中难以分辨的语义或区域编辑属性，这无法实现摄影风格的语义属性转移，如从一个男人的照片中转移胡须。在本文中，我们提出了一个基于图像的3D语义属性转移方法(SAT3D)，通过从参考图像中编辑语义属性。对于提出的方法，探索是在一个预先训练的3D感知StyleGAN基generator的样式空间中进行的，通过学习与样式代码通道相关的语义属性和样式码之间的相关性。为了指导，我们与一组基于短语的描述符组关联每个属性，并开发了一个定量测量模块(QMM)，以基于描述符组在图像中定量描述属性特征。

    arXiv:2408.01664v1 Announce Type: new  Abstract: GAN-based image editing task aims at manipulating image attributes in the latent space of generative models. Most of the previous 2D and 3D-aware approaches mainly focus on editing attributes in images with ambiguous semantics or regions from a reference image, which fail to achieve photographic semantic attribute transfer, such as the beard from a photo of a man. In this paper, we propose an image-driven Semantic Attribute Transfer method in 3D (SAT3D) by editing semantic attributes from a reference image. For the proposed method, the exploration is conducted in the style space of a pre-trained 3D-aware StyleGAN-based generator by learning the correlations between semantic attributes and style code channels. For guidance, we associate each attribute with a set of phrase-based descriptor groups, and develop a Quantitative Measurement Module (QMM) to quantitatively describe the attribute characteristics in images based on descriptor group
    
[^69]: 基于专家演示的非线性连续约束学习算法 (PUCL)

    Positive-Unlabeled Constraint Learning (PUCL) for Inferring Nonlinear Continuous Constraints Functions from Expert Demonstrations

    [https://arxiv.org/abs/2408.01622](https://arxiv.org/abs/2408.01622)

    本论文提出了一个名为PUCL的新算法，用于从专家演示中推断未知连续约束函数，无需事先了解约束参数化和环境模型。算法通过训练策略从可行和不可行路径中提取信息，逐步优化约束函数。

    

    论文介绍了一种新型的“正负未标注约束学习”(PUCL)算法，用于从专家演示中推断非线性连续约束函数，而不需要预先知道真实的约束参数化或者环境模型。在我们的框架中，我们把所有的演示数据都视为正样例（可行的）数据，并且在学习策略时创造潜在的不可行轨迹作为未标注的数据。在每次迭代中，首先更新策略，然后应用一个两步的正负未标注学习过程，其中首先使用距离度量来确定可靠的不可行数据，随后使用正负未标注数据学习一个确定性约束函数，它代表了一个有界集上的近似，并且在可行域的相邻区域内。通过这样的迭代过程，我们可以优化策略以提高数据集的质量并减弱策略的不确定性，最终学习到更精确的约束函数。本算法在机器人任务的规划和复杂环境中具有潜在的应用价值，那里完整的约束可能既未知也不易准确表达。

    arXiv:2408.01622v1 Announce Type: new  Abstract: Planning for a wide range of real-world robotic tasks necessitates to know and write all constraints. However, instances exist where these constraints are either unknown or challenging to specify accurately. A possible solution is to infer the unknown constraints from expert demonstration. This paper presents a novel Positive-Unlabeled Constraint Learning (PUCL) algorithm to infer a continuous arbitrary constraint function from demonstration, without requiring prior knowledge of the true constraint parameterization or environmental model as existing works. Within our framework, we treat all data in demonstrations as positive (feasible) data, and learn a control policy to generate potentially infeasible trajectories, which serve as unlabeled data. In each iteration, we first update the policy and then a two-step positive-unlabeled learning procedure is applied, where it first identifies reliable infeasible data using a distance metric, an
    
[^70]: 改进心理健康预筛查：一种新型心理困扰评估GPT

    Advancing Mental Health Pre-Screening: A New Custom GPT for Psychological Distress Assessment

    [https://arxiv.org/abs/2408.01614](https://arxiv.org/abs/2408.01614)

    本研究提出了“心理分析师”，一种基于OpenAI GPT-4的定制模型，优化用于心理健康障碍的预筛查。该模型通过DSM-5、PHQ-8详细数据描述和大量训练数据的使用，在识别心理困扰方面表现出色，并显示出在预测PHQ-8评分方面的精确度。通过验证结果显示，该模型在改善心理健康支持和服务方面显示出巨大的潜力。

    

    这项研究介绍了一种名为“心理分析师”的定制GPT模型，该模型基于OpenAI的GPT-4，优化用于心理健康障碍的预筛查。该模型以DSM-5、PHQ-8详细数据描述和大量训练数据为优化基础，擅长解码心理困扰的微妙语言指示。模型采用双任务框架，包括二元分类和PHQ-8评分的三阶段计算，包括初步评估、详细分析和独立评估，展示了其精细的分析能力。使用DAIC-WOZ数据集进行的验证显示了F1和宏观F1分数分别为0.929和0.949，并且在PHQ-8评分方面的最低MAE和RMSE分别为2.89和3.69。这些结果凸显了该模型的高准确性和在提高公众心理健康支持、提升可及性、成本效益和作为专业人士第二意见方面的变革潜力。

    arXiv:2408.01614v1 Announce Type: cross  Abstract: This study introduces 'Psycho Analyst', a custom GPT model based on OpenAI's GPT-4, optimized for pre-screening mental health disorders. Enhanced with DSM-5, PHQ-8, detailed data descriptions, and extensive training data, the model adeptly decodes nuanced linguistic indicators of mental health disorders. It utilizes a dual-task framework that includes binary classification and a three-stage PHQ-8 score computation involving initial assessment, detailed breakdown, and independent assessment, showcasing refined analytic capabilities. Validation with the DAIC-WOZ dataset reveals F1 and Macro-F1 scores of 0.929 and 0.949, respectively, along with the lowest MAE and RMSE of 2.89 and 3.69 in PHQ-8 scoring. These results highlight the model's precision and transformative potential in enhancing public mental health support, improving accessibility, cost-effectiveness, and serving as a second opinion for professionals.
    
[^71]: 标题：社会和对抗性数据源下的可信赖机器学习

    Trustworthy Machine Learning under Social and Adversarial Data Sources

    [https://arxiv.org/abs/2408.01596](https://arxiv.org/abs/2408.01596)

    本文探讨了在社会和对抗性数据源影响下如何确保机器学习系统的输出仍然是可信赖的，提出了全新的理论框架和技术。

    

    摘要：近年来，机器学习领域取得了显著的突破。随着机器学习越来越多地渗透到生活的各个方面，个人和组织越来越频繁地与这些系统互动，表现出各种社会和对抗性的行为。这些行为可能对机器学习系统的行为和性能产生显著影响。特别地，在这些互动过程中，数据可能是由战略性的个体产生的，由自私的数据收集者收集，可能被敌对的攻击者篡改，并且被用来建立满足多个目标的预测器、模型和政策。因此，机器学习系统的输出可能会恶化，比如深度神经网络对对抗性示例的易感性（Shafahi et al., 2018; Szegedy et al., 2013）以及在存在战略个体的情境下经典算法的性能下降（Ahmadi et al., 2021）。解决这些问题要求开发全新的理论框架和技术，这些框架和技术能够确保机器学习系统的输出在面对道德和战略性的数据源时仍然是可信赖的。

    arXiv:2408.01596v1 Announce Type: cross  Abstract: Machine learning has witnessed remarkable breakthroughs in recent years. As machine learning permeates various aspects of daily life, individuals and organizations increasingly interact with these systems, exhibiting a wide range of social and adversarial behaviors. These behaviors may have a notable impact on the behavior and performance of machine learning systems. Specifically, during these interactions, data may be generated by strategic individuals, collected by self-interested data collectors, possibly poisoned by adversarial attackers, and used to create predictors, models, and policies satisfying multiple objectives. As a result, the machine learning systems' outputs might degrade, such as the susceptibility of deep neural networks to adversarial examples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished performance of classic algorithms in the presence of strategic individuals (Ahmadi et al., 2021). Addressing th
    
[^72]: 基于Conformal方法的高斯扩散模型在个体治疗效应估计中的应用

    Conformal Diffusion Models for Individual Treatment Effect Estimation and Inference

    [https://arxiv.org/abs/2408.01582](https://arxiv.org/abs/2408.01582)

    本文提出了一种利用高斯扩散模型结合Conformal方法，对大规模随机对照试验中的个体治疗效应进行高效估计的新方法。通过探索预测数据的模式和理论优势，该方法能够处理大规模数据和不同的干预方案，并对治疗效应进行精确估计。

    

    本文提出了一种基于Conformal方法的高斯扩散模型，用于从大规模随机对照试验中估计个体治疗效应。通过对个体接受干预前后的预后结果进行高斯过程建模，模型推断出了一个张量数据结构，将研究问题转化为协变量中间过程的微分方程。并通过探索过往预测数据的模式和理论优势，可以高效地估计出治疗效应的分布。我们的模型不仅能够处理大规模数据和不同的干预方案，还能够通过合理的假设得到合适的统计判断。我们通过模拟实验表明，该方法相比传统治疗效应估计方法，具有更好的精度。同时，我们还研究了在大规模数据中，治疗效应估计的与数据相关的偏差和混杂效果的影响。

    arXiv:2408.01582v1 Announce Type: cross  Abstract: Estimating treatment effects from observational data is of central interest across numerous application domains. Individual treatment effect offers the most granular measure of treatment effect on an individual level, and is the most useful to facilitate personalized care. However, its estimation and inference remain underdeveloped due to several challenges. In this article, we propose a novel conformal diffusion model-based approach that addresses those intricate challenges. We integrate the highly flexible diffusion modeling, the model-free statistical inference paradigm of conformal inference, along with propensity score and covariate local approximation that tackle distributional shifts. We unbiasedly estimate the distributions of potential outcomes for individual treatment effect, construct an informative confidence interval, and establish rigorous theoretical guarantees. We demonstrate the competitive performance of the proposed 
    
[^73]: 使用部分表面触觉成像的机器人赋能机器学习方法诊断胃息肉的诊断

    Robot-Enabled Machine Learning-Based Diagnosis of Gastric Cancer Polyps Using Partial Surface Tactile Imaging

    [https://arxiv.org/abs/2408.01554](https://arxiv.org/abs/2408.01554)

    该研究提出使用新型光学触觉传感器和机器学习算法，结合七自由度机器人和个性化、增材制造的胃癌肿瘤假体，进行胃息肉诊断。

    

    本文旨在共同解决高级胃癌肿瘤的消化道诊断中的现有限制。首次，我们提出（i）使用并评估我们最近开发的光学触觉传感器（VTS），以及（ii）使用它们的纹理特征的补充机器学习（ML）算法进行分类。利用一个七自由度（DoF）的机器人机械手和独特的自定义设计并通过增材制造的方法制成的假肿瘤，我们证明了使用VTS进行数据自动收集的优势，解决了传统机器学习（ML）方法中遇到的稀缺数据和偏见问题。我们的合成数据训练的ML模型在混合形态特征和传感器不完全接触下的评估中也成功地进行了比较，并与使用各种统计指标的传统ML模型进行了比较。

    arXiv:2408.01554v1 Announce Type: cross  Abstract: In this paper, to collectively address the existing limitations on endoscopic diagnosis of Advanced Gastric Cancer (AGC) Tumors, for the first time, we propose (i) utilization and evaluation of our recently developed Vision-based Tactile Sensor (VTS), and (ii) a complementary Machine Learning (ML) algorithm for classifying tumors using their textural features. Leveraging a seven DoF robotic manipulator and unique custom-designed and additively-manufactured realistic AGC tumor phantoms, we demonstrated the advantages of automated data collection using the VTS addressing the problem of data scarcity and biases encountered in traditional ML-based approaches. Our synthetic-data-trained ML model was successfully evaluated and compared with traditional ML models utilizing various statistical metrics even under mixed morphological characteristics and partial sensor contact.
    
[^74]: 基于上下文跨模态注意力的音频-视觉深度伪造检测与定位

    Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization

    [https://arxiv.org/abs/2408.01532](https://arxiv.org/abs/2408.01532)

    本文提出了一种基于RNN的音频-视觉深度伪造检测和定位的新框架，通过跨模态注意力和上下文信息的学习，提高检测准确性并定位伪造图像的不自然区域。

    

    arXiv:2408.01532v1 公告类型: 交叉 摘要: 在数字时代，深度伪造和合成媒体的出现对社会政治的完整性和诚信构成了重大威胁。基于多模态操纵的深度伪造，如音频-视觉深度伪造，更加逼真，威胁更大。现有的多模态深度伪造检测器通常基于跨模态数据的异构流融合，如音频和视频信号。然而，数据的异构性在有效融合和因此多模态深度伪造检测中创造了分布模态差距。在本论文中，我们提出了一种基于循环神经网络（RNNs）的新颖多模态注意力框架，用于音频-视觉深度伪造的检测。该提出的框架应用注意力到多模态多序列表示上，并学习它们之间的贡献性特征，用于深度伪造检测和位置识别。通过这种方式，我们的模型不仅能够提高深度伪造检测的准确率，而且还能对伪造图像中的不自然区域进行定位。我们的实验结果表明，与现有的多模态方法相比，我们的模型在多个公开数据集上的性能更为优越。

    arXiv:2408.01532v1 Announce Type: cross  Abstract: In the digital age, the emergence of deepfakes and synthetic media presents a significant threat to societal and political integrity. Deepfakes based on multi-modal manipulation, such as audio-visual, are more realistic and pose a greater threat. Current multi-modal deepfake detectors are often based on the attention-based fusion of heterogeneous data streams from multiple modalities. However, the heterogeneous nature of the data (such as audio and visual signals) creates a distributional modality gap and poses a significant challenge in effective fusion and hence multi-modal deepfake detection. In this paper, we propose a novel multi-modal attention framework based on recurrent neural networks (RNNs) that leverages contextual information for audio-visual deepfake detection. The proposed approach applies attention to multi-modal multi-sequence representations and learns the contributing features among them for deepfake detection and lo
    
[^75]: 这里是中国论文的标题

    Analyzing LLMs' Capabilities to Establish Implicit User Sentiment of Software Desirability

    [https://arxiv.org/abs/2408.01527](https://arxiv.org/abs/2408.01527)

    这里是中文摘要的总结

    

    这里是中文学术摘要

    arXiv:2408.01527v1 Announce Type: cross  Abstract: This study explores the use of several LLMs for providing quantitative zero-shot sentiment analysis of implicit software desirability expressed by users. The study provides scaled numerical sentiment analysis unlike other methods that simply classify sentiment as positive, neutral, or negative. Numerical analysis provides deeper insights into the magnitude of sentiment, to drive better decisions regarding product desirability.   Data is collected through the use of the Microsoft Product Desirability Toolkit (PDT), a well-known qualitative user experience analysis tool. For initial exploration, the PDT metric was given to users of ZORQ, a gamification system used in undergraduate computer science education. The PDT data collected was fed through several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a leading transfer learning technique, Twitter-Roberta-Base-Sentiment (TRBS), and through Vader, a leading sentiment analysis 
    
[^76]: 参数空间梯度流与输出空间线性插值等效

    Gradient flow in parameter space is equivalent to linear interpolation in output space

    [https://arxiv.org/abs/2408.01517](https://arxiv.org/abs/2408.01517)

    该论文证明参数空间的梯度流可通过重新参数化等效于输出空间的线性插值，并且在参数雅可比矩阵满秩的条件下，全局最小值可达。

    

    arXiv:2408.01517v1 公告类型：交叉 摘要：我们对神经网络深度学习中许多训练算法背后的标准参数空间梯度流进行了证明，证明其可以被连续变形为适应性梯度流，该梯度流在输出空间中导致（受限）欧氏梯度流。此外，如果关于参数的输出雅可比矩阵对于固定训练数据具有满秩，则可以重新参数化时间变量，使得 resulting flow 只是线性插值，并且可以实现全局最小值。

    arXiv:2408.01517v1 Announce Type: cross  Abstract: We prove that the usual gradient flow in parameter space that underlies many training algorithms for neural networks in deep learning can be continuously deformed into an adapted gradient flow which yields (constrained) Euclidean gradient flow in output space. Moreover, if the Jacobian of the outputs with respect to the parameters is full rank (for fixed training data), then the time variable can be reparametrized so that the resulting flow is simply linear interpolation, and a global minimum can be achieved.
    
[^77]: 本地价值基准：一个合作构建的可扩展的大型语言模型价值对齐和伦理安全评估基准

    LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models

    [https://arxiv.org/abs/2408.01460](https://arxiv.org/abs/2408.01460)

    本地价值基准是一个针对大型语言模型评估其与澳大利亚价值观一致性的可扩展型框架，帮助世界各地的监管机构制定适合自己的评估标准。

    

    arXiv:2408.01460v1 宣布类型：交叉 摘要：随着大型语言模型（LLMs）的普及，对它们与当地价值观和伦理标准的对齐评估变得越来越重要，尤其是在现有的基准往往反映其创建者的文化、法律和意识形态价值观的背景下。在本文中介绍的\textsc{LocalValueBench}是一个可扩展的基准，旨在评估大型语言模型与澳大利亚价值观的一致性，并为世界各地的监管机构提供了根据本地价值观对对语言模型的标准制定自己的提案。通过采用一种新的伦理推理类型学和一种质疑方法，我们精心编排了全面的问题，并利用了提示工程策略来探测大型语言模型对本地价值观的一致性。我们的评估标准量化了与本地价值观的偏差，确保了评估过程的严格性。对美国供应商的三款商业LLM的比较分析揭示了它们在实现和限制方面的显著洞察，证明了它们的有效性和局限性，并展示了这一批评视角的重要性和实用性。

    arXiv:2408.01460v1 Announce Type: cross  Abstract: The proliferation of large language models (LLMs) requires robust evaluation of their alignment with local values and ethical standards, especially as existing benchmarks often reflect the cultural, legal, and ideological values of their creators. \textsc{LocalValueBench}, introduced in this paper, is an extensible benchmark designed to assess LLMs' adherence to Australian values, and provides a framework for regulators worldwide to develop their own LLM benchmarks for local value alignment. Employing a novel typology for ethical reasoning and an interrogation approach, we curated comprehensive questions and utilized prompt engineering strategies to probe LLMs' value alignment. Our evaluation criteria quantified deviations from local values, ensuring a rigorous assessment process. Comparative analysis of three commercial LLMs by USA vendors revealed significant insights into their effectiveness and limitations, demonstrating the critic
    
[^78]: AgentPeerTalk：通过带有代理AI的辨别能力增强学校学生对抗校园欺凌和玩笑的能力

    AgentPeerTalk: Empowering Students through Agentic-AI-Driven Discernment of Bullying and Joking in Peer Interactions in Schools

    [https://arxiv.org/abs/2408.01459](https://arxiv.org/abs/2408.01459)

    该研究通过使用ChatGPT-4等大型语言模型，发现代理式AI技术可能有助于辨别校园欺凌与玩笑，为学生的心理安全提供有效支持。

    

    本研究探讨了大型语言模型(LLM)在辨别学校中同伴互动中的欺凌与玩笑方面的潜力，旨在为学生的心理健康提供有效和及时的防护。我们使用了ChatGPT-4、Gemini 1.5 Pro和Claude 3 Opus，并经过人工审查评估了它们的功效。结果显示，并不是所有的LLM都适合采用代理式方法。ChatGPT-4在这方面的表现最为突出。我们注意到不同LLM输出的差异，这可能受到了政治上的过度纠正、上下文窗口限制和训练数据的预先偏见的影响。在实施了代理式方法后，ChatGPT-4在特定情境下的准确率有了显著提升，凸显了它能为易受伤害的学生提供持续、实时支持的能力。本研究强调，在教育环境中使用代理AI技术的重要性，并为该领域开辟了一条新的发展道路。

    arXiv:2408.01459v1 Announce Type: cross  Abstract: Addressing school bullying effectively and promptly is crucial for the mental health of students. This study examined the potential of large language models (LLMs) to empower students by discerning between bullying and joking in school peer interactions. We employed ChatGPT-4, Gemini 1.5 Pro, and Claude 3 Opus, evaluating their effectiveness through human review. Our results revealed that not all LLMs were suitable for an agentic approach, with ChatGPT-4 showing the most promise. We observed variations in LLM outputs, possibly influenced by political overcorrectness, context window limitations, and pre-existing bias in their training data. ChatGPT-4 excelled in context-specific accuracy after implementing the agentic approach, highlighting its potential to provide continuous, real-time support to vulnerable students. This study underlines the significant social impact of using agentic AI in educational settings, offering a new avenue f
    
[^79]: 调查有害吗？反思人工智能研究、发展和治理中的调查使用方式

    Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance

    [https://arxiv.org/abs/2408.01458](https://arxiv.org/abs/2408.01458)

    本文批评了人工智能领域的公众调查，指出这些调查容易受到西方知识和价值观的影响，并建议在全球化的背景下设计更敏感的调查方法。

    

    arXiv:2408.01458v1 宣布类型：交叉  摘要：呼吁与公众在人工智能（AI）研究、发展和治理中的接触，导致使用调查来捕获与AI相关的人们对其价值、观念和经历的看法。在本论文中，我们对与这些话题相关的公众调查状况进行了批判性审视。通过对我们开展的一个覆盖六个国家的调查试点的自我反思分析以及对我们确定的人工智能相关44篇论文中包含的调查的系统文献回顾，我们探讨了关于AI的调查到目前为止所涉及的普遍观点和研究方法学上的微妙之处。我们发现，AI领域的公众调查在设计上容易受到特定于西方的知识、价值观和假设的损害，包括在它们对伦理概念和社会价值的定位中，以及在它们对部署策略的相关负面讨论中缺乏足够的批判性对话，以及它们在报告中的透明度不一。根据我们的发现，我们提出了在全球化和多元化的人工智能技术和观念的背景下，设计调查和文化有别的受众时需要更加敏感的建议。

    arXiv:2408.01458v1 Announce Type: cross  Abstract: Calls for engagement with the public in Artificial Intelligence (AI) research, development, and governance are increasing, leading to the use of surveys to capture people's values, perceptions, and experiences related to AI. In this paper, we critically examine the state of human participant surveys associated with these topics. Through both a reflexive analysis of a survey pilot spanning six countries and a systematic literature review of 44 papers featuring public surveys related to AI, we explore prominent perspectives and methodological nuances associated with surveys to date. We find that public surveys on AI topics are vulnerable to specific Western knowledge, values, and assumptions in their design, including in their positioning of ethical concepts and societal values, lack sufficient critical discourse surrounding deployment strategies, and demonstrate inconsistent forms of transparency in their reporting. Based on our finding
    
[^80]: 安曼城市，约旦：自下而上建设可持续城市

    Amman City, Jordan: Toward a Sustainable City from the Ground Up

    [https://arxiv.org/abs/2408.01454](https://arxiv.org/abs/2408.01454)

    安曼智慧城市项目介绍了如何通过创新技术改善市民生活质量和城市环境。

    

    arXiv:2408.01454v1 公告类型：交叉 摘要：近年来，智能城市（SCs）的理念受到了广泛关注。SCs的理念旨在提高市民的生活质量并保护城市环境。随着我们步入下一代智能城市时代，探索SC理念的所有相关方面变得至关重要。近年来，信息技术的发展促进了日常生活中物品智能化的趋势，旨在使人类生活更加便捷舒适。SCs的模式作为一个回应，旨在构建一个具有先进特征的未来城市。尽管SCs的实施仍面临许多挑战，但越来越多的研究开始关注这一领域。如今，不同城市正在采纳SCs的特点来提升服务和居民的生活质量。本工作为读者提供了关于安曼智慧城市的有用和重要信息。

    arXiv:2408.01454v1 Announce Type: cross  Abstract: The idea of smart cities (SCs) has gained substantial attention in recent years. The SC paradigm aims to improve citizens' quality of life and protect the city's environment. As we enter the age of next-generation SCs, it is important to explore all relevant aspects of the SC paradigm. In recent years, the advancement of Information and Communication Technologies (ICT) has produced a trend of supporting daily objects with smartness, targeting to make human life easier and more comfortable. The paradigm of SCs appears as a response to the purpose of building the city of the future with advanced features. SCs still face many challenges in their implementation, but increasingly more studies regarding SCs are implemented. Nowadays, different cities are employing SC features to enhance services or the residents quality of life. This work provides readers with useful and important information about Amman Smart City.
    
[^81]: 环境影响报告与语言模型在常识问答中的分析 - 以外部知识为例子

    Reporting and Analysing the Environmental Impact of Language Models on the Example of Commonsense Question Answering with External Knowledge

    [https://arxiv.org/abs/2408.01453](https://arxiv.org/abs/2408.01453)

    本文研究了语言模型在常识问答中应用的环境影响，强调了减少人工智能任务对环境影响的重要性。

    

    本文首先介绍了常识问答中的外部知识应用，通过分析语言模型对环境的潜在影响。全球碳排放正在以惊人的速度增长，造成了气候和环境的变化。全球数据中心的碳排放估计占美国2021年温室气体排放的0.5%。2022年底，大型语言模型（LLMs）的问世引起了社会对这类新型语言模型的极大兴趣。目前，许多公司已推出包含不同LLM的产品，而更多的模型正在开发中。在深度学习领域，只有达到最佳性能的模型才会获得关注和应用。然而，高效和研究的环境影响常常被忽视。本文旨在探讨和分析构建和发展此类模型对环境可能造成的负面影响，并提出一些解决方案以缓解负面影响。通过对案例的详细调查，本文计划展示了执行人工智能任务的实际情况，并对如何减少这些任务的环境足迹进行了讨论。最后，本文提出了严格要求的环境评估标准，并致力于减少在开发和使用LLMs的过程中对环境的破坏。

    arXiv:2408.01453v1 Announce Type: cross  Abstract: Human-produced emissions are growing at an alarming rate, causing already observable changes in the climate and environment in general. Each year global carbon dioxide emissions hit a new record, and it is reported that 0.5% of total US greenhouse gas emissions are attributed to data centres as of 2021. The release of ChatGPT in late 2022 sparked social interest in Large Language Models (LLMs), the new generation of Language Models with a large number of parameters and trained on massive amounts of data. Currently, numerous companies are releasing products featuring various LLMs, with many more models in development and awaiting release. Deep Learning research is a competitive field, with only models that reach top performance attracting attention and being utilized. Hence, achieving better accuracy and results is often the first priority, while the model's efficiency and the environmental impact of the study are neglected. However, LL
    
[^82]: 一种新的神经网络环境成本估计模型及其在适应性生命周期中的应用

    Estimating Environmental Cost Throughout Model's Adaptive Life Cycle

    [https://arxiv.org/abs/2408.01446](https://arxiv.org/abs/2408.01446)

    本文提出了一种预测指数PreIndex，用来估计在模型适应性生命周期的再培训过程中，从当前数据分布到新数据分布的变化中，所涉及的环境成本（如碳排放和能源消耗）。

    

    arXiv:2408.01446v1 公告类型: 交叉  翻译摘要: 随着神经网络在当前时代的快速发展，需要越来越多的能源来训练和使用模型。特别是，这伴随着碳排放到环境中的增加。为了减少人工智能/深度学习时代的碳足迹以及相关的能源需求，我们提出了一种模型再培训的预测指数，PreIndex，以估计与模型再培训相关的环境成本，如碳排放和能源消耗。模型再培训是为了适应数据分布的变化或在数据分布之间的变化/差异。PreIndex指数可以用来估算从当前数据分布到新数据分布的重新训练的成本，它也与Model的适应性生命周期有关。我们的研究旨在为模型的适应性生命周期的设计提供支持，从而帮助降低再培训的成本和环境影响。

    arXiv:2408.01446v1 Announce Type: cross  Abstract: With the rapid increase in the research, development, and application of neural networks in the current era, there is a proportional increase in the energy needed to train and use models. Crucially, this is accompanied by the increase in carbon emissions into the environment. A sustainable and socially beneficial approach to reducing the carbon footprint and rising energy demands associated with the modern age of AI/deep learning is the adaptive and continuous reuse of models with regard to changes in the environment of model deployment or variations/changes in the input data. In this paper, we propose PreIndex, a predictive index to estimate the environmental and compute resources associated with model retraining to distributional shifts in data. PreIndex can be used to estimate environmental costs such as carbon emissions and energy usage when retraining from current data distribution to new data distribution. It also correlates with
    
[^83]: 深圳科技大学GAN: 改善自动驾驶在不利条件下的对象识别图像生成

    SUSTechGAN: Image Generation for Object Recognition in Adverse Conditions of Autonomous Driving

    [https://arxiv.org/abs/2408.01430](https://arxiv.org/abs/2408.01430)

    深圳科技大学提出的GAN模型增强了在不利条件下自动驾驶车辆对象识别的能力，通过生成图像增加了训练数据的多样性。

    

    arXiv:2408.01430v1 宣布类型: 交叉 摘要: 自驾驶车显著受益于基于数据的深度神经网络。然而，自动驾驶车的数据通常符合长尾分布，其中关键的驾驶数据在不利条件下难以收集。尽管生成对抗性网络（GANs）已经被应用到为自动驾驶车添加数据，但生成不利条件下的驾驶图像仍然是一个挑战。在本工作中，我们提出了一种新型的深圳科技大学GAN，它具有双重注意模块和多尺度生成器，用于生成图像以改善在不利条件下的自动驾驶车辆对象识别能力。我们测试了深圳科技大学GAN和现有的知名GAN，以确保在雨天和夜晚等不利条件下生成驾驶图像，并将生成的图像应用到重新训练对象识别网络中。具体来说，我们将生成的图像加入到训练数据集中，重新训练著名的YOLOv5，并评估了图像改进对象识别网络的效果。

    arXiv:2408.01430v1 Announce Type: cross  Abstract: Autonomous driving significantly benefits from data-driven deep neural networks. However, the data in autonomous driving typically fits the long-tailed distribution, in which the critical driving data in adverse conditions is hard to collect. Although generative adversarial networks (GANs) have been applied to augment data for autonomous driving, generating driving images in adverse conditions is still challenging. In this work, we propose a novel SUSTechGAN with dual attention modules and multi-scale generators to generate driving images for improving object recognition of autonomous driving in adverse conditions. We test the SUSTechGAN and the existing well-known GANs to generate driving images in adverse conditions of rain and night and apply the generated images to retrain object recognition networks. Specifically, we add generated images into the training datasets to retrain the well-known YOLOv5 and evaluate the improvement of th
    
[^84]: 迁移式对抗性面部图像对隐私保护

    Transferable Adversarial Facial Images for Privacy Protection

    [https://arxiv.org/abs/2408.01428](https://arxiv.org/abs/2408.01428)

    本文提出了一种新的面部隐私保护方案，能在保持高视觉质量的同时提高转移能力。通过直接塑造整个面部空间，而不是仅利用妆容信息等一种特征来整合对抗性噪声，该方案能够在黑盒场景中生成自然且高度可转移的对抗性面部图像。

    

    arXiv:2408.01428v1 宣布类型：新 摘要：由于深度人脸识别（FR）系统的成功，人们对使用这些系统在数字世界中追踪用户的能力给予了高度重视。之前的研究通过在面部图像中引入不可察觉的对抗性噪声来误导这些人脸识别模型，实现了增强面部隐私保护的目标。然而，他们高度依赖于用户选择的参考来指导对抗性噪声的生成，并且在黑盒场景中无法同时创建自然且高度可转移的对抗性面部图像。因此，我们提出了一个全新的面部隐私保护方案，该方案在保持高视觉质量的同时提高了转移能力。我们提议直接塑造整个面部空间，而不是利用类似于妆容信息的一种面部特征来整合对抗性噪声。为实现这一目标，我们首先利用全局对抗性潜变量搜索

    arXiv:2408.01428v1 Announce Type: new  Abstract: The success of deep face recognition (FR) systems has raised serious privacy concerns due to their ability to enable unauthorized tracking of users in the digital world. Previous studies proposed introducing imperceptible adversarial noises into face images to deceive those face recognition models, thus achieving the goal of enhancing facial privacy protection. Nevertheless, they heavily rely on user-chosen references to guide the generation of adversarial noises, and cannot simultaneously construct natural and highly transferable adversarial face images in black-box scenarios. In light of this, we present a novel face privacy protection scheme with improved transferability while maintain high visual quality. We propose shaping the entire face space directly instead of exploiting one kind of facial characteristic like makeup information to integrate adversarial noises. To achieve this goal, we first exploit global adversarial latent sear
    
[^85]: Siamese Transformer 网络对于少样本图像分类

    Siamese Transformer Networks for Few-shot Image Classification

    [https://arxiv.org/abs/2408.01427](https://arxiv.org/abs/2408.01427)

    本研究提出了基于Siamese Transformer的网络，通过提取全局和局部特征，结合了Euclidean distance measure，在少样本图像分类任务中取得了显著提升。

    

    arXiv:2408.01427v1 宣布类型: 新 摘要: 人类在视觉分类任务中表现出非凡的效率，能够准确识别和分类新图像，需要的示例很少。这种能力归功于他们能够专注于细节并识别之前看到的和新图像之间的共同特征。相比之下，现有的少样本图像分类方法往往侧重于全局特征或局部特征，很少有研究考虑这两种特征的整合。为了解决这个限制，我们提出了一种基于 Siamese Transformer 网络(STN)的新方法。我们的方法使用两个并行分支网络，利用预训练的视觉Transformer(ViT)架构来提取全局和局部特征。特别是，我们实现了一个使用ViT-Small网络架构的网络，并使用通过自我监督学习获得预训练的模型参数对分支网络进行初始化。我们采用了欧氏距离度量来对全局特征和局部特征进行量化，并将两者结合起来，以提高少数样本图像分类的性能。在多个公开数据集上的实验结果表明，与现有的先进方法相比，我们的方法在相应少样本和单一样本条件下均取得了显著的提升。

    arXiv:2408.01427v1 Announce Type: new  Abstract: Humans exhibit remarkable proficiency in visual classification tasks, accurately recognizing and classifying new images with minimal examples. This ability is attributed to their capacity to focus on details and identify common features between previously seen and new images. In contrast, existing few-shot image classification methods often emphasize either global features or local features, with few studies considering the integration of both. To address this limitation, we propose a novel approach based on the Siamese Transformer Network (STN). Our method employs two parallel branch networks utilizing the pre-trained Vision Transformer (ViT) architecture to extract global and local features, respectively. Specifically, we implement the ViT-Small network architecture and initialize the branch networks with pre-trained model parameters obtained through self-supervised learning. We apply the Euclidean distance measure to the global featur
    
[^86]: 论文标题翻译

    Dissecting Dissonance: Benchmarking Large Multimodal Models Against Self-Contradictory Instructions

    [https://arxiv.org/abs/2408.01091](https://arxiv.org/abs/2408.01091)

    中文总结要点

    

    论文摘要翻译

    arXiv:2408.01091v1 Announce Type: new  Abstract: Large multimodal models (LMMs) excel in adhering to human instructions. However, self-contradictory instructions may arise due to the increasing trend of multimodal interaction and context length, which is challenging for language beginners and vulnerable populations. We introduce the Self-Contradictory Instructions benchmark to evaluate the capability of LMMs in recognizing conflicting commands. It comprises 20,000 conflicts, evenly distributed between language and vision paradigms. It is constructed by a novel automatic dataset creation framework, which expedites the process and enables us to encompass a wide range of instruction forms. Our comprehensive evaluation reveals current LMMs consistently struggle to identify multimodal instruction discordance due to a lack of self-awareness. Hence, we propose the Cognitive Awakening Prompting to inject cognition from external, largely enhancing dissonance detection. The dataset and code are 
    
[^87]: 这里是翻译过的论文标题

    CIResDiff: A Clinically-Informed Residual Diffusion Model for Predicting Idiopathic Pulmonary Fibrosis Progression

    [https://arxiv.org/abs/2408.00938](https://arxiv.org/abs/2408.00938)

    本研究提出了一种基于临床知识改进的扩散模型，用于更准确地预测特发性肺纤维化（IPF）的进展。

    

    这里是翻译过的论文摘要

    arXiv:2408.00938v1 Announce Type: cross  Abstract: The progression of Idiopathic Pulmonary Fibrosis (IPF) significantly correlates with higher patient mortality rates. Early detection of IPF progression is critical for initiating timely treatment, which can effectively slow down the advancement of the disease. However, the current clinical criteria define disease progression requiring two CT scans with a one-year interval, presenting a dilemma: a disease progression is identified only after the disease has already progressed. To this end, in this paper, we develop a novel diffusion model to accurately predict the progression of IPF by generating patient's follow-up CT scan from the initial CT scan. Specifically, from the clinical prior knowledge, we tailor improvements to the traditional diffusion model and propose a Clinically-Informed Residual Diffusion model, called CIResDiff. The key innovations of CIResDiff include 1) performing the target region pre-registration to align the lung
    
[^88]: UlRe-NeRF: 使用神经渲染的3D超声成像，通过超声反射方向参数化

    UlRe-NeRF: 3D Ultrasound Imaging through Neural Rendering with Ultrasound Reflection Direction Parameterization

    [https://arxiv.org/abs/2408.00860](https://arxiv.org/abs/2408.00860)

    该模型通过将超声反射方向参数化和谐波编码与神经渲染结合，生成接近真实物理的3D超声图像，提高了图像质量和处理复杂反射的能力。

    

    arXiv:2408.00860v1 公告类型：新提交  摘要：三维超声成像在医疗诊断中广泛使用，是一项关键技术。然而，传统的三维超声成像方法存在固定分辨率、存储效率低、上下文连接不足等问题，导致在处理复杂的图像异常和反射特性时表现不佳。最近，基于NeRF（神经辐射场）的技术在视角合成和三维重建方面取得了显著进步，但在高清晰度超声成像方面仍有研究缺口。为了解决这些问题，我们提出了一种新的模型UlRe-NeRF，它将隐式的神经网络和显式的超声体绘制功能集成到一个超声神经渲染架构中。该模型包含了反射方向参数化和谐波编码，使用方向性MLP模块生成视角依赖的高频反射强度估计，以及一个空间MLP模块来估计整个空间内的反射强度变化，从而提高图像的质量和真实性。通过这项技术，UlRe-NeRF能够提供接近真实物理的3D ultrasound渲染，并且具有更高效的存储和更优的处理能力，尤其是在处理复杂反射和透视问题时。实验结果表明，UlRe-NeRF在各种复杂场景中的表现优于现有技术，为超声成像领域提供了新的解决方案。

    arXiv:2408.00860v1 Announce Type: new  Abstract: Three-dimensional ultrasound imaging is a critical technology widely used in medical diagnostics. However, traditional 3D ultrasound imaging methods have limitations such as fixed resolution, low storage efficiency, and insufficient contextual connectivity, leading to poor performance in handling complex artifacts and reflection characteristics. Recently, techniques based on NeRF (Neural Radiance Fields) have made significant progress in view synthesis and 3D reconstruction, but there remains a research gap in high-quality ultrasound imaging. To address these issues, we propose a new model, UlRe-NeRF, which combines implicit neural networks and explicit ultrasound volume rendering into an ultrasound neural rendering architecture. This model incorporates reflection direction parameterization and harmonic encoding, using a directional MLP module to generate view-dependent high-frequency reflection intensity estimates, and a spatial MLP mod
    
[^89]: 迷失在翻译中：文本到图像扩散模型中的潜在概念不一致

    Lost in Translation: Latent Concept Misalignment in Text-to-Image Diffusion Models

    [https://arxiv.org/abs/2408.00230](https://arxiv.org/abs/2408.00230)

    文章探讨了文本到图像扩散模型在处理文字与图像概念映射时存在的问题，并提出了一种基于大型语言模型的解决方案，有效提高了模型对文字提示的响应一致性。

    

    这篇文章讨论了文本到图像扩散模型在概念映射方面所遇到的挑战。在现有的模型中，当输入包括两个潜在概念的组合时（例如，“一杯冰可乐”这个词组），模型常常生成冰可乐与玻璃杯的组合。这种不一致的问题是因为文本和图像之间的潜在概念映射存在问题。为了解决这些问题，我们提出了一种基于大型语言模型的自动化管道，并通过实际的评估确认了该方法的有效性。

    arXiv:2408.00230v2 Announce Type: replace  Abstract: Advancements in text-to-image diffusion models have broadened extensive downstream practical applications, but such models often encounter misalignment issues between text and image. Taking the generation of a combination of two disentangled concepts as an example, say given the prompt "a tea cup of iced coke", existing models usually generate a glass cup of iced coke because the iced coke usually co-occurs with the glass cup instead of the tea one during model training. The root of such misalignment is attributed to the confusion in the latent semantic space of text-to-image diffusion models, and hence we refer to the "a tea cup of iced coke" phenomenon as Latent Concept Misalignment (LC-Mis). We leverage large language models (LLMs) to thoroughly investigate the scope of LC-Mis, and develop an automated pipeline for aligning the latent semantics of diffusion models to text prompts. Empirical assessments confirm the effectiveness of
    
[^90]: 基于偏好的抽象论证案例基于推理（附录版）

    Preference-Based Abstract Argumentation for Case-Based Reasoning (with Appendix)

    [https://arxiv.org/abs/2408.00108](https://arxiv.org/abs/2408.00108)

    本文提出了AA-CBR-P（基于偏好的抽象论证案例基于推理），它允许用户根据特定偏好对案例进行排序，并证明了模型在遵循这些偏好时进行预测的能力。这种方法在评估头颅肿瘤患者不同评估方法的有效性上得到了实验验证。

    

    在本文中，我们提出了一种名为AA-CBR-P的创新方法，它将用户定义的偏好与抽象论证和案例基于推理（CBR）相结合。具体来说，AA-CBR-P允许用户通过定义多个比较案例的方法来表达偏好，并按照特定的偏好顺序对这些比较方法进行排序。我们将证明，当模型进行预测时，它会毫无保留地遵守这些偏好，并展示出先前对于案例基于推理的抽象论证方法不能有效地表达对论证成分的偏好。此外，我们还展示了这种方法在临床测试中的实际应用，该测试评估了不同评估方法在头颅肿瘤患者诊断中的有效性。通过真实世界数据的呈现，我们揭示了AA-CBR-P如何可能被应用于医疗领域的实际案例中。

    arXiv:2408.00108v2 Announce Type: replace  Abstract: In the pursuit of enhancing the efficacy and flexibility of interpretable, data-driven classification models, this work introduces a novel incorporation of user-defined preferences with Abstract Argumentation and Case-Based Reasoning (CBR). Specifically, we introduce Preference-Based Abstract Argumentation for Case-Based Reasoning (which we call AA-CBR-P), allowing users to define multiple approaches to compare cases with an ordering that specifies their preference over these comparison approaches. We prove that the model inherently follows these preferences when making predictions and show that previous abstract argumentation for case-based reasoning approaches are insufficient at expressing preferences over constituents of an argument. We then demonstrate how this can be applied to a real-world medical dataset sourced from a clinical trial evaluating differing assessment methods of patients with a primary brain tumour. We show empi
    
[^91]: 使用流算法和K-means聚类实现RAG（检索增强生成）

    Implementing Streaming algorithm and k-means clusters to RAG

    [https://arxiv.org/abs/2407.21300](https://arxiv.org/abs/2407.21300)

    论文提出了一种结合流算法和K-means聚类的RAG改进方案，以高效更新索引并缩短查询时间，同时节省内存资源。|>

    

    arXiv:2407.21300v2 公告类型：替换交叉 - 摘要：检索增强生成（RAG）在利用大型语言模型协助信息检索方面取得了巨大成功，因为它建立了一个外部知识数据库。然而，它也有许多问题：由于数据库巨大，它消耗了大量内存。面对海量流数据时，它无法及时更新已建立的索引数据库。为了节省建立数据库的内存消耗并保持准确性，我们提出了一种新的方法，将流算法和K-means聚类与RAG结合起来。我们的方法应用流算法来更新索引并减少内存消耗。然后使用K-means算法将彼此相似度高的文档聚类在一起，这样查询时间就会缩短。我们对四种方法进行了对比实验，结果表明，使用流算法和K-means聚类的RAG在准确性和内存方面表现良好。对于大规模的数据集，我们的方法在计算和内存消耗上都比传统RAG方法更高效。

    arXiv:2407.21300v2 Announce Type: replace-cross  Abstract: Retrieval-augmented generation (RAG) has achieved great success in information retrieval to assist large language models because it builds an external knowledge database. However, it also has many problems: it consumes a lot of memory because of the huge database. When faced with massive streaming data, it is unable to update the established index database in time. To save the memory of building the database and maintain accuracy simultaneously, we proposed a new approach combining a streaming algorithm and k-means cluster with RAG. Our approach applies a streaming algorithm to update the index and reduce memory consumption. Then use the k-means algorithm to cluster documents with high similarities together, the query time will be shortened by doing this. We conducted comparative experiments on four methods, and the results show that RAG with streaming algorithm and k-means cluster performs well in accuracy and memory. For mass
    
[^92]: 整数值训练与 spikes 驱动推理的 SNN 对象检测，具备高性能与低能耗

    Integer-Valued Training and Spike-Driven Inference Spiking Neural Network for High-performance and Energy-efficient Object Detection

    [https://arxiv.org/abs/2407.20708](https://arxiv.org/abs/2407.20708)

    设计了一种采用整数值训练和脉冲驱动推理的新型SNN，在对象检测任务上取得了比传统ANNs更好的性能，同时实现了高能效和实时检测能力。

    

    arXiv:2407.20708v3 宣布类型：替换 摘要： 与人工神经网络（ANNs）相比，具有生物学合理性和低功耗优势的突触神经网络（SNNs）目前仅限于执行简单的分类任务。在这项工作中，我们的目标是弥合对象检测中ANNs和SNNs之间的性能差距。我们的设计围绕网络结构和突触神经元展开。首先，YOLO系列向相应突触版本的转换过程中存在复杂模块设计导致的信号损耗。我们通过简化原始YOLO并集成元SNN块来解决这个问题，从而设计出SpikeYOLO架构。其次，对象检测对转换为二进制突触的过程中电位量的量化误差更为敏感。为了解决这个问题，我们设计了一种新类型的突触神经元，它能够在训练期间以整数值激活，同时保持脉冲驱动的预测性能。此外，还设计了优化后的训练方法和轻量级 SNN 网络结构，使其在保留高精度对象检测结果的同时，实现了优于多其它 SNN 网络架构的低能耗处理。最终，该设计在真实机器人硬件上实现了高性能、低能耗的实时对象检测，展示了可行性。 | 关键词：spiking neural networks, object detection, artificial neural networks, energy efficiency, real-time detection

    arXiv:2407.20708v3 Announce Type: replace  Abstract: Brain-inspired Spiking Neural Networks (SNNs) have bio-plausibility and low-power advantages over Artificial Neural Networks (ANNs). Applications of SNNs are currently limited to simple classification tasks because of their poor performance. In this work, we focus on bridging the performance gap between ANNs and SNNs on object detection. Our design revolves around network architecture and spiking neuron. First, the overly complex module design causes spike degradation when the YOLO series is converted to the corresponding spiking version. We design a SpikeYOLO architecture to solve this problem by simplifying the vanilla YOLO and incorporating meta SNN blocks. Second, object detection is more sensitive to quantization errors in the conversion of membrane potentials into binary spikes by spiking neurons. To address this challenge, we design a new spiking neuron that activates Integer values during training while maintaining spike-driv
    
[^93]: AOTree:基于方面顺序树的模型在可解释推荐中的应用

    AOTree: Aspect Order Tree-based Model for Explainable Recommendation

    [https://arxiv.org/abs/2407.19937](https://arxiv.org/abs/2407.19937)

    AOTree模型通过捕获用户评论中的方面顺序，为可解释的推荐系统提供了一种新的方法。

    

    arXiv:2407.19937v2 公告类型：替换交叉 摘要：推荐系统近年来不仅追求推荐的准确性，还希望提供解释，帮助用户更好地理解。然而，大多数现有的可解释推荐系统只考虑评论中的内容重要性，如词语或方面，忽视了它们之间的关系。这种忽视忽视了人类决策过程中的至关重要的顺序维度，导致性能不佳。因此，本文提出基于方面顺序树的AOTree可解释推荐方法，灵感来源于认知和决策心理学的决定因素依赖理论，旨在捕捉用户决策过程中的依赖关系。我们首先通过分析用户的评论来验证该理论在推荐场景中的有效性。然后，根据该理论，提出的AOTree扩展了决策树的构建，以捕捉用户决策过程中的方面顺序。

    arXiv:2407.19937v2 Announce Type: replace-cross  Abstract: Recent recommender systems aim to provide not only accurate recommendations but also explanations that help users understand them better. However, most existing explainable recommendations only consider the importance of content in reviews, such as words or aspects, and ignore the ordering relationship among them. This oversight neglects crucial ordering dimensions in the human decision-making process, leading to suboptimal performance. Therefore, in this paper, we propose Aspect Order Tree-based (AOTree) explainable recommendation method, inspired by the Order Effects Theory from cognitive and decision psychology, in order to capture the dependency relationships among decisive factors. We first validate the theory in the recommendation scenario by analyzing the reviews of the users. Then, according to the theory, the proposed AOTree expands the construction of the decision tree to capture aspect orders in users' decision-makin
    
[^94]: VersusDebias: 通用的零样本文本到图像模型的基于小语言模型的提示工程和生成对手的偏激消除

    VersusDebias: Universal Zero-Shot Debiasing for Text-to-Image Models via SLM-Based Prompt Engineering and Generative Adversary

    [https://arxiv.org/abs/2407.19524](https://arxiv.org/abs/2407.19524)

    我们提出了一种通用的文本到图像模型偏激消除框架VersusDebias，使用小语言模型和生成对手机制来减少偏激想象的影响，并通过提示工程生成无偏的提示。

    

    arXiv:2407.19524v2 公告类型：替换 摘要：随着文本到图像（T2I）模型的快速发展，人类图像生成中对某些社会群体的偏见越来越受到关注。现有方法仅基于特定模型的固定提示，无法适应T2I模型更新速度快和实际场景中提示多样性的趋势。此外，它们还不能考虑到想象的风险，导致预期结果和实际结果之间存在偏差。为了解决这个问题，我们引入了VersusDebias，这是一个针对T2I模型中偏见的全新且通用的偏激消除框架，它由一个生成对手机制（GAM）和一个使用小语言模型的偏激消除生成机制组成。自适应的GAM为每个提示生成专用的属性数组，以减少T2I模型中想象的影响。SLM使用提示工程为T2I模型生成无偏提示。

    arXiv:2407.19524v2 Announce Type: replace  Abstract: With the rapid development of Text-to-Image models, biases in human image generation against demographic groups social attract more and more concerns. Existing methods are designed based on certain models with fixed prompts, unable to accommodate the trend of high-speed updating of Text-to-Image (T2I) models and variable prompts in practical scenes. Additionally, they fail to consider the possibility of hallucinations, leading to deviations between expected and actual results. To address this issue, we introduce VersusDebias, a novel and universal debiasing framework for biases in T2I models, consisting of one generative adversarial mechanism (GAM) and one debiasing generation mechanism using a small language model (SLM). The self-adaptive GAM generates specialized attribute arrays for each prompts for diminishing the influence of hallucinations from T2I models. The SLM uses prompt engineering to generate debiased prompts for the T2I
    
[^95]: 论文标题

    Integrating Cognitive AI with Generative Models for Enhanced Question Answering in Skill-based Learning

    [https://arxiv.org/abs/2407.19393](https://arxiv.org/abs/2407.19393)

    这里是中文总结出的一句话要点

    

    论文摘要

    arXiv:2407.19393v2 Announce Type: replace  Abstract: In online learning, the ability to provide quick and accurate feedback to learners is crucial. In skill-based learning, learners need to understand the underlying concepts and mechanisms of a skill to be able to apply it effectively. While videos are a common tool in online learning, they cannot comprehend or assess the skills being taught. Additionally, while Generative AI methods are effective in searching and retrieving answers from a text corpus, it remains unclear whether these methods exhibit any true understanding. This limits their ability to provide explanations of skills or help with problem-solving. This paper proposes a novel approach that merges Cognitive AI and Generative AI to address these challenges. We employ a structured knowledge representation, the TMK (Task-Method-Knowledge) model, to encode skills taught in an online Knowledge-based AI course. Leveraging techniques such as Large Language Models, Chain-of-Though
    
[^96]: 更真实的旅行日记生成：使用LLM代理和个性化个人资料

    Be More Real: Travel Diary Generation Using LLM Agents and Individual Profiles

    [https://arxiv.org/abs/2407.18932](https://arxiv.org/abs/2407.18932)

    该研究引入了一种基于LLM代理的工作框架，通过提取个体的流动性模式和推理生成轨迹，实现了更真实的城市级旅行日记生成，并考虑了不同的个人特征。

    

    arXiv:2407.18932v2 Announce Type: 替换交叉

    arXiv:2407.18932v2 Announce Type: replace-cross  Abstract: Human mobility is inextricably linked to social issues such as traffic congestion, energy consumption, and public health; however, privacy concerns restrict access to mobility data. Recently, research have utilized Large Language Models (LLMs) for human mobility generation, in which the challenge is how LLMs can understand individuals' mobility behavioral differences to generate realistic trajectories conforming to real world contexts. This study handles this problem by presenting an LLM agent-based framework (MobAgent) composing two phases: understanding-based mobility pattern extraction and reasoning-based trajectory generation, which enables generate more real travel diaries at urban scale, considering different individual profiles. MobAgent extracts reasons behind specific mobility trendiness and attribute influences to provide reliable patterns; infers the relationships between contextual factors and underlying motivations
    
[^97]: PP-TIL：基于实例转移模仿学习的自主驾驶个性化规划

    PP-TIL: Personalized Planning for Autonomous Driving with Instance-based Transfer Imitation Learning

    [https://arxiv.org/abs/2407.18569](https://arxiv.org/abs/2407.18569)

    该方法通过结合模仿学习和深度强化学习，提高个性化驾驶规划的性能，尤其是在大量数据支持和泛化能力方面。

    

    arXiv:2407.18569v3 预告类型：替换  摘要：在城市自动化驾驶中，个性化运动规划具有重要意义，它能够满足个体用户的独特需求。然而，以往的努力经常在同时解决两个关键方面时遇到困难：在复杂的都市环境中进行个性化的规划，以及通过数据利用来提高规划性能。问题的根源在于用户数据的昂贵和有限性，以及场景状态空间趋向无穷大的因素，这些因素导致模型训练时出现过拟合和泛化能力差的问题。因此，我们提出了基于实例的转移模仿学习方法。这种方法通过从广泛的专家领域数据向用户领域进行知识转移，从根本上解决了这些问题。我们首先使用大规模的专家数据对预训练模型进行训练。然后，在用户数据上进行精细调整。我们的方法结合了模仿学习和深度强化学习的方法，并且通过实例级匹配和策略追踪来提高性能。在多个市内驾驶仿真环境中进行详细评估后，结果表明，我们的 PP-TIL 方法在提高规划效率和适应性方面取得了显著的改进，同时在大规模多用户数据集上显示出良好的泛化能力。

    arXiv:2407.18569v3 Announce Type: replace  Abstract: Personalized motion planning holds significant importance within urban automated driving, catering to the unique requirements of individual users. Nevertheless, prior endeavors have frequently encountered difficulties in simultaneously addressing two crucial aspects: personalized planning within intricate urban settings and enhancing planning performance through data utilization. The challenge arises from the expensive and limited nature of user data, coupled with the scene state space tending towards infinity. These factors contribute to overfitting and poor generalization problems during model training. Henceforth, we propose an instance-based transfer imitation learning approach. This method facilitates knowledge transfer from extensive expert domain data to the user domain, presenting a fundamental resolution to these issues. We initially train a pre-trained model using large-scale expert data. Subsequently, during the fine-tunin
    
[^98]: 自动解释选择对于科学发现的论文

    Automated Explanation Selection for Scientific Discovery

    [https://arxiv.org/abs/2407.17454](https://arxiv.org/abs/2407.17454)

    这篇论文提出了一种结合机器学习和自动化推理的科学发现循环，用于生成和选择解释，并引入了新的解释选择标准。

    

    arXiv:2407.17454v2 公告类型: 替换 摘要: 自动化推理是年轻但迅速成长的解释性人工智能(XAI)领域的一个关键技术。解释性帮助在人工智能系统的可信度上超越它们的预测准确性和稳健性。在本文中，我们提出了一种结合机器学习和自动化推理的科学发现循环，用于生成和选择解释。我们提出了一种解释选择问题的分类，它吸取了社会学和认知科学的洞见。这些选择标准包含现有的概念，并扩展了新的属性。

    arXiv:2407.17454v2 Announce Type: replace  Abstract: Automated reasoning is a key technology in the young but rapidly growing field of Explainable Artificial Intelligence (XAI). Explanability helps build trust in artificial intelligence systems beyond their mere predictive accuracy and robustness. In this paper, we propose a cycle of scientific discovery that combines machine learning with automated reasoning for the generation and the selection of explanations. We present a taxonomy of explanation selection problems that draws on insights from sociology and cognitive science. These selection criteria subsume existing notions and extend them with new properties.
    
[^99]: 利用语义单元分析多义性进化

    Analyzing the Polysemy Evolution using Semantic Cells

    [https://arxiv.org/abs/2407.16110](https://arxiv.org/abs/2407.16110)

    本文通过分析“春天”一词在不同语境中的4种含义，揭示了词汇多义性的演化是由语义单元的修改所引起的，并且这一过程是随时间逐渐发生的。

    

    arXiv:2407.16110v2 公告类型：替换-交叉 摘要：词义会随时间发展而演变。同一天不同时间对同一个词的理解可能不同，同一个词的不同意义可能是相互演化的结果，即它们可能是父母和子女关系。如果我们把Juba看作一个不断发展的生态系统，学习正确答案的模式，如果不随词义的变化而变化，那就不再有效了。本文采取了一个案例研究，展示了由作者提出并引入了一些初始状态多样性的小变化，分析了用Chat GPT收集的四个不同意义的句子集合，即春天的含义。特别的是，对包含1000个句子的序列进行排序分析，每个序列都是对“春天”一词的不同意义的句子，结果显示，当按顺序排列这些词义时，在分析中，“春天”一词的多义性随时间而逐渐增加。

    arXiv:2407.16110v2 Announce Type: replace-cross  Abstract: The senses of words evolve. The sense of the same word may change from today to tomorrow, and multiple senses of the same word may be the result of the evolution of each other, that is, they may be parents and children. If we view Juba as an evolving ecosystem, the paradigm of learning the correct answer, which does not move with the sense of a word, is no longer valid. This paper is a case study that shows that word polysemy is an evolutionary consequence of the modification of Semantic Cells, which has al-ready been presented by the author, by introducing a small amount of diversity in its initial state as an example of analyzing the current set of short sentences. In particular, the analysis of a sentence sequence of 1000 sentences in some order for each of the four senses of the word Spring, collected using Chat GPT, shows that the word acquires the most polysemy monotonically in the analysis when the senses are arranged in
    
[^100]: 多模态知识增强的全切片病理学基础模型

    A Multimodal Knowledge-enhanced Whole-slide Pathology Foundation Model

    [https://arxiv.org/abs/2407.15362](https://arxiv.org/abs/2407.15362)

    文章提出了一种全新的网络结构，通过整合病理切片图像、病理报告和基因表达谱的多模态数据，训练出一个能够理解病理切片全局特征的模型，并在多种下游任务上取得了优于单一模态模型的性能。

    

    arXiv:2407.15362v2 宣布类型：替换交叉  翻译：在任务无关的基础模型领域取得了显著的进步，该模型提高了多种下游临床任务的性能。尽管性能显著，但仍存在一些挑战。首先，先前的工作要么依赖于仅视觉数据，要么依赖于视觉-描述数据，而忽略了对于多种临床应用至关重要的病理报告和基因表达谱。其次，目前病理FM的进展主要集中在切片级，其中切片级预训练的有限上下文未能捕捉全切片模式。我们 curated 了包含最大数量的 H\&E 诊断全切片图像和相关病理报告和 RNA-Seq 数据的多元模态数据集，总共得到了 26,169 个来自 10,275 名患者和 32 种癌症类型的 slide-level 模态对。为了利用这些数据进行癌症病理学的研究，我们提出了一个全新的网络结构，该结构可以同时学习全切片图像的高级纹理特征和病理报告中的文本知识。通过这种多模态的预训练，我们的模型能够更好地理解病理切片的全局特征，并且在多种下游任务上取得了优于单一模态预训练模型的性能。

    arXiv:2407.15362v2 Announce Type: replace-cross  Abstract: Remarkable strides in computational pathology have been made in the task-agnostic foundation model that advances the performance of a wide array of downstream clinical tasks. Despite the promising performance, there are still several challenges. First, prior works have resorted to either vision-only or vision-captions data, disregarding invaluable pathology reports and gene expression profiles which respectively offer distinct knowledge for versatile clinical applications. Second, the current progress in pathology FMs predominantly concentrates on the patch level, where the restricted context of patch-level pretraining fails to capture whole-slide patterns. Here we curated the largest multimodal dataset consisting of H\&E diagnostic whole slide images and their associated pathology reports and RNA-Seq data, resulting in 26,169 slide-level modality pairs from 10,275 patients across 32 cancer types. To leverage these data for CPa
    
[^101]: Think-on-Graph 2.0: 一种基于深度和可解释的知识图引导检索的大型语言模型推理方法

    Think-on-Graph 2.0: Deep and Interpretable Large Language Model Reasoning with Knowledge Graph-guided Retrieval

    [https://arxiv.org/abs/2407.10805](https://arxiv.org/abs/2407.10805)

    Think-on-Graph 2.0 是一种改进的 RAG 框架，通过将问题与知识图对齐，促进深度推理和提高 LLM 结果的准确性和可靠性。

    

    arXiv:2407.10805v2 公告类型: 替换交叉  翻译摘要: 基于检索的生成(RAG)方法通过允许动态的信息检索来显著改进大型语言模型(LLMs)，以此来解决生成内容知识鸿沟和幻觉的问题。然而，这些系统在处理复杂的推理和跨多样题的一致性方面往往表现不佳。在本文中，我们介绍了一个增强的RAG框架，Think-on-Graph 2.0，它将问题与知识图对齐并将知识图作为一种导航工具，加深并改进了RAG模式的信息收集和集成。基于知识图的导航促进了深层和长距离的关联，以保持逻辑一致性和优化检索的准确性和互操作性。同时，通过精确的指令指导的语义相似性，可以更好地确保事实一致性。ToG${2.0}$不仅提高了LLMs响应的准确性和可靠性，还展示了在确保语义对话上下文精准性方面的潜力。

    arXiv:2407.10805v2 Announce Type: replace-cross  Abstract: Retrieval-augmented generation (RAG) has significantly advanced large language models (LLMs) by enabling dynamic information retrieval to mitigate knowledge gaps and hallucinations in generated content. However, these systems often falter with complex reasoning and consistency across diverse queries. In this work, we present Think-on-Graph 2.0, an enhanced RAG framework that aligns questions with the knowledge graph and uses it as a navigational tool, which deepens and refines the RAG paradigm for information collection and integration. The KG-guided navigation fosters deep and long-range associations to uphold logical consistency and optimize the scope of retrieval for precision and interoperability. In conjunction, factual consistency can be better ensured through semantic similarity guided by precise directives. ToG${2.0}$ not only improves the accuracy and reliability of LLMs' responses but also demonstrates the potential o
    
[^102]: ISMRNN：带有Mamba的隐式分割RNN方法，用于长时期时间序列预测

    ISMRNN: An Implicitly Segmented RNN Method with Mamba for Long-Term Time Series Forecasting

    [https://arxiv.org/abs/2407.10768](https://arxiv.org/abs/2407.10768)

    本文提出了一种改进的RNN模型ISMRNN，通过隐式分割和时间序列特异性Mamba解码器的结合，有效解决了传统RNN模型在处理长期依赖和信息丢失方面的局限性，提高了长时期时间序列预测的性能，尤其是在股票价格、比特币价格和能源消耗等数据集上的长期预测方面。

    

    arXiv:2407.10768v5 宣布类型：替换交叉

    arXiv:2407.10768v5 Announce Type: replace-cross  Abstract: Long time series forecasting aims to utilize historical information to forecast future states over extended horizons. Traditional RNN-based series forecasting methods struggle to effectively address long-term dependencies and gradient issues in long time series problems. Recently, SegRNN has emerged as a leading RNN-based model tailored for long-term series forecasting, demonstrating state-of-the-art performance while maintaining a streamlined architecture through innovative segmentation and parallel decoding techniques. Nevertheless, SegRNN has several limitations: its fixed segmentation disrupts data continuity and fails to effectively leverage information across different segments, the segmentation strategy employed by SegRNN does not fundamentally address the issue of information loss within the recurrent structure. To address these issues, we propose the ISMRNN method with three key enhancements: we introduce an implicit s
    
[^103]: 预测和理解人类行为决策：基于大型语言模型和认知实例学习的新见解

    Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning

    [https://arxiv.org/abs/2407.09281](https://arxiv.org/abs/2407.09281)

    本文通过比较大型语言模型与认知实例学习模型在预测人类行为决策方面的表现，发现大型语言模型在快速适应反馈方面表现出色，而认知实例学习模型则在处理延迟反馈方面更为有效。

    

    arXiv:2407.09281v2 宣布类型：替换 摘要：大型语言模型（LLMs）在各种任务中展示了自己的能力，包括语言翻译和复杂的推理。部署人工智能（AI）辅助系统提供有用的帮助之前，理解并预测人类行为和偏见至关重要，但这仍然是一个有待解决的问题。本文通过利用LLMs的推理和生成能力，预测人们在两个连续的决策任务中的行为。这些任务涉及在 exploitative（探索性）和 exploratory（经验性）行动之间取得平衡，处理延迟反馈，这些都是模拟现实生活决策过程的要素。我们比较了LLMs与一种认知实例学习（IBL）模型的表现，后者模仿了人类经验性的决策制定。我们的发现表明，LLMs在迅速整合反馈以提高预测准确性方面表现出色。相比之下，认知IBL模型在延迟反馈的适应上表现更佳。

    arXiv:2407.09281v2 Announce Type: replace  Abstract: Large Language Models (LLMs) have demonstrated their capabilities across various tasks, from language translation to complex reasoning. Understanding and predicting human behavior and biases are crucial for artificial intelligence (AI) assisted systems to provide useful assistance, yet it remains an open question whether these models can achieve this. This paper addresses this gap by leveraging the reasoning and generative capabilities of the LLMs to predict human behavior in two sequential decision-making tasks. These tasks involve balancing between exploitative and exploratory actions and handling delayed feedback, both essential for simulating real-life decision processes. We compare the performance of LLMs with a cognitive instance-based learning (IBL) model, which imitates human experiential decision-making. Our findings indicate that LLMs excel at rapidly incorporating feedback to enhance prediction accuracy. In contrast, the c
    
[^104]: 数据与多模态大型语言模型协同演进的调查研究

    The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective

    [https://arxiv.org/abs/2407.08583](https://arxiv.org/abs/2407.08583)

    论文讨论了多模态大型语言模型与数据协同发展的关系，表明两者在模型性能和数据质量提升中起到相互促进的作用。

    

    arXiv:2407.08583v2 通告类型：替换交叉

    arXiv:2407.08583v2 Announce Type: replace-cross  Abstract: The rapid development of large language models (LLMs) has been witnessed in recent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the modality from text to a broader spectrum of domains, attracting widespread attention due to the broader range of application scenarios. As LLMs and MLLMs rely on vast amounts of model parameters and data to achieve emergent capabilities, the importance of data is receiving increasingly widespread attention and recognition. Tracing and analyzing recent data-oriented works for MLLMs, we find that the development of models and data is not two separate paths but rather interconnected. On the one hand, vaster and higher-quality data contribute to better performance of MLLMs; on the other hand, MLLMs can facilitate the development of data. The co-development of multi-modal data and MLLMs requires a clear view of 1) at which development stages of MLLMs specific data-centric approache
    
[^105]: 标题：平滑性与逼近之间的桥梁：图神经网络中过度平滑的理论上洞察

    Bridging Smoothness and Approximation: Theoretical Insights into Over-Smoothing in Graph Neural Networks

    [https://arxiv.org/abs/2407.01281](https://arxiv.org/abs/2407.01281)

    这项研究通过建立理论框架评估了图卷积网络逼近目标函数的限度，揭示了过度平滑现象的本质，并提出了新的视角来理解该问题。

    

    摘要：在这项研究中，我们探索了定义在图上函数的逼近理论。我们的研究建立在从$K$函数性导出的逼近结果的基础上。我们建立了一个理论框架，来评估目标函数使用图卷积网络（GCN）逼近的下界，并考察这些网络中常见的过度平滑现象。首先，我们对图上的$K$函数性进行了介绍，并建立了它与模光滑性之间的等价性。随后，我们分析了一种典型的GCN类型，展示了输出中高频能量的衰减，这表明了过度平滑的现象。这项分析为GCN中过度平滑的本质提供了理论见解。此外，我们还建立了目标函数由GCNs逼近的下界，这个下界是由这些函数的模光滑性支配的。这一发现为理解GCN中过度平滑的问题提供了新的视角。

    arXiv:2407.01281v2 Announce Type: replace-cross  Abstract: In this paper, we explore the approximation theory of functions defined on graphs. Our study builds upon the approximation results derived from the $K$-functional. We establish a theoretical framework to assess the lower bounds of approximation for target functions using Graph Convolutional Networks (GCNs) and examine the over-smoothing phenomenon commonly observed in these networks. Initially, we introduce the concept of a $K$-functional on graphs, establishing its equivalence to the modulus of smoothness. We then analyze a typical type of GCN to demonstrate how the high-frequency energy of the output decays, an indicator of over-smoothing. This analysis provides theoretical insights into the nature of over-smoothing within GCNs. Furthermore, we establish a lower bound for the approximation of target functions by GCNs, which is governed by the modulus of smoothness of these functions. This finding offers a new perspective on t
    
[^106]: 中文翻译的论文标题

    Investigating and Mitigating the Multimodal Hallucination Snowballing in Large Vision-Language Models

    [https://arxiv.org/abs/2407.00569](https://arxiv.org/abs/2407.00569)

    中文摘要提炼的要点

    

    中文翻译的论文摘要

    arXiv:2407.00569v4 Announce Type: replace-cross  Abstract: Though advanced in understanding visual information with human languages, Large Vision-Language Models (LVLMs) still suffer from multimodal hallucinations. A natural concern is that during multimodal interaction, the generated hallucinations could influence the LVLMs' subsequent generation. Thus, we raise a question: When presented with a query relevant to the previously generated hallucination, will LVLMs be misled and respond incorrectly, even though the ground visual information exists? To answer this, we propose a framework called MMHalSnowball to evaluate LVLMs' behaviors when encountering generated hallucinations, where LVLMs are required to answer specific visual questions within a curated hallucinatory conversation. Crucially, our experiment shows that the performance of open-source LVLMs drops by at least $31\%$, indicating that LVLMs are prone to accept the generated hallucinations and make false claims that they woul
    
[^107]: InterCLIP-MEP：交互式CLIP和增强记忆预测器在多模态 sarcasm 检测中的应用

    InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection

    [https://arxiv.org/abs/2406.16464](https://arxiv.org/abs/2406.16464)

    InterCLIP-MEP 框架使用交互式 CLIP 和增强的记忆预测器改进了对社交媒体上多模态 sarcasm 的检测效果。

    

    arXiv:2406.16464v3 公告类型：替换交叉 摘要：社交媒体上 sarcasm 的普遍存在，通过文字和图像的组合表达，为情感分析和意图挖掘带来了巨大挑战。现有的多模态 sarcasm 检测方法已经证明存在高估性能的问题，因为它们很难有效地捕捉到文字和图像之间互动产生的精细 sarcastic 线索。为了解决这些问题，我们提出了 InterCLIP-MEP，一个用于多模态 sarcasm 检测的全新框架。特别是，我们引入了交互式 CLIP（InterCLIP）作为骨干，提取文字图像表示，通过在每个编码器中直接嵌入跨模态信息，从而改善了表示，更好地捕捉文字和图像之间的互动。此外，我们还设计了一种有效的培训策略，为了适应我们提出的增强记忆预测器（MEP）调整InterCLIP。MEP使用一个动态的、固定长度的双通道记忆系统来增强对 sarcasm 的检测，并且准确率大幅度提升。

    arXiv:2406.16464v3 Announce Type: replace-cross  Abstract: The prevalence of sarcasm in social media, conveyed through text-image combinations, presents significant challenges for sentiment analysis and intention mining. Existing multi-modal sarcasm detection methods have been proven to overestimate performance, as they struggle to effectively capture the intricate sarcastic cues that arise from the interaction between an image and text. To address these issues, we propose InterCLIP-MEP, a novel framework for multi-modal sarcasm detection. Specifically, we introduce an Interactive CLIP (InterCLIP) as the backbone to extract text-image representations, enhancing them by embedding cross-modality information directly within each encoder, thereby improving the representations to capture text-image interactions better. Furthermore, an efficient training strategy is designed to adapt InterCLIP for our proposed Memory-Enhanced Predictor (MEP). MEP uses a dynamic, fixed-length dual-channel mem
    
[^108]: 我们应该微调还是RAG？评估不同适应LLM对话的技巧

    Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue

    [https://arxiv.org/abs/2406.06399](https://arxiv.org/abs/2406.06399)

    文章研究了大型语言模型在对话生成任务中的局限性，对比了在context学习与微调等不同适应技术在不同对话类型中的性能差异。

    

    arXiv:2406.06399v3 声明类型：替换交叉摘要：我们研究了大型语言模型（LLM）在人类机器对话中响应生成任务的局限性。在文献中，对于不同类型的对话（例如开放域对话）已经提出了多种技术。然而，这些技术的评价在基础LLM、对话类型和评价指标方面都受到了限制。在这项工作中，我们对不同的LLM适应技术进行了广泛分析，这些技术在应用于不同类型的对话时进行了应用。我们选择了两个基础LLM，即Llama-2和Mistral，以及四种对话类型：开放域对话、知识赋能对话、任务导向对话和问答对话。我们在每个对话类型的特定数据集上评估了适用于in-context学习的内部知识集成技术。我们在评估和探索各种可能性的同时，使用了一致性评估和探索策略。

    arXiv:2406.06399v3 Announce Type: replace-cross  Abstract: We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and expl
    
[^109]: 观点指导的强化学习

    Opinion-Guided Reinforcement Learning

    [https://arxiv.org/abs/2405.17287](https://arxiv.org/abs/2405.17287)

    本文提出了一种通过观点指导强化学习的方法，通过模型的提供者，我们可以更有效的优化强化学习代理在不同的环境和不确定性条件下的表现，同时对于在人工和人类指导下的经济效率都取得了积极的结果。

    

    arXiv:2405.17287v2 宣布类型：替换交叉  翻译摘要：在强化学习中，人类指导往往能够提升学习代理的性能。然而，人类指导通常是基于不完全的信息和猜测，而不是系统的论证。虽然这些指导有一定的不确定性，例如由于对问题的部分了解或一无所知而引起，但它们也会比可以得到的硬证据早出现。因此，通过观点指导强化学习代理，有可能实现更有效的学习过程，但也带来了对观点进行建模和管理的问题。本文介绍了一种通过观点指导强化学习代理的方法。为此，我们提供了一个端到端的方法来管理和建模顾问的指导。为此，我们评估了在不同水平的不确定性下，通过多种建议策略，与合成（或acle）和人类顾问的实用性。我们的方法在多个环境下展示了对不同质量和不确定性的指导的不依赖性，并能够提高强化学习代理的性能。同时，方法在经济效率方面也表现出色，在合成顾问条件下，可以避免高达90%的人工决策，而在人类顾问条件下也能够缩小决策的错误率。

    arXiv:2405.17287v2 Announce Type: replace-cross  Abstract: Human guidance is often desired in reinforcement learning to improve the performance of the learning agent. However, human insights are often mere opinions and educated guesses rather than well-formulated arguments. While opinions are subject to uncertainty, e.g., due to partial informedness or ignorance about a problem, they also emerge earlier than hard evidence can be produced. Thus, guiding reinforcement learning agents by way of opinions offers the potential for more performant learning processes, but comes with the challenge of modeling and managing opinions in a formal way. In this article, we present a method to guide reinforcement learning agents through opinions. To this end, we provide an end-to-end method to model and manage advisors' opinions. To assess the utility of the approach, we evaluate it with synthetic (oracle) and human advisors, at different levels of uncertainty, and under multiple advice strategies. Ou
    
[^110]: 双重动态ISAC预编码方法在车载网络中的应用：一种约束下的深度强化学习（CDRL）策略

    Doubly-Dynamic ISAC Precoding for Vehicular Networks: A Constrained Deep Reinforcement Learning (CDRL) Approach

    [https://arxiv.org/abs/2405.14347](https://arxiv.org/abs/2405.14347)

    本文提出了一种基于约束深度强化学习的双重动态ISAC预编码策略，旨在提高车载网络中的通信效率，尤其是在动态变化的环境中。

    

    arXiv:2405.14347v2 宣布类型：替换交叉 摘要：集成感知与通信（ISAC）技术对于实现车载网络至关重要。然而，在这种场景中，通信信道表现出动态变化的特点，潜在的目标可能会迅速移动，产生一种双重动态现象。这种特性为实时预编码器设计和实施带来了挑战。尽管基于优化的解决方案得到了广泛的研究，但这些方法复杂且严重依赖于不切实际的完全预先信息。为了解决这一挑战，我们提出使用约束下的深度强化学习（CDRL）策略，以实现在ISAC预编码器设计中的动态更新。此外，我们还将为PD-DDPG双深度确定性策略梯度和Wolpertinger架构作出特别设计，以便在复杂约束和用户数量可变的情况下有效训练该算法。我们提出的方案不仅可以基于观察到的现象进行适应，还能够提升车载网络的性能，并在不确定性和动态变化的环境中保持较高的传输速率。

    arXiv:2405.14347v2 Announce Type: replace-cross  Abstract: Integrated sensing and communication (ISAC) technology is essential for enabling the vehicular networks. However, the communication channel in this scenario exhibits time-varying characteristics, and the potential targets may move rapidly, creating a doubly-dynamic phenomenon. This nature poses a challenge for real-time precoder design. While optimization-based solutions are widely researched, they are complex and heavily rely on perfect prior information, which is impractical in double dynamics. To address this challenge, we propose using constrained deep reinforcement learning (CDRL) to facilitate dynamic updates to the ISAC precoder design. Additionally, the primal dual-deep deterministic policy gradient (PD-DDPG) and Wolpertinger architecture are tailored to efficiently train the algorithm under complex constraints and variable numbers of users. The proposed scheme not only adapts to the dynamics based on observations but a
    
[^111]: VR-GPT：用于智能虚拟现实应用的视觉语言模型

    VR-GPT: Visual Language Model for Intelligent Virtual Reality Applications

    [https://arxiv.org/abs/2405.11537](https://arxiv.org/abs/2405.11537)

    文章提出了一种将视觉语言模型应用在VR环境中来提升用户交互和任务效率的创新方法，通过unity引擎和自研的VLM，实现了无需视觉文本指令的实时、直观用户交互。使用语音识别和文本转语音技术，有效提升了用户完成复杂任务的效率和舒适度。

    

    arXiv:2405.11537v3 公告类型：替换

    arXiv:2405.11537v3 Announce Type: replace  Abstract: The advent of immersive Virtual Reality applications has transformed various domains, yet their integration with advanced artificial intelligence technologies like Visual Language Models remains underexplored. This study introduces a pioneering approach utilizing VLMs within VR environments to enhance user interaction and task efficiency. Leveraging the Unity engine and a custom-developed VLM, our system facilitates real-time, intuitive user interactions through natural language processing, without relying on visual text instructions. The incorporation of speech-to-text and text-to-speech technologies allows for seamless communication between the user and the VLM, enabling the system to guide users through complex tasks effectively. Preliminary experimental results indicate that utilizing VLMs not only reduces task completion times but also improves user comfort and task engagement compared to traditional VR interaction methods.
    
[^112]: 基于对话模型的新型同情境学习方法，用于数据提取和材料属性预测

    Dynamic In-context Learning with Conversational Models for Data Extraction and Materials Property Prediction

    [https://arxiv.org/abs/2405.10448](https://arxiv.org/abs/2405.10448)

    此工具是一种结合了对话型大型语言模型的开源提取工具，能够高效、准确地从科学文献中提取材料属性数据，已经在二维材料的厚度等关键参数上取得了超过95%的性能。

    

    为了解决科学文献中结构化信息提取的准确性问题，我们提出了一种名为PropertyExtractor的开源工具。该工具利用高级对话型大型语言模型（如Google的gemini-pro和OpenAI的gpt-4），结合零样本和少样本同情境学习，以及旨在动态细化信息层次结构的工程化提示信息，实现材料属性数据的自动、高效、可扩展和准确的识别、提取和验证。对材料数据进行的测试显示，该工具的精确率和召回率超过95%，误差率约为9%，验证了工具的有效性和灵活性。该工具的数据库包括二维材料厚度的关键参数，用于设备集成，以及能量电池材料的电位数据。

    arXiv:2405.10448v2 Announce Type: replace-cross  Abstract: The advent of natural language processing and large language models (LLMs) has revolutionized the extraction of data from unstructured scholarly papers. However, ensuring data trustworthiness remains a significant challenge. In this paper, we introduce PropertyExtractor, an open-source tool that leverages advanced conversational LLMs like Google gemini-pro and OpenAI gpt-4, blends zero-shot with few-shot in-context learning, and employs engineered prompts for the dynamic refinement of structured information hierarchies - enabling autonomous, efficient, scalable, and accurate identification, extraction, and verification of material property data. Our tests on material data demonstrate precision and recall that exceed 95\% with an error rate of approximately 9%, highlighting the effectiveness and versatility of the toolkit. Finally, databases for 2D material thicknesses, a critical parameter for device integration, and energy ban
    
[^113]: 扩展视野：为长尾胸部X线分类启用混合量子迁移学习

    Expanding the Horizon: Enabling Hybrid Quantum Transfer Learning for Long-Tailed Chest X-Ray Classification

    [https://arxiv.org/abs/2405.00156](https://arxiv.org/abs/2405.00156)

    利用Jax框架加速量子模拟，适用于长尾胸部X线多标签分类的高效混合量子迁移学习。

    

    arXiv:2405.00156v2 公告类型：替换交叉  翻译：量子机器学习（QML）在大型胸部X线（CXR）数据集中提高罕见但关键疾病的多标签分类能力方面具有理论上的优势，这得益于它相对于经典机器学习（CML）在样本效率和泛化能力方面的量子优势。虽然先前文献已经在小数据集上探索了QML在二分类任务中的应用，但由于对量子硬件的访问限制和计算上的昂贵模拟，它主要集中在有限的CXRs上。为此，我们实现了基于Jax的框架，该框架能够以对当前软件提供者有显著改进的方式在具有较大量子比特架构的模拟上进行模拟。我们评估了基于Jax的框架在效率和对于长尾分类的混合量子迁移学习方面的性能，该框架在具有8、14和19种疾病标签的大型CXR数据集上得到了测试。基于Jax的框架：性能更好，能够加速量子模拟，有利于长尾胸部X线分类的多标签学习。

    arXiv:2405.00156v2 Announce Type: replace-cross  Abstract: Quantum machine learning (QML) has the potential for improving the multi-label classification of rare, albeit critical, diseases in large-scale chest x-ray (CXR) datasets due to theoretical quantum advantages over classical machine learning (CML) in sample efficiency and generalizability. While prior literature has explored QML with CXRs, it has focused on binary classification tasks with small datasets due to limited access to quantum hardware and computationally expensive simulations. To that end, we implemented a Jax-based framework that enables the simulation of medium-sized qubit architectures with significant improvements in wall-clock time over current software offerings. We evaluated the performance of our Jax-based framework in terms of efficiency and performance for hybrid quantum transfer learning for long-tailed classification across 8, 14, and 19 disease labels using large-scale CXR datasets. The Jax-based framewor
    
[^114]: N多代理随机团队协作

    N-Agent Ad Hoc Teamwork

    [https://arxiv.org/abs/2404.10740](https://arxiv.org/abs/2404.10740)

    该论文研究了在动态变化队友数量和类型的环境中，N个自治代理如何进行合作的问题，并提出了相应的理论和算法以解决这一挑战。

    

    arXiv:2404.10740v2 公告类型：替换 摘要：当前学习合作多代理行为的方法假设相对限制性的设置。在标准完全合作多代理强化学习中，学习算法控制场景中的所有代理，而在随机团队工作中，学习算法通常假设只控制场景中单个代理。然而，现实世界中的许多合作情形远不那么严格。例如，在自动驾驶场景中，一家公司可能用相同的学习算法训练其车辆，但一旦上路，这些车辆必须与另一家公司车辆合作。为了扩展可以优化地处理合作学习方法的场景类别，我们引入了N代理随机团队工作（NAHT），其中一组自治代理必须与具有动态变化数量的动态类型队友互动并合作。本文正式表述了这一问题，并提出了一系列的理论和算法来解决这一挑战。

    arXiv:2404.10740v2 Announce Type: replace  Abstract: Current approaches to learning cooperative multi-agent behaviors assume relatively restrictive settings. In standard fully cooperative multi-agent reinforcement learning, the learning algorithm controls $\textit{all}$ agents in the scenario, while in ad hoc teamwork, the learning algorithm usually assumes control over only a $\textit{single}$ agent in the scenario. However, many cooperative settings in the real world are much less restrictive. For example, in an autonomous driving scenario, a company might train its cars with the same learning algorithm, yet once on the road, these cars must cooperate with cars from another company. Towards expanding the class of scenarios that cooperative learning methods may optimally address, we introduce $N$-agent ad hoc teamwork (NAHT), where a set of autonomous agents must interact and cooperate with dynamically varying numbers and types of teammates. This paper formalizes the problem, and prop
    
[^115]: 开放偏见：文本到图像生成模型中的开放集偏差检测

    OpenBias: Open-set Bias Detection in Text-to-Image Generative Models

    [https://arxiv.org/abs/2404.07990](https://arxiv.org/abs/2404.07990)

    本文提出OpenBias，一个检测文本到图像生成模型中开放集偏见的系统，无需预先定义的偏差集合，利用大型语言模型和视觉问答模型来识别和量化这些模型可能存在的偏差，解决了现有方法无法处理开放集偏差的问题，提供定量证据。

    

    arXiv:2404.07990v2 公告类型：替换  摘要：文本到图像生成模型正变得越来越受欢迎，并且对普通大众越来越可访问。随着这些模型的大规模部署，深入探究它们的稳定性和公平性变得至关重要，以避免传播和延续任何类型的偏见。然而，现有的工作集中在检测预先定义的有限集偏差，限制研究局限于众所周知的概念。在本文中，我们挑战文本到图像生成模型中的开放集偏差检测问题，提出OpenBias，一个新的管道，可以在没有访问任何预编译集合的情况下识别和量化偏见的严重性。OpenBias由三个阶段组成。在第一个阶段，我们利用大型语言模型（LLM）基于一组提示提出偏差。其次，目标生成模型使用相同的提示集生成图像。最后，一个视觉问答模型识别先前提议偏差的程度。我们对11个类别的自然语言描述（包括“人种”、“性别”和“经济状态”）进行实验，证明了OpenBias能够检测模型生成的图像中的开放集偏差。我们的方法不仅解决了现有工作无法处理的开放集问题，而且能够提供有关模型中实际存在的偏见的定量证据。

    arXiv:2404.07990v2 Announce Type: replace  Abstract: Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previou
    
[^116]: 使用可泛化高斯点积的强化学习

    Reinforcement Learning with Generalizable Gaussian Splatting

    [https://arxiv.org/abs/2404.07950](https://arxiv.org/abs/2404.07950)

    我们提出了一种基于可泛化高斯点积的强化学习方法，该方法在不同的环境中提供了更清晰和泛化的场景表示，并通过直接使用形状函数和概率分布去除了“黑箱”效应，使得方法更易于理解和可视化。

    

    arXiv:2404.07950v2 公告类型：替换 摘要：在基于视觉的强化学习任务中，优秀的数据表示至关重要。环境表示的质量直接影响了学习任务的成功。以往的基于视觉的强化学习通常使用显式或隐式的方法来表示环境，如图像、点、体素和神经辐射场。然而，这些表示方法存在若干缺点。它们要么无法描述复杂的局部几何，要么在从未见过的新场景中泛化能力差，或者需要精确的背景遮罩。此外，这些隐式的神经表示就像是一个“黑箱”，严重阻碍了可解释性。与传统的隐式神经表示方法相比，3D高斯点积(3DGS)作为一种显式的场景表示和可微的渲染方法，被认为是对重排和表示方法的一种革命性改变。在本文中，我们提出了一种新颖的可泛化高斯点积方法的强化学习。这种方法能够提供更清晰的场景描述，并且在不同的环境中表现出优异的泛化能力。更重要的是，我们的方法通过直接使用形状函数和概率分布来表示场景，使得所提出的方法易于理解和去“黑箱”，从而可以为强化学习任务提供更深入的见解。

    arXiv:2404.07950v2 Announce Type: replace  Abstract: An excellent representation is crucial for reinforcement learning (RL) performance, especially in vision-based reinforcement learning tasks. The quality of the environment representation directly influences the achievement of the learning task. Previous vision-based RL typically uses explicit or implicit ways to represent environments, such as images, points, voxels, and neural radiance fields. However, these representations contain several drawbacks. They cannot either describe complex local geometries or generalize well to unseen scenes, or require precise foreground masks. Moreover, these implicit neural representations are akin to a ``black box", significantly hindering interpretability. 3D Gaussian Splatting (3DGS), with its explicit scene representation and differentiable rendering nature, is considered a revolutionary change for reconstruction and representation methods. In this paper, we propose a novel Generalizable Gaussian
    
[^117]: 混合RAG：通过语义搜索和混合查询基础检索器提高RAG准确性

    Blended RAG: Improving RAG (Retriever-Augmented Generation) Accuracy with Semantic Search and Hybrid Query-Based Retrievers

    [https://arxiv.org/abs/2404.07220](https://arxiv.org/abs/2404.07220)

    论文提出了“混合RAG”方法，通过结合语义搜索技术和混合查询策略，改善了RAG系统的准确性，并在多个IR和生成式问答数据集上取得了突破性成果。

    

    检索增强生成（RAG）是将私人知识库文档集与大型语言模型（LLM）结合以构建生成式问答（Question-Answering）系统的一种流行方法。然而，随着文档集的扩大，RAG的准确性变得越来越具有挑战性，检索器在这一过程中扮演了重要角色，通过从文档集中提取最相关的文档给LLM提供上下文，从而显著影响了整体RAG的准确性。在这项研究中，我们提出了“混合RAG”方法，它利用了语义搜索技术，如密集向量索引和稀疏编码器索引，并与混合查询策略相结合。我们的研究在信息检索（IR）数据集，如NQ和TREC-COVID数据集上取得了更好的检索结果，并设定了新的基准。我们还将这种“混合检索器”扩展到了RAG系统中，在诸如SQUAD之类的生成式问答数据集上展示了显著更好的结果，甚至超过了fine-tuning的RAG系统性能。

    arXiv:2404.07220v2 Announce Type: replace-cross  Abstract: Retrieval-Augmented Generation (RAG) is a prevalent approach to infuse a private knowledge base of documents with Large Language Models (LLM) to build Generative Q\&A (Question-Answering) systems. However, RAG accuracy becomes increasingly challenging as the corpus of documents scales up, with Retrievers playing an outsized role in the overall RAG accuracy by extracting the most relevant document from the corpus to provide context to the LLM. In this paper, we propose the 'Blended RAG' method of leveraging semantic search techniques, such as Dense Vector indexes and Sparse Encoder indexes, blended with hybrid query strategies. Our study achieves better retrieval results and sets new benchmarks for IR (Information Retrieval) datasets like NQ and TREC-COVID datasets. We further extend such a 'Blended Retriever' to the RAG system to demonstrate far superior results on Generative Q\&A datasets like SQUAD, even surpassing fine-tunin
    
[^118]: 《思维查询逻辑：借助知识图谱引导大型语言模型回答复杂逻辑查询》

    Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs

    [https://arxiv.org/abs/2404.04264](https://arxiv.org/abs/2404.04264)

    LGOT通过结合大型语言模型与知识图谱，解决了逻辑查询中的误导性问题及知识图的不完整性问题，提升了问答系统准确性。

    

    arXiv:2404.04264v3 Announce Type: replace-cross 概要：尽管在许多任务中表现出色，大型语言模型（LLMs）在面对需要知识准确性的任务时，可能会生成误导性的信息甚至错误的答案。当应对需要多步逻辑推理的逻辑查询时，这个问题就更明显了。相反，基于知识图（KG）的问答方法在知识图的帮助下能够准确地识别正确的答案，但是当知识图本身不完整时，其准确性会迅速下降。如何在相互受益的方式中整合知识图谱推理与LLM以减轻LLM的误导性问题以及知识图的不完整问题，这仍然是一个关键挑战。在本文中，我们提出了“思维查询逻辑”（LGOT），这是第一个将LLMS与知识图结合在一起的方法，以解决上述问题。这为LLMs和知识图中的知识集成提供了新的视角，并具有解决复杂逻辑查询的能力。我们通过实验证明，LGOT能够显著提高问答系统的准确性和可靠性，同时减少错误答案的概率。

    arXiv:2404.04264v3 Announce Type: replace-cross  Abstract: Despite the superb performance in many tasks, large language models (LLMs) bear the risk of generating hallucination or even wrong answers when confronted with tasks that demand the accuracy of knowledge. The issue becomes even more noticeable when addressing logic queries that require multiple logic reasoning steps. On the other hand, knowledge graph (KG) based question answering methods are capable of accurately identifying the correct answers with the help of knowledge graph, yet its accuracy could quickly deteriorate when the knowledge graph itself is sparse and incomplete. It remains a critical challenge on how to integrate knowledge graph reasoning with LLMs in a mutually beneficial way so as to mitigate both the hallucination problem of LLMs as well as the incompleteness issue of knowledge graphs. In this paper, we propose 'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs with knowledge grap
    
[^119]: 通过体验环境和学习布朗运动模仿羽毛球球员行为

    Offline Imitation of Badminton Player Behavior via Experiential Contexts and Brownian Motion

    [https://arxiv.org/abs/2403.12406](https://arxiv.org/abs/2403.12406)

    该研究提出了一种新的层次离线模仿学习模型RallyNet，旨在模仿羽毛球比赛中球员的行为决策过程。

    

    arXiv:2403.12406v2 新闻类型：替换摘要：在动态和快速战术参与的下，羽毛球作为一个需要交替决策的本原模式，在各种领域中见证了从离线专家数据中学习的进步。然而，在离线模仿人类球员行为方面，如何在羽毛球比赛中采取交替行动的行为仍没有得到充分的探索。模仿对手的行为对球员有益，通过在比赛前提供方向性，允许他们进行战略发展。然而，直接应用现有的方法会遇到由于比赛的内在层次和交替行动的累加效应而导致的困难。在本文中，我们提出了RallyNet，一个针对羽毛球球员行为的新的层次离线模仿学习模型：(i) RallyNet通过建模决定决策过程

    arXiv:2403.12406v2 Announce Type: replace  Abstract: In the dynamic and rapid tactic involvements of turn-based sports, badminton stands out as an intrinsic paradigm that requires alter-dependent decision-making of players. While the advancement of learning from offline expert data in sequential decision-making has been witnessed in various domains, how to rally-wise imitate the behaviors of human players from offline badminton matches has remained underexplored. Replicating opponents' behavior benefits players by allowing them to undergo strategic development with direction before matches. However, directly applying existing methods suffers from the inherent hierarchy of the match and the compounding effect due to the turn-based nature of players alternatively taking actions. In this paper, we propose RallyNet, a novel hierarchical offline imitation learning model for badminton player behaviors: (i) RallyNet captures players' decision dependencies by modeling decision-making processes
    
[^120]: 梦想许多世界：学习情境世界模型有助于零样本泛化

    Dreaming of Many Worlds: Learning Contextual World Models Aids Zero-Shot Generalization

    [https://arxiv.org/abs/2403.10967](https://arxiv.org/abs/2403.10967)

    该研究通过改进Dreamer V3的世界模型，提出了一种新的情境重复状态空间模型（cRSSM），这种模型能够通过包含情境信息来实现更好的零样本泛化能力。该方法在两个不同的CARL基准任务上取得了更好的结果，并且在两个额外的数据集上也验证了其泛化性能的提升。

    

    arXiv:2403.10967v2 公告类型：替换交叉  翻译过的摘要：零样本泛化（ZSG）到未见动态是创建通用能力的身体化代理的主要挑战。为了解决更广泛的问题，我们从情境强化学习（cRL）的简单设置开始，假定对参数化系统动态变化的环境值的可观测性，例如机器人的质量或尺寸，而不做关于马尔可夫状态可观测性的进一步简化假设。为了实现对未见环境变化的自适应，我们提出了情境重复状态空间模型（cRSSM），该方法是对Dreamer（v3）(Hafner等，2023)的一种情境世界模型的改进。这允许世界模型通过观察来推测潜在的马尔可夫状态，并建模潜在动态，从而对情境强化学习任务进行评估。我们在CARL基准套件中选择了两个任务，这些任务专门用来研究情境RL。我們的方法在两个CARL基准套件中的任务上进行了评价。我们的实验表明，在两个不同的任务上，与 baselines 相比，我们的方法在 zero-shot 泛化方面取得了更好的结果。我们的方法采用了 steps，其中通过将 world model 的输出用作即将到来的观测的预测，来实在地融合情境信息，进而提高了泛化能力。我们还在两个不同数据集上进行了额外的验证实验，证明了通过简单地将 context 与 observation 结合，就可以提高泛化性能。这些结果均展现了结合 context 和 world model 能够大幅提高 EUD 和最终性能，展示出这种方法在推断 latent dynamic 方面的潜力。

    arXiv:2403.10967v2 Announce Type: replace-cross  Abstract: Zero-shot generalization (ZSG) to unseen dynamics is a major challenge for creating generally capable embodied agents. To address the broader challenge, we start with the simpler setting of contextual reinforcement learning (cRL), assuming observability of the context values that parameterize the variation in the system's dynamics, such as the mass or dimensions of a robot, without making further simplifying assumptions about the observability of the Markovian state. Toward the goal of ZSG to unseen variation in context, we propose the contextual recurrent state-space model (cRSSM), which introduces changes to the world model of Dreamer (v3) (Hafner et al., 2023). This allows the world model to incorporate context for inferring latent Markovian states from the observations and modeling the latent dynamics. Our approach is evaluated on two tasks from the CARL benchmark suite, which is tailored to study contextual RL. Our experim
    
[^121]: 高更新比深度 RL 解析：抗击值分歧

    Dissecting Deep RL with High Update Ratios: Combatting Value Divergence

    [https://arxiv.org/abs/2403.05996](https://arxiv.org/abs/2403.05996)

    研究表明，在强化学习中，当梯度更新次数远远超过环境样本时，通过对抗值函数分歧，算法能够保持学习能力，避免了优先偏见的出现。

    

    本文表明，在环境样本数量远少于梯度更新次数的情况下，深度强化学习算法可以通过对抗值函数分歧，并不reset网络参数，而保持学习能力。Nikishin 等人的一项近期研究（2022年）指出在一个较大的更新数据比下，出现了优先偏见，即代理对早期的交互过度拟合，而忽视后来的交互，从而损害了其学习能力。在本研究中，我们对导致优先偏见的现象进行了调查。我们检查了训练的前期阶段，这些阶段被认为是导致无法学习的原因，并发现一个根本的挑战是长期存在的值函数分歧。不仅仅是在未知分布的数据上，甚至在已知分布的数据上，我们也发现了过度膨胀的Q值，并且发现这种现象与在未见过的动作预测上的过估计有关，这种过估计是由优化器的力推动的。

    arXiv:2403.05996v3 Announce Type: replace-cross  Abstract: We show that deep reinforcement learning algorithms can retain their ability to learn without resetting network parameters in settings where the number of gradient updates greatly exceeds the number of environment samples by combatting value function divergence. Under large update-to-data ratios, a recent study by Nikishin et al. (2022) suggested the emergence of a primacy bias, in which agents overfit early interactions and downplay later experience, impairing their ability to learn. In this work, we investigate the phenomena leading to the primacy bias. We inspect the early stages of training that were conjectured to cause the failure to learn and find that one fundamental challenge is a long-standing acquaintance: value function divergence. Overinflated Q-values are found not only on out-of-distribution but also in-distribution data and can be linked to overestimation on unseen action prediction propelled by optimizer moment
    
[^122]: 大型语言模型在可控推荐系统中的对齐

    Aligning Large Language Models for Controllable Recommendations

    [https://arxiv.org/abs/2403.05063](https://arxiv.org/abs/2403.05063)

    我们提出了一种通过强化学习对语言模型进行微调和适应以提高它们遵循推荐系统和人类意图的能力的方法。

    

    arXiv:2403.05063v2 Announce Type: replace-cross 摘要：在大型语言模型（LLMs）表现出卓越的一般智能的启发下，研究人员已经开始探索其在开创下一代推荐系统方面的应用——这些系统是会话性的、可解释的，并且是可控的。然而，现有的文献主要集中在将领域特定的知识整合到LLMs中以提高准确性，往往忽视了遵循指令的能力。为了解决这一不足，我们首先介绍了一系列监督学习任务，这些任务被增加了由传统推荐模型得出的标签，旨在显着提高LLMs在遵循推荐特定指令方面的能力。随后，我们还开发了一种基于强化学习的对齐过程，以进一步增强LLMs在响应用户意图和减少格式错误方面的能力。通过在两个真实世界数据集上的广泛实验，我们的方法证明了这种方法的有效性和实用性，为开发更智能、更可控的推荐系统奠定了基础。

    arXiv:2403.05063v2 Announce Type: replace-cross  Abstract: Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method
    
[^123]: 《PrimeComposer: 使用注意力引导加速渐进式组合扩散的图像合成技术》

    PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering

    [https://arxiv.org/abs/2403.05053](https://arxiv.org/abs/2403.05053)

    研究提出了一种新的渐进式组合扩散方法，专注于图像合成中的前景生成，并通过改进的注意力引导策略显著提高了合成速度和质量。

    

    arXiv:2403.05053v2 公告类型：替换 摘要：图像合成涉及将给定对象无缝地整合到特定的视觉环境中。当前的训练免费方法依赖于从几个采样器中提取注意力权重，以指导生成器。然而，由于这些权重是源自不同的上下文，它们的组合导致了一致性的困惑和外观信息的损失。这些问题在它们过分关注背景生成时变得更加严重，即使在这种情况下这是不必要的任务。这不仅妨碍了它们的快速实施，而且也影响了前景生成的质量。此外，这些方法在过渡区域引入了不必要的艺术颜料。在本论文中，我们将图像合成视为一种基于主题的局部编辑任务，仅专注于前景的生成。在每一次编辑中，所编辑的前景与噪声背景相结合，以维持场景的一致性。为了解决剩余的问题，我们提出了PrimeComposer，这是一种更快的前景为主提升注意力引导加速的渐进式组合扩散图像合成方法。

    arXiv:2403.05053v2 Announce Type: replace  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. Current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only impedes their swift implementation but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tra
    
[^124]: 时间序列增量学习：基准和评估

    Class-incremental Learning for Time Series: Benchmark and Evaluation

    [https://arxiv.org/abs/2402.12035](https://arxiv.org/abs/2402.12035)

    这项研究为时间序列增量学习问题提供了一个全面的评估框架，并指出了当前算法的局限性。

    

    arXiv:2402.12035v2 公告类型：替换 - 交叉  摘要：现实世界的环境本质上是非平稳的，经常随着时间的推移引入新的类别。这在时间序列分类方面尤其常见，就像医疗保健中出现新的疾病分类或人类活动识别中添加新的活动一样。在这种情况下，学习系统需要有效地吸收新的类别，同时避免对旧类别的灾难性遗忘，这导致了类增量学习（CIL）问题。然而，尽管在图像和语言领域取得了令人鼓舞的进展，但时间序列数据领域的CIL研究仍然相对不发达。现有的研究在实验设计上不一致，需要在一个广泛的数据集上对方法进行全面的评估和基准测试。因此，我们首先概述了时间序列类增量学习（TSCIL）问题，强调了它独特的挑战，并收集了一个广泛的基准数据集，用于深入分析和比较现有的CIL算法。我们严格定义了CIL的三个关键挑战：类不匹配性的处理、在线学习性能的评估、以及对不同类别增量的适应。在四次ETS和三个人动作数据集的实验中，我们为CIL方法提供了详细的比较，显示了当前方法的局限性，并指出了未来研究的方向。

    arXiv:2402.12035v2 Announce Type: replace-cross  Abstract: Real-world environments are inherently non-stationary, frequently introducing new classes over time. This is especially common in time series classification, such as the emergence of new disease classification in healthcare or the addition of new activities in human activity recognition. In such cases, a learning system is required to assimilate novel classes effectively while avoiding catastrophic forgetting of the old ones, which gives rise to the Class-incremental Learning (CIL) problem. However, despite the encouraging progress in the image and language domains, CIL for time series data remains relatively understudied. Existing studies suffer from inconsistent experimental designs, necessitating a comprehensive evaluation and benchmarking of methods across a wide range of datasets. To this end, we first present an overview of the Time Series Class-incremental Learning (TSCIL) problem, highlight its unique challenges, and co
    
[^125]: 《自动驾驶出租车事故剖析：通用汽车Cruise公司与一名行人碰撞事件的教训》

    Anatomy of a Robotaxi Crash: Lessons from the Cruise Pedestrian Dragging Mishap

    [https://arxiv.org/abs/2402.06046](https://arxiv.org/abs/2402.06046)

    事故表明自动驾驶汽车在实际交通中存在风险，尤其是对紧急情况的识别和响应存在不足。

    

    arXiv:2402.06046v3 公告类型: 替换-跨越 摘要: 2023年10月，在美国加利福尼亚州旧金山的通勤高峰时段，一辆通用汽车Cruise品牌的自动驾驶出租车在一处学校附近与一名行人相撞。这起事故发生后，通用汽车Cruise公司处理的紧急响应过程受到了严厉的批评，原因是该自动驾驶出租车在撞击行人后未能及时停车，导致行人被拖行了一段距离。这不仅仅是一起伤亡事件，它还显示出自动驾驶汽车在现实世界的道路上进行部署时的潜在安全问题。这起事故也引起了公众和监管机构对自动驾驶技术安全性的关注，并且突出了当前交通安全法规与自动驾驶汽车技术之间的差距。这一研究旨在从监管角度分析事故处理过程并从中汲取教训，研究不仅要关注事故本身，还要关注事故发生后的事故响应方式，以及自动驾驶汽车如何有效识别和应对交通事故。此外，研究的另一个重点是自动驾驶系统如何准确地构建事故发生后的环境模型，以及公司在面对此类紧急情况时应该采取哪些相应的安全措施。通过对不同报告材料的信息进行整合和分析，本研究还旨在探究自动驾驶系统可能面临的安全挑战，并提出潜在改进措施，以确保未来自动驾驶汽车在实际道路环境中的安全运行。

    arXiv:2402.06046v3 Announce Type: replace-cross  Abstract: An October 2023 crash between a GM Cruise robotaxi and a pedestrian in San Francisco resulted not only in a severe injury, but also dramatic upheaval at that company that will likely have lasting effects throughout the industry. Is-sues stem not just from the loss events themselves, but also from how Cruise mishandled dealing with their robotaxi dragging a pedestrian under the vehicle after the initial post-crash stop. External investigation reports provide raw material describing the incident and critique the company's response from a regulatory point of view, but exclude safety engineering recommendations from scope. We highlight specific facts and relationships among events by tying together different pieces of the external report material. We then explore safety lessons that might be learned related to: recognizing and responding to nearby mishaps, building an accurate world model of a post-collision scenario, the in-adequa
    
[^126]: 组多视图自编码器用于空间编码的3D形状分析

    Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding

    [https://arxiv.org/abs/2312.16477](https://arxiv.org/abs/2312.16477)

    本文提出了一种基于知识蒸馏的压缩方法，用于减少3D形状识别中视图级别方法的参数数量，同时保持性能。通过设计一种名为GMViT的高性能大型模型，以及引入空间自编码器增强特征表示，该方法在一个名为DeCoV的策略下实现了在图像分类任务上的较好性能。

    

    arXiv:2312.16477v3 公告类型：替换  摘要：近年来，基于视图的3D形状识别方法的结果已经饱和，并且由于参数尺寸巨大，性能优异的模型无法部署在内存受限的设备上。为了解决这个问题，我们为这一领域引入了一种基于知识蒸馏的压缩方法，这种方法在尽可能保留模型性能的同时显著减少了参数的数量。具体来说，为了提高小型模型的能力，我们设计了一个高性能的大型模型，称为组多视图视觉Transformer（GMViT）。在GMViT中，视图级别的ViT首先建立了视图级别特征之间的关系。此外，为了捕获更深层次的特征，我们对视图级别特征进行了分组模块的处理，使其提升到了组级别特征。最后，组级别ViT将组级别特征整合成完整的、结构良好的3D形状描述符。值得注意的是，在这两个ViT中，我们都引入了空间自编码器来进一步增强特征表示。我们的压缩策略叫做DeCoV,它可以在图像分类任务上达到比当前最佳压缩技术更好的性能。在论文中，我们详细说明了如何使用知识蒸馏来实现这一愿景，并讨论了DeCoV在另一方面的影响可能给我们带来的便利。

    arXiv:2312.16477v3 Announce Type: replace  Abstract: In recent years, the results of view-based 3D shape recognition methods have saturated, and models with excellent performance cannot be deployed on memory-limited devices due to their huge size of parameters. To address this problem, we introduce a compression method based on knowledge distillation for this field, which largely reduces the number of parameters while preserving model performance as much as possible. Specifically, to enhance the capabilities of smaller models, we design a high-performing large model called Group Multi-view Vision Transformer (GMViT). In GMViT, the view-level ViT first establishes relationships between view-level features. Additionally, to capture deeper features, we employ the grouping module to enhance view-level features into group-level features. Finally, the group-level ViT aggregates group-level features into complete, well-formed 3D shape descriptors. Notably, in both ViTs, we introduce spatial e
    
[^127]: 使用对抗性正则化的鲁棒生存分析

    Robust Survival Analysis with Adversarial Regularization

    [https://arxiv.org/abs/2312.16019](https://arxiv.org/abs/2312.16019)

    本文提出了一种使用对抗性正则化的鲁棒生存分析方法，通过神经网络验证技术提高了生存模型在面对数据集不确定性时的性能。

    

    arXiv:2312.16019v3 宣布类型：替换交叉  翻译：生存分析（SA）模型事件发生的时间，在医学、国防、金融和航空航天等领域的应用。最近的工作显示，神经网络（NN）可以捕捉SA中复杂的相互关系。然而，数据集的不确定性（例如，噪声测量、人类错误）可能会损害模型性能。为了解决这个问题，我们利用了神经网络验证的最新进展，创建了用于鲁棒的、完全参数化的生存模型的算法。我们介绍了一个鲁棒损失函数，并使用CROWN-IBP正则化来处理最小化最大化问题中的计算挑战。在我们的生存分析与对抗性正则化（SAWAR）方法在SurvSet数据集上的评估中，我们发现，在我们的方法与各种污染下的负对数似然（NegLL）、积分布雷尔分数（IBS）和一致性指数（CI）进行比较时，它显著优于 baselines。这证明了对抗性正则化增强了SA的表现。

    arXiv:2312.16019v3 Announce Type: replace-cross  Abstract: Survival Analysis (SA) models the time until an event occurs, with applications in fields like medicine, defense, finance, and aerospace. Recent work shows that Neural Networks (NNs) can capture complex relationships in SA. However, dataset uncertainties (e.g., noisy measurements, human error) can degrade model performance. To address this, we leverage NN verification advances to create algorithms for robust, fully-parametric survival models. We introduce a robust loss function and use CROWN-IBP regularization to handle computational challenges in the Min-Max problem. Evaluating our approach on SurvSet datasets, we find that our Survival Analysis with Adversarial Regularization (SAWAR) method consistently outperforms baselines under various perturbations with respect to Negative Log Likelihood (NegLL), Integrated Brier Score (IBS), and Concordance Index (CI). This demonstrates that adversarial regularization enhances SA perform
    
[^128]: 利用新型 GPT-4 API

    Exploiting Novel GPT-4 APIs

    [https://arxiv.org/abs/2312.14302](https://arxiv.org/abs/2312.14302)

    本研究对新型 GPT-4 APIs 的新功能进行了利用，发现即使是微调模型也可以移除其核心保护措施，并且能够进行函数调用和知识检索的劫持。

    

    天文学术：2312.14302v2 公告类型：替换交叉 摘要：语言模型攻击通常假设两种极端的威胁模型：完全开放访问模型的权重，或者是仅限于文本生成API的封闭访问。然而，现实世界的API往往比仅仅文本生成要灵活得多：这些API暴露的"灰盒"访问导致了新的威胁途径。为了探索这一点，我们红队对GPT-4 APIs暴露的新功能进行了三向研究：微调、函数调用和知识检索。我们发现，即使是微调一个模型也只有15个有害示例或100个良性示例就可以移除GPT-4的核心保护措施，使得可以产生一系列有害输出。此外，我们还发现GPT-4助理愿意透露函数调用模式，并且可以被导向执行任意函数调用。最后，我们还发现知识检索可以被通过注入指令到检索文档中进行劫持。这些漏洞表明，任何对API功能的新增都可能导致安全风险，尤其是对于这些新API提供的额外能力和权限，必须被仔细审视和管理。

    arXiv:2312.14302v2 Announce Type: replace-cross  Abstract: Language model attacks typically assume one of two extreme threat models: full white-box access to model weights, or black-box access limited to a text generation API. However, real-world APIs are often more flexible than just text generation: these APIs expose "gray-box" access leading to new threat vectors. To explore this, we red-team three new functionalities exposed in the GPT-4 APIs: fine-tuning, function calling and knowledge retrieval. We find that fine-tuning a model on as few as 15 harmful examples or 100 benign examples can remove core safeguards from GPT-4, enabling a range of harmful outputs. Furthermore, we find that GPT-4 Assistants readily divulge the function call schema and can be made to execute arbitrary function calls. Finally, we find that knowledge retrieval can be hijacked by injecting instructions into retrieval documents. These vulnerabilities highlight that any additions to the functionality exposed b
    
[^129]: 可靠的学术会议问题解答：基于大型语言模型的研究

    Reliable Academic Conference Question Answering: A Study Based on Large Language Model

    [https://arxiv.org/abs/2310.13028](https://arxiv.org/abs/2310.13028)

    该研究开发了一个ConferenceQA数据集，并通过组织学术会议数据和问题-答案对标注，提高了大型语言模型在学术问题解答方面的可靠性和时效性。

    

    arXiv:2310.13028v2 公告类型：替换-交叉  摘要：随着学术会议的发展，学者们不断需要获取关于学术会议的准确和及时的信息。由于信息分散，使用一个智能的问题解答系统来高效地处理研究者的查询，并确保对最新进展的意识是必要的。最近，大型语言模型（LLMs）在问题解答方面展示了出色的能力，并通过检索外部知识来处理过时知识得到了增强。然而，这些方法由于缺乏最新的会议信息而失败。为了解决这一挑战，我们开发了ConferenceQA数据集，它包括七个多样化的学术会议。具体来说，对于每个会议，我们首先通过半自动方法组织学术会议数据为树状格式。然后，我们对每个会议的问题-答案对进行标注。

    arXiv:2310.13028v2 Announce Type: replace-cross  Abstract: As the development of academic conferences fosters global scholarly communication, researchers consistently need to obtain accurate and up-to-date information about academic conferences. Since the information is scattered, using an intelligent question-answering system to efficiently handle researchers' queries and ensure awareness of the latest advancements is necessary. Recently, Large Language Models (LLMs) have demonstrated impressive capabilities in question answering, and have been enhanced by retrieving external knowledge to deal with outdated knowledge. However, these methods fail to work due to the lack of the latest conference knowledge. To address this challenge, we develop the ConferenceQA dataset, consisting of seven diverse academic conferences. Specifically, for each conference, we first organize academic conference data in a tree-structured format through a semi-automated method. Then we annotate question-answer
    
[^130]: 剖析人类与AI在关键安全行业中的交互：系统性文献综述

    Unpacking Human-AI Interaction in Safety-Critical Industries: A Systematic Literature Review

    [https://arxiv.org/abs/2310.03392](https://arxiv.org/abs/2310.03392)

    该研究系统性综述了在关键安全行业中人类与人工智能交互的研究，指出了目前研究中的局限性与挑战，并提出了改善该领域的研究最佳实践。

    

    arXiv:2310.03392v2 公告类型：替换交叉  翻译摘要：在关键安全行业中确保人类与人工智能交互（HAII）的质量至关重要。如果未能做到这一点，可能会导致灾难性的、甚至是致命的后果。尽管这一紧迫性，但有关HAII的现有研究仍然有限、碎片化和不一致。我们在这里提出了一项对该领域文献的调查，并提出了应该改善该领域的研究最佳实践。我们将我们的调查分为以下几个领域：1) 用于描述HAII的术语，2) AI赋能系统的核心角色，3) 影响HAII的因素，以及4) 如何衡量HAII。此外，我们还描述了在讨论的这些文章中用于关键安全行业的AI赋能系统的功能和成熟度。我们的研究表明，文献中没有单一的术语被用来描述HAII，而且有些术语有多种含义。根据我们的文献调研，七种因素影响了HAII：用户特征（例如，用户个性），用户感知，以及用户-AI关系。总体来说，这些研究为我们更好地理解HAII提供的视角是多维的。我们还提出了在安全关键行业中评估AI赋能系统和HAII需求的框架。最后，我们对未来的研究进行了展望，本文的研究对于提高HAII在关键安全行业中的实践和管理至关重要。

    arXiv:2310.03392v2 Announce Type: replace-cross  Abstract: Ensuring quality human-AI interaction (HAII) in safety-critical industries is essential. Failure to do so can lead to catastrophic and deadly consequences. Despite this urgency, existing research on HAII is limited, fragmented, and inconsistent. We present here a survey of that literature and recommendations for research best practices that should improve the field. We divided our investigation into the following areas: 1) terms used to describe HAII, 2) primary roles of AI-enabled systems, 3) factors that influence HAII, and 4) how HAII is measured. Additionally, we described the capabilities and maturity of the AI-enabled systems used in safety-critical industries discussed in these articles. We found that no single term is used across the literature to describe HAII and some terms have multiple meanings. According to our literature, seven factors influence HAII: user characteristics (e.g., user personality), user perceptions
    
[^131]: 智能制造系统中的时间序列分类：对先进的机器学习算法实验评估的现状

    Time-Series Classification in Smart Manufacturing Systems: An Experimental Evaluation of State-of-the-Art Machine Learning Algorithms

    [https://arxiv.org/abs/2310.02812](https://arxiv.org/abs/2310.02812)

    本研究通过实证评估了先进的机器学习算法在智能制造系统中的时间序列分类任务中的表现，发现了经典机器学习算法和深度学习算法在处理制造业复杂场景时的优越性能，并为制造业的时间序列分析提供了决策支持。

    

    制造行业正在收集大量多样化的数据，这要感谢传感器的数量不断增多和检测技术的快速进步。在这多种数据类型中，时间序列数据在智能制造系统（SMS）中扮演着关键角色。因此，时间序列分类（TSC）在这一行业领域中显得尤为重要。本研究的目的是通过提供对制造和工业领域中时间序列分类任务的最先进机器学习和深度学习算法的严格实验评估来解决这一空白。首先，我们探索并汇总了来自时间序列分类和制造文献的超过92种先进算法的列表。随后，我们从列表中选择了最能代表算法的36种算法。为了评估这些算法在制造业分类任务中的性能，我们精心挑选了22个制造业数据集，这些数据集涵盖了不同特征的制造业问题。之后，我们对选定的算法进行了实施并进行了评估，并利用这些算法对数据集进行了处理和优化。算法的性能得到了详细的统计分析，包括准确率、召回率、F1分数和ROC曲线等关键性能指标。通过彻底的分析，我们发现了一些经典机器学习算法在时间序列分类任务中的优越表现，同时也识别出了深度学习算法在处理复杂制造业场景时的强大潜力。此外，我们还对算法的执行效率进行了评估，以确定在制造业的实际应用中可能面临的问题。我们的研究不仅为进一步的研究提供了宝贵的见解，而且在制造业的时间序列分析方面为实践者提供了重要的决策支持。我们的研究结果表明，虽然存在一些性能出色的算法，但还没有在任何公认的基准数据集中表现出绝对优势的算法。因此，研究人员可能会发现更多的算法需要进一步的探索和改进，以适应制造业的实际需求。

    arXiv:2310.02812v2 Announce Type: replace-cross  Abstract: Manufacturing is gathering extensive amounts of diverse data, thanks to the growing number of sensors and rapid advances in sensing technologies. Among the various data types available in SMS settings, time-series data plays a pivotal role. Hence, TSC emerges is crucial in this domain. The objective of this study is to fill this gap by providing a rigorous experimental evaluation of the SoTA ML and DL algorithms for TSC tasks in manufacturing and industrial settings. We first explored and compiled a comprehensive list of more than 92 SoTA algorithms from both TSC and manufacturing literature. Following, we selected the 36 most representative algorithms from this list. To evaluate their performance across various manufacturing classification tasks, we curated a set of 22 manufacturing datasets, representative of different characteristics that cover diverse manufacturing problems. Subsequently, we implemented and evaluated the al
    
[^132]: 关于相对于单元子公式传播的非冗余CNF公式

    On CNF formulas irredundant with respect to unit clause propagation

    [https://arxiv.org/abs/2309.01750](https://arxiv.org/abs/2309.01750)

    本文证明了对于某个特定形式的对称确定性霍恩函数，存在一个非冗余CNF公式，它相较于最小的大约$n^2$倍，这表明了在移除变量时可能存在的非冗余性问题。

    

    arXiv:2309.01750v4 公告类型：替换交叉  摘要：两个CNF公式称为ucp等价，如果它们在单元子公式传播（UCP）方面表现出相同的特性。如果从原始公式中移除任何子公式就会导致一个不再与原始公式ucp等价的公式，则该公式称为ucp冗余。已知结果的后果是，非冗余公式的大小与最小ucp等价公式大小的比值不超过$n^2$，其中$n$是变量的数量。我们展示了一个与最小ucp等价公式大小相比大得多、因素为$\Omega(n/\ln n)$的非冗余公式，用于对称确定霍恩函数，因此，上述比率的上限不能小于这个值。

    arXiv:2309.01750v4 Announce Type: replace-cross  Abstract: Two CNF formulas are called ucp-equivalent, if they behave in the same way with respect to the unit clause propagation (UCP). A formula is called ucp-irredundant, if removing any clause leads to a formula which is not ucp-equivalent to the original one. As a consequence of known results, the ratio of the size of a ucp-irredundant formula and the size of a smallest ucp-equivalent formula is at most $n^2$, where $n$ is the number of the variables. We demonstrate an example of a ucp-irredundant formula for a symmetric definite Horn function which is larger than a smallest ucp-equivalent formula by a factor $\Omega(n/\ln n)$ and, hence, a general upper bound on the above ratio cannot be smaller than this.
    
[^133]: 利用大型AI模型 empowered multimodal semantic communications

    Large AI Model Empowered Multimodal Semantic Communications

    [https://arxiv.org/abs/2309.01249](https://arxiv.org/abs/2309.01249)

    本文提出了一种基于大型AI模型的大型AI模型-强化型多模态语义通信（LAM-MSC）框架，该框架利用多模态语言模型（MLM）和大型语言模型（LLM）进行多模态数据转换，以保持语义一致性，并进行个性化语义提取或恢复。

    

    arXiv:2309.01249v2 公告类型：替换 摘要：在语义通信（SC）系统中集成多模态信号，如文本、音频、图像和视频，可以提供具有低延迟和高质量的沉浸式体验，这在语义层次上。然而，多模态SC也存在一些挑战，包括数据异质性、语义模糊性和信号在传输过程中的失真。在大型AI模型，特别是多模态语言模型（MLM）和大型语言模型（LLM）方面最近的进展，为解决这些问题提供了潜在的解决方案。因此，我们提出了基于大型AI模型的多模态SC（LAM-MSC）框架，其中我们首先介绍了多模态对齐（MMA），它使用MLM来允许在多模态和单模态数据之间进行转换，同时保持语义一致性。然后，我们提出了一个个性化的LLM-based Knowledge Base（LKB），允许用户执行个性化的语义提取或恢复。

    arXiv:2309.01249v2 Announce Type: replace  Abstract: Multimodal signals, including text, audio, image, and video, can be integrated into Semantic Communication (SC) systems to provide an immersive experience with low latency and high quality at the semantic level. However, the multimodal SC has several challenges, including data heterogeneity, semantic ambiguity, and signal distortion during transmission. Recent advancements in large AI models, particularly in the Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential solutions for addressing these issues. To this end, we propose a Large AI Model-based Multimodal SC (LAM-MSC) framework, where we first present the MLM-based Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation between multimodal and unimodal data while preserving semantic consistency. Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows users to perform personalized semantic extraction or recovery
    
[^134]: LAMBO：用大型人工智能模型增强的边缘智能

    LAMBO: Large AI Model Empowered Edge Intelligence

    [https://arxiv.org/abs/2308.15078](https://arxiv.org/abs/2308.15078)

    LAMBO框架采用大型AI模型，通过输入嵌入和AED模型，结合ACE学习进行预训练，解决了边缘智能中异构约束、感知不全等问题，并提高了模型的泛化能力。

    

    arXiv:2308.15078v2 公告类型：替换 摘要：下一代边缘智能预计将通过卸载技术为各种应用带来益处。然而，传统的外加载架构面临 several 几个问题，包括异构约束、部分感知、不确定性泛化和不具有可伸缩性。在这篇论文中，我们提出了一个基于大型人工智能模型的外加载（LAMBO）框架，解决这些问题，该框架拥有超过一亿个参数。我们首先使用输入嵌入（IE）来通过异构约束和任务提示实现标准化特征表示。然后，我们引入一个新的不对称编码器-解码器（AED）作为决策模型，这是一种改进的Transformer架构，它包括一个深度编码器和一个浅度解码器用于全局感知和决策。接下来，我们使用演员-批评者学习（ACL）对AED进行预训练，在相应的提示下为不同的优化任务，增强AED的多任务泛化能力。我们还介绍了一种基于AED的双向交互影响机制，用于提升决策质量的鲁棒性和优化任务间的迁移学习能力。最后，我们在不同的任务和网络架构上进行了广泛的实验，证明了LAMBO的有效性和鲁棒性。

    arXiv:2308.15078v2 Announce Type: replace  Abstract: Next-generation edge intelligence is anticipated to benefit various applications via offloading techniques. However, traditional offloading architectures face several issues, including heterogeneous constraints, partial perception, uncertain generalization, and lack of tractability. In this paper, we propose a Large AI Model-Based Offloading (LAMBO) framework with over one billion parameters for solving these problems. We first use input embedding (IE) to achieve normalized feature representation with heterogeneous constraints and task prompts. Then, we introduce a novel asymmetric encoder-decoder (AED) as the decision-making model, which is an improved transformer architecture consisting of a deep encoder and a shallow decoder for global perception and decision. Next, actor-critic learning (ACL) is used to pre-train the AED for different optimization tasks under corresponding prompts, enhancing the AED's generalization in multi-task
    
[^135]: 利用语言模型能力进行声事件检测

    Leveraging Language Model Capabilities for Sound Event Detection

    [https://arxiv.org/abs/2308.11530](https://arxiv.org/abs/2308.11530)

    本文提出了一种采用预训练的声学和语言模型，结合使用多模态表示学习，以构建一个更有效地进行声事件检测的框架。

    

    arXiv:2308.11530v2 公告类型: 替换交叉链

    arXiv:2308.11530v2 Announce Type: replace-cross  Abstract: Large language models reveal deep comprehension and fluent generation in the field of multi-modality. Although significant advancements have been achieved in audio multi-modality, existing methods are rarely leverage language model for sound event detection (SED). In this work, we propose an end-to-end framework for understanding audio features while simultaneously generating sound event and their temporal location. Specifically, we employ pretrained acoustic models to capture discriminative features across different categories and language models for autoregressive text generation. Conventional methods generally struggle to obtain features in pure audio domain for classification. In contrast, our framework utilizes the language model to flexibly understand abundant semantic context aligned with the acoustic representation. The experimental results showcase the effectiveness of proposed method in enhancing timestamps precision 
    
[^136]: 基于归纳法的复杂异构信息网络元路径学习

    Inductive Meta-path Learning for Schema-complex Heterogeneous Information Networks

    [https://arxiv.org/abs/2307.03937](https://arxiv.org/abs/2307.03937)

    本文提出了一种名为SchemaWalk的算法，用于在复杂异构信息网络中学习元路径，该算法无需枚举所有路径实例即可高效地进行学习。

    

    arXiv:2307.03937v2 公告类型：替换

    arXiv:2307.03937v2 Announce Type: replace  Abstract: Heterogeneous Information Networks (HINs) are information networks with multiple types of nodes and edges. The concept of meta-path, i.e., a sequence of entity types and relation types connecting two entities, is proposed to provide the meta-level explainable semantics for various HIN tasks. Traditionally, meta-paths are primarily used for schema-simple HINs, e.g., bibliographic networks with only a few entity types, where meta-paths are often enumerated with domain knowledge. However, the adoption of meta-paths for schema-complex HINs, such as knowledge bases (KBs) with hundreds of entity and relation types, has been limited due to the computational complexity associated with meta-path enumeration. Additionally, effectively assessing meta-paths requires enumerating relevant path instances, which adds further complexity to the meta-path learning process. To address these challenges, we propose SchemaWalk, an inductive meta-path learn
    
[^137]: 基于大型AI模型 semantic communications

    Large AI Model-Based Semantic Communications

    [https://arxiv.org/abs/2307.03492](https://arxiv.org/abs/2307.03492)

    文章提出了一种基于大型AI模型的语义通信框架，通过SKB将图像分割成语义段，然后通过ASI对这些段进行加权整合，实现更高效的语义通信。

    

    arXiv:2307.03492v2 宣布类型: replace 摘要: 语义通信(SC)是一种新兴的智能范式，为各种未来应用，如元宇宙、混合现实和物联网提供解决方案。然而，在当前的SC系统中，知识库(KB)的建设面临一些问题，包括知识表示有限、知识更新频繁和知识共享不安全。幸运的是，大型AI模型的开发为解决这些问题提供了新的解决方案。在这里，我们提出了一个基于大型AI模型的SC框架(LAM-SC)，专门设计用于图像数据。我们首先应用基于segment anything model (SAM)的知识库(SKB)，它可以使用通用语义知识将原始图像分割成不同的语义段。然后，我们提出了基于注意力的语义整合方法(ASI)，该方法无需人类参与即可对由SKB生成的语义段进行加权整合，并将它们整合为语义感知图像。此外，我们还展示了如何在LAM-SC框架中利用LAM来进行更细粒度的语义分割，以及在多场景情境下实现高效的语义通信。通过实证研究，我们的LAM-SC框架在提高通信效率和降低错误率方面展现了出色的性能，这为未来的SC系统提供了有价值的参考和实践指导。

    arXiv:2307.03492v2 Announce Type: replace  Abstract: Semantic communication (SC) is an emerging intelligent paradigm, offering solutions for various future applications like metaverse, mixed reality, and the Internet of Everything. However, in current SC systems, the construction of the knowledge base (KB) faces several issues, including limited knowledge representation, frequent knowledge updates, and insecure knowledge sharing. Fortunately, the development of the large AI model (LAM) provides new solutions to overcome the above issues. Here, we propose a LAM-based SC framework (LAM-SC) specifically designed for image data, where we first apply the segment anything model (SAM)-based KB (SKB) that can split the original image into different semantic segments by universal semantic knowledge. Then, we present an attention-based semantic integration (ASI) to weigh the semantic segments generated by SKB without human participation and integrate them as the semantic aware image. Additionall
    
[^138]: 《人工智造 · 影像印记》

    The Cultivated Practices of Text-to-Image Generation

    [https://arxiv.org/abs/2306.11393](https://arxiv.org/abs/2306.11393)

    在《人工智造 · 影像印记》一章中，作者描述了文本到图像生成技术的里程碑式发展以及在其中扮演关键角色的“催生工程”。文章提醒我们需要对这种共创生态系统可能带来的影响进行深入思考。

    

    人类正在进入一个全新的创造时代，任何人在线都可以使用生成的人工智能（AI）来创建数字信息。其中，文本到图像生成的技术尤为流行，数以百万计的实践者在线创作AI图像和艺术作品。本文首先概述了创造一个健康的文本到图像生成在线共创生态系统的关键发展，然后详细描述了这个生态系统中的关键元素。文中特别关注了催生工程--一种被AI艺术社区广泛接受的艺术实践。随后，文章建议这个逐渐成型的共创生态系统是一个独立的人工智能系统，它支持人类创造力，同时也可能限制未来AI的发展和影响未来代际的发展。文章讨论了这个系统可能带来的风险和挑战。

    arXiv:2306.11393v2 Announce Type: replace-cross  Abstract: Humankind is entering a novel creative era in which anybody can synthesize digital information using generative artificial intelligence (AI). Text-to-image generation, in particular, has become vastly popular and millions of practitioners produce AI-generated images and AI art online. This chapter first gives an overview of the key developments that enabled a healthy co-creative online ecosystem around text-to-image generation to rapidly emerge, followed by a high-level description of key elements in this ecosystem. A particular focus is placed on prompt engineering, a creative practice that has been embraced by the AI art community. It is then argued that the emerging co-creative ecosystem constitutes an intelligent system on its own - a system that both supports human creativity, but also potentially entraps future generations and limits future development efforts in AI. The chapter discusses the potential risks and dangers o
    
[^139]: 医疗保健知识图谱综述：资源、应用与承诺

    A Review on Knowledge Graphs for Healthcare: Resources, Applications, and Promises

    [https://arxiv.org/abs/2306.04802](https://arxiv.org/abs/2306.04802)

    这篇论文综述了医疗保健知识图谱的发展，强调了大型语言模型在构建更准确和全面的知识图谱中的应用，并讨论了可信的生成内容和模型评估的潜在改进。

    

    arXiv:2306.04802v4 | 公告类型：替换

    arXiv:2306.04802v4 Announce Type: replace  Abstract: Healthcare knowledge graphs (HKGs) are valuable tools for organizing biomedical concepts and their relationships with interpretable structures. The recent advent of large language models (LLMs) has paved the way for building more comprehensive and accurate HKGs. This, in turn, can improve the reliability of generated content and enable better evaluation of LLMs. However, the challenges of HKGs such as regarding data heterogeneity and limited coverage are not fully understood, highlighting the need for detailed reviews. This work provides the first comprehensive review of HKGs. It summarizes the pipeline and key techniques for HKG construction, as well as the common utilization approaches, i.e., model-free and model-based. The existing HKG resources are also organized based on the data types they capture and application domains they cover, along with relevant statistical information (Resource available at https://github.com/lujiaying/
    
[^140]: 受外部时间过程影响的马尔可夫决策过程

    Markov Decision Processes under External Temporal Processes

    [https://arxiv.org/abs/2305.16056](https://arxiv.org/abs/2305.16056)

    这篇论文研究了在不断变化的外部时间过程影响下的马尔可夫决策过程，并提出了一种策略迭代算法来处理这个问题，同时分析了解决方案的样本复杂性和性能。

    

    arXiv:2305.16056v2 公告类型：替换交叉  翻译摘要：大多数强化学习算法都将其运作的环境视为一个稳定的、隔离的和不受干扰的环境。然而，在现实世界的应用中，环境由于各种外部事件不断变化。为了解决这个问题，我们研究了在受到外部时间过程影响下的马尔可夫决策过程（MDP）。我们formalize了这一概念，并讨论了在哪些条件下问题可以得到合适的解决。我们提出了一种策略迭代算法来解决这个问题，并对它的性能进行了理论分析。我们导出了算法的样本复杂性的结果，并研究了它与环境非稳定性程度的关系。然后，我们进行了实验，以在经典的控制环境中说明我们的结果。

    arXiv:2305.16056v2 Announce Type: replace-cross  Abstract: Most reinforcement learning algorithms treat the context under which they operate as a stationary, isolated, and undisturbed environment. However, in real world applications, environments constantly change due to a variety of external events. To address this problem, we study Markov Decision Processes (MDP) under the influence of an external temporal process. We formalize this notion and discuss conditions under which the problem becomes tractable with suitable solutions. We propose a policy iteration algorithm to solve this problem and theoretically analyze its performance. We derive results on the sample complexity of the algorithm and study its dependency on the extent of non-stationarity of the environment. We then conduct experiments to illustrate our results in a classic control environment.
    
[^141]: 我们应该参加会议更多还是更少？公平性下的注意力调制

    Should We Attend More or Less? Modulating Attention for Fairness

    [https://arxiv.org/abs/2305.13088](https://arxiv.org/abs/2305.13088)

    这项研究提出了一种通过调整注意力权重来提高自然语言处理模型公平性的方法，该方法在模型训练后实施，对模型性能影响很小。

    

    arXiv:2305.13088v2 公告类型：替换交叉网络 摘要：自然语言处理（NLP）的进步既带来了机遇也带来了挑战。尽管近期的发展使得在高性能模型上进行多项任务的发展成为可能，但它同时也带来了从数据中学习有害偏见的风险，如性别偏见。在这项工作中，我们研究了当前先进NLP模型中广泛使用的注意力机制在社会偏见传播中的作用。具体来说，我们研究了注意力分布的熵与模型性能和公平性的关系。然后，我们提出了一个新颖的方法来调制注意力权重，以在训练后改善模型的公平性。由于我们的方法仅在训练后和推断前应用，它是一种中间处理方法，因此其计算成本比现有的处理方法和预处理方法要低。我们的结果表明，公平性有所提高，且几乎没有影响模型的性能。

    arXiv:2305.13088v2 Announce Type: replace-cross  Abstract: The advances in natural language processing (NLP) pose both opportunities and challenges. While recent progress enables the development of high-performing models for a variety of tasks, it also poses the risk of models learning harmful biases from the data, such as gender stereotypes. In this work, we investigate the role of attention, a widely-used technique in current state-of-the-art NLP models, in the propagation of social biases. Specifically, we study the relationship between the entropy of the attention distribution and the model's performance and fairness. We then propose a novel method for modulating attention weights to improve model fairness after training. Since our method is only applied post-training and pre-inference, it is an intra-processing method and is, therefore, less computationally expensive than existing in-processing and pre-processing approaches. Our results show an increase in fairness and minimal per
    
[^142]: 程序语言模型中涌现的程序语义表示

    Emergent Representations of Program Semantics in Language Models Trained on Programs

    [https://arxiv.org/abs/2305.11169](https://arxiv.org/abs/2305.11169)

    即使未曾直接训练过，AI模型也在阅读代码的过程中学习到了程序语义表示

    

    我们表明，虽然只是在训练中预测下一个字符，代码语言模型（LMs）也能学会代表程序的正式语义。具体来说，我们为一种专门用于在二维网格世界中导航的域特定语言训练一个Transformer模型。文档库中的每个程序都伴随着一个格盘世界状态的（部分）规范，形式为几个输入输出格盘世界状态。尽管没有提供任何其他归纳偏差，我们发现一个探测分类器能够从训练过程中提取越来越准确的程序语义表示，这些表示隐藏在语言模型的隐藏状态中，这表明语言模型在未经正式训练的情况下，学会了程序意义上的解释能力。我们还开发了一种新颖的干预性基线，它使我们能够区分由语言模型代表的内容和通过探索器学习的内容。我们旨在通过这种方式进APA官方客服

    arXiv:2305.11169v3 Announce Type: replace-cross  Abstract: We present evidence that language models (LMs) of code can learn to represent the formal semantics of programs, despite being trained only to perform next-token prediction. Specifically, we train a Transformer model on a synthetic corpus of programs written in a domain-specific language for navigating 2D grid world environments. Each program in the corpus is preceded by a (partial) specification in the form of several input-output grid world states. Despite providing no further inductive biases, we find that a probing classifier is able to extract increasingly accurate representations of the unobserved, intermediate grid world states from the LM hidden states over the course of training, suggesting the LM acquires an emergent ability to interpret programs in the formal sense. We also develop a novel interventional baseline that enables us to disambiguate what is represented by the LM as opposed to learned by the probe. We antic
    
[^143]: 环境约束下的情境依赖通信

    Context-dependent communication under environmental constraints

    [https://arxiv.org/abs/2305.05821](https://arxiv.org/abs/2305.05821)

    论文研究了在环境约束下，情境依赖通信如何从一种情境信号模型中产生，并探讨了发送者和接收者如何利用认知能力克服环境限制，实现有效沟通。

    

    arXiv:2305.05821v2 宣布类型：替换 摘要：有大量证据表明，现实世界中的通信不能简化为发送具有无情境意义的信号。在本工作中，基于经典 Lewis（1969）信号模型的一种变体，我们探讨了在情境化场景中产生情境依赖通信的条件。特别是，我们证明，减少词汇量的大小压力足以促进这种出现。同时，我们还研究了在接收者的指称选择环境条件下，能够自行利用发送者的认知能力和环境条件。我们展示了一个事实，即环境约束接收者的指称选择可以由发送者单方面地利用，而无需接收者的语境消歧能力。与普遍的假设相一致，发送者对情境的意识似乎是情境通信所必需的。我们建议，情境依赖的通信是一种情境的多层处理过程。

    arXiv:2305.05821v2 Announce Type: replace  Abstract: There is significant evidence that real-world communication cannot be reduced to sending signals with context-independent meaning. In this work, based on a variant of the classical Lewis (1969) signaling model, we explore the conditions for the emergence of context-dependent communication in a situated scenario. In particular, we demonstrate that pressure to minimise the vocabulary size is sufficient for such emergence. At the same time, we study the environmental conditions and cognitive capabilities that enable contextual disambiguation of symbol meanings. We show that environmental constraints on the receiver's referent choice can be unilaterally exploited by the sender, without disambiguation capabilities on the receiver's end. Consistent with common assumptions, the sender's awareness of the context appears to be required for contextual communication. We suggest that context-dependent communication is a situated multilayered phe
    
[^144]: 视觉学习者与网络图像文本对

    Vision Learners Meet Web Image-Text Pairs

    [https://arxiv.org/abs/2301.07088](https://arxiv.org/abs/2301.07088)

    新型视觉学习者MUG通过自监督学习，在网络图像文本配对数据上进行预训练，旨在改进视觉表示。

    

    arXiv:2301.07088v3 公告类型：替换 摘要： 许多自监督学习方法在一组精心编排的图像Net-1K数据集上进行预训练。在本工作中，考虑到网络数据出色的可扩展性，我们考虑在由网络来源的图像文本配对数据上进行自监督预训练。首先，我们在类似配置的设置中，对代表性的自监督预训练方法在大型网络数据上的表现进行了基准测试。我们比较了一系列方法，包括使用掩码训练目标的单模态方法，以及使用图像文本对比性训练的多模态方法。我们观察到，现有的多模态方法在视觉转移学习任务上并没有超过单模态方法的表现。我们推导出一个信息论观点来解释这些基准结果，该观点为设计一种新型视觉学习者提供了洞察。受此洞察的启发，我们介绍了一种新的视觉表示预训练方法MUlti-modal Generator（MUG），它从

    arXiv:2301.07088v3 Announce Type: replace  Abstract: Many self-supervised learning methods are pre-trained on the well-curated ImageNet-1K dataset. In this work, given the excellent scalability of web data, we consider self-supervised pre-training on noisy web sourced image-text paired data. First, we conduct a benchmark study of representative self-supervised pre-training methods on large-scale web data in a like-for-like setting. We compare a range of methods, including single-modal ones that use masked training objectives and multi-modal ones that use image-text constrastive training. We observe that existing multi-modal methods do not outperform their single-modal counterparts on vision transfer learning tasks. We derive an information-theoretical view to explain these benchmark results, which provides insight into how to design a novel vision learner. Inspired by this insight, we present a new visual representation pre-training method, MUlti-modal Generator~(MUG), that learns from
    
[^145]: 不同环境中决策时刻与背景规划方法的基于价值决策比较

    A Look at Value-Based Decision-Time vs. Background Planning Methods Across Different Settings

    [https://arxiv.org/abs/2206.08442](https://arxiv.org/abs/2206.08442)

    本研究比较了不同环境中基于价值的决策时刻规划和背景规划方法的有效性，并在理论上和实验中验证了哪一种方法在改进代理行为方面表现更好。

    

    arXiv:2206.08442v2 公告类型：替换交叉 摘要：在基于模型的强化学习（RL）中，代理可以利用学习到的模型以不同的方式改进其行为。两者的常见方式是通过决策时刻规划和背景规划方法。本研究旨在了解在不同的环境中，基于价值的决策时刻规划和背景规划方法之间的比较。为此目标，我们首先考虑基于价值的决策时刻和背景规划方法的简化实例，并提供理论结果，说明在常规的RL和转移学习环境中，哪一种方法会表现得更好。然后，我们考虑它们在同一环境中的现代实例，并提出关于在同一环境中哪一种方法会表现更好的假设。最后，我们进行 illustrative 实验来验证这些理论结果和假设。总体来看，我们的发现表明，尽管基于价值的决策时刻规划方法可能会在某些环境中比背景规划方法表现得更好，但实际情况可能会根据不同的环境和任务而有所不同。在一个特定的任务上，决策时刻规划可能会优于背景规划，而在另一个任务上，背景规划可能会更有优势。总的来说，我们的研究表明在不同的设置中考虑基于价值的决策时刻规划和背景规划方法时，需要进行具体的评估和比较。

    arXiv:2206.08442v2 Announce Type: replace-cross  Abstract: In model-based reinforcement learning (RL), an agent can leverage a learned model to improve its way of behaving in different ways. Two of the prevalent ways to do this are through decision-time and background planning methods. In this study, we are interested in understanding how the value-based versions of these two planning methods will compare against each other across different settings. Towards this goal, we first consider the simplest instantiations of value-based decision-time and background planning methods and provide theoretical results on which one will perform better in the regular RL and transfer learning settings. Then, we consider the modern instantiations of them and provide hypotheses on which one will perform better in the same settings. Finally, we perform illustrative experiments to validate these theoretical results and hypotheses. Overall, our findings suggest that even though value-based versions of the 
    
[^146]: 基于自语义蒸馏的知识图嵌入置信度感知

    Confidence-aware Self-Semantic Distillation on Knowledge Graph Embedding

    [https://arxiv.org/abs/2206.02963](https://arxiv.org/abs/2206.02963)

    本文提出了一种基于自语义蒸馏的知识图嵌入方法，该方法利用自我知识蒸馏增强KGE在低维空间中的性能，无需预训练的高维模型，且操作简单。

    

    arXiv:2206.02963v3 公告类型：替换交叉 摘要：知识图嵌入（KGE），即将实体和关系映射到连续的向量空间中，已经吸引了大量关注。虽然高维KGE方法提供了更好的性能，但它们以显著的计算和内存开销为代价。降低嵌入维度显著降低了模型性能。尽管最近的一些努力利用知识蒸馏或非欧几里得表示学习来提高低维KGE的有效性，但它们要么需要一个预先训练的高维教师模型，要么涉及复杂的非欧几里得操作，从而增加了相当多的额外计算成本。为了解决这一问题，这项工作提出了一种基于置信度感知自我知识蒸馏（CSD）的方法，该方法在低维空间中从自身学习以增强KGE。具体来说，CSD从以前迭代的嵌入中提取知识，这些知识可以根据学习到的模型性能视为正确的或错误的，从而改进了低维KGE模型。通过这种方式，CSD为低维KGE的性能提升提供了一种实用且引人注目的解决方案。

    arXiv:2206.02963v3 Announce Type: replace-cross  Abstract: Knowledge Graph Embedding (KGE), which projects entities and relations into continuous vector spaces, has garnered significant attention. Although high-dimensional KGE methods offer better performance, they come at the expense of significant computation and memory overheads. Decreasing embedding dimensions significantly deteriorates model performance. While several recent efforts utilize knowledge distillation or non-Euclidean representation learning to augment the effectiveness of low-dimensional KGE, they either necessitate a pre-trained high-dimensional teacher model or involve complex non-Euclidean operations, thereby incurring considerable additional computational costs. To address this, this work proposes Confidence-aware Self-Knowledge Distillation (CSD) that learns from the model itself to enhance KGE in a low-dimensional space. Specifically, CSD extracts knowledge from embeddings in previous iterations, which would be 
    

