{
    "title": "Paying U-Attention to Textures: Multi-Stage Hourglass Vision Transformer for Universal Texture Synthesis",
    "abstract": "arXiv:2202.11703v3 Announce Type: replace  Abstract: We present a novel U-Attention vision Transformer for universal texture synthesis. We exploit the natural long-range dependencies enabled by the attention mechanism to allow our approach to synthesize diverse textures while preserving their structures in a single inference. We propose a hierarchical hourglass backbone that attends to the global structure and performs patch mapping at varying scales in a coarse-to-fine-to-coarse stream. Completed by skip connection and convolution designs that propagate and fuse information at different scales, our hierarchical U-Attention architecture unifies attention to features from macro structures to micro details, and progressively refines synthesis results at successive stages. Our method achieves stronger 2$\\times$ synthesis than previous work on both stochastic and structured textures while generalizing to unseen textures without fine-tuning. Ablation studies demonstrate the effectiveness of",
    "link": "https://arxiv.org/abs/2202.11703",
    "context": "Title: Paying U-Attention to Textures: Multi-Stage Hourglass Vision Transformer for Universal Texture Synthesis\nAbstract: arXiv:2202.11703v3 Announce Type: replace  Abstract: We present a novel U-Attention vision Transformer for universal texture synthesis. We exploit the natural long-range dependencies enabled by the attention mechanism to allow our approach to synthesize diverse textures while preserving their structures in a single inference. We propose a hierarchical hourglass backbone that attends to the global structure and performs patch mapping at varying scales in a coarse-to-fine-to-coarse stream. Completed by skip connection and convolution designs that propagate and fuse information at different scales, our hierarchical U-Attention architecture unifies attention to features from macro structures to micro details, and progressively refines synthesis results at successive stages. Our method achieves stronger 2$\\times$ synthesis than previous work on both stochastic and structured textures while generalizing to unseen textures without fine-tuning. Ablation studies demonstrate the effectiveness of",
    "path": "papers/22/02/2202.11703.json",
    "total_tokens": 440,
    "tldr": "该文章提出了一种新型的U-Attention Vision Transformer，用于实现对多种类型纹理的无监督合成。该模型通过使用自注意力机制来捕捉纹理中的长期依赖关系，能在一次推理过程中合成出具有特定结构的不同纹理。论文中的模型架构包括一个层次化的“hourglass”网络，它能够在一系列分辨率的架构中分别关注纹理的宏观结构和微观细节，并且在细化合成结果的过程中实现从粗到精再到粗的多次操作。通过在不同的尺度上使用信息传播和融合的设计，该模型有效地结合了对纹理特征的注意力处理，并在结构和细节上实现了更好的合成效果。实验结果表明，该模型在纹理合成任务上取得了显著的性能提升，并且没有进行任何形式的微调。"
}