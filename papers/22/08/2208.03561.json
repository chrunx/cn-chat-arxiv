{
    "title": "Study of detecting behavioral signatures within DeepFake videos",
    "abstract": "arXiv:2208.03561v2 Announce Type: replace  Abstract: There is strong interest in the generation of synthetic video imagery of people talking for various purposes, including entertainment, communication, training, and advertisement. With the development of deep fake generation models, synthetic video imagery will soon be visually indistinguishable to the naked eye from a naturally capture video. In addition, many methods are continuing to improve to avoid more careful, forensic visual analysis. Some deep fake videos are produced through the use of facial puppetry, which directly controls the head and face of the synthetic image through the movements of the actor, allow the actor to 'puppet' the image of another. In this paper, we address the question of whether one person's movements can be distinguished from the original speaker by controlling the visual appearance of the speaker but transferring the behavior signals from another source. We conduct a study by comparing synthetic imager",
    "link": "https://arxiv.org/abs/2208.03561",
    "context": "Title: Study of detecting behavioral signatures within DeepFake videos\nAbstract: arXiv:2208.03561v2 Announce Type: replace  Abstract: There is strong interest in the generation of synthetic video imagery of people talking for various purposes, including entertainment, communication, training, and advertisement. With the development of deep fake generation models, synthetic video imagery will soon be visually indistinguishable to the naked eye from a naturally capture video. In addition, many methods are continuing to improve to avoid more careful, forensic visual analysis. Some deep fake videos are produced through the use of facial puppetry, which directly controls the head and face of the synthetic image through the movements of the actor, allow the actor to 'puppet' the image of another. In this paper, we address the question of whether one person's movements can be distinguished from the original speaker by controlling the visual appearance of the speaker but transferring the behavior signals from another source. We conduct a study by comparing synthetic imager",
    "path": "papers/22/08/2208.03561.json",
    "total_tokens": 309,
    "tldr": "该文章研究了在深度伪造视频中检测行为标志的创新方法，能够通过控制视觉外观并转移行为信号来自其他源的方式，来区分一个人与其他说话者的行为标志。"
}