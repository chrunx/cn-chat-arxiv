{
    "title": "MunchSonic: Tracking Fine-grained Dietary Actions through Active Acoustic Sensing on Eyeglasses",
    "abstract": "arXiv:2405.21004v2 Announce Type: replace-cross  Abstract: We introduce MunchSonic, an AI-powered active acoustic sensing system integrated into eyeglasses to track fine-grained dietary actions. MunchSonic emits inaudible ultrasonic waves from the eyeglass frame, with the reflected signals capturing detailed positions and movements of body parts, including the mouth, jaw, arms, and hands involved in eating. These signals are processed by a deep learning pipeline to classify six actions: hand-to-mouth movements for food intake, chewing, drinking, talking, face-hand touching, and other activities (null). In an unconstrained study with 12 participants, MunchSonic achieved a 93.5% macro F1-score in a user-independent evaluation with a 2-second resolution in tracking these actions, also demonstrating its effectiveness in tracking eating episodes and food intake frequency within those episodes.",
    "link": "https://arxiv.org/abs/2405.21004",
    "context": "Title: MunchSonic: Tracking Fine-grained Dietary Actions through Active Acoustic Sensing on Eyeglasses\nAbstract: arXiv:2405.21004v2 Announce Type: replace-cross  Abstract: We introduce MunchSonic, an AI-powered active acoustic sensing system integrated into eyeglasses to track fine-grained dietary actions. MunchSonic emits inaudible ultrasonic waves from the eyeglass frame, with the reflected signals capturing detailed positions and movements of body parts, including the mouth, jaw, arms, and hands involved in eating. These signals are processed by a deep learning pipeline to classify six actions: hand-to-mouth movements for food intake, chewing, drinking, talking, face-hand touching, and other activities (null). In an unconstrained study with 12 participants, MunchSonic achieved a 93.5% macro F1-score in a user-independent evaluation with a 2-second resolution in tracking these actions, also demonstrating its effectiveness in tracking eating episodes and food intake frequency within those episodes.",
    "path": "papers/24/05/2405.21004.json",
    "total_tokens": 398,
    "tldr": "该文章创新地提出了一种集成在眼镜上的主动声学传感器系统MunchSonic，能够通过发射不可见超声波并分析反射信号来精确追踪饮食行为中的精细动作。这项技术不仅能区分六种不同的饮食动作（如咀嚼、喝水、说话等），还能在无约束环境中对12名参与者进行测试，并且展现出了高达93.5%的宏观F1分数的性能，显示出其在跟踪饮食行为和食物摄入频率方面的有效性。"
}