{
    "title": "Reduced storage direct tensor ring decomposition for convolutional neural networks compression",
    "abstract": "arXiv:2405.10802v2 Announce Type: replace  Abstract: Convolutional neural networks (CNNs) are among the most widely used machine learning models for computer vision tasks, such as image classification. To improve the efficiency of CNNs, many CNNs compressing approaches have been developed. Low-rank methods approximate the original convolutional kernel with a sequence of smaller convolutional kernels, which leads to reduced storage and time complexities. In this study, we propose a novel low-rank CNNs compression method that is based on reduced storage direct tensor ring decomposition (RSDTR). The proposed method offers a higher circular mode permutation flexibility, and it is characterized by large parameter and FLOPS compression rates, while preserving a good classification accuracy of the compressed network. The experiments, performed on the CIFAR-10 and ImageNet datasets, clearly demonstrate the efficiency of RSDTR in comparison to other state-of-the-art CNNs compression approaches.",
    "link": "https://arxiv.org/abs/2405.10802",
    "context": "Title: Reduced storage direct tensor ring decomposition for convolutional neural networks compression\nAbstract: arXiv:2405.10802v2 Announce Type: replace  Abstract: Convolutional neural networks (CNNs) are among the most widely used machine learning models for computer vision tasks, such as image classification. To improve the efficiency of CNNs, many CNNs compressing approaches have been developed. Low-rank methods approximate the original convolutional kernel with a sequence of smaller convolutional kernels, which leads to reduced storage and time complexities. In this study, we propose a novel low-rank CNNs compression method that is based on reduced storage direct tensor ring decomposition (RSDTR). The proposed method offers a higher circular mode permutation flexibility, and it is characterized by large parameter and FLOPS compression rates, while preserving a good classification accuracy of the compressed network. The experiments, performed on the CIFAR-10 and ImageNet datasets, clearly demonstrate the efficiency of RSDTR in comparison to other state-of-the-art CNNs compression approaches.",
    "path": "papers/24/05/2405.10802.json",
    "total_tokens": 670,
    "translated_title": "使用减少存储的直接张量环分解技术压缩卷积神经网络",
    "translated_abstract": "arXiv:2405.10802v2 公告类型：替换",
    "tldr": "本文提出了一种基于减少存储直接张量环分解的新型CNNs压缩方法，该方法在保持高分类准确性的同时，实现了参数和计算复杂度的大幅降低，并在CIFAR-10和ImageNet数据集上得到了验证。"
}