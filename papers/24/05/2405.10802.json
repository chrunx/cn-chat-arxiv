{
    "title": "Reduced storage direct tensor ring decomposition for convolutional neural networks compression",
    "abstract": "arXiv:2405.10802v2 Announce Type: replace  Abstract: Convolutional neural networks (CNNs) are among the most widely used machine learning models for computer vision tasks, such as image classification. To improve the efficiency of CNNs, many CNNs compressing approaches have been developed. Low-rank methods approximate the original convolutional kernel with a sequence of smaller convolutional kernels, which leads to reduced storage and time complexities. In this study, we propose a novel low-rank CNNs compression method that is based on reduced storage direct tensor ring decomposition (RSDTR). The proposed method offers a higher circular mode permutation flexibility, and it is characterized by large parameter and FLOPS compression rates, while preserving a good classification accuracy of the compressed network. The experiments, performed on the CIFAR-10 and ImageNet datasets, clearly demonstrate the efficiency of RSDTR in comparison to other state-of-the-art CNNs compression approaches.",
    "link": "https://arxiv.org/abs/2405.10802",
    "context": "Title: Reduced storage direct tensor ring decomposition for convolutional neural networks compression\nAbstract: arXiv:2405.10802v2 Announce Type: replace  Abstract: Convolutional neural networks (CNNs) are among the most widely used machine learning models for computer vision tasks, such as image classification. To improve the efficiency of CNNs, many CNNs compressing approaches have been developed. Low-rank methods approximate the original convolutional kernel with a sequence of smaller convolutional kernels, which leads to reduced storage and time complexities. In this study, we propose a novel low-rank CNNs compression method that is based on reduced storage direct tensor ring decomposition (RSDTR). The proposed method offers a higher circular mode permutation flexibility, and it is characterized by large parameter and FLOPS compression rates, while preserving a good classification accuracy of the compressed network. The experiments, performed on the CIFAR-10 and ImageNet datasets, clearly demonstrate the efficiency of RSDTR in comparison to other state-of-the-art CNNs compression approaches.",
    "path": "papers/24/05/2405.10802.json",
    "total_tokens": 348,
    "tldr": "该文章提出了一种基于减少存储的直接张量环分解（RSDTR）的 convolutional neural networks (CNNs) 压缩方法，该方法通过更高的循环模式排列灵活性和较大的参数和FLOPS压缩率，在保持良好的压缩网络分类精度方面表现出了比其他当前先进CNN压缩方法的效率。"
}