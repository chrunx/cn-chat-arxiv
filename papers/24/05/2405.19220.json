{
    "title": "WRDScore: New Metric for Evaluation of Natural Language Generation Models",
    "abstract": "arXiv:2405.19220v4 Announce Type: replace-cross  Abstract: Evaluating natural language generation models, particularly for method name prediction, poses significant challenges. A robust metric must account for the versatility of method naming, considering both semantic and syntactic variations. Traditional overlap-based metrics fail to capture these nuances. Existing embedding-based metrics often suffer from imbalanced precision and recall, lack normalized scores, or make unrealistic assumptions about sequences. To address these limitations, we propose WRDScore, a novel metric that strikes a balance between simplicity and effectiveness. Our metric is lightweight, normalized, and precision-recall-oriented, avoiding unrealistic assumptions while aligning well with human judgments.",
    "link": "https://arxiv.org/abs/2405.19220",
    "context": "Title: WRDScore: New Metric for Evaluation of Natural Language Generation Models\nAbstract: arXiv:2405.19220v4 Announce Type: replace-cross  Abstract: Evaluating natural language generation models, particularly for method name prediction, poses significant challenges. A robust metric must account for the versatility of method naming, considering both semantic and syntactic variations. Traditional overlap-based metrics fail to capture these nuances. Existing embedding-based metrics often suffer from imbalanced precision and recall, lack normalized scores, or make unrealistic assumptions about sequences. To address these limitations, we propose WRDScore, a novel metric that strikes a balance between simplicity and effectiveness. Our metric is lightweight, normalized, and precision-recall-oriented, avoiding unrealistic assumptions while aligning well with human judgments.",
    "path": "papers/24/05/2405.19220.json",
    "total_tokens": 318,
    "tldr": "该文章提出了一个新的自然语言生成模型评估指标WRDScore，它能够综合考虑方法的命名多样性，包括语义和语法上的差异，有效地解决了传统评估方法无法全面捕捉这些差异的难题。WRDScore是一个轻量级、标准化且精度-召回度量相结合的指标，避免了现有方法中可能存在的假设不足的问题，并更贴合人类对评估结果的判断。"
}