{
    "title": "Eliciting Informative Text Evaluations with Large Language Models",
    "abstract": "arXiv:2405.15077v3 Announce Type: replace-cross  Abstract: Peer prediction mechanisms motivate high-quality feedback with provable guarantees. However, current methods only apply to rather simple reports, like multiple-choice or scalar numbers. We aim to broaden these techniques to the larger domain of text-based reports, drawing on the recent developments in large language models. This vastly increases the applicability of peer prediction mechanisms as textual feedback is the norm in a large variety of feedback channels: peer reviews, e-commerce customer reviews, and comments on social media.   We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM) and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms utilize LLMs as predictors, mapping from one agent's report to a prediction of her peer's report. Theoretically, we show that when the LLM prediction is sufficiently accurate, our mechanisms can incentivize high effort and truth-telling as ",
    "link": "https://arxiv.org/abs/2405.15077",
    "context": "Title: Eliciting Informative Text Evaluations with Large Language Models\nAbstract: arXiv:2405.15077v3 Announce Type: replace-cross  Abstract: Peer prediction mechanisms motivate high-quality feedback with provable guarantees. However, current methods only apply to rather simple reports, like multiple-choice or scalar numbers. We aim to broaden these techniques to the larger domain of text-based reports, drawing on the recent developments in large language models. This vastly increases the applicability of peer prediction mechanisms as textual feedback is the norm in a large variety of feedback channels: peer reviews, e-commerce customer reviews, and comments on social media.   We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM) and the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms utilize LLMs as predictors, mapping from one agent's report to a prediction of her peer's report. Theoretically, we show that when the LLM prediction is sufficiently accurate, our mechanisms can incentivize high effort and truth-telling as ",
    "path": "papers/24/05/2405.15077.json",
    "total_tokens": 617,
    "translated_title": "使用大型语言模型获取信息丰富的文本评估",
    "translated_abstract": "摘要：同行预测机制以有保证的保证激励高质量的反馈。然而，现有的方法只适用于相当简单的报告，如多项选择或标量数字。我们的目的是将这些技术扩展到文本报告的大领域，利用大型语言模型最近的发展。这大大扩展了同行预测机制的适用范围，因为文本反馈在大量反馈渠道中很常见：同行评审、电子商务顾客评价和社会媒体上的评论。我们介绍两种机制，即生成性同行预测机制（GPPM）和生成性概要同行预测机制（GSPPM）。这些机制利用LLM作为预测器，从一个人的报告中映射到对她的同伴报告的预测。从理论上讲，我们证明当LLM的预测足够准确时，我们的机制可以激励高强度的努力并说实话，",
    "tldr": "本文提出了一种使用大型语言模型提高信息丰富文本评估机制的效力的方法，旨在扩大同行预测机制的应用范围。"
}