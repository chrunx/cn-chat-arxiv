{
    "title": "Hummer: Towards Limited Competitive Preference Dataset",
    "abstract": "arXiv:2405.11647v3 Announce Type: replace  Abstract: Preference datasets are essential for incorporating human preferences into pre-trained language models, playing a key role in the success of Reinforcement Learning from Human Feedback. However, these datasets often demonstrate conflicting alignment objectives, leading to increased vulnerability to jailbreak attacks and challenges in adapting downstream tasks to prioritize specific alignment objectives without negatively impacting others. In this work, we introduce a novel statistical metric, Alignment Dimension Conflict, to quantify the degree of conflict within preference datasets. We then present \\texttt{Hummer} and its fine-grained variant, \\texttt{Hummer-F}, as innovative pairwise preference datasets with reduced-conflict alignment objectives. \\texttt{Hummer} is built based on UltraFeedback and is enhanced by AI feedback from GPT-4, marking as the first preference dataset aimed at reducing the competition between alignment object",
    "link": "https://arxiv.org/abs/2405.11647",
    "context": "Title: Hummer: Towards Limited Competitive Preference Dataset\nAbstract: arXiv:2405.11647v3 Announce Type: replace  Abstract: Preference datasets are essential for incorporating human preferences into pre-trained language models, playing a key role in the success of Reinforcement Learning from Human Feedback. However, these datasets often demonstrate conflicting alignment objectives, leading to increased vulnerability to jailbreak attacks and challenges in adapting downstream tasks to prioritize specific alignment objectives without negatively impacting others. In this work, we introduce a novel statistical metric, Alignment Dimension Conflict, to quantify the degree of conflict within preference datasets. We then present \\texttt{Hummer} and its fine-grained variant, \\texttt{Hummer-F}, as innovative pairwise preference datasets with reduced-conflict alignment objectives. \\texttt{Hummer} is built based on UltraFeedback and is enhanced by AI feedback from GPT-4, marking as the first preference dataset aimed at reducing the competition between alignment object",
    "path": "papers/24/05/2405.11647.json",
    "total_tokens": 321,
    "tldr": "该文章提出了一种名为“Hummer”的偏好数据集，旨在减少偏好数据集中不同对齐目标之间的冲突，从而提高从人类反馈中学习的算法的鲁棒性和有效性。"
}