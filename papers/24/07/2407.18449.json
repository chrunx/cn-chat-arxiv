{
    "title": "Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation",
    "abstract": "arXiv:2407.18449v2 Announce Type: replace-cross  Abstract: Foundation models pretrained on large-scale datasets are revolutionizing the field of computational pathology (CPath). The generalization ability of foundation models is crucial for the success in various downstream clinical tasks. However, current foundation models have only been evaluated on a limited type and number of tasks, leaving their generalization ability and overall performance unclear. To address this gap, we established a most comprehensive benchmark to evaluate the performance of off-the-shelf foundation models across six distinct clinical task types, encompassing a total of 39 specific tasks. Our findings reveal that existing foundation models excel at certain task types but struggle to effectively handle the full breadth of clinical tasks. To improve the generalization of pathology foundation models, we propose a unified knowledge distillation framework consisting of both expert and self knowledge distillation, ",
    "link": "https://arxiv.org/abs/2407.18449",
    "context": "Title: Towards A Generalizable Pathology Foundation Model via Unified Knowledge Distillation\nAbstract: arXiv:2407.18449v2 Announce Type: replace-cross  Abstract: Foundation models pretrained on large-scale datasets are revolutionizing the field of computational pathology (CPath). The generalization ability of foundation models is crucial for the success in various downstream clinical tasks. However, current foundation models have only been evaluated on a limited type and number of tasks, leaving their generalization ability and overall performance unclear. To address this gap, we established a most comprehensive benchmark to evaluate the performance of off-the-shelf foundation models across six distinct clinical task types, encompassing a total of 39 specific tasks. Our findings reveal that existing foundation models excel at certain task types but struggle to effectively handle the full breadth of clinical tasks. To improve the generalization of pathology foundation models, we propose a unified knowledge distillation framework consisting of both expert and self knowledge distillation, ",
    "path": "papers/24/07/2407.18449.json",
    "total_tokens": 314,
    "tldr": "该文章提出了一个统一的见解去除框架来改进病理学基础模型的泛化能力，该框架通过专家和自我见解去除技术将知识赋予基础模型，从而有助于其在多个不同临床任务上的有效性能。"
}