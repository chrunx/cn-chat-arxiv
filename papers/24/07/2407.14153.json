{
    "title": "ESP-MedSAM: Efficient Self-Prompting SAM for Universal Image Segmentation",
    "abstract": "arXiv:2407.14153v2 Announce Type: replace-cross  Abstract: The Segment Anything Model (SAM) has demonstrated outstanding adaptation to medical image segmentation but still faces three major challenges. Firstly, the huge computational costs of SAM limit its real-world applicability. Secondly, SAM depends on manual annotations (e.g., points, boxes) as prompts, which are laborious and impractical in clinical scenarios. Thirdly, SAM handles all segmentation targets equally, which is suboptimal for diverse medical modalities with inherent heterogeneity. To address these issues, we propose an Efficient Self-Prompting SAM for universal medical image segmentation, named ESP-MedSAM. We devise a Multi-Modal Decoupled Knowledge Distillation (MMDKD) strategy to distil common image knowledge and domain-specific medical knowledge from the foundation model to train a lightweight image encoder and a modality controller. Further, they combine with the additionally introduced Self-Patch Prompt Generator",
    "link": "https://arxiv.org/abs/2407.14153",
    "context": "Title: ESP-MedSAM: Efficient Self-Prompting SAM for Universal Image Segmentation\nAbstract: arXiv:2407.14153v2 Announce Type: replace-cross  Abstract: The Segment Anything Model (SAM) has demonstrated outstanding adaptation to medical image segmentation but still faces three major challenges. Firstly, the huge computational costs of SAM limit its real-world applicability. Secondly, SAM depends on manual annotations (e.g., points, boxes) as prompts, which are laborious and impractical in clinical scenarios. Thirdly, SAM handles all segmentation targets equally, which is suboptimal for diverse medical modalities with inherent heterogeneity. To address these issues, we propose an Efficient Self-Prompting SAM for universal medical image segmentation, named ESP-MedSAM. We devise a Multi-Modal Decoupled Knowledge Distillation (MMDKD) strategy to distil common image knowledge and domain-specific medical knowledge from the foundation model to train a lightweight image encoder and a modality controller. Further, they combine with the additionally introduced Self-Patch Prompt Generator",
    "path": "papers/24/07/2407.14153.json",
    "total_tokens": 472,
    "tldr": "该文章提出了一种名为ESP-MedSAM的 efficient self-prompting SAM（Segment Anything Model），针对医疗图像 segmentation 的三个主要挑战：显著降低计算成本、简化数据标注过程并提升对不同医疗模态的适应性。通过 Multi-Modal Decoupled Knowledge Distillation（MMDKD）策略，文章创新性地将通用的图像知识和特定于医学领域的知识从基础模型中提炼出来，用于训练一个轻量级的图像编码器和一种称为 modality controller 的模块，以此减轻了专家标注的负担并提高了模型在不同医学模态上的性能。 Additionally, a self-patch prompting generator was introduced to further enhance the model's ability to adapt to diverse medical imaging tasks, making ESP-MedSAM a significant improvement over previous SAM models in terms of efficiency and applicability for medical image segmentation."
}