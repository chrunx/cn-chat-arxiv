{
    "title": "Bridging Smoothness and Approximation: Theoretical Insights into Over-Smoothing in Graph Neural Networks",
    "abstract": "arXiv:2407.01281v2 Announce Type: replace-cross  Abstract: In this paper, we explore the approximation theory of functions defined on graphs. Our study builds upon the approximation results derived from the $K$-functional. We establish a theoretical framework to assess the lower bounds of approximation for target functions using Graph Convolutional Networks (GCNs) and examine the over-smoothing phenomenon commonly observed in these networks. Initially, we introduce the concept of a $K$-functional on graphs, establishing its equivalence to the modulus of smoothness. We then analyze a typical type of GCN to demonstrate how the high-frequency energy of the output decays, an indicator of over-smoothing. This analysis provides theoretical insights into the nature of over-smoothing within GCNs. Furthermore, we establish a lower bound for the approximation of target functions by GCNs, which is governed by the modulus of smoothness of these functions. This finding offers a new perspective on t",
    "link": "https://arxiv.org/abs/2407.01281",
    "context": "Title: Bridging Smoothness and Approximation: Theoretical Insights into Over-Smoothing in Graph Neural Networks\nAbstract: arXiv:2407.01281v2 Announce Type: replace-cross  Abstract: In this paper, we explore the approximation theory of functions defined on graphs. Our study builds upon the approximation results derived from the $K$-functional. We establish a theoretical framework to assess the lower bounds of approximation for target functions using Graph Convolutional Networks (GCNs) and examine the over-smoothing phenomenon commonly observed in these networks. Initially, we introduce the concept of a $K$-functional on graphs, establishing its equivalence to the modulus of smoothness. We then analyze a typical type of GCN to demonstrate how the high-frequency energy of the output decays, an indicator of over-smoothing. This analysis provides theoretical insights into the nature of over-smoothing within GCNs. Furthermore, we establish a lower bound for the approximation of target functions by GCNs, which is governed by the modulus of smoothness of these functions. This finding offers a new perspective on t",
    "path": "papers/24/07/2407.01281.json",
    "total_tokens": 656,
    "translated_title": "标题：平滑性与逼近之间的桥梁：图神经网络中过度平滑的理论上洞察",
    "translated_abstract": "摘要：在这项研究中，我们探索了定义在图上函数的逼近理论。我们的研究建立在从$K$函数性导出的逼近结果的基础上。我们建立了一个理论框架，来评估目标函数使用图卷积网络（GCN）逼近的下界，并考察这些网络中常见的过度平滑现象。首先，我们对图上的$K$函数性进行了介绍，并建立了它与模光滑性之间的等价性。随后，我们分析了一种典型的GCN类型，展示了输出中高频能量的衰减，这表明了过度平滑的现象。这项分析为GCN中过度平滑的本质提供了理论见解。此外，我们还建立了目标函数由GCNs逼近的下界，这个下界是由这些函数的模光滑性支配的。这一发现为理解GCN中过度平滑的问题提供了新的视角。",
    "tldr": "这项研究通过建立理论框架评估了图卷积网络逼近目标函数的限度，揭示了过度平滑现象的本质，并提出了新的视角来理解该问题。",
    "en_tdlr": "This study establishes theoretical insights into the over-smoothing phenomenon in Graph Neural Networks, offering a new perspective on the limitations of Graph Convolutional Networks' approximation of target functions."
}