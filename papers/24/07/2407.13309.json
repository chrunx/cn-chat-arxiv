{
    "title": "Exposure Completing for Temporally Consistent Neural High Dynamic Range Video Rendering",
    "abstract": "arXiv:2407.13309v2 Announce Type: replace  Abstract: High dynamic range (HDR) video rendering from low dynamic range (LDR) videos where frames are of alternate exposure encounters significant challenges, due to the exposure change and absence at each time stamp. The exposure change and absence make existing methods generate flickering HDR results. In this paper, we propose a novel paradigm to render HDR frames via completing the absent exposure information, hence the exposure information is complete and consistent. Our approach involves interpolating neighbor LDR frames in the time dimension to reconstruct LDR frames for the absent exposures. Combining the interpolated and given LDR frames, the complete set of exposure information is available at each time stamp. This benefits the fusing process for HDR results, reducing noise and ghosting artifacts therefore improving temporal consistency. Extensive experimental evaluations on standard benchmarks demonstrate that our method achieves s",
    "link": "https://arxiv.org/abs/2407.13309",
    "context": "Title: Exposure Completing for Temporally Consistent Neural High Dynamic Range Video Rendering\nAbstract: arXiv:2407.13309v2 Announce Type: replace  Abstract: High dynamic range (HDR) video rendering from low dynamic range (LDR) videos where frames are of alternate exposure encounters significant challenges, due to the exposure change and absence at each time stamp. The exposure change and absence make existing methods generate flickering HDR results. In this paper, we propose a novel paradigm to render HDR frames via completing the absent exposure information, hence the exposure information is complete and consistent. Our approach involves interpolating neighbor LDR frames in the time dimension to reconstruct LDR frames for the absent exposures. Combining the interpolated and given LDR frames, the complete set of exposure information is available at each time stamp. This benefits the fusing process for HDR results, reducing noise and ghosting artifacts therefore improving temporal consistency. Extensive experimental evaluations on standard benchmarks demonstrate that our method achieves s",
    "path": "papers/24/07/2407.13309.json",
    "total_tokens": 337,
    "tldr": "该文章提出了一种新的方法来渲染时间一致的神经高动态范围视频，通过在时间维度上插值相邻的低动态范围帧来重建缺失曝光信息的低动态范围帧，从而在每个时间戳上提供完整的曝光信息，提高了HDR视频的渲染质量。"
}