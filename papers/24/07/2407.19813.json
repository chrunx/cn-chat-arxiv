{
    "title": "Improving Retrieval Augmented Language Model with Self-Reasoning",
    "abstract": "arXiv:2407.19813v2 Announce Type: replace-cross  Abstract: The Retrieval-Augmented Language Model (RALM) has shown remarkable performance on knowledge-intensive tasks by incorporating external knowledge during inference, which mitigates the factual hallucinations inherited in large language models (LLMs). Despite these advancements, challenges persist in the implementation of RALMs, particularly concerning their reliability and traceability. To be specific, the irrelevant document retrieval may result in unhelpful response generation or even deteriorate the performance of LLMs, while the lack of proper citations in generated outputs complicates efforts to verify the trustworthiness of the models. To this end, we propose a novel self-reasoning framework aimed at improving the reliability and traceability of RALMs, whose core idea is to leverage reasoning trajectories generated by the LLM itself. The framework involves constructing self-reason trajectories with three processes: a relevan",
    "link": "https://arxiv.org/abs/2407.19813",
    "context": "Title: Improving Retrieval Augmented Language Model with Self-Reasoning\nAbstract: arXiv:2407.19813v2 Announce Type: replace-cross  Abstract: The Retrieval-Augmented Language Model (RALM) has shown remarkable performance on knowledge-intensive tasks by incorporating external knowledge during inference, which mitigates the factual hallucinations inherited in large language models (LLMs). Despite these advancements, challenges persist in the implementation of RALMs, particularly concerning their reliability and traceability. To be specific, the irrelevant document retrieval may result in unhelpful response generation or even deteriorate the performance of LLMs, while the lack of proper citations in generated outputs complicates efforts to verify the trustworthiness of the models. To this end, we propose a novel self-reasoning framework aimed at improving the reliability and traceability of RALMs, whose core idea is to leverage reasoning trajectories generated by the LLM itself. The framework involves constructing self-reason trajectories with three processes: a relevan",
    "path": "papers/24/07/2407.19813.json",
    "total_tokens": 795,
    "translated_title": "论文标题 ： 《通过自我推理改进检索增强的语言模型》",
    "translated_abstract": "",
    "tldr": "本文提出了一种自我推理框架，旨在改进检索增强的语言模型的可靠性和可追溯性，通过在生成过程中整合外部知识，减少无帮助或误导性响应的产生，并改善模型的透明度和可信度。"
}