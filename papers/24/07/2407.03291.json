{
    "title": "VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation",
    "abstract": "arXiv:2407.03291v2 Announce Type: replace-cross  Abstract: Complex human activity recognition (CHAR) remains a pivotal challenge within ubiquitous computing, especially in the context of smart environments. Existing studies typically require meticulous labeling of both atomic and complex activities, a task that is labor-intensive and prone to errors due to the scarcity and inaccuracies of available datasets. Most prior research has focused on datasets that either precisely label atomic activities or, at minimum, their sequence approaches that are often impractical in real world settings.In response, we introduce VCHAR (Variance-Driven Complex Human Activity Recognition), a novel framework that treats the outputs of atomic activities as a distribution over specified intervals. Leveraging generative methodologies, VCHAR elucidates the reasoning behind complex activity classifications through video-based explanations, accessible to users without prior machine learning expertise. Our evalu",
    "link": "https://arxiv.org/abs/2407.03291",
    "context": "Title: VCHAR:Variance-Driven Complex Human Activity Recognition framework with Generative Representation\nAbstract: arXiv:2407.03291v2 Announce Type: replace-cross  Abstract: Complex human activity recognition (CHAR) remains a pivotal challenge within ubiquitous computing, especially in the context of smart environments. Existing studies typically require meticulous labeling of both atomic and complex activities, a task that is labor-intensive and prone to errors due to the scarcity and inaccuracies of available datasets. Most prior research has focused on datasets that either precisely label atomic activities or, at minimum, their sequence approaches that are often impractical in real world settings.In response, we introduce VCHAR (Variance-Driven Complex Human Activity Recognition), a novel framework that treats the outputs of atomic activities as a distribution over specified intervals. Leveraging generative methodologies, VCHAR elucidates the reasoning behind complex activity classifications through video-based explanations, accessible to users without prior machine learning expertise. Our evalu",
    "path": "papers/24/07/2407.03291.json",
    "total_tokens": 318,
    "tldr": "该文章提出了VCHAR框架，一种基于variances驱动的复杂人类活动识别方法，该方法通过生成表示来有效识别和解释视频中的复杂活动，从而减少了传统的标签化负担。"
}