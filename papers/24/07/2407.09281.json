{
    "title": "Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning",
    "abstract": "arXiv:2407.09281v2 Announce Type: replace  Abstract: Large Language Models (LLMs) have demonstrated their capabilities across various tasks, from language translation to complex reasoning. Understanding and predicting human behavior and biases are crucial for artificial intelligence (AI) assisted systems to provide useful assistance, yet it remains an open question whether these models can achieve this. This paper addresses this gap by leveraging the reasoning and generative capabilities of the LLMs to predict human behavior in two sequential decision-making tasks. These tasks involve balancing between exploitative and exploratory actions and handling delayed feedback, both essential for simulating real-life decision processes. We compare the performance of LLMs with a cognitive instance-based learning (IBL) model, which imitates human experiential decision-making. Our findings indicate that LLMs excel at rapidly incorporating feedback to enhance prediction accuracy. In contrast, the c",
    "link": "https://arxiv.org/abs/2407.09281",
    "context": "Title: Predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning\nAbstract: arXiv:2407.09281v2 Announce Type: replace  Abstract: Large Language Models (LLMs) have demonstrated their capabilities across various tasks, from language translation to complex reasoning. Understanding and predicting human behavior and biases are crucial for artificial intelligence (AI) assisted systems to provide useful assistance, yet it remains an open question whether these models can achieve this. This paper addresses this gap by leveraging the reasoning and generative capabilities of the LLMs to predict human behavior in two sequential decision-making tasks. These tasks involve balancing between exploitative and exploratory actions and handling delayed feedback, both essential for simulating real-life decision processes. We compare the performance of LLMs with a cognitive instance-based learning (IBL) model, which imitates human experiential decision-making. Our findings indicate that LLMs excel at rapidly incorporating feedback to enhance prediction accuracy. In contrast, the c",
    "path": "papers/24/07/2407.09281.json",
    "total_tokens": 683,
    "translated_title": "预测和理解人类行为决策：基于大型语言模型和认知实例学习的新见解",
    "translated_abstract": "arXiv:2407.09281v2 宣布类型：替换 摘要：大型语言模型（LLMs）在各种任务中展示了自己的能力，包括语言翻译和复杂的推理。部署人工智能（AI）辅助系统提供有用的帮助之前，理解并预测人类行为和偏见至关重要，但这仍然是一个有待解决的问题。本文通过利用LLMs的推理和生成能力，预测人们在两个连续的决策任务中的行为。这些任务涉及在 exploitative（探索性）和 exploratory（经验性）行动之间取得平衡，处理延迟反馈，这些都是模拟现实生活决策过程的要素。我们比较了LLMs与一种认知实例学习（IBL）模型的表现，后者模仿了人类经验性的决策制定。我们的发现表明，LLMs在迅速整合反馈以提高预测准确性方面表现出色。相比之下，认知IBL模型在延迟反馈的适应上表现更佳。",
    "tldr": "本文通过比较大型语言模型与认知实例学习模型在预测人类行为决策方面的表现，发现大型语言模型在快速适应反馈方面表现出色，而认知实例学习模型则在处理延迟反馈方面更为有效。"
}