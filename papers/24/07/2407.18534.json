{
    "title": "Boosting Cross-Domain Point Classification via Distilling Relational Priors from 2D Transformers",
    "abstract": "arXiv:2407.18534v2 Announce Type: replace  Abstract: Semantic pattern of an object point cloud is determined by its topological configuration of local geometries. Learning discriminative representations can be challenging due to large shape variations of point sets in local regions and incomplete surface in a global perspective, which can be made even more severe in the context of unsupervised domain adaptation (UDA). In specific, traditional 3D networks mainly focus on local geometric details and ignore the topological structure between local geometries, which greatly limits their cross-domain generalization. Recently, the transformer-based models have achieved impressive performance gain in a range of image-based tasks, benefiting from its strong generalization capability and scalability stemming from capturing long range correlation across local patches. Inspired by such successes of visual transformers, we propose a novel Relational Priors Distillation (RPD) method to extract relat",
    "link": "https://arxiv.org/abs/2407.18534",
    "context": "Title: Boosting Cross-Domain Point Classification via Distilling Relational Priors from 2D Transformers\nAbstract: arXiv:2407.18534v2 Announce Type: replace  Abstract: Semantic pattern of an object point cloud is determined by its topological configuration of local geometries. Learning discriminative representations can be challenging due to large shape variations of point sets in local regions and incomplete surface in a global perspective, which can be made even more severe in the context of unsupervised domain adaptation (UDA). In specific, traditional 3D networks mainly focus on local geometric details and ignore the topological structure between local geometries, which greatly limits their cross-domain generalization. Recently, the transformer-based models have achieved impressive performance gain in a range of image-based tasks, benefiting from its strong generalization capability and scalability stemming from capturing long range correlation across local patches. Inspired by such successes of visual transformers, we propose a novel Relational Priors Distillation (RPD) method to extract relat",
    "path": "papers/24/07/2407.18534.json",
    "total_tokens": 717,
    "translated_title": "通过从2D变压器中提炼关系先验知识来提升跨域点分类性能",
    "translated_abstract": "arXiv:2407.18534v2 公告类型：替换摘要：对象点云的语义模式是由其局部几何配置决定的。学习区分性表示在局部区域形状多变和全局视角下表面不完备的情况下可能会非常困难，这在无监督域调整（UDA）的背景下更是如此。具体来说，传统的3D网络主要集中在局部几何细节上，忽视了局部几何之间的拓扑结构，这极大地限制了它们在跨域泛化方面的性能。最近，基于视觉的变压器模型在各种图像任务中取得了显著的性能提升，得益于它强大的概括能力和可扩展性，这些能力源于在局部图斑间捕捉长距离的相关性。受到此类视觉变压器成功经验的启发，我们提出了一种新颖的“关系先验知识提炼”（RPD）方法，以提取点云样本之间的关系先验知识，从而使其在跨域学习中更加稳健。我们的方法首先利用一系列预训练的2D视觉网络对关系先验进行编码，然后将编码的信息通过蒸馏机制传递给3D网络。通过这种方式，3D网络可以从2D网络中“学习”到关系先验，从而提升其对不同域数据集的点分类任务的适应性。",
    "tldr": "本文提出的RPD方法通过蒸馏机制让3D网络从预训练的2D视觉网络中学习关系先验知识，提高了其在跨域点分类任务上的性能。"
}