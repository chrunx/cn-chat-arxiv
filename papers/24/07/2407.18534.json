{
    "title": "Boosting Cross-Domain Point Classification via Distilling Relational Priors from 2D Transformers",
    "abstract": "arXiv:2407.18534v2 Announce Type: replace  Abstract: Semantic pattern of an object point cloud is determined by its topological configuration of local geometries. Learning discriminative representations can be challenging due to large shape variations of point sets in local regions and incomplete surface in a global perspective, which can be made even more severe in the context of unsupervised domain adaptation (UDA). In specific, traditional 3D networks mainly focus on local geometric details and ignore the topological structure between local geometries, which greatly limits their cross-domain generalization. Recently, the transformer-based models have achieved impressive performance gain in a range of image-based tasks, benefiting from its strong generalization capability and scalability stemming from capturing long range correlation across local patches. Inspired by such successes of visual transformers, we propose a novel Relational Priors Distillation (RPD) method to extract relat",
    "link": "https://arxiv.org/abs/2407.18534",
    "context": "Title: Boosting Cross-Domain Point Classification via Distilling Relational Priors from 2D Transformers\nAbstract: arXiv:2407.18534v2 Announce Type: replace  Abstract: Semantic pattern of an object point cloud is determined by its topological configuration of local geometries. Learning discriminative representations can be challenging due to large shape variations of point sets in local regions and incomplete surface in a global perspective, which can be made even more severe in the context of unsupervised domain adaptation (UDA). In specific, traditional 3D networks mainly focus on local geometric details and ignore the topological structure between local geometries, which greatly limits their cross-domain generalization. Recently, the transformer-based models have achieved impressive performance gain in a range of image-based tasks, benefiting from its strong generalization capability and scalability stemming from capturing long range correlation across local patches. Inspired by such successes of visual transformers, we propose a novel Relational Priors Distillation (RPD) method to extract relat",
    "path": "papers/24/07/2407.18534.json",
    "total_tokens": 383,
    "tldr": "该文章提出了一种名为Relational Priors Distillation (RPD)的全新方法，旨在通过从2D变换器中提取关系先验知识来显著提高跨域点分类的性能。该方法是跨域自监督学习中的创新，能够更好地处理点云在局部和全局范围内的形状变化，以及在无监督域适应中的表现受限问题。通过这种方式，RPD不仅能够捕捉到局部几何细节，还能理解局部几何之间的拓扑结构，这对于提高跨域泛化能力至关重要。"
}