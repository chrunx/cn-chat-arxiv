{
    "title": "Autoverse: An Evolvable Game Language for Learning Robust Embodied Agents",
    "abstract": "arXiv:2407.04221v2 Announce Type: replace  Abstract: We introduce Autoverse, an evolvable, domain-specific language for single-player 2D grid-based games, and demonstrate its use as a scalable training ground for Open-Ended Learning (OEL) algorithms. Autoverse uses cellular-automaton-like rewrite rules to describe game mechanics, allowing it to express various game environments (e.g. mazes, dungeons, sokoban puzzles) that are popular testbeds for Reinforcement Learning (RL) agents. Each rewrite rule can be expressed as a series of simple convolutions, allowing for environments to be parallelized on the GPU, thereby drastically accelerating RL training. Using Autoverse, we propose jump-starting open-ended learning by imitation learning from search. In such an approach, we first evolve Autoverse environments (their rules and initial map topology) to maximize the number of iterations required by greedy tree search to discover a new best solution, producing a curriculum of increasingly com",
    "link": "https://arxiv.org/abs/2407.04221",
    "context": "Title: Autoverse: An Evolvable Game Language for Learning Robust Embodied Agents\nAbstract: arXiv:2407.04221v2 Announce Type: replace  Abstract: We introduce Autoverse, an evolvable, domain-specific language for single-player 2D grid-based games, and demonstrate its use as a scalable training ground for Open-Ended Learning (OEL) algorithms. Autoverse uses cellular-automaton-like rewrite rules to describe game mechanics, allowing it to express various game environments (e.g. mazes, dungeons, sokoban puzzles) that are popular testbeds for Reinforcement Learning (RL) agents. Each rewrite rule can be expressed as a series of simple convolutions, allowing for environments to be parallelized on the GPU, thereby drastically accelerating RL training. Using Autoverse, we propose jump-starting open-ended learning by imitation learning from search. In such an approach, we first evolve Autoverse environments (their rules and initial map topology) to maximize the number of iterations required by greedy tree search to discover a new best solution, producing a curriculum of increasingly com",
    "path": "papers/24/07/2407.04221.json",
    "total_tokens": 481,
    "tldr": "该文章提出Autoverse，一种可进化、针对性的语言，用于学习具有鲁棒身体特征的智能体，并通过其作为开放式学习算法可扩展培训平台的实际案例。Autoverse使用类似于细胞自动机的规则描述游戏机制，支持各种游戏环境的描述，如迷宫、地下室等，这些环境对于强化学习算法的测试非常有用。每条规则可以被简化的卷积操作所表示，这允许在GPU上并行处理环境，大幅度加速强化学习的训练过程。通过使用Autoverse，该文提出了一种通过模仿学习和搜索来迅速启动开放式学习的策略。在这种策略中，首先通过进化选择Autoverse环境的规则和初始地图拓扑来最大化贪婪搜索发现新最佳解决方案的迭代次数，从而创建了一个难度逐渐增加的课程。"
}