{
    "title": "PyBench: Evaluating LLM Agent on various real-world coding tasks",
    "abstract": "arXiv:2407.16732v2 Announce Type: replace-cross  Abstract: The LLM Agent, equipped with a code interpreter, is capable of automatically solving real-world coding tasks, such as data analysis and image editing.   However, existing benchmarks primarily focus on either simplistic tasks, such as completing a few lines of code, or on extremely complex and specific tasks at the repository level, neither of which are representative of various daily coding tasks.   To address this gap, we introduce \\textbf{PyBench}, a benchmark encompassing five main categories of real-world tasks, covering more than 10 types of files. Given a high-level user query and related files, the LLM Agent needs to reason and execute Python code via a code interpreter for a few turns before making a formal response to fulfill the user's requirements. Successfully addressing tasks in PyBench demands a robust understanding of various Python packages, superior reasoning capabilities, and the ability to incorporate feedbac",
    "link": "https://arxiv.org/abs/2407.16732",
    "context": "Title: PyBench: Evaluating LLM Agent on various real-world coding tasks\nAbstract: arXiv:2407.16732v2 Announce Type: replace-cross  Abstract: The LLM Agent, equipped with a code interpreter, is capable of automatically solving real-world coding tasks, such as data analysis and image editing.   However, existing benchmarks primarily focus on either simplistic tasks, such as completing a few lines of code, or on extremely complex and specific tasks at the repository level, neither of which are representative of various daily coding tasks.   To address this gap, we introduce \\textbf{PyBench}, a benchmark encompassing five main categories of real-world tasks, covering more than 10 types of files. Given a high-level user query and related files, the LLM Agent needs to reason and execute Python code via a code interpreter for a few turns before making a formal response to fulfill the user's requirements. Successfully addressing tasks in PyBench demands a robust understanding of various Python packages, superior reasoning capabilities, and the ability to incorporate feedbac",
    "path": "papers/24/07/2407.16732.json",
    "total_tokens": 391,
    "tldr": "该文章创新性地开发了PyBench基准测试，它可以衡量具有代码解释器的LLM代理在解决各种真实世界编码任务方面的能力，这些任务包括数据分析和图像编辑等。PyBench的引入填补了尽管现有基准测试主要集中在简单或特定类型的任务上，但真实世界中的编码任务却涵盖了多种不同类型的文件。因此，PyBench成为评估LLM代理在模拟编程任务中表现的一个重要工具。"
}