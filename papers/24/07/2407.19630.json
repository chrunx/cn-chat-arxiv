{
    "title": "LLMs' Understanding of Natural Language Revealed",
    "abstract": "arXiv:2407.19630v2 Announce Type: replace  Abstract: Large language models (LLMs) are the result of a massive experiment in bottom-up, data-driven reverse engineering of language at scale. Despite their utility in a number of downstream NLP tasks, ample research has shown that LLMs are incapable of performing reasoning in tasks that require quantification over and the manipulation of symbolic variables (e.g., planning and problem solving); see for example [25][26]. In this document, however, we will focus on testing LLMs for their language understanding capabilities, their supposed forte. As we will show here, the language understanding capabilities of LLMs have been widely exaggerated. While LLMs have proven to generate human-like coherent language (since that's how they were designed), their language understanding capabilities have not been properly tested. In particular, we believe that the language understanding capabilities of LLMs should be tested by performing an operation that ",
    "link": "https://arxiv.org/abs/2407.19630",
    "context": "Title: LLMs' Understanding of Natural Language Revealed\nAbstract: arXiv:2407.19630v2 Announce Type: replace  Abstract: Large language models (LLMs) are the result of a massive experiment in bottom-up, data-driven reverse engineering of language at scale. Despite their utility in a number of downstream NLP tasks, ample research has shown that LLMs are incapable of performing reasoning in tasks that require quantification over and the manipulation of symbolic variables (e.g., planning and problem solving); see for example [25][26]. In this document, however, we will focus on testing LLMs for their language understanding capabilities, their supposed forte. As we will show here, the language understanding capabilities of LLMs have been widely exaggerated. While LLMs have proven to generate human-like coherent language (since that's how they were designed), their language understanding capabilities have not been properly tested. In particular, we believe that the language understanding capabilities of LLMs should be tested by performing an operation that ",
    "path": "papers/24/07/2407.19630.json",
    "total_tokens": 703,
    "translated_title": "LLMs' Understanding of Natural Language Revealed",
    "translated_abstract": "arXiv:2407.19630v2 公告类型：替换 摘要：大规模语言模型（LLMs）是一项大规模的数据驱动倒置工程实验成果，旨在从底部向上对语言进行大规模的数据驱动反向工程。尽管LLMs在许多下游自然语言处理任务中显示出它们的效用，但大量的研究表明，LLMs在执行需要对符号变量进行量化和操作的任务方面是无能为力的，例如计划和问题解决。具体来说，我们在本文档中将重点测试LLMs的语言理解能力，这是它们的专长。正如我们将要展示的那样，LLMs的语言理解能力已经被广泛地夸大了。虽然LLMs已经被证明能够生成类似人类的连贯语言（因为这就是它们的设计方式），但它们的语言理解能力尚未被正确测试。特别是，我们认为应该通过执行一个操作来测试LLMs的语言理解能力，这个操作需要能够辨识和理解语言的语法结构，同时也能执行逻辑推理。",
    "tldr": "本文揭示了LLMs语言理解能力的夸大。虽然LLMs能够生成连贯的语言，但其对语言的理解能力并未得到充分测试。Abstract中的操作表明，评估LLMs的语言理解能力需要辨识语言的语法结构并执行逻辑推理。"
}