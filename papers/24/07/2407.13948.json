{
    "title": "Assurance of AI Systems From a Dependability Perspective",
    "abstract": "arXiv:2407.13948v2 Announce Type: replace  Abstract: We outline the principles of classical assurance for computer-based systems that pose significant risks. We then consider application of these principles to systems that employ Artificial Intelligence (AI) and Machine Learning (ML).   A key element in this \"dependability\" perspective is a requirement to have near-complete understanding of the behavior of critical components, and this is considered infeasible for AI and ML. Hence the dependability perspective aims to minimize trust in AI and ML elements by using \"defense in depth\" with a hierarchy of less complex systems, some of which may be highly assured conventionally engineered components, to \"guard\" them. This may be contrasted with the \"trustworthy\" perspective that seeks to apply assurance to the AI and ML elements themselves.   In cyber-physical and many other systems, it is difficult to provide guards that do not depend on AI and ML to perceive their environment (e.g., other",
    "link": "https://arxiv.org/abs/2407.13948",
    "context": "Title: Assurance of AI Systems From a Dependability Perspective\nAbstract: arXiv:2407.13948v2 Announce Type: replace  Abstract: We outline the principles of classical assurance for computer-based systems that pose significant risks. We then consider application of these principles to systems that employ Artificial Intelligence (AI) and Machine Learning (ML).   A key element in this \"dependability\" perspective is a requirement to have near-complete understanding of the behavior of critical components, and this is considered infeasible for AI and ML. Hence the dependability perspective aims to minimize trust in AI and ML elements by using \"defense in depth\" with a hierarchy of less complex systems, some of which may be highly assured conventionally engineered components, to \"guard\" them. This may be contrasted with the \"trustworthy\" perspective that seeks to apply assurance to the AI and ML elements themselves.   In cyber-physical and many other systems, it is difficult to provide guards that do not depend on AI and ML to perceive their environment (e.g., other",
    "path": "papers/24/07/2407.13948.json",
    "total_tokens": 336,
    "tldr": "该文章探讨了基于可靠性的人工智能系统保障原则，提出在系统设计中通过设置多层次的防御机制来确保关键组件的行为可被充分理解，以减少对人工智能和机器学习元素的信任。"
}