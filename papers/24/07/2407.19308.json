{
    "title": "Comprehensive Attribution: Inherently Explainable Vision Model with Feature Detector",
    "abstract": "arXiv:2407.19308v2 Announce Type: replace  Abstract: As deep vision models' popularity rapidly increases, there is a growing emphasis on explanations for model predictions. The inherently explainable attribution method aims to enhance the understanding of model behavior by identifying the important regions in images that significantly contribute to predictions. It is achieved by cooperatively training a selector (generating an attribution map to identify important features) and a predictor (making predictions using the identified features). Despite many advancements, existing methods suffer from the incompleteness problem, where discriminative features are masked out, and the interlocking problem, where the non-optimized selector initially selects noise, causing the predictor to fit on this noise and perpetuate the cycle. To address these problems, we introduce a new objective that discourages the presence of discriminative features in the masked-out regions thus enhancing the comprehe",
    "link": "https://arxiv.org/abs/2407.19308",
    "context": "Title: Comprehensive Attribution: Inherently Explainable Vision Model with Feature Detector\nAbstract: arXiv:2407.19308v2 Announce Type: replace  Abstract: As deep vision models' popularity rapidly increases, there is a growing emphasis on explanations for model predictions. The inherently explainable attribution method aims to enhance the understanding of model behavior by identifying the important regions in images that significantly contribute to predictions. It is achieved by cooperatively training a selector (generating an attribution map to identify important features) and a predictor (making predictions using the identified features). Despite many advancements, existing methods suffer from the incompleteness problem, where discriminative features are masked out, and the interlocking problem, where the non-optimized selector initially selects noise, causing the predictor to fit on this noise and perpetuate the cycle. To address these problems, we introduce a new objective that discourages the presence of discriminative features in the masked-out regions thus enhancing the comprehe",
    "path": "papers/24/07/2407.19308.json",
    "total_tokens": 355,
    "tldr": "该文章提出了一个新型的基于联合训练的图像模型，它能够解释深度模型的预测。通过在训练中同时优化一个选择器和预测器，该模型能够在不损害重要特征的情况下，有效地识别并解释图像中的关键区域。这种方法通过一个特定的目标函数，解决了现有的方法中存在的特征完全性和互锁问题，从而提供了更加强大且解释性的视觉模型。"
}