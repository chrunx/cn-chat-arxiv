{
    "title": "ViG-Bias: Visually Grounded Bias Discovery and Mitigation",
    "abstract": "arXiv:2407.01996v3 Announce Type: replace  Abstract: The proliferation of machine learning models in critical decision making processes has underscored the need for bias discovery and mitigation strategies. Identifying the reasons behind a biased system is not straightforward, since in many occasions they are associated with hidden spurious correlations which are not easy to spot. Standard approaches rely on bias audits performed by analyzing model performance in pre-defined subgroups of data samples, usually characterized by common attributes like gender or ethnicity when it comes to people, or other specific attributes defining semantically coherent groups of images. However, it is not always possible to know a-priori the specific attributes defining the failure modes of visual recognition systems. Recent approaches propose to discover these groups by leveraging large vision language models, which enable the extraction of cross-modal embeddings and the generation of textual descripti",
    "link": "https://arxiv.org/abs/2407.01996",
    "context": "Title: ViG-Bias: Visually Grounded Bias Discovery and Mitigation\nAbstract: arXiv:2407.01996v3 Announce Type: replace  Abstract: The proliferation of machine learning models in critical decision making processes has underscored the need for bias discovery and mitigation strategies. Identifying the reasons behind a biased system is not straightforward, since in many occasions they are associated with hidden spurious correlations which are not easy to spot. Standard approaches rely on bias audits performed by analyzing model performance in pre-defined subgroups of data samples, usually characterized by common attributes like gender or ethnicity when it comes to people, or other specific attributes defining semantically coherent groups of images. However, it is not always possible to know a-priori the specific attributes defining the failure modes of visual recognition systems. Recent approaches propose to discover these groups by leveraging large vision language models, which enable the extraction of cross-modal embeddings and the generation of textual descripti",
    "path": "papers/24/07/2407.01996.json",
    "total_tokens": 369,
    "tldr": "该文章提出一种名为ViG-Bias的方法，该方法通过结合视觉表示和语言表示，能够发现和缓解视觉识别系统的潜在偏差。具体来说，该研究利用大规模的视觉语言模型来提取跨模态的嵌入表示，并生成描述性的文本，以此发现数据集中可能存在的不良性能模式。通过这种方式，ViG-Bias能够揭示隐藏的、非直接描述性的偏差来源，为视觉识别系统中的偏差识别和优化提供了一个新的视角。"
}