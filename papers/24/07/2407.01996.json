{
    "title": "ViG-Bias: Visually Grounded Bias Discovery and Mitigation",
    "abstract": "arXiv:2407.01996v3 Announce Type: replace  Abstract: The proliferation of machine learning models in critical decision making processes has underscored the need for bias discovery and mitigation strategies. Identifying the reasons behind a biased system is not straightforward, since in many occasions they are associated with hidden spurious correlations which are not easy to spot. Standard approaches rely on bias audits performed by analyzing model performance in pre-defined subgroups of data samples, usually characterized by common attributes like gender or ethnicity when it comes to people, or other specific attributes defining semantically coherent groups of images. However, it is not always possible to know a-priori the specific attributes defining the failure modes of visual recognition systems. Recent approaches propose to discover these groups by leveraging large vision language models, which enable the extraction of cross-modal embeddings and the generation of textual descripti",
    "link": "https://arxiv.org/abs/2407.01996",
    "context": "Title: ViG-Bias: Visually Grounded Bias Discovery and Mitigation\nAbstract: arXiv:2407.01996v3 Announce Type: replace  Abstract: The proliferation of machine learning models in critical decision making processes has underscored the need for bias discovery and mitigation strategies. Identifying the reasons behind a biased system is not straightforward, since in many occasions they are associated with hidden spurious correlations which are not easy to spot. Standard approaches rely on bias audits performed by analyzing model performance in pre-defined subgroups of data samples, usually characterized by common attributes like gender or ethnicity when it comes to people, or other specific attributes defining semantically coherent groups of images. However, it is not always possible to know a-priori the specific attributes defining the failure modes of visual recognition systems. Recent approaches propose to discover these groups by leveraging large vision language models, which enable the extraction of cross-modal embeddings and the generation of textual descripti",
    "path": "papers/24/07/2407.01996.json",
    "total_tokens": 638,
    "translated_title": "ViG-Bias：基于视觉的偏差发现与缓解",
    "translated_abstract": "arXiv:2407.01996v3 公告类型：替换  摘要：在关键决策过程中广泛采用机器学习模型，凸显了发现和缓解偏差策略的必要性。由于很多时候这些偏差与难以察觉的隐藏的伪相关性有关，因此确定系统表现出偏差的根本原因并不直接。标准方法依赖于通过对模型在数据样本预定义子群上的性能进行分析来执行偏差审核，尤其是在涉及到人类时，通常会基于性别或种族等常见属性，或者是为了图像等其他特定属性定义的语义上有意义的组。然而，并不总是有可能事先知道定义视觉识别系统失败模式的详细属性。最近的方法提出通过利用大型视觉语言模型来发现这些小组，这些模型能够提取跨模态嵌入并生成描述性文本，从而可以在未预先定义的情况下发现导致模型表现不佳的属性组合。",
    "tldr": "ViG-Bias是一种新方法，用于在视觉模型中自动发现和缓解潜藏的偏差，通过大型视觉语言模型提取跨模态嵌入，即使在属性未知的场景中也能识别出系统失败的模式。",
    "en_tdlr": "ViG-Bias is a new approach for automatically discovering and mitigating hidden biases in visual models, through the extraction of cross-modal embeddings by large vision language models, enabling the identification of failure modes even when attributes are unknown."
}