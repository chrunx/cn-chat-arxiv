{
    "title": "D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions",
    "abstract": "arXiv:2407.02604v2 Announce Type: replace  Abstract: Large vision language models (VLMs) have progressed incredibly from research to applicability for general-purpose use cases. LLaVA-Med, a pioneering large language and vision assistant for biomedicine, can perform multi-modal biomedical image and data analysis to provide a natural language interface for radiologists. While it is highly generalizable and works with multi-modal data, it is currently limited by well-known challenges that exist in the large language model space. Hallucinations and imprecision in responses can lead to misdiagnosis which currently hinder the clinical adaptability of VLMs. To create precise, user-friendly models in healthcare, we propose D-Rax -- a domain-specific, conversational, radiologic assistance tool that can be used to gain insights about a particular radiologic image. In this study, we enhance the conversational analysis of chest X-ray (CXR) images to support radiological reporting, offering compre",
    "link": "https://arxiv.org/abs/2407.02604",
    "context": "Title: D-Rax: Domain-specific Radiologic assistant leveraging multi-modal data and eXpert model predictions\nAbstract: arXiv:2407.02604v2 Announce Type: replace  Abstract: Large vision language models (VLMs) have progressed incredibly from research to applicability for general-purpose use cases. LLaVA-Med, a pioneering large language and vision assistant for biomedicine, can perform multi-modal biomedical image and data analysis to provide a natural language interface for radiologists. While it is highly generalizable and works with multi-modal data, it is currently limited by well-known challenges that exist in the large language model space. Hallucinations and imprecision in responses can lead to misdiagnosis which currently hinder the clinical adaptability of VLMs. To create precise, user-friendly models in healthcare, we propose D-Rax -- a domain-specific, conversational, radiologic assistance tool that can be used to gain insights about a particular radiologic image. In this study, we enhance the conversational analysis of chest X-ray (CXR) images to support radiological reporting, offering compre",
    "path": "papers/24/07/2407.02604.json",
    "total_tokens": 706,
    "translated_title": "D-Rax: 域特定放射学助手，通过多模态数据和专家模型预测提升",
    "translated_abstract": "arXiv:2407.02604v2 公告类型：替换 摘要：大型视觉语言模型（VLMs）从研究领域发展到了适用于各种用途的程度，这在医学图像和数据的多模态分析中表现尤为突出。尽管目前的VLMs能够在多模态数据领域提供广泛的适用性，并可用于帮助解决医学中的问题，但由于该领域本身存在的一些挑战，如模型的不确定性、错误的预测和建议等，VLMs在临床上的应用仍然受限。在本研究中，我们提出并设计了一个以胸部X光片（CXR）为重点的域特定、会话式放射学助手——D-Rax。通过结合领域专家的见解和多模态技术的先进性，D-Rax能够准确且高效地解读CXR图像，从而为放射科医生提供一条全新的自然语言接口，并有助于提高放射学报告的精确性和完整性。目前我们正在逐步完善D-Rax的功能，并计划进行更多临床实验，以评估其对医疗实践的潜在影响。",
    "tldr": "D-Rax 是一个新的域特定放射学助手，能够通过结合多模态数据和专家模型预测，更精确地帮助放射科医生处理胸部X光片。",
    "en_tdlr": "D-Rax is a new domain-specific radiology assistant that uses multimodal data and expert model predictions to assist radiologists more accurately with chest X-ray images."
}