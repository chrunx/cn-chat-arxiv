{
    "title": "Quantised Global Autoencoder: A Holistic Approach to Representing Visual Data",
    "abstract": "arXiv:2407.11913v2 Announce Type: replace  Abstract: In quantised autoencoders, images are usually split into local patches, each encoded by one token. This representation is redundant in the sense that the same number of tokens is spend per region, regardless of the visual information content in that region. Adaptive discretisation schemes like quadtrees are applied to allocate tokens for patches with varying sizes, but this just varies the region of influence for a token which nevertheless remains a local descriptor. Modern architectures add an attention mechanism to the autoencoder which infuses some degree of global information into the local tokens. Despite the global context, tokens are still associated with a local image region. In contrast, our method is inspired by spectral decompositions which transform an input signal into a superposition of global frequencies. Taking the data-driven perspective, we learn custom basis functions corresponding to the codebook entries in our VQ",
    "link": "https://arxiv.org/abs/2407.11913",
    "context": "Title: Quantised Global Autoencoder: A Holistic Approach to Representing Visual Data\nAbstract: arXiv:2407.11913v2 Announce Type: replace  Abstract: In quantised autoencoders, images are usually split into local patches, each encoded by one token. This representation is redundant in the sense that the same number of tokens is spend per region, regardless of the visual information content in that region. Adaptive discretisation schemes like quadtrees are applied to allocate tokens for patches with varying sizes, but this just varies the region of influence for a token which nevertheless remains a local descriptor. Modern architectures add an attention mechanism to the autoencoder which infuses some degree of global information into the local tokens. Despite the global context, tokens are still associated with a local image region. In contrast, our method is inspired by spectral decompositions which transform an input signal into a superposition of global frequencies. Taking the data-driven perspective, we learn custom basis functions corresponding to the codebook entries in our VQ",
    "path": "papers/24/07/2407.11913.json",
    "total_tokens": 404,
    "tldr": "该文章提出了一种量化全局自编码器（Quantised Global Autoencoder），该方法提供了一种全面的方法来表示视觉数据。它摒弃了以往在量化自动编码器中将图像分割成局部斑块然后每个斑块通过一个编码符表示的做法，而是通过一种类似于频谱分解的思路，将输入信号转化为一组自定义基础函数的超矢量，这组基础函数在训练过程中被学习出来，以更好地代表全局图像内容。这种方法可以更有效地捕捉到图像的全局特征，同时保持了局部信息的细节，从而在数据表示上做出了重要的贡献。"
}