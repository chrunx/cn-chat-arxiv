{
    "title": "Diffusion Models for Offline Multi-agent Reinforcement Learning with Safety Constraints",
    "abstract": "arXiv:2407.00741v5 Announce Type: replace  Abstract: In recent advancements in Multi-agent Reinforcement Learning (MARL), its application has extended to various safety-critical scenarios. However, most methods focus on online learning, which presents substantial risks when deployed in real-world settings. Addressing this challenge, we introduce an innovative framework integrating diffusion models within the MARL paradigm. This approach notably enhances the safety of actions taken by multiple agents through risk mitigation while modeling coordinated action. Our framework is grounded in the Centralized Training with Decentralized Execution (CTDE) architecture, augmented by a Diffusion Model for prediction trajectory generation. Additionally, we incorporate a specialized algorithm to further ensure operational safety. We evaluate our model against baselines on the DSRL benchmark. Experiment results demonstrate that our model not only adheres to stringent safety constraints but also achie",
    "link": "https://arxiv.org/abs/2407.00741",
    "context": "Title: Diffusion Models for Offline Multi-agent Reinforcement Learning with Safety Constraints\nAbstract: arXiv:2407.00741v5 Announce Type: replace  Abstract: In recent advancements in Multi-agent Reinforcement Learning (MARL), its application has extended to various safety-critical scenarios. However, most methods focus on online learning, which presents substantial risks when deployed in real-world settings. Addressing this challenge, we introduce an innovative framework integrating diffusion models within the MARL paradigm. This approach notably enhances the safety of actions taken by multiple agents through risk mitigation while modeling coordinated action. Our framework is grounded in the Centralized Training with Decentralized Execution (CTDE) architecture, augmented by a Diffusion Model for prediction trajectory generation. Additionally, we incorporate a specialized algorithm to further ensure operational safety. We evaluate our model against baselines on the DSRL benchmark. Experiment results demonstrate that our model not only adheres to stringent safety constraints but also achie",
    "path": "papers/24/07/2407.00741.json",
    "total_tokens": 760,
    "translated_title": "具有安全约束的离线多 agent 强化学习的扩散模型",
    "translated_abstract": "arXiv:2407.00741v5 公告类型：替换 摘要：在多 agent 强化学习（MARL）的最新进展中，其应用已扩展到各种具有安全风险的场景。然而，大多数方法都侧重于在线学习，这在实际部署中可能会带来重大风险。为了解决这一挑战，我们介绍了一种创新的框架，将扩散模型整合到 MARL 范式中。这种方法通过风险缓解和协同动作建模显著提高了多个代理的行动安全性。我们的框架基于集成就地、分布式执行（CTDE）架构，并增加了预测轨迹生成的扩散模型。此外，我们还引入了一种特定的算法以确保操作安全性。我们对DSRL基准进行了评估，实验结果表明，我们的模型不仅严格遵守严格的安全限制，而且还实现了与命令和控制相比的性能提升。通过上下文预测和行为规划，我们的方法不仅能够提高智能体的集体性能，还能够更有效地应对复杂的动态环境。",
    "tldr": "本文提出了一种在离线多智能体强化学习中整合扩散模型的创新方法，该方法通过风险管理和协同动作建模提高了多个代理行动的安全性。框架基于集成就地、分布式执行的架构，并利用扩散模型进行预测轨迹生成。我们的方法在DSRL基准测试中实现了与命令和控制相比的性能提升，并能更有效地应对复杂的动态环境。"
}