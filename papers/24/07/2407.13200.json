{
    "title": "Adapt PointFormer: 3D Point Cloud Analysis via Adapting 2D Visual Transformers",
    "abstract": "arXiv:2407.13200v2 Announce Type: replace  Abstract: Pre-trained large-scale models have exhibited remarkable efficacy in computer vision, particularly for 2D image analysis. However, when it comes to 3D point clouds, the constrained accessibility of data, in contrast to the vast repositories of images, poses a challenge for the development of 3D pre-trained models. This paper therefore attempts to directly leverage pre-trained models with 2D prior knowledge to accomplish the tasks for 3D point cloud analysis. Accordingly, we propose the Adaptive PointFormer (APF), which fine-tunes pre-trained 2D models with only a modest number of parameters to directly process point clouds, obviating the need for mapping to images. Specifically, we convert raw point clouds into point embeddings for aligning dimensions with image tokens. Given the inherent disorder in point clouds, in contrast to the structured nature of images, we then sequence the point embeddings to optimize the utilization of 2D a",
    "link": "https://arxiv.org/abs/2407.13200",
    "context": "Title: Adapt PointFormer: 3D Point Cloud Analysis via Adapting 2D Visual Transformers\nAbstract: arXiv:2407.13200v2 Announce Type: replace  Abstract: Pre-trained large-scale models have exhibited remarkable efficacy in computer vision, particularly for 2D image analysis. However, when it comes to 3D point clouds, the constrained accessibility of data, in contrast to the vast repositories of images, poses a challenge for the development of 3D pre-trained models. This paper therefore attempts to directly leverage pre-trained models with 2D prior knowledge to accomplish the tasks for 3D point cloud analysis. Accordingly, we propose the Adaptive PointFormer (APF), which fine-tunes pre-trained 2D models with only a modest number of parameters to directly process point clouds, obviating the need for mapping to images. Specifically, we convert raw point clouds into point embeddings for aligning dimensions with image tokens. Given the inherent disorder in point clouds, in contrast to the structured nature of images, we then sequence the point embeddings to optimize the utilization of 2D a",
    "path": "papers/24/07/2407.13200.json",
    "total_tokens": 397,
    "tldr": "该文章提出了一种可适应的点Former（PointFormer）模型，它通过改编自2D视觉Transformer的预训练模型来分析3D点云数据，无需将点云映射到图像。这种直接适应2D知识处理3D数据的策略，在保持少量参数的同时对2D模型进行了微调，绕过了传统方法中所需的图像映射步骤，从而提高了3D点云分析的效率。"
}