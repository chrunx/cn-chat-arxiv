{
    "title": "Adapt PointFormer: 3D Point Cloud Analysis via Adapting 2D Visual Transformers",
    "abstract": "arXiv:2407.13200v2 Announce Type: replace  Abstract: Pre-trained large-scale models have exhibited remarkable efficacy in computer vision, particularly for 2D image analysis. However, when it comes to 3D point clouds, the constrained accessibility of data, in contrast to the vast repositories of images, poses a challenge for the development of 3D pre-trained models. This paper therefore attempts to directly leverage pre-trained models with 2D prior knowledge to accomplish the tasks for 3D point cloud analysis. Accordingly, we propose the Adaptive PointFormer (APF), which fine-tunes pre-trained 2D models with only a modest number of parameters to directly process point clouds, obviating the need for mapping to images. Specifically, we convert raw point clouds into point embeddings for aligning dimensions with image tokens. Given the inherent disorder in point clouds, in contrast to the structured nature of images, we then sequence the point embeddings to optimize the utilization of 2D a",
    "link": "https://arxiv.org/abs/2407.13200",
    "context": "Title: Adapt PointFormer: 3D Point Cloud Analysis via Adapting 2D Visual Transformers\nAbstract: arXiv:2407.13200v2 Announce Type: replace  Abstract: Pre-trained large-scale models have exhibited remarkable efficacy in computer vision, particularly for 2D image analysis. However, when it comes to 3D point clouds, the constrained accessibility of data, in contrast to the vast repositories of images, poses a challenge for the development of 3D pre-trained models. This paper therefore attempts to directly leverage pre-trained models with 2D prior knowledge to accomplish the tasks for 3D point cloud analysis. Accordingly, we propose the Adaptive PointFormer (APF), which fine-tunes pre-trained 2D models with only a modest number of parameters to directly process point clouds, obviating the need for mapping to images. Specifically, we convert raw point clouds into point embeddings for aligning dimensions with image tokens. Given the inherent disorder in point clouds, in contrast to the structured nature of images, we then sequence the point embeddings to optimize the utilization of 2D a",
    "path": "papers/24/07/2407.13200.json",
    "total_tokens": 791,
    "translated_title": "自适应PointFormer: 通过适应2D视觉变换器分析3D点云",
    "translated_abstract": "arXiv:2407.13200v2 公告类型: 替换 摘要: 预训练的大型模型在计算机视觉领域表现出了惊人的有效性，特别是在2D图像分析方面。然而，当涉及到3D点云时，与图像的大量数据库相比，数据访问的局限性为开发3D预训练模型带来了挑战。因此，本研究试图直接利用具有2D先验知识的预训练模型来完成3D点云分析的任务。因此，我们提出了自适应PointFormer（APF），它仅使用少量参数对预训练的2D模型进行微调，以便直接处理点云，无需映射到图像上。具体来说，我们将原始点云转换为点嵌入，以与图像符号的维度对齐。考虑到点云的内在无序性与图像的结构性质之间的差异，我们接着对点嵌入进行序列化，以优化2D注意力机制的使用。我们还采用了一种新颖的多尺度自回归生成网络来辅助生成细化后的点云，并利用正则化策略来减少稀疏性，从而提升模型性能。在各类点云数据集上的实验表明，APF不仅能有效地学习低维空间中的点云表示，同时还能显著提高FD²-Net等现有方法的性能。",
    "tldr": "该研究提出了一种自适应PointFormer（APF），通过微调2D视觉模型直接处理3D点云，从而无需将点云映射到图像上。这种方法可以有效学习低维空间中的点云表示，同时显著提高现有方法性能。"
}