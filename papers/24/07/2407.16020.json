{
    "title": "Sparks of Quantum Advantage and Rapid Retraining in Machine Learning",
    "abstract": "arXiv:2407.16020v4 Announce Type: replace-cross  Abstract: The advent of quantum computing holds the potential to revolutionize various fields by solving complex problems more efficiently than classical computers. Despite this promise, practical quantum advantage is hindered by current hardware limitations, notably the small number of qubits and high noise levels. In this study, we leverage adiabatic quantum computers to optimize Kolmogorov-Arnold Networks, a powerful neural network architecture for representing complex functions with minimal parameters. By modifying the network to use Bezier curves as the basis functions and formulating the optimization problem into a Quadratic Unconstrained Binary Optimization problem, we create a fixed-sized solution space, independent of the number of training samples. This strategy allows for the optimization of an entire neural network in a single training iteration in which, due to order of operations, a majority of the processing is done using ",
    "link": "https://arxiv.org/abs/2407.16020",
    "context": "Title: Sparks of Quantum Advantage and Rapid Retraining in Machine Learning\nAbstract: arXiv:2407.16020v4 Announce Type: replace-cross  Abstract: The advent of quantum computing holds the potential to revolutionize various fields by solving complex problems more efficiently than classical computers. Despite this promise, practical quantum advantage is hindered by current hardware limitations, notably the small number of qubits and high noise levels. In this study, we leverage adiabatic quantum computers to optimize Kolmogorov-Arnold Networks, a powerful neural network architecture for representing complex functions with minimal parameters. By modifying the network to use Bezier curves as the basis functions and formulating the optimization problem into a Quadratic Unconstrained Binary Optimization problem, we create a fixed-sized solution space, independent of the number of training samples. This strategy allows for the optimization of an entire neural network in a single training iteration in which, due to order of operations, a majority of the processing is done using ",
    "path": "papers/24/07/2407.16020.json",
    "total_tokens": 346,
    "tldr": "该文章通过将Kolmogorov-Arnold网络优化与量子计算结合，利用QUBO问题将神经网络的训练迭代简化为单一过程，从而在减少训练样本数量的情况下实现了网络参数的有效优化。此外，通过使用Bezier曲线和固定的二进制解决方案空间，研究减少了传统深度学习训练中所需的迭代次数，提高了计算效率。"
}