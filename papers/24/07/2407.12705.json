{
    "title": "IMAGDressing-v1: Customizable Virtual Dressing",
    "abstract": "arXiv:2407.12705v2 Announce Type: replace  Abstract: Latest advances have achieved realistic virtual try-on (VTON) through localized garment inpainting using latent diffusion models, significantly enhancing consumers' online shopping experience. However, existing VTON technologies neglect the need for merchants to showcase garments comprehensively, including flexible control over garments, optional faces, poses, and scenes. To address this issue, we define a virtual dressing (VD) task focused on generating freely editable human images with fixed garments and optional conditions. Meanwhile, we design a comprehensive affinity metric index (CAMI) to evaluate the consistency between generated images and reference garments. Then, we propose IMAGDressing-v1, which incorporates a garment UNet that captures semantic features from CLIP and texture features from VAE. We present a hybrid attention module, including a frozen self-attention and a trainable cross-attention, to integrate garment feat",
    "link": "https://arxiv.org/abs/2407.12705",
    "context": "Title: IMAGDressing-v1: Customizable Virtual Dressing\nAbstract: arXiv:2407.12705v2 Announce Type: replace  Abstract: Latest advances have achieved realistic virtual try-on (VTON) through localized garment inpainting using latent diffusion models, significantly enhancing consumers' online shopping experience. However, existing VTON technologies neglect the need for merchants to showcase garments comprehensively, including flexible control over garments, optional faces, poses, and scenes. To address this issue, we define a virtual dressing (VD) task focused on generating freely editable human images with fixed garments and optional conditions. Meanwhile, we design a comprehensive affinity metric index (CAMI) to evaluate the consistency between generated images and reference garments. Then, we propose IMAGDressing-v1, which incorporates a garment UNet that captures semantic features from CLIP and texture features from VAE. We present a hybrid attention module, including a frozen self-attention and a trainable cross-attention, to integrate garment feat",
    "path": "papers/24/07/2407.12705.json",
    "total_tokens": 399,
    "tldr": "该文章提出了一种名为IMAGDressing-v1的系统，它借助先进的生成模型实现了更真实的虚拟试衣效果，特别地，该系统可以让用户自由编辑人物图像，并可根据需求添加或更改服装、脸部、姿势和背景场景。此外，文章还引入了一种名为CAMI的综合性一致性评估指标，用以验证所生成图像与参考服装的一致性。通过一个独特的混合注意力模块，IMAGDressing-v1能够将服装的特征与图像的其他特征有效地结合，从而提供了高保真度的虚拟试衣体验。"
}