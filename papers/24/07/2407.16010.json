{
    "title": "AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations",
    "abstract": "arXiv:2407.16010v2 Announce Type: replace-cross  Abstract: For many use-cases, it is often important to explain the prediction of a black-box model by identifying the most influential training data samples. Existing approaches lack customization for user intent and often provide a homogeneous set of explanation samples, failing to reveal the model's reasoning from different angles.   In this paper, we propose AIDE, an approach for providing antithetical (i.e., contrastive), intent-based, diverse explanations for opaque and complex models. AIDE distinguishes three types of explainability intents: interpreting a correct, investigating a wrong, and clarifying an ambiguous prediction. For each intent, AIDE selects an appropriate set of influential training samples that support or oppose the prediction either directly or by contrast. To provide a succinct summary, AIDE uses diversity-aware sampling to avoid redundancy and increase coverage of the training data.   We demonstrate the effectiv",
    "link": "https://arxiv.org/abs/2407.16010",
    "context": "Title: AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations\nAbstract: arXiv:2407.16010v2 Announce Type: replace-cross  Abstract: For many use-cases, it is often important to explain the prediction of a black-box model by identifying the most influential training data samples. Existing approaches lack customization for user intent and often provide a homogeneous set of explanation samples, failing to reveal the model's reasoning from different angles.   In this paper, we propose AIDE, an approach for providing antithetical (i.e., contrastive), intent-based, diverse explanations for opaque and complex models. AIDE distinguishes three types of explainability intents: interpreting a correct, investigating a wrong, and clarifying an ambiguous prediction. For each intent, AIDE selects an appropriate set of influential training samples that support or oppose the prediction either directly or by contrast. To provide a succinct summary, AIDE uses diversity-aware sampling to avoid redundancy and increase coverage of the training data.   We demonstrate the effectiv",
    "path": "papers/24/07/2407.16010.json",
    "total_tokens": 385,
    "tldr": "该文章提出了AIDE（Antithetical, Intent-based, and Diverse Example-based Explanations）方法，实现了根据用户意图提供多样化的对照（contrastive）解释，通过支持或反对预测的正反例子，来解释黑盒模型，并对正确、错误或模糊预测进行解释。AIDE通过多样性采样避免解释的重复和提高训练数据的覆盖度，有效地实现了个性化解释。"
}