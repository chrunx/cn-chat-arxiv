{
    "title": "Temporal Feature Matters: A Framework for Diffusion Model Quantization",
    "abstract": "arXiv:2407.19547v2 Announce Type: replace  Abstract: The Diffusion models, widely used for image generation, face significant challenges related to their broad applicability due to prolonged inference times and high memory demands. Efficient Post-Training Quantization (PTQ) is crucial to address these issues. However, unlike traditional models, diffusion models critically rely on the time-step for the multi-round denoising. Typically, each time-step is encoded into a hypersensitive temporal feature by several modules. Despite this, existing PTQ methods do not optimize these modules individually. Instead, they employ unsuitable reconstruction objectives and complex calibration methods, leading to significant disturbances in the temporal feature and denoising trajectory, as well as reduced compression efficiency. To address these challenges, we introduce a novel quantization framework that includes three strategies: 1) TIB-based Maintenance: Based on our innovative Temporal Information B",
    "link": "https://arxiv.org/abs/2407.19547",
    "context": "Title: Temporal Feature Matters: A Framework for Diffusion Model Quantization\nAbstract: arXiv:2407.19547v2 Announce Type: replace  Abstract: The Diffusion models, widely used for image generation, face significant challenges related to their broad applicability due to prolonged inference times and high memory demands. Efficient Post-Training Quantization (PTQ) is crucial to address these issues. However, unlike traditional models, diffusion models critically rely on the time-step for the multi-round denoising. Typically, each time-step is encoded into a hypersensitive temporal feature by several modules. Despite this, existing PTQ methods do not optimize these modules individually. Instead, they employ unsuitable reconstruction objectives and complex calibration methods, leading to significant disturbances in the temporal feature and denoising trajectory, as well as reduced compression efficiency. To address these challenges, we introduce a novel quantization framework that includes three strategies: 1) TIB-based Maintenance: Based on our innovative Temporal Information B",
    "path": "papers/24/07/2407.19547.json",
    "total_tokens": 344,
    "tldr": "该文章提出了一种全新的量化框架，旨在高效地对扩散模型进行后训练量化。该框架通过维护基于时间信息的基本（Temporal Information Basis）特征，解决了传统量化方法对时间步长敏感的特征优化不足问题。框架中的三个策略有效降低了量化过程中对时间特征的干扰，提高了压缩效率。"
}