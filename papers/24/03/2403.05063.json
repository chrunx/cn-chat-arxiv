{
    "title": "Aligning Large Language Models for Controllable Recommendations",
    "abstract": "arXiv:2403.05063v2 Announce Type: replace-cross  Abstract: Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method",
    "link": "https://arxiv.org/abs/2403.05063",
    "context": "Title: Aligning Large Language Models for Controllable Recommendations\nAbstract: arXiv:2403.05063v2 Announce Type: replace-cross  Abstract: Inspired by the exceptional general intelligence of Large Language Models (LLMs), researchers have begun to explore their application in pioneering the next generation of recommender systems - systems that are conversational, explainable, and controllable. However, existing literature primarily concentrates on integrating domain-specific knowledge into LLMs to enhance accuracy, often neglecting the ability to follow instructions. To address this gap, we initially introduce a collection of supervised learning tasks, augmented with labels derived from a conventional recommender model, aimed at explicitly improving LLMs' proficiency in adhering to recommendation-specific instructions. Subsequently, we develop a reinforcement learning-based alignment procedure to further strengthen LLMs' aptitude in responding to users' intentions and mitigating formatting errors. Through extensive experiments on two real-world datasets, our method",
    "path": "papers/24/03/2403.05063.json",
    "total_tokens": 300,
    "tldr": "该文章提出了一种将大型语言模型与推荐系统的指示相结合的策略，使其在遵守特定指示和提高用户意图响应准确性方面表现得更好。"
}