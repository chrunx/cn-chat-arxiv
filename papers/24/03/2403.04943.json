{
    "title": "AFreeCA: Annotation-Free Counting for All",
    "abstract": "arXiv:2403.04943v2 Announce Type: replace  Abstract: Object counting methods typically rely on manually annotated datasets. The cost of creating such datasets has restricted the versatility of these networks to count objects from specific classes (such as humans or penguins), and counting objects from diverse categories remains a challenge. The availability of robust text-to-image latent diffusion models (LDMs) raises the question of whether these models can be utilized to generate counting datasets. However, LDMs struggle to create images with an exact number of objects based solely on text prompts but they can be used to offer a dependable \\textit{sorting} signal by adding and removing objects within an image. Leveraging this data, we initially introduce an unsupervised sorting methodology to learn object-related features that are subsequently refined and anchored for counting purposes using counting data generated by LDMs. Further, we present a density classifier-guided method for d",
    "link": "https://arxiv.org/abs/2403.04943",
    "context": "Title: AFreeCA: Annotation-Free Counting for All\nAbstract: arXiv:2403.04943v2 Announce Type: replace  Abstract: Object counting methods typically rely on manually annotated datasets. The cost of creating such datasets has restricted the versatility of these networks to count objects from specific classes (such as humans or penguins), and counting objects from diverse categories remains a challenge. The availability of robust text-to-image latent diffusion models (LDMs) raises the question of whether these models can be utilized to generate counting datasets. However, LDMs struggle to create images with an exact number of objects based solely on text prompts but they can be used to offer a dependable \\textit{sorting} signal by adding and removing objects within an image. Leveraging this data, we initially introduce an unsupervised sorting methodology to learn object-related features that are subsequently refined and anchored for counting purposes using counting data generated by LDMs. Further, we present a density classifier-guided method for d",
    "path": "papers/24/03/2403.04943.json",
    "total_tokens": 703,
    "translated_title": "无注释计数所有：所有类型的无注释计数方法",
    "translated_abstract": "arXiv:2403.04943v2 公告类型：替换 摘要：传统的计数方法通常依赖于人工注释的数据集。创建这些数据集的成本限制了这些网络的数量类别的灵活性（如人类或企鹅），并且从多种类别中计数对象仍然是一个挑战。可靠的文本到图像潜伏扩散模型（LDM）的出现，引发了一个问题，即这些模型是否能够用来生成计数数据集。但是，LDM们仅凭文本提示很难创建精确数量的对象图像，但它们可以用来提供一种可靠的“排序”信号，通过在图像中添加和移除对象来实现这一点。借助这一点数据，我们首先介绍了一种无监督的排序方法，该方法学习的对象相关的特征在进行进一步的细化和计数数据集生成后的锚定。此外，我们还提出了一种密度分类器指导的方法，用于区分不同的计数标签，并让分类器注重样本中实际计数物体的数量。这种方法鼓励分类器在计数物体的中心位置设置他们的决策边界，以便获得更精准的计数结果。就当前而言，该方法在特定类型的强烈注释数据集上的表现不甚理想，但在本研究中，我们说明了如何使用相同的方法在几乎无注释的全类别数据集上取得准确率显著提升，这表明该方法在无注释全类别数据集上的应用潜力。",
    "tldr": "本研究提出了一种无需人工注释的数据集即可进行几乎所有类型对象计数的方法。",
    "en_tdlr": "This study proposes a method to count objects of almost all types without the need for manually annotated datasets."
}