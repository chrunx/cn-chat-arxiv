{
    "title": "Threats, Attacks, and Defenses in Machine Unlearning: A Survey",
    "abstract": "arXiv:2403.13682v3 Announce Type: replace-cross  Abstract: Machine Unlearning (MU) has gained considerable attention recently for its potential to achieve Safe AI by removing the influence of specific data from trained machine learning models. This process, known as knowledge removal, addresses AI governance concerns of training data such as quality, sensitivity, copyright restrictions, and obsolescence. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten. Furthermore, effective knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the safe and responsible use of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service, allowing users to submit requests to remove specific data from the training corpus. However, ",
    "link": "https://arxiv.org/abs/2403.13682",
    "context": "Title: Threats, Attacks, and Defenses in Machine Unlearning: A Survey\nAbstract: arXiv:2403.13682v3 Announce Type: replace-cross  Abstract: Machine Unlearning (MU) has gained considerable attention recently for its potential to achieve Safe AI by removing the influence of specific data from trained machine learning models. This process, known as knowledge removal, addresses AI governance concerns of training data such as quality, sensitivity, copyright restrictions, and obsolescence. This capability is also crucial for ensuring compliance with privacy regulations such as the Right To Be Forgotten. Furthermore, effective knowledge removal mitigates the risk of harmful outcomes, safeguarding against biases, misinformation, and unauthorized data exploitation, thereby enhancing the safe and responsible use of AI systems. Efforts have been made to design efficient unlearning approaches, with MU services being examined for integration with existing machine learning as a service, allowing users to submit requests to remove specific data from the training corpus. However, ",
    "path": "papers/24/03/2403.13682.json",
    "total_tokens": 356,
    "tldr": "该文章详细介绍了机器洗白（MU）作为一种确保AI安全和合规性的技术，强调了其在纠正训练数据中的问题、避免隐私侵犯和相关法律法规的遵守中的重要性。机器洗白允许用户删除特定数据的模型影响，为AI领域提供了一种保护个人隐私和防止不良影响的策略。此外，文章还讨论了这种技术的安全性考量以及挑战，为未来的研究和工作指出了方向。"
}