{
    "title": "Duwak: Dual Watermarks in Large Language Models",
    "abstract": "arXiv:2403.13000v2 Announce Type: replace-cross  Abstract: As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable patterns without significantly affecting generated text quality and semantics. However, the efficiency in detecting watermarks, i.e., the minimum number of tokens required to assert detection with significance and robustness against post-editing, is still debatable. In this paper, we propose, Duwak, to fundamentally enhance the efficiency and quality of watermarking by embedding dual secret patterns in both token probability distribution and sampling schemes. To mitigate expression degradation caused by biasing toward certain tokens, we design a contrastive search to watermark the sampling scheme, which minimizes the token repetition and e",
    "link": "https://arxiv.org/abs/2403.13000",
    "context": "Title: Duwak: Dual Watermarks in Large Language Models\nAbstract: arXiv:2403.13000v2 Announce Type: replace-cross  Abstract: As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable patterns without significantly affecting generated text quality and semantics. However, the efficiency in detecting watermarks, i.e., the minimum number of tokens required to assert detection with significance and robustness against post-editing, is still debatable. In this paper, we propose, Duwak, to fundamentally enhance the efficiency and quality of watermarking by embedding dual secret patterns in both token probability distribution and sampling schemes. To mitigate expression degradation caused by biasing toward certain tokens, we design a contrastive search to watermark the sampling scheme, which minimizes the token repetition and e",
    "path": "papers/24/03/2403.13000.json",
    "total_tokens": 355,
    "tldr": "该文章提出Duwak，一种在大型语言模型中嵌入双重秘密模式的方法，以提高检测效率和质量。这种方法通过在概率分布和采样方案中嵌入双重秘密模式，不仅提高了检测的有效性，还通过设计对比搜索来减少标记采样方案时产生的重复性，从而最小化了文本生成过程中的单词重复。"
}