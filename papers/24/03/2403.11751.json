{
    "title": "Relational Representation Learning Network for Cross-Spectral Image Patch Matching",
    "abstract": "arXiv:2403.11751v2 Announce Type: replace  Abstract: Recently, feature relation learning has drawn widespread attention in cross-spectral image patch matching. However, existing related research focuses on extracting diverse relations between image patch features and ignores sufficient intrinsic feature representations of individual image patches. Therefore, we propose an innovative relational representation learning idea that simultaneously focuses on sufficiently mining the intrinsic features of individual image patches and the relations between image patch features. Based on this, we construct a Relational Representation Learning Network (RRL-Net). Specifically, we innovatively construct an autoencoder to fully characterize the individual intrinsic features, and introduce a feature interaction learning (FIL) module to extract deep-level feature relations. To further fully mine individual intrinsic features, a lightweight multi-dimensional global-to-local attention (MGLA) module is c",
    "link": "https://arxiv.org/abs/2403.11751",
    "context": "Title: Relational Representation Learning Network for Cross-Spectral Image Patch Matching\nAbstract: arXiv:2403.11751v2 Announce Type: replace  Abstract: Recently, feature relation learning has drawn widespread attention in cross-spectral image patch matching. However, existing related research focuses on extracting diverse relations between image patch features and ignores sufficient intrinsic feature representations of individual image patches. Therefore, we propose an innovative relational representation learning idea that simultaneously focuses on sufficiently mining the intrinsic features of individual image patches and the relations between image patch features. Based on this, we construct a Relational Representation Learning Network (RRL-Net). Specifically, we innovatively construct an autoencoder to fully characterize the individual intrinsic features, and introduce a feature interaction learning (FIL) module to extract deep-level feature relations. To further fully mine individual intrinsic features, a lightweight multi-dimensional global-to-local attention (MGLA) module is c",
    "path": "papers/24/03/2403.11751.json",
    "total_tokens": 336,
    "tldr": "该文章提出了一种名为RRL-Net的模型，通过构建一个自动编码器来充分捕获个体图像块的特性，并通过一个特征交互学习模块来提取深层次的特征关系，同时通过一个轻量级的多维全局到局部注意力模块进一步挖掘个体特征，以在高光谱数据匹配中实现更精确的匹配。"
}