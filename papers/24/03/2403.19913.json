{
    "title": "MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models",
    "abstract": "arXiv:2403.19913v2 Announce Type: replace-cross  Abstract: Large language models such as ChatGPT and GPT-4 have recently achieved astonishing performance on a variety of natural language processing tasks. In this paper, we propose MANGO, a benchmark to evaluate their capabilities to perform text-based mapping and navigation. Our benchmark includes 53 mazes taken from a suite of textgames: each maze is paired with a walkthrough that visits every location but does not cover all possible paths. The task is question-answering: for each maze, a large language model reads the walkthrough and answers hundreds of mapping and navigation questions such as \"How should you go to Attic from West of House?\" and \"Where are we if we go north and east from Cellar?\". Although these questions are easy to humans, it turns out that even GPT-4, the best-to-date language model, performs poorly at answering them. Further, our experiments suggest that a strong mapping and navigation ability would benefit large",
    "link": "https://arxiv.org/abs/2403.19913",
    "context": "Title: MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models\nAbstract: arXiv:2403.19913v2 Announce Type: replace-cross  Abstract: Large language models such as ChatGPT and GPT-4 have recently achieved astonishing performance on a variety of natural language processing tasks. In this paper, we propose MANGO, a benchmark to evaluate their capabilities to perform text-based mapping and navigation. Our benchmark includes 53 mazes taken from a suite of textgames: each maze is paired with a walkthrough that visits every location but does not cover all possible paths. The task is question-answering: for each maze, a large language model reads the walkthrough and answers hundreds of mapping and navigation questions such as \"How should you go to Attic from West of House?\" and \"Where are we if we go north and east from Cellar?\". Although these questions are easy to humans, it turns out that even GPT-4, the best-to-date language model, performs poorly at answering them. Further, our experiments suggest that a strong mapping and navigation ability would benefit large",
    "path": "papers/24/03/2403.19913.json",
    "total_tokens": 371,
    "tldr": "该文章提出MANGO基准测试，用于评估大型语言模型在文本式规划和导航任务上的能力，虽然任务对人类来说简单，但即使是GPT-4这样的顶级模型在这方面的表现也不佳，显示了在规划和导航上的能力可能对大规模语言模型有所帮助。"
}