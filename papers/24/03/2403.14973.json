{
    "title": "Pose-Aware Self-Supervised Learning with Viewpoint Trajectory Regularization",
    "abstract": "arXiv:2403.14973v2 Announce Type: replace  Abstract: Learning visual features from unlabeled images has proven successful for semantic categorization, often by mapping different $views$ of the same object to the same feature to achieve recognition invariance. However, visual recognition involves not only identifying $what$ an object is but also understanding $how$ it is presented. For example, seeing a car from the side versus head-on is crucial for deciding whether to stay put or jump out of the way. While unsupervised feature learning for downstream viewpoint reasoning is important, it remains under-explored, partly due to the lack of a standardized evaluation method and benchmarks.   We introduce a new dataset of adjacent image triplets obtained from a viewpoint trajectory, without any semantic or pose labels. We benchmark both semantic classification and pose estimation accuracies on the same visual feature. Additionally, we propose a viewpoint trajectory regularization loss for le",
    "link": "https://arxiv.org/abs/2403.14973",
    "context": "Title: Pose-Aware Self-Supervised Learning with Viewpoint Trajectory Regularization\nAbstract: arXiv:2403.14973v2 Announce Type: replace  Abstract: Learning visual features from unlabeled images has proven successful for semantic categorization, often by mapping different $views$ of the same object to the same feature to achieve recognition invariance. However, visual recognition involves not only identifying $what$ an object is but also understanding $how$ it is presented. For example, seeing a car from the side versus head-on is crucial for deciding whether to stay put or jump out of the way. While unsupervised feature learning for downstream viewpoint reasoning is important, it remains under-explored, partly due to the lack of a standardized evaluation method and benchmarks.   We introduce a new dataset of adjacent image triplets obtained from a viewpoint trajectory, without any semantic or pose labels. We benchmark both semantic classification and pose estimation accuracies on the same visual feature. Additionally, we propose a viewpoint trajectory regularization loss for le",
    "path": "papers/24/03/2403.14973.json",
    "total_tokens": 353,
    "tldr": "该文章提出了一种新的基于视角轨迹相邻图像三元组数据的无监督学习方法，用于学习可以提升多种视觉任务（包括语义分类和姿态估计）性能的视觉特征。借助这种数据和损失函数，研究成果强调了将视角信息整合到视觉特征学习中的重要性，并可能促进在无监督学习框架下视角感知能力的进一步提升。"
}