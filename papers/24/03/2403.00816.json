{
    "title": "Read and Think: An Efficient Step-wise Multimodal Language Model for Document Understanding and Reasoning",
    "abstract": "arXiv:2403.00816v2 Announce Type: replace-cross  Abstract: Understanding the contents of multimodal documents is essential to accurately extract relevant evidence and use it for reasoning. Existing document understanding models tend to generate answers with a single word or phrase directly, ignoring the source document's evidence and lacking interpretability. In this work, we address the lack of step-wise capabilities through data augmentation and extension. Specifically, We use Multi-modal Large Language Models (MLLMs), which have strong visual understanding and reasoning abilities, as data generators to generate step-wise question-and-answer pairs for document images and use a high-performance LLM as the error detector to filter out noisy data. This step-wise data generation pipeline is implemented using both template-based and few-shot methods. We then use the generated high-quality data to train a humanized document understanding and reasoning model, specifically designed to solve ",
    "link": "https://arxiv.org/abs/2403.00816",
    "context": "Title: Read and Think: An Efficient Step-wise Multimodal Language Model for Document Understanding and Reasoning\nAbstract: arXiv:2403.00816v2 Announce Type: replace-cross  Abstract: Understanding the contents of multimodal documents is essential to accurately extract relevant evidence and use it for reasoning. Existing document understanding models tend to generate answers with a single word or phrase directly, ignoring the source document's evidence and lacking interpretability. In this work, we address the lack of step-wise capabilities through data augmentation and extension. Specifically, We use Multi-modal Large Language Models (MLLMs), which have strong visual understanding and reasoning abilities, as data generators to generate step-wise question-and-answer pairs for document images and use a high-performance LLM as the error detector to filter out noisy data. This step-wise data generation pipeline is implemented using both template-based and few-shot methods. We then use the generated high-quality data to train a humanized document understanding and reasoning model, specifically designed to solve ",
    "path": "papers/24/03/2403.00816.json",
    "total_tokens": 374,
    "tldr": "该文章提出了一种高效的多模态语言模型，通过数据增强和扩展，使其具有了逐步理解和推理的能力。该模型能够从文档图像中逐步产生问题解答对，并通过 high-performance LLM 进行错误检测以过滤噪音数据。最终，该模型训练出了一个人类化的文档理解与推理系统，解决了现有模型直接生成答案而忽略证据及缺乏解释性的问题。"
}