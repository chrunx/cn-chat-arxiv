{
    "title": "PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering",
    "abstract": "arXiv:2403.05053v2 Announce Type: replace  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. Current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only impedes their swift implementation but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tra",
    "link": "https://arxiv.org/abs/2403.05053",
    "context": "Title: PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering\nAbstract: arXiv:2403.05053v2 Announce Type: replace  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. Current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only impedes their swift implementation but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tra",
    "path": "papers/24/03/2403.05053.json",
    "total_tokens": 640,
    "translated_title": "《PrimeComposer: 使用注意力引导加速渐进式组合扩散的图像合成技术》",
    "translated_abstract": "arXiv:2403.05053v2 公告类型：替换 摘要：图像合成涉及将给定对象无缝地整合到特定的视觉环境中。当前的训练免费方法依赖于从几个采样器中提取注意力权重，以指导生成器。然而，由于这些权重是源自不同的上下文，它们的组合导致了一致性的困惑和外观信息的损失。这些问题在它们过分关注背景生成时变得更加严重，即使在这种情况下这是不必要的任务。这不仅妨碍了它们的快速实施，而且也影响了前景生成的质量。此外，这些方法在过渡区域引入了不必要的艺术颜料。在本论文中，我们将图像合成视为一种基于主题的局部编辑任务，仅专注于前景的生成。在每一次编辑中，所编辑的前景与噪声背景相结合，以维持场景的一致性。为了解决剩余的问题，我们提出了PrimeComposer，这是一种更快的前景为主提升注意力引导加速的渐进式组合扩散图像合成方法。",
    "tldr": "研究提出了一种新的渐进式组合扩散方法，专注于图像合成中的前景生成，并通过改进的注意力引导策略显著提高了合成速度和质量。"
}