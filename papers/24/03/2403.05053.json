{
    "title": "PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering",
    "abstract": "arXiv:2403.05053v2 Announce Type: replace  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. Current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only impedes their swift implementation but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tra",
    "link": "https://arxiv.org/abs/2403.05053",
    "context": "Title: PrimeComposer: Faster Progressively Combined Diffusion for Image Composition with Attention Steering\nAbstract: arXiv:2403.05053v2 Announce Type: replace  Abstract: Image composition involves seamlessly integrating given objects into a specific visual context. Current training-free methods rely on composing attention weights from several samplers to guide the generator. However, since these weights are derived from disparate contexts, their combination leads to coherence confusion and loss of appearance information. These issues worsen with their excessive focus on background generation, even when unnecessary in this task. This not only impedes their swift implementation but also compromises foreground generation quality. Moreover, these methods introduce unwanted artifacts in the transition area. In this paper, we formulate image composition as a subject-based local editing task, solely focusing on foreground generation. At each step, the edited foreground is combined with the noisy background to maintain scene consistency. To address the remaining issues, we propose PrimeComposer, a faster tra",
    "path": "papers/24/03/2403.05053.json",
    "total_tokens": 322,
    "tldr": "该文章提出PrimeComposer，这是一种通过注意力引导的速度更快、质量更优的渐进式组合式扩散图像合成方法，它专注于局部编辑以保持场景一致性，有效减少了背景噪声，避免了过渡区域的不良效果。"
}