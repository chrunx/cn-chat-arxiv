{
    "title": "Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents",
    "abstract": "arXiv:2403.04202v5 Announce Type: replace-cross  Abstract: Growing concerns about safety and alignment of AI systems highlight the importance of embedding moral capabilities in artificial agents: a promising solution is the use of learning from experience, i.e., Reinforcement Learning. In multi-agent (social) environments, complex population-level phenomena may emerge from interactions between individual learning agents. Many of the existing studies rely on simulated social dilemma environments to study the interactions of independent learning agents; however, they tend to ignore the moral heterogeneity that is likely to be present in societies of agents in practice. For example, at different points in time a single learning agent may face opponents who are consequentialist (i.e., focused on maximizing outcomes over time), norm-based (i.e., conforming to specific norms), or virtue-based (i.e., considering a combination of different virtues). The extent to which agents' co-development m",
    "link": "https://arxiv.org/abs/2403.04202",
    "context": "Title: Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents\nAbstract: arXiv:2403.04202v5 Announce Type: replace-cross  Abstract: Growing concerns about safety and alignment of AI systems highlight the importance of embedding moral capabilities in artificial agents: a promising solution is the use of learning from experience, i.e., Reinforcement Learning. In multi-agent (social) environments, complex population-level phenomena may emerge from interactions between individual learning agents. Many of the existing studies rely on simulated social dilemma environments to study the interactions of independent learning agents; however, they tend to ignore the moral heterogeneity that is likely to be present in societies of agents in practice. For example, at different points in time a single learning agent may face opponents who are consequentialist (i.e., focused on maximizing outcomes over time), norm-based (i.e., conforming to specific norms), or virtue-based (i.e., considering a combination of different virtues). The extent to which agents' co-development m",
    "path": "papers/24/03/2403.04202.json",
    "total_tokens": 357,
    "tldr": "该文章揭示了在由具有不同道德倾向学习代理组成的异质化社会群体中，道德行为动态的复杂性。通过对学习代理在不同时间点面对不同道德类型对手的交互行为的研究，该研究强调了在现实世界中引入道德能力的AI系统，需要考虑道德多样性的重要性。"
}