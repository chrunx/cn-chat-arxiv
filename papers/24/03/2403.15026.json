{
    "title": "VRSO: Visual-Centric Reconstruction for Static Object Annotation",
    "abstract": "arXiv:2403.15026v2 Announce Type: replace  Abstract: As a part of the perception results of intelligent driving systems, static object detection (SOD) in 3D space provides crucial cues for driving environment understanding. With the rapid deployment of deep neural networks for SOD tasks, the demand for high-quality training samples soars. The traditional, also reliable, way is manual labelling over the dense LiDAR point clouds and reference images. Though most public driving datasets adopt this strategy to provide SOD ground truth (GT), it is still expensive and time-consuming in practice. This paper introduces VRSO, a visual-centric approach for static object annotation. Experiments on the Waymo Open Dataset show that the mean reprojection error from VRSO annotation is only 2.6 pixels, around four times lower than the Waymo Open Dataset labels (10.6 pixels). VRSO is distinguished in low cost, high efficiency, and high quality: (1) It recovers static objects in 3D space with only camer",
    "link": "https://arxiv.org/abs/2403.15026",
    "context": "Title: VRSO: Visual-Centric Reconstruction for Static Object Annotation\nAbstract: arXiv:2403.15026v2 Announce Type: replace  Abstract: As a part of the perception results of intelligent driving systems, static object detection (SOD) in 3D space provides crucial cues for driving environment understanding. With the rapid deployment of deep neural networks for SOD tasks, the demand for high-quality training samples soars. The traditional, also reliable, way is manual labelling over the dense LiDAR point clouds and reference images. Though most public driving datasets adopt this strategy to provide SOD ground truth (GT), it is still expensive and time-consuming in practice. This paper introduces VRSO, a visual-centric approach for static object annotation. Experiments on the Waymo Open Dataset show that the mean reprojection error from VRSO annotation is only 2.6 pixels, around four times lower than the Waymo Open Dataset labels (10.6 pixels). VRSO is distinguished in low cost, high efficiency, and high quality: (1) It recovers static objects in 3D space with only camer",
    "path": "papers/24/03/2403.15026.json",
    "total_tokens": 428,
    "tldr": "该文章介绍了VRSO，一种基于视觉的方法用于静态对象标注，该方法在Waymo Open Dataset上进行实验，展示了较低的重新投影误差，相比标准的Waymo Open Datasetlabels低了约四倍（前者为10.6像素，后者仅为2.6像素）。VRSO方法因其成本低廉、效率高、质量高而得到广泛关注，它仅通过摄像头图像和参考图像就能恢复静态对象在3D空间中的标注，极大地降低了手动标注的复杂性和成本，提高了标注速度和标注准确性。"
}