{
    "title": "VRSO: Visual-Centric Reconstruction for Static Object Annotation",
    "abstract": "arXiv:2403.15026v2 Announce Type: replace  Abstract: As a part of the perception results of intelligent driving systems, static object detection (SOD) in 3D space provides crucial cues for driving environment understanding. With the rapid deployment of deep neural networks for SOD tasks, the demand for high-quality training samples soars. The traditional, also reliable, way is manual labelling over the dense LiDAR point clouds and reference images. Though most public driving datasets adopt this strategy to provide SOD ground truth (GT), it is still expensive and time-consuming in practice. This paper introduces VRSO, a visual-centric approach for static object annotation. Experiments on the Waymo Open Dataset show that the mean reprojection error from VRSO annotation is only 2.6 pixels, around four times lower than the Waymo Open Dataset labels (10.6 pixels). VRSO is distinguished in low cost, high efficiency, and high quality: (1) It recovers static objects in 3D space with only camer",
    "link": "https://arxiv.org/abs/2403.15026",
    "context": "Title: VRSO: Visual-Centric Reconstruction for Static Object Annotation\nAbstract: arXiv:2403.15026v2 Announce Type: replace  Abstract: As a part of the perception results of intelligent driving systems, static object detection (SOD) in 3D space provides crucial cues for driving environment understanding. With the rapid deployment of deep neural networks for SOD tasks, the demand for high-quality training samples soars. The traditional, also reliable, way is manual labelling over the dense LiDAR point clouds and reference images. Though most public driving datasets adopt this strategy to provide SOD ground truth (GT), it is still expensive and time-consuming in practice. This paper introduces VRSO, a visual-centric approach for static object annotation. Experiments on the Waymo Open Dataset show that the mean reprojection error from VRSO annotation is only 2.6 pixels, around four times lower than the Waymo Open Dataset labels (10.6 pixels). VRSO is distinguished in low cost, high efficiency, and high quality: (1) It recovers static objects in 3D space with only camer",
    "path": "papers/24/03/2403.15026.json",
    "total_tokens": 793,
    "translated_title": "VRSO：基于视觉的静态对象重建方法",
    "translated_abstract": "arXiv:2403.15026v2 公告类型：替换 摘要：作为智能驾驶系统感知结果的一部分，空间中静态对象的检测（SOD）为驾驶环境理解提供了关键提示。随着深层神经网络在SOD任务上的快速部署，对高质量训练样本的需求正在飙升。传统且可靠的方法是对密集激光雷达点云和参考图像进行手动标记。尽管大多数公共驾驶数据集都采用这种方式来提供SOD的 ground truth (GT)，但在实践中，它仍然非常昂贵和耗时。本研究介绍了VRSO，一种基于视觉的静态对象标注方法。在Waymo Open Dataset上的实验表明，VRSO标注的重投影误差只有2.6个像素，大约是Waymo Open Dataset标签（10.6像素）的四倍。VRSO在成本低、效率高和质量高方面表现突出：（1）它只需要摄像头图像和参考深度，就能在3D空间中恢复静态对象；（2）与其他基于视觉的方法相比，VRSO能够提供更准确的三维重建；（3）VRSO还能够处理难以捕捉的细节，如行人和非固定的交通标志。此外，VRSO的训练和评估过程不需要特定的3D场景，可以是完全数据驱动的，并在实际驾驶场景中通过真实车辆进行测试。目前在公共数据集上测试VRSO，你可以在arXiv上获取代码和数据，并在未来的驾驶数据集中应用我们的方法。",
    "tldr": "VRSO方法通过使用摄像头图像和参考深度，在3D空间中准确恢复静态对象，并且能够处理难以捕捉的细节，在Waymo Open Dataset上表现出色。",
    "en_tdlr": "VRSO employs camera images and reference depth to accurately recover static objects in 3D space, handling challenging details, and excels on the Waymo Open Dataset."
}