{
    "title": "A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing",
    "abstract": "arXiv:2403.02504v3 Announce Type: replace-cross  Abstract: Given that natural language serves as the primary conduit for expressing thoughts and emotions, text analysis has become a key technique in psychological research. It enables the extraction of valuable insights from natural language, facilitating endeavors like personality traits assessment, mental health monitoring, and sentiment analysis in interpersonal communications. In text analysis, existing studies often resort to either human coding, which is time-consuming, using pre-built dictionaries, which often fails to cover all possible scenarios, or training models from scratch, which requires large amounts of labeled data. In this tutorial, we introduce the pretrain-finetune paradigm. The pretrain-finetune paradigm represents a transformative approach in text analysis and natural language processing. This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in f",
    "link": "https://arxiv.org/abs/2403.02504",
    "context": "Title: A Tutorial on the Pretrain-Finetune Paradigm for Natural Language Processing\nAbstract: arXiv:2403.02504v3 Announce Type: replace-cross  Abstract: Given that natural language serves as the primary conduit for expressing thoughts and emotions, text analysis has become a key technique in psychological research. It enables the extraction of valuable insights from natural language, facilitating endeavors like personality traits assessment, mental health monitoring, and sentiment analysis in interpersonal communications. In text analysis, existing studies often resort to either human coding, which is time-consuming, using pre-built dictionaries, which often fails to cover all possible scenarios, or training models from scratch, which requires large amounts of labeled data. In this tutorial, we introduce the pretrain-finetune paradigm. The pretrain-finetune paradigm represents a transformative approach in text analysis and natural language processing. This paradigm distinguishes itself through the use of large pretrained language models, demonstrating remarkable efficiency in f",
    "path": "papers/24/03/2403.02504.json",
    "total_tokens": 754,
    "translated_title": "自然语言处理预训练-微调范式教程",
    "translated_abstract": "arXiv:2403.02504v3 新闻类型：替换-交叉  摘要：由于自然语言充当表达思想和情感的主要渠道，文本分析已成为心理学研究中的重要技术。它使从自然语言中提取出宝贵见解成为可能，支持诸如评估个性特征、监测心理健康和人际沟通中的情感分析等努力。在文本分析中，现有的研究通常会采用手动编码，这是一种耗时的方法，使用预先构建的词典，这种方法通常无法涵盖所有可能的情况，或者从头开始训练模型，这需要大量的标记数据。在本教程中，我们介绍预训练-微调范式。预训练-微调范式代表了文本分析和自然语言处理中的一个根本变革方法。这种范式通过使用大型预训练语言模型而与众不同，显示出在负责多种不同任务时的高效率和通用性。通过在特定任务上进行微调和微调，这些模型能够以相对较小的标注数据集获得几乎与从头开始训练时相同的性能水平。此外，预训练模型为研究者提供了丰富的上下文表示和语言理解能力，而无需每个新任务都需要从头开始学习。",
    "tldr": "论文介绍了自然语言处理领域中预训练-微调范式的重要性和优势，该范式通过使用大型预训练语言模型，可以在特定任务上进行微调和微调，以相对较小的标注数据集获得接近从零开始的性能，并且提供丰富的上下文表示和语言理解能力。"
}