{
    "title": "STaR-GATE: Teaching Language Models to Ask Clarifying Questions",
    "abstract": "arXiv:2403.19154v3 Announce Type: replace-cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity (GATE; Li et al., 2023), models often struggle to ask good questions. We explore a language model's ability to self-improve (STaR; Zelikman et al., 2022) by rewarding the model for generating useful questions-a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model-the Questioner-and a Roleplayer whose preferences are unknown to the Questioner. By asking questions, the Questioner elicits preferences from the Roleplayer. The Questioner is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an Oracle with access to the Roleplayer's latent preferences. After two iterations of self-improvement, the Question",
    "link": "https://arxiv.org/abs/2403.19154",
    "context": "Title: STaR-GATE: Teaching Language Models to Ask Clarifying Questions\nAbstract: arXiv:2403.19154v3 Announce Type: replace-cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity (GATE; Li et al., 2023), models often struggle to ask good questions. We explore a language model's ability to self-improve (STaR; Zelikman et al., 2022) by rewarding the model for generating useful questions-a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model-the Questioner-and a Roleplayer whose preferences are unknown to the Questioner. By asking questions, the Questioner elicits preferences from the Roleplayer. The Questioner is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an Oracle with access to the Roleplayer's latent preferences. After two iterations of self-improvement, the Question",
    "path": "papers/24/03/2403.19154.json",
    "total_tokens": 358,
    "tldr": "该文章提出了一种名为STaR-GATE的方法，通过自我改进的方式奖励语言模型生成有用问题，以提高其在完成任务时的提问能力。"
}