{
    "title": "Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context",
    "abstract": "arXiv:2403.05530v4 Announce Type: replace-cross  Abstract: In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvem",
    "link": "https://arxiv.org/abs/2403.05530",
    "context": "Title: Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context\nAbstract: arXiv:2403.05530v4 Announce Type: replace-cross  Abstract: In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvem",
    "path": "papers/24/03/2403.05530.json",
    "total_tokens": 445,
    "tldr": "该文章介绍了Gemini 1.5家族的新模型版本，这些模型能够处理并整合从数百万tokens上下文中提取的细粒度信息，其中包含多种长文本、视频和音频。这种高度计算效率的模型在长上下文检索、长文档问答、长视频问答和长上下文自动语音识别方面取得了显著的性能提升，并且在广泛的标准测试中保持了或超越了Gemini 1.0 Ultra的性能水平。研究了这些模型在长上下文能力方面的界限，发现了持续的性能改进。"
}