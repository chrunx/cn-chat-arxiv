{
    "title": "Causal Equal Protection as Algorithmic Fairness",
    "abstract": "arXiv:2402.12062v3 Announce Type: replace-cross  Abstract: By combining the philosophical literature on statistical evidence and the interdisciplinary literature on algorithmic fairness, we revisit recent objections against classification parity in light of causal analyses of algorithmic fairness and the distinction between predictive and diagnostic evidence. We focus on trial proceedings as a black-box classification algorithm in which defendants are sorted into two groups by convicting or acquitting them. We defend a novel principle, causal equal protection, that combines classification parity with the causal approach. In the do-calculus, causal equal protection requires that individuals should not be subject to uneven risks of classification error because of their protected or socially salient characteristics. The explicit use of protected characteristics, however, may be required if it equalizes these risks.",
    "link": "https://arxiv.org/abs/2402.12062",
    "context": "Title: Causal Equal Protection as Algorithmic Fairness\nAbstract: arXiv:2402.12062v3 Announce Type: replace-cross  Abstract: By combining the philosophical literature on statistical evidence and the interdisciplinary literature on algorithmic fairness, we revisit recent objections against classification parity in light of causal analyses of algorithmic fairness and the distinction between predictive and diagnostic evidence. We focus on trial proceedings as a black-box classification algorithm in which defendants are sorted into two groups by convicting or acquitting them. We defend a novel principle, causal equal protection, that combines classification parity with the causal approach. In the do-calculus, causal equal protection requires that individuals should not be subject to uneven risks of classification error because of their protected or socially salient characteristics. The explicit use of protected characteristics, however, may be required if it equalizes these risks.",
    "path": "papers/24/02/2402.12062.json",
    "total_tokens": 391,
    "tldr": "该文章通过结合统计证据的哲学文献和算法公平性跨学科文献，对分类平等领域的最新质疑进行了重审，并考虑了对算法公平性的因果分析以及预测证据和诊断证据的区别。文章在审判程序中使用分类器作为黑箱算法，其中被告根据定罪或无罪释放被分类到两个不同的群体。文章提出了一个新的原则“因果平等保护”，该原则结合了分类平等和因果方法。在d-分离算子中，因果平等保护要求个人的分类错误风险不应因他们的受保护特征或社会上的显著特征而不同。然而，如果使用受保护特征可以平等化这些风险，则可能需要明确使用这些特征。"
}