{
    "title": "EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions",
    "abstract": "arXiv:2402.17485v2 Announce Type: replace  Abstract: In this work, we tackle the challenge of enhancing the realism and expressiveness in talking head video generation by focusing on the dynamic and nuanced relationship between audio cues and facial movements. We identify the limitations of traditional techniques that often fail to capture the full spectrum of human expressions and the uniqueness of individual facial styles. To address these issues, we propose EMO, a novel framework that utilizes a direct audio-to-video synthesis approach, bypassing the need for intermediate 3D models or facial landmarks. Our method ensures seamless frame transitions and consistent identity preservation throughout the video, resulting in highly expressive and lifelike animations. Experimental results demonsrate that EMO is able to produce not only convincing speaking videos but also singing videos in various styles, significantly outperforming existing state-of-the-art methodologies in terms of express",
    "link": "https://arxiv.org/abs/2402.17485",
    "context": "Title: EMO: Emote Portrait Alive -- Generating Expressive Portrait Videos with Audio2Video Diffusion Model under Weak Conditions\nAbstract: arXiv:2402.17485v2 Announce Type: replace  Abstract: In this work, we tackle the challenge of enhancing the realism and expressiveness in talking head video generation by focusing on the dynamic and nuanced relationship between audio cues and facial movements. We identify the limitations of traditional techniques that often fail to capture the full spectrum of human expressions and the uniqueness of individual facial styles. To address these issues, we propose EMO, a novel framework that utilizes a direct audio-to-video synthesis approach, bypassing the need for intermediate 3D models or facial landmarks. Our method ensures seamless frame transitions and consistent identity preservation throughout the video, resulting in highly expressive and lifelike animations. Experimental results demonsrate that EMO is able to produce not only convincing speaking videos but also singing videos in various styles, significantly outperforming existing state-of-the-art methodologies in terms of express",
    "path": "papers/24/02/2402.17485.json",
    "total_tokens": 374,
    "tldr": "该文章的核心创新在于提出了一种名为EMO的框架，它使用了一种直接的音频-视频合成方法，无需中间的3D模型或面部特征点，能够增强说话和唱歌视频生成中的现实感和表达力。该方法确保了视频中帧的连续性以及身份的一致性，生成了高度逼真和自然的动画。实验结果表明，EMO在表达性和领先技术上均得到了显著提升。"
}