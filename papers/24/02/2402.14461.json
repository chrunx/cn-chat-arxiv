{
    "title": "S^2Former-OR: Single-Stage Bi-Modal Transformer for Scene Graph Generation in OR",
    "abstract": "arXiv:2402.14461v2 Announce Type: replace  Abstract: Scene graph generation (SGG) of surgical procedures is crucial in enhancing holistically cognitive intelligence in the operating room (OR). However, previous works have primarily relied on multi-stage learning, where the generated semantic scene graphs depend on intermediate processes with pose estimation and object detection. This pipeline may potentially compromise the flexibility of learning multimodal representations, consequently constraining the overall effectiveness. In this study, we introduce a novel single-stage bi-modal transformer framework for SGG in the OR, termed S^2Former-OR, aimed to complementally leverage multi-view 2D scenes and 3D point clouds for SGG in an end-to-end manner. Concretely, our model embraces a View-Sync Transfusion scheme to encourage multi-view visual information interaction. Concurrently, a Geometry-Visual Cohesion operation is designed to integrate the synergic 2D semantic features into 3D point",
    "link": "https://arxiv.org/abs/2402.14461",
    "context": "Title: S^2Former-OR: Single-Stage Bi-Modal Transformer for Scene Graph Generation in OR\nAbstract: arXiv:2402.14461v2 Announce Type: replace  Abstract: Scene graph generation (SGG) of surgical procedures is crucial in enhancing holistically cognitive intelligence in the operating room (OR). However, previous works have primarily relied on multi-stage learning, where the generated semantic scene graphs depend on intermediate processes with pose estimation and object detection. This pipeline may potentially compromise the flexibility of learning multimodal representations, consequently constraining the overall effectiveness. In this study, we introduce a novel single-stage bi-modal transformer framework for SGG in the OR, termed S^2Former-OR, aimed to complementally leverage multi-view 2D scenes and 3D point clouds for SGG in an end-to-end manner. Concretely, our model embraces a View-Sync Transfusion scheme to encourage multi-view visual information interaction. Concurrently, a Geometry-Visual Cohesion operation is designed to integrate the synergic 2D semantic features into 3D point",
    "path": "papers/24/02/2402.14461.json",
    "total_tokens": 391,
    "tldr": "该文章提出了一种名为S^2Former-OR的单阶段双模态 transformer框架，用于在手术室场景图中进行综合自洽的学习。该模型通过一种视图同步融合方案促进了多视角视觉信息的交互，并通过几何视觉协同操作将2D语义特征与3D点云数据结合，实现了在手术室中以端到端的方式进行多模态数据融合和场景图生成。"
}