{
    "title": "Zero shot VLMs for hate meme detection: Are we there yet?",
    "abstract": "arXiv:2402.12198v2 Announce Type: replace-cross  Abstract: Multimedia content on social media is rapidly evolving, with memes gaining prominence as a distinctive form. Unfortunately, some malicious users exploit memes to target individuals or vulnerable communities, making it imperative to identify and address such instances of hateful memes. Extensive research has been conducted to address this issue by developing hate meme detection models. However, a notable limitation of traditional machine/deep learning models is the requirement for labeled datasets for accurate classification. Recently, the research community has witnessed the emergence of several visual language models that have exhibited outstanding performance across various tasks. In this study, we aim to investigate the efficacy of these visual language models in handling intricate tasks such as hate meme detection. We use various prompt settings to focus on zero-shot classification of hateful/harmful memes. Through our anal",
    "link": "https://arxiv.org/abs/2402.12198",
    "context": "Title: Zero shot VLMs for hate meme detection: Are we there yet?\nAbstract: arXiv:2402.12198v2 Announce Type: replace-cross  Abstract: Multimedia content on social media is rapidly evolving, with memes gaining prominence as a distinctive form. Unfortunately, some malicious users exploit memes to target individuals or vulnerable communities, making it imperative to identify and address such instances of hateful memes. Extensive research has been conducted to address this issue by developing hate meme detection models. However, a notable limitation of traditional machine/deep learning models is the requirement for labeled datasets for accurate classification. Recently, the research community has witnessed the emergence of several visual language models that have exhibited outstanding performance across various tasks. In this study, we aim to investigate the efficacy of these visual language models in handling intricate tasks such as hate meme detection. We use various prompt settings to focus on zero-shot classification of hateful/harmful memes. Through our anal",
    "path": "papers/24/02/2402.12198.json",
    "total_tokens": 954,
    "translated_title": "零样本VLM在仇恨meme检测中的应用：我们还不足以应对吗？",
    "translated_abstract": "arXiv:2402.12198v2 更改消息类型：替换证书  摘要更改通知类型：替换-交叉  摘要：社交媒体上的多媒体内容正在迅速发展，meme作为一种独特的形式越来越受到人们的关注。不幸的是，一些不良用户利用meme来攻击个人或脆弱的社区，这使得识别和解决这类仇恨meme变得至关重要。这项研究已经开发出了多种仇恨meme检测模型，以解决这个问题。然而，传统机器/深度学习模型的一个显着局限性是需要大量的标签数据来进行准确的分类。最近，研究界见证了各种视觉语言模型的出现，这些模型在各种任务上表现出色。在本研究中，我们旨在调查这些视觉语言模型在处理复杂的任务，如仇恨meme检测方面的有效性。我们使用了各种提示设置，专注于仇恨/有害meme的零样本分类。通过我们的分析表明，某些零样本设置显示出处理复杂矢量任务的潜力和可行性。然而，我们也要指出，目前的零样本方法在准确性和泛化能力方面还存在局限性。尽管如此，随着研究的不断深入，我们有理由相信，这些由最新技术驱动的模型将为识别和缓解网上仇恨meme的传播做出重大贡献。  我们在使用大量示例短语的基础上进了一步，应用了一系列用于检测和分类仇恨meme的零样本多模态提示词（prompts）。我们发现，在某些情况下，维基百科的词条和描述性短语可用于指定特定类型的仇恨内容，即使在不需要预先训练的分类器的情况下，它们也能促进模型的有效判别式学习。在后续的实验中，我们探索了将零样本多模态Prompt改写（rephrasing）策略应用于极端言论、敏感主题等相关领域的多模态学习前训练（prompt rephrasing for multi-modal learning pretraining），并发现该方法可在不牺牲模型性能的情况下有效提高零样本到实验域的泛化能力。整体而言，我们的结果表明，尽管面临挑战，零样本多模态提示词（prompts）作为一种新颖的范式，其潜力已被证明是广大的。我们的研究指出，将来的工作应致力于进一步的研究和开发，以解决此类方法的局限性，并扩展它们在网络空间仇恨内容检测和响应中的应用。",
    "tldr": "本文旨在探究视觉语言模型在零样本情况下识别仇恨meme的能力，并发现尽管当前零样本方法在准确性和泛化能力方面存在局限性，但未来研究有潜力解决这些局限性并扩大其在网络空间仇恨内容检测和响应中的应用。",
    "en_tdlr": "This study investigates the ability of visual language models to detect hate memes in zero-shot scenarios, and highlights the potential for future research to address current limitations and expand their application in the detection and response to online hate content."
}