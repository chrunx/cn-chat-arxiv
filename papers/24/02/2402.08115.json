{
    "title": "On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks",
    "abstract": "arXiv:2402.08115v2 Announce Type: replace  Abstract: There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative prompting in the context of reasoning and planning. We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24, Graph Coloring, and STRI",
    "link": "https://arxiv.org/abs/2402.08115",
    "context": "Title: On the Self-Verification Limitations of Large Language Models on Reasoning and Planning Tasks\nAbstract: arXiv:2402.08115v2 Announce Type: replace  Abstract: There has been considerable divergence of opinion on the reasoning abilities of Large Language Models (LLMs). While the initial optimism that reasoning might emerge automatically with scale has been tempered thanks to a slew of counterexamples--ranging from multiplication to simple planning--there persists a wide spread belief that LLMs can self-critique and improve their own solutions in an iterative fashion. This belief seemingly rests on the assumption that verification of correctness should be easier than generation--a rather classical argument from computational complexity--which should be irrelevant to LLMs to the extent that what they are doing is approximate retrieval. In this paper, we set out to systematically investigate the effectiveness of iterative prompting in the context of reasoning and planning. We present a principled empirical study of the performance of GPT-4 in three domains: Game of 24, Graph Coloring, and STRI",
    "path": "papers/24/02/2402.08115.json",
    "total_tokens": 334,
    "tldr": "该文章通过系统地研究大型语言模型在推理和规划领域的自我验证能力，揭示了在现实世界任务中，大型语言模型的性能并不像人们所期望的那样可靠，特别是在复杂规划和问题解决领域。"
}