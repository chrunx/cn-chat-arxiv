{
    "title": "Cooperation and Control in Delegation Games",
    "abstract": "arXiv:2402.15821v2 Announce Type: replace-cross  Abstract: Many settings of interest involving humans and machines -- from virtual personal assistants to autonomous vehicles -- can naturally be modelled as principals (humans) delegating to agents (machines), which then interact with each other on their principals' behalf. We refer to these multi-principal, multi-agent scenarios as delegation games. In such games, there are two important failure modes: problems of control (where an agent fails to act in line their principal's preferences) and problems of cooperation (where the agents fail to work well together). In this paper we formalise and analyse these problems, further breaking them down into issues of alignment (do the players have similar preferences?) and capabilities (how competent are the players at satisfying those preferences?). We show -- theoretically and empirically -- how these measures determine the principals' welfare, how they can be estimated using limited observatio",
    "link": "https://arxiv.org/abs/2402.15821",
    "context": "Title: Cooperation and Control in Delegation Games\nAbstract: arXiv:2402.15821v2 Announce Type: replace-cross  Abstract: Many settings of interest involving humans and machines -- from virtual personal assistants to autonomous vehicles -- can naturally be modelled as principals (humans) delegating to agents (machines), which then interact with each other on their principals' behalf. We refer to these multi-principal, multi-agent scenarios as delegation games. In such games, there are two important failure modes: problems of control (where an agent fails to act in line their principal's preferences) and problems of cooperation (where the agents fail to work well together). In this paper we formalise and analyse these problems, further breaking them down into issues of alignment (do the players have similar preferences?) and capabilities (how competent are the players at satisfying those preferences?). We show -- theoretically and empirically -- how these measures determine the principals' welfare, how they can be estimated using limited observatio",
    "path": "papers/24/02/2402.15821.json",
    "total_tokens": 433,
    "tldr": "该文章探讨了一种名为委托博弈的模型，它模拟了人类与机器（如个人虚拟助手和自动驾驶车辆）之间的工作关系。研究人员研究了委托游戏中的两种重要失败模式：控制问题和合作问题。控制问题涉及代理人的行为与其委托人偏好不一致，而合作问题则指代理人之间在执行任务时的协作不佳。论文深入分析了这些问题，并将它们进一步划分为偏好一致性和执行能力两个方面。通过理论分析和有限观测数据，研究者证明了这些因素如何影响委托人的福利，并探讨了如何使用现有信息来估计这些问题。总的来说，该研究为理解人类与机器之间的工作协作提供了新的视角，并可能对涉及多方交互的自动化系统设计有重要启示。"
}