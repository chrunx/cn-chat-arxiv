{
    "title": "New Job, New Gender? Measuring the Social Bias in Image Generation Models",
    "abstract": "arXiv:2401.00763v2 Announce Type: replace-cross  Abstract: Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel evaluation framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race",
    "link": "https://arxiv.org/abs/2401.00763",
    "context": "Title: New Job, New Gender? Measuring the Social Bias in Image Generation Models\nAbstract: arXiv:2401.00763v2 Announce Type: replace-cross  Abstract: Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel evaluation framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race",
    "path": "papers/24/01/2401.00763.json",
    "total_tokens": 333,
    "tldr": "该文章提供一种名为BiasPainter的框架，能够准确、自动且全面地触发图像生成模型中的社会偏见，弥补了以往研究在评估图像生成模型偏见时的局限性，包括准确度不足、过度依赖人工劳动及分析不全面的问题。"
}