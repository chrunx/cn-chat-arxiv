{
    "title": "SVIPTR: Fast and Efficient Scene Text Recognition with Vision Permutable Extractor",
    "abstract": "arXiv:2401.10110v4 Announce Type: replace  Abstract: Scene Text Recognition (STR) is an important and challenging upstream task for building structured information databases, that involves recognizing text within images of natural scenes. Although current state-of-the-art (SOTA) models for STR exhibit high performance, they typically suffer from low inference efficiency due to their reliance on hybrid architectures comprised of visual encoders and sequence decoders. In this work, we propose a VIsion Permutable extractor for fast and efficient Scene Text Recognition (SVIPTR), which achieves an impressive balance between high performance and rapid inference speeds in the domain of STR. Specifically, SVIPTR leverages a visual-semantic extractor with a pyramid structure, characterized by the Permutation and combination of local and global self-attention layers. This design results in a lightweight and efficient model and its inference is insensitive to input length. Extensive experimental ",
    "link": "https://arxiv.org/abs/2401.10110",
    "context": "Title: SVIPTR: Fast and Efficient Scene Text Recognition with Vision Permutable Extractor\nAbstract: arXiv:2401.10110v4 Announce Type: replace  Abstract: Scene Text Recognition (STR) is an important and challenging upstream task for building structured information databases, that involves recognizing text within images of natural scenes. Although current state-of-the-art (SOTA) models for STR exhibit high performance, they typically suffer from low inference efficiency due to their reliance on hybrid architectures comprised of visual encoders and sequence decoders. In this work, we propose a VIsion Permutable extractor for fast and efficient Scene Text Recognition (SVIPTR), which achieves an impressive balance between high performance and rapid inference speeds in the domain of STR. Specifically, SVIPTR leverages a visual-semantic extractor with a pyramid structure, characterized by the Permutation and combination of local and global self-attention layers. This design results in a lightweight and efficient model and its inference is insensitive to input length. Extensive experimental ",
    "path": "papers/24/01/2401.10110.json",
    "total_tokens": 350,
    "tldr": "该文章提出了一种名为SVIPTR的视觉可变提取器，用于快速且高效的场景文本识别。SVIPTR通过一种视觉-语义提取器，结合了自注意力的局部和全局层级，以及输入文本长度的动态调整，实现了在提高性能的同时保持了快速的推理速度。"
}