{
    "title": "Preservation of Feature Stability in Machine Learning Under Data Uncertainty for Decision Support in Critical Domains",
    "abstract": "arXiv:2401.11044v2 Announce Type: replace-cross  Abstract: In a world where Machine Learning (ML) is increasingly deployed to support decision-making in critical domains, providing decision-makers with explainable, stable, and relevant inputs becomes fundamental. Understanding how machine learning works under missing data and how this affects feature variability is paramount. This is even more relevant as machine learning approaches focus on standardising decision-making approaches that rely on an idealised set of features. However, decision-making in human activities often relies on incomplete data, even in critical domains. This paper addresses this gap by conducting a set of experiments using traditional machine learning methods that look for optimal decisions in comparison to a recently deployed machine learning method focused on a classification that is more descriptive and mimics human decision making, allowing for the natural integration of explainability. We found that the ML d",
    "link": "https://arxiv.org/abs/2401.11044",
    "context": "Title: Preservation of Feature Stability in Machine Learning Under Data Uncertainty for Decision Support in Critical Domains\nAbstract: arXiv:2401.11044v2 Announce Type: replace-cross  Abstract: In a world where Machine Learning (ML) is increasingly deployed to support decision-making in critical domains, providing decision-makers with explainable, stable, and relevant inputs becomes fundamental. Understanding how machine learning works under missing data and how this affects feature variability is paramount. This is even more relevant as machine learning approaches focus on standardising decision-making approaches that rely on an idealised set of features. However, decision-making in human activities often relies on incomplete data, even in critical domains. This paper addresses this gap by conducting a set of experiments using traditional machine learning methods that look for optimal decisions in comparison to a recently deployed machine learning method focused on a classification that is more descriptive and mimics human decision making, allowing for the natural integration of explainability. We found that the ML d",
    "path": "papers/24/01/2401.11044.json",
    "total_tokens": 330,
    "tldr": "该文章通过实验比较了传统机器学习方法在缺失数据下的决策效果，以及一种旨在描述性预测并模拟人类决策的机器学习方法的性能。研究发现，后者更好地适应了包含不完整数据的复杂决策环境，提高了决策过程中的解释性和稳定性。"
}