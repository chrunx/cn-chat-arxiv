{
    "title": "Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs",
    "abstract": "arXiv:2408.04331v1 Announce Type: cross  Abstract: Large language models (LLMs) and large multimodal models (LMMs) have significantly impacted the AI community, industry, and various economic sectors. In journalism, integrating AI poses unique challenges and opportunities, particularly in enhancing the quality and efficiency of news reporting. This study explores how LLMs and LMMs can assist journalistic practice by generating contextualised captions for images accompanying news articles. We conducted experiments using the GoodNews dataset to evaluate the ability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of context: entire news articles, or extracted named entities. In addition, we compared their performance to a two-stage pipeline composed of a captioning model (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs (GPT-4 or LLaMA). We assess a diversity of models, and we find that while the choice of contextualisation model is a significant fact",
    "link": "https://arxiv.org/abs/2408.04331",
    "context": "Title: Enhancing Journalism with AI: A Study of Contextualized Image Captioning for News Articles using LLMs and LMMs\nAbstract: arXiv:2408.04331v1 Announce Type: cross  Abstract: Large language models (LLMs) and large multimodal models (LMMs) have significantly impacted the AI community, industry, and various economic sectors. In journalism, integrating AI poses unique challenges and opportunities, particularly in enhancing the quality and efficiency of news reporting. This study explores how LLMs and LMMs can assist journalistic practice by generating contextualised captions for images accompanying news articles. We conducted experiments using the GoodNews dataset to evaluate the ability of LMMs (BLIP-2, GPT-4v, or LLaVA) to incorporate one of two types of context: entire news articles, or extracted named entities. In addition, we compared their performance to a two-stage pipeline composed of a captioning model (BLIP-2, OFA, or ViT-GPT2) with post-hoc contextualisation with LLMs (GPT-4 or LLaMA). We assess a diversity of models, and we find that while the choice of contextualisation model is a significant fact",
    "path": "papers/24/08/2408.04331.json",
    "total_tokens": 459,
    "tldr": "该文章探讨了如何使用大型语言模型（LLMs）和大型多模态模型（LMMs）来增强新闻文章的图像描述质量，从而提升新闻报道的效率和质量。通过实验对比了多种模型的性能，包括BLIP-2、GPT-4v、LLaVA、OFA、ViT-GPT2以及GPT-4和LLaMA，并分析了不同类型上下文（整个新闻文章或抽取的命名实体）对模型效果的影响。文章发现，尽管不同模型的选择对描述质量有显著影响，但使用LLMs进行后续的上下文整合是一个有效的改进策略。"
}