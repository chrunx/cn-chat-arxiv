{
    "title": "Temporal Logic Planning via Zero-Shot Policy Composition",
    "abstract": "arXiv:2408.04215v1 Announce Type: new  Abstract: This work develops a zero-shot mechanism for an agent to satisfy a Linear Temporal Logic (LTL) specification given existing task primitives. Oftentimes, autonomous robots need to satisfy spatial and temporal goals that are unknown until run time. Prior research addresses the problem by learning policies that are capable of executing a high-level task specified using LTL, but they incorporate the specification into the learning process; therefore, any change to the specification requires retraining the policy. Other related research addresses the problem by creating skill-machines which, given a specification change, do not require full policy retraining but require fine-tuning on the skill-machine to guarantee satisfaction. We present a more a flexible approach -- to learn a set of minimum-violation (MV) task primitive policies that can be used to satisfy arbitrary LTL specifications without retraining or fine-tuning. Task primitives can",
    "link": "https://arxiv.org/abs/2408.04215",
    "context": "Title: Temporal Logic Planning via Zero-Shot Policy Composition\nAbstract: arXiv:2408.04215v1 Announce Type: new  Abstract: This work develops a zero-shot mechanism for an agent to satisfy a Linear Temporal Logic (LTL) specification given existing task primitives. Oftentimes, autonomous robots need to satisfy spatial and temporal goals that are unknown until run time. Prior research addresses the problem by learning policies that are capable of executing a high-level task specified using LTL, but they incorporate the specification into the learning process; therefore, any change to the specification requires retraining the policy. Other related research addresses the problem by creating skill-machines which, given a specification change, do not require full policy retraining but require fine-tuning on the skill-machine to guarantee satisfaction. We present a more a flexible approach -- to learn a set of minimum-violation (MV) task primitive policies that can be used to satisfy arbitrary LTL specifications without retraining or fine-tuning. Task primitives can",
    "path": "papers/24/08/2408.04215.json",
    "total_tokens": 328,
    "tldr": "该文章提出了一种利用零样本策略组合方法，使机器人能够在没有预先训练和微调的情况下，基于一系列最小冲突任务基本动作执行任意线性时序逻辑(LTL)规范的创新解决方案。"
}