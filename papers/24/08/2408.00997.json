{
    "title": "A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments",
    "abstract": "arXiv:2408.00997v1 Announce Type: new  Abstract: Training a model-free reinforcement learning agent requires allowing the agent to sufficiently explore the environment to search for an optimal policy. In safety-constrained environments, utilizing unsupervised exploration or a non-optimal policy may lead the agent to undesirable states, resulting in outcomes that are potentially costly or hazardous for both the agent and the environment. In this paper, we introduce a new exploration framework for navigating the grid environments that enables model-free agents to interact with the environment while adhering to safety constraints. Our framework includes a pre-training phase, during which the agent learns to identify potentially unsafe states based on both observable features and specified safety constraints in the environment. Subsequently, a binary classification model is trained to predict those unsafe states in new environments that exhibit similar dynamics. This trained classifier emp",
    "link": "https://arxiv.org/abs/2408.00997",
    "context": "Title: A Safe Exploration Strategy for Model-free Task Adaptation in Safety-constrained Grid Environments\nAbstract: arXiv:2408.00997v1 Announce Type: new  Abstract: Training a model-free reinforcement learning agent requires allowing the agent to sufficiently explore the environment to search for an optimal policy. In safety-constrained environments, utilizing unsupervised exploration or a non-optimal policy may lead the agent to undesirable states, resulting in outcomes that are potentially costly or hazardous for both the agent and the environment. In this paper, we introduce a new exploration framework for navigating the grid environments that enables model-free agents to interact with the environment while adhering to safety constraints. Our framework includes a pre-training phase, during which the agent learns to identify potentially unsafe states based on both observable features and specified safety constraints in the environment. Subsequently, a binary classification model is trained to predict those unsafe states in new environments that exhibit similar dynamics. This trained classifier emp",
    "path": "papers/24/08/2408.00997.json",
    "total_tokens": 529,
    "translated_title": "一种在安全约束网格环境中实现无模型任务适应的安全探索策略",
    "translated_abstract": "在这项研究中，我们提出了一个无模型策略，用于在安全约束的网格环境中进行探索，这种方法确保了同时探索环境并遵守约束条件。Our safety-aware exploration strategy allows agents to learn new tasks without compromising the environment's safety, thereby facilitating learning in practical environments. This approach is particularly advantageous for robotic navigation in complex environments that may include obstacles and unpredictable conditions.",
    "tldr": "我们的研究提出了一个无模型策略，确保机器人能够在遵守安全限制的同时，学习和适应新任务，这个方法对于处理复杂环境中的未知条件和障碍特别有利，如可能包括的障碍物。"
}