{
    "title": "Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning",
    "abstract": "arXiv:2408.04414v1 Announce Type: cross  Abstract: Retrieval-Augmented Language Models (RALMs) have significantly improved performance in open-domain question answering (QA) by leveraging external knowledge. However, RALMs still struggle with unanswerable queries, where the retrieved contexts do not contain the correct answer, and with conflicting information, where different sources provide contradictory answers due to imperfect retrieval. This study introduces an in-context learning-based approach to enhance the reasoning capabilities of RALMs, making them more robust in imperfect retrieval scenarios. Our method incorporates Machine Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the model's capabilities to identify unanswerabilities and conflicts among the retrieved contexts. Experiments on two open-domain QA datasets show that our approach increases accuracy in identifying unanswerable and conflicting scenarios without requiring additional fine-tuning. Th",
    "link": "https://arxiv.org/abs/2408.04414",
    "context": "Title: Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning\nAbstract: arXiv:2408.04414v1 Announce Type: cross  Abstract: Retrieval-Augmented Language Models (RALMs) have significantly improved performance in open-domain question answering (QA) by leveraging external knowledge. However, RALMs still struggle with unanswerable queries, where the retrieved contexts do not contain the correct answer, and with conflicting information, where different sources provide contradictory answers due to imperfect retrieval. This study introduces an in-context learning-based approach to enhance the reasoning capabilities of RALMs, making them more robust in imperfect retrieval scenarios. Our method incorporates Machine Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the model's capabilities to identify unanswerabilities and conflicts among the retrieved contexts. Experiments on two open-domain QA datasets show that our approach increases accuracy in identifying unanswerable and conflicting scenarios without requiring additional fine-tuning. Th",
    "path": "papers/24/08/2408.04414.json",
    "total_tokens": 331,
    "tldr": "该文章提出了一种基于案例的推理方法，通过在语言模型中集成机器阅读理解演示，显著提升了检索增强语言模型在面对错误检索结果时的鲁棒性，特别是对于难以回答的问题和检索到的信息冲突情况。"
}