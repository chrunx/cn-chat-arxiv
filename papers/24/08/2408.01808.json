{
    "title": "ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features",
    "abstract": "arXiv:2408.01808v1 Announce Type: cross  Abstract: Extensive research has revealed that adversarial examples (AE) pose a significant threat to voice-controllable smart devices. Recent studies have proposed black-box adversarial attacks that require only the final transcription from an automatic speech recognition (ASR) system. However, these attacks typically involve many queries to the ASR, resulting in substantial costs. Moreover, AE-based adversarial audio samples are susceptible to ASR updates. In this paper, we identify the root cause of these limitations, namely the inability to construct AE attack samples directly around the decision boundary of deep learning (DL) models. Building on this observation, we propose ALIF, the first black-box adversarial linguistic feature-based attack pipeline. We leverage the reciprocal process of text-to-speech (TTS) and ASR models to generate perturbations in the linguistic embedding space where the decision boundary resides. Based on the ALIF pi",
    "link": "https://arxiv.org/abs/2408.01808",
    "context": "Title: ALIF: Low-Cost Adversarial Audio Attacks on Black-Box Speech Platforms using Linguistic Features\nAbstract: arXiv:2408.01808v1 Announce Type: cross  Abstract: Extensive research has revealed that adversarial examples (AE) pose a significant threat to voice-controllable smart devices. Recent studies have proposed black-box adversarial attacks that require only the final transcription from an automatic speech recognition (ASR) system. However, these attacks typically involve many queries to the ASR, resulting in substantial costs. Moreover, AE-based adversarial audio samples are susceptible to ASR updates. In this paper, we identify the root cause of these limitations, namely the inability to construct AE attack samples directly around the decision boundary of deep learning (DL) models. Building on this observation, we propose ALIF, the first black-box adversarial linguistic feature-based attack pipeline. We leverage the reciprocal process of text-to-speech (TTS) and ASR models to generate perturbations in the linguistic embedding space where the decision boundary resides. Based on the ALIF pi",
    "path": "papers/24/08/2408.01808.json",
    "total_tokens": 733,
    "translated_title": "ALIF: 低成本基于 adversarial audio 攻击的黑盒语音平台使用 linguistics features",
    "translated_abstract": "arXiv:2408.01808v1 公告类型: 交叉  这是 arXiv 上一个预印本的摘要翻译。原文是研究中发现 adversarial examples (AE) 对声音控制智能设备构成严重威胁。最近的研究提出了仅需要自动语音识别 (ASR) 系统最终转录的黑盒攻击。但是，这些攻击通常需要对 ASR 进行很多查询，这导致了巨大的成本。此外，基于 AE 的敌意音频样本容易受到 ASR 更新的影响。在本文中，我们确定了这些限制的根本原因，即无法直接在深度学习 (DL) 模型决策边界上构造 AE 攻击样本。基于这一观察，我们提出了 ALIF，即第一个基于黑盒 adversarial linguistic feature 的攻击管道。我们利用文本到语音 (TTS) 和 ASR 模型之间的互逆过程在 linguistic embedding 空间中生成扰动，其中决策边界存在。基于 ALIF 管道，我们能够生成仅需要几步查询便能欺骗 ASR 的低成本音频样本。此外，由于我们将攻击在 linguistic feature 空间中进行，这些样本能够很好地抵抗 ASR 更新，展示了我们的方法在现实世界中的潜在应用价值。",
    "tldr": "本文提出了一种新型的基于 linguistic feature 的黑盒语音识别模型攻击方法，该方法能够生成成本低且能抵抗模型更新的敌意音频样本，以成功欺骗 ASR 系统。"
}