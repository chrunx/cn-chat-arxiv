{
    "title": "Deep Patch Visual SLAM",
    "abstract": "arXiv:2408.01654v1 Announce Type: new  Abstract: Recent work in visual SLAM has shown the effectiveness of using deep network backbones. Despite excellent accuracy, however, such approaches are often expensive to run or do not generalize well zero-shot. Their runtime can also fluctuate wildly while their frontend and backend fight for access to GPU resources. To address these problems, we introduce Deep Patch Visual (DPV) SLAM, a method for monocular visual SLAM on a single GPU. DPV-SLAM maintains a high minimum framerate and small memory overhead (5-7G) compared to existing deep SLAM systems. On real-world datasets, DPV-SLAM runs at 1x-4x real-time framerates. We achieve comparable accuracy to DROID-SLAM on EuRoC and TartanAir while running 2.5x faster using a fraction of the memory. DPV-SLAM is an extension to the DPVO visual odometry system; its code can be found in the same repository: https://github.com/princeton-vl/DPVO",
    "link": "https://arxiv.org/abs/2408.01654",
    "context": "Title: Deep Patch Visual SLAM\nAbstract: arXiv:2408.01654v1 Announce Type: new  Abstract: Recent work in visual SLAM has shown the effectiveness of using deep network backbones. Despite excellent accuracy, however, such approaches are often expensive to run or do not generalize well zero-shot. Their runtime can also fluctuate wildly while their frontend and backend fight for access to GPU resources. To address these problems, we introduce Deep Patch Visual (DPV) SLAM, a method for monocular visual SLAM on a single GPU. DPV-SLAM maintains a high minimum framerate and small memory overhead (5-7G) compared to existing deep SLAM systems. On real-world datasets, DPV-SLAM runs at 1x-4x real-time framerates. We achieve comparable accuracy to DROID-SLAM on EuRoC and TartanAir while running 2.5x faster using a fraction of the memory. DPV-SLAM is an extension to the DPVO visual odometry system; its code can be found in the same repository: https://github.com/princeton-vl/DPVO",
    "path": "papers/24/08/2408.01654.json",
    "total_tokens": 762,
    "translated_title": "深度补丁视觉SLAM",
    "translated_abstract": "arXiv:2408.01654v1 公告类型：新发表  摘要：近年来，视觉SLAM领域的研究显示了使用深度网络骨干结构的有效性。尽管准确性优异，然而，这些方法往往运行成本高昂，且在零样本学习时表现不佳。此外，它们的运行时性能波动较大，而前端的竞争也使得GPU资源有限。为了解决这些问题，我们提出了深度补丁视觉（DPV）SLAM方法，这是一种单GPU上的单目视觉SLAM技术。与现有的深度SLAM系统相比，DPV-SLAM在保持高最低帧率的同事，拥有较低的内存消耗（5-7G）。在现实世界数据集上，DPV-SLAM的帧率可以达到1x到4x的实际帧率。我们在EuRoC和TartanAir数据集上取得了与DROID-SLAM相当的准确性，而使用的是其内存消耗的一小部分，并且运行速度是其2.5倍。DPV-SLAM是DPVO视觉运动系统的一个扩展；它的代码可以在同一仓库中找到：https://github.com/princeton-vl/DPVO",
    "tldr": "我们提出了一种名为“深度补丁视觉SLAM”的新方法，它能在单GPU上实现高质量的单目视觉SLAM，即使在大型数据集上也能保持接近真实时间的帧率，同时内存消耗仅为现有系统的很小一部分。",
    "en_tdlr": "We introduced a new method called \"Deep Patch Visual SLAM,\" which enables high-quality monocular visual SLAM on a single GPU, maintaining near real-time frame rates on large datasets while consuming a fraction of the memory of existing systems."
}