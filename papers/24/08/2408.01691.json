{
    "title": "TreeCSS: An Efficient Framework for Vertical Federated Learning",
    "abstract": "arXiv:2408.01691v1 Announce Type: cross  Abstract: Vertical federated learning (VFL) considers the case that the features of data samples are partitioned over different participants. VFL consists of two main steps, i.e., identify the common data samples for all participants (alignment) and train model using the aligned data samples (training). However, when there are many participants and data samples, both alignment and training become slow. As such, we propose TreeCSS as an efficient VFL framework that accelerates the two main steps. In particular, for sample alignment, we design an efficient multi-party private set intersection (MPSI) protocol called Tree-MPSI, which adopts a tree-based structure and a data-volume-aware scheduling strategy to parallelize alignment among the participants. As model training time scales with the number of data samples, we conduct coreset selection (CSS) to choose some representative data samples for training. Our CCS method adopts a clustering-based sc",
    "link": "https://arxiv.org/abs/2408.01691",
    "context": "Title: TreeCSS: An Efficient Framework for Vertical Federated Learning\nAbstract: arXiv:2408.01691v1 Announce Type: cross  Abstract: Vertical federated learning (VFL) considers the case that the features of data samples are partitioned over different participants. VFL consists of two main steps, i.e., identify the common data samples for all participants (alignment) and train model using the aligned data samples (training). However, when there are many participants and data samples, both alignment and training become slow. As such, we propose TreeCSS as an efficient VFL framework that accelerates the two main steps. In particular, for sample alignment, we design an efficient multi-party private set intersection (MPSI) protocol called Tree-MPSI, which adopts a tree-based structure and a data-volume-aware scheduling strategy to parallelize alignment among the participants. As model training time scales with the number of data samples, we conduct coreset selection (CSS) to choose some representative data samples for training. Our CCS method adopts a clustering-based sc",
    "path": "papers/24/08/2408.01691.json",
    "total_tokens": 386,
    "tldr": "该文章提出了TreeCSS框架，这是一个高效的多方垂直联合学习（VFL）解决方案，通过采用树结构策略并优化数据量分配，显著加快了多党私有集交集（MPSI）协议中的样本对齐步骤。同时，通过选择核心集（coreset selection, CSS）来缩减样本数量，以减少训练模型的复杂性，从而整体上提升了VFL的效率。"
}