{
    "title": "SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals",
    "abstract": "arXiv:2408.04575v1 Announce Type: new  Abstract: Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner. By focusing on token-based substitutions, SCENE creates contextually appropriate and seman-tically meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques.",
    "link": "https://arxiv.org/abs/2408.04575",
    "context": "Title: SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals\nAbstract: arXiv:2408.04575v1 Announce Type: new  Abstract: Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner. By focusing on token-based substitutions, SCENE creates contextually appropriate and seman-tically meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques.",
    "path": "papers/24/08/2408.04575.json",
    "total_tokens": 411,
    "tldr": "该文章通过介绍SCENE（Soft Counterfactual Evaluation for Natural language Explainability），提出了一种评估机器学习模型，特别是在自然语言处理（NLP）任务中的透明度和责任性的新方法。SCENE利用大型语言模型（LLMs）生成软交互式假想（Soft Counterfactual）解释，无需大量调优。该方法通过评估Validitysoft和Csoft指标来衡量其在文本分类任务中对模型 agnostic 的XAI（可解释人工智能）方法的有效性。根据CNN、RNN和BERT等架构的适用性，SCENE为XAI技术提供了有价值的见解。"
}