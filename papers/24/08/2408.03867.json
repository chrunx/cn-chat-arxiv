{
    "title": "Surgformer: Surgical Transformer with Hierarchical Temporal Attention for Surgical Phase Recognition",
    "abstract": "arXiv:2408.03867v1 Announce Type: new  Abstract: Existing state-of-the-art methods for surgical phase recognition either rely on the extraction of spatial-temporal features at a short-range temporal resolution or adopt the sequential extraction of the spatial and temporal features across the entire temporal resolution. However, these methods have limitations in modeling spatial-temporal dependency and addressing spatial-temporal redundancy: 1) These methods fail to effectively model spatial-temporal dependency, due to the lack of long-range information or joint spatial-temporal modeling. 2) These methods utilize dense spatial features across the entire temporal resolution, resulting in significant spatial-temporal redundancy. In this paper, we propose the Surgical Transformer (Surgformer) to address the issues of spatial-temporal modeling and redundancy in an end-to-end manner, which employs divided spatial-temporal attention and takes a limited set of sparse frames as input. Moreover,",
    "link": "https://arxiv.org/abs/2408.03867",
    "context": "Title: Surgformer: Surgical Transformer with Hierarchical Temporal Attention for Surgical Phase Recognition\nAbstract: arXiv:2408.03867v1 Announce Type: new  Abstract: Existing state-of-the-art methods for surgical phase recognition either rely on the extraction of spatial-temporal features at a short-range temporal resolution or adopt the sequential extraction of the spatial and temporal features across the entire temporal resolution. However, these methods have limitations in modeling spatial-temporal dependency and addressing spatial-temporal redundancy: 1) These methods fail to effectively model spatial-temporal dependency, due to the lack of long-range information or joint spatial-temporal modeling. 2) These methods utilize dense spatial features across the entire temporal resolution, resulting in significant spatial-temporal redundancy. In this paper, we propose the Surgical Transformer (Surgformer) to address the issues of spatial-temporal modeling and redundancy in an end-to-end manner, which employs divided spatial-temporal attention and takes a limited set of sparse frames as input. Moreover,",
    "path": "papers/24/08/2408.03867.json",
    "total_tokens": 343,
    "tldr": "该文章提出了一种名为Surgformer的手术阶段识别Transformer模型，通过利用分层的时间注意力机制有效地建模了手术视频中的空间和时间依赖性，并减少了解析输入视频时的时间和空间冗余，从而提高了手术阶段的识别精度。"
}