{
    "title": "wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech",
    "abstract": "arXiv:2408.04174v1 Announce Type: cross  Abstract: Knowledge graphs (KGs) enhance the performance of large language models (LLMs) and search engines by providing structured, interconnected data that improves reasoning and context-awareness. However, KGs only focus on text data, thereby neglecting other modalities such as speech. In this work, we introduce wav2graph, the first framework for supervised learning knowledge graph from speech data. Our pipeline are straightforward: (1) constructing a KG based on transcribed spoken utterances and a named entity database, (2) converting KG into embedding vectors, and (3) training graph neural networks (GNNs) for node classification and link prediction tasks. Through extensive experiments conducted in inductive and transductive learning contexts using state-of-the-art GNN models, we provide baseline results and error analysis for node classification and link prediction tasks on human transcripts and automatic speech recognition (ASR) transcript",
    "link": "https://arxiv.org/abs/2408.04174",
    "context": "Title: wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech\nAbstract: arXiv:2408.04174v1 Announce Type: cross  Abstract: Knowledge graphs (KGs) enhance the performance of large language models (LLMs) and search engines by providing structured, interconnected data that improves reasoning and context-awareness. However, KGs only focus on text data, thereby neglecting other modalities such as speech. In this work, we introduce wav2graph, the first framework for supervised learning knowledge graph from speech data. Our pipeline are straightforward: (1) constructing a KG based on transcribed spoken utterances and a named entity database, (2) converting KG into embedding vectors, and (3) training graph neural networks (GNNs) for node classification and link prediction tasks. Through extensive experiments conducted in inductive and transductive learning contexts using state-of-the-art GNN models, we provide baseline results and error analysis for node classification and link prediction tasks on human transcripts and automatic speech recognition (ASR) transcript",
    "path": "papers/24/08/2408.04174.json",
    "total_tokens": 372,
    "tldr": "该文章提出了一种基于人工转录和自动语音识别（ASR）的转录文本的框架，用于从语音数据中进行知识图谱的监督学习。通过构建基于转录语音的KG，将其转换为嵌入向量，并使用GNN进行节点分类和链接预测任务训练，从而扩展了现有文本主导的知识图谱的范围，使其涵盖了语音数据。"
}