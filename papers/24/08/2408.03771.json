{
    "title": "Methodological Explainability Evaluation of an Interpretable Deep Learning Model for Post-Hepatectomy Liver Failure Prediction Incorporating Counterfactual Explanations and Layerwise Relevance Propagation: A Prospective In Silico Trial",
    "abstract": "arXiv:2408.03771v1 Announce Type: new  Abstract: Artificial intelligence (AI)-based decision support systems have demonstrated value in predicting post-hepatectomy liver failure (PHLF) in hepatocellular carcinoma (HCC). However, they often lack transparency, and the impact of model explanations on clinicians' decisions has not been thoroughly evaluated. Building on prior research, we developed a variational autoencoder-multilayer perceptron (VAE-MLP) model for preoperative PHLF prediction. This model integrated counterfactuals and layerwise relevance propagation (LRP) to provide insights into its decision-making mechanism. Additionally, we proposed a methodological framework for evaluating the explainability of AI systems. This framework includes qualitative and quantitative assessments of explanations against recognized biomarkers, usability evaluations, and an in silico clinical trial. Our evaluations demonstrated that the model's explanation correlated with established biomarkers an",
    "link": "https://arxiv.org/abs/2408.03771",
    "context": "Title: Methodological Explainability Evaluation of an Interpretable Deep Learning Model for Post-Hepatectomy Liver Failure Prediction Incorporating Counterfactual Explanations and Layerwise Relevance Propagation: A Prospective In Silico Trial\nAbstract: arXiv:2408.03771v1 Announce Type: new  Abstract: Artificial intelligence (AI)-based decision support systems have demonstrated value in predicting post-hepatectomy liver failure (PHLF) in hepatocellular carcinoma (HCC). However, they often lack transparency, and the impact of model explanations on clinicians' decisions has not been thoroughly evaluated. Building on prior research, we developed a variational autoencoder-multilayer perceptron (VAE-MLP) model for preoperative PHLF prediction. This model integrated counterfactuals and layerwise relevance propagation (LRP) to provide insights into its decision-making mechanism. Additionally, we proposed a methodological framework for evaluating the explainability of AI systems. This framework includes qualitative and quantitative assessments of explanations against recognized biomarkers, usability evaluations, and an in silico clinical trial. Our evaluations demonstrated that the model's explanation correlated with established biomarkers an",
    "path": "papers/24/08/2408.03771.json",
    "total_tokens": 450,
    "tldr": "该文章开发了一种基于 variational autoencoder-multilayer perceptron (VAE-MLP) 的模型，用于预测肝细胞癌（HCC）患者手术后的肝脏衰竭（PHLF），并在决策支持系统中有效集成 counterfactual 解释和 layerwise relevance propagation 方法以提高模型的透明度。同时，该文章还提出了一套方法论框架以评价人工智能系统的解释能力，包括对解释与公认生物标志物的相关性评估、用户体验评估以及模拟临床试验，证明了解释性 AI 系统在 HCC 患者 PHLF 预测中的潜在价值。"
}