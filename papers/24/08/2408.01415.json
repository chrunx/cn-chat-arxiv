{
    "title": "Conditional LoRA Parameter Generation",
    "abstract": "arXiv:2408.01415v1 Announce Type: new  Abstract: Generative models have achieved remarkable success in image, video, and text domains. Inspired by this, researchers have explored utilizing generative models to generate neural network parameters. However, these efforts have been limited by the parameter size and the practicality of generating high-performance parameters. In this paper, we propose COND P-DIFF, a novel approach that demonstrates the feasibility of controllable high-performance parameter generation, particularly for LoRA (Low-Rank Adaptation) weights, during the fine-tuning process. Specifically, we employ an autoencoder to extract efficient latent representations for parameters. We then train a conditional latent diffusion model to synthesize high-performing model parameters from random noise based on specific task conditions. Experimental results in both computer vision and natural language processing domains consistently demonstrate that COND P-DIFF can generate high-pe",
    "link": "https://arxiv.org/abs/2408.01415",
    "context": "Title: Conditional LoRA Parameter Generation\nAbstract: arXiv:2408.01415v1 Announce Type: new  Abstract: Generative models have achieved remarkable success in image, video, and text domains. Inspired by this, researchers have explored utilizing generative models to generate neural network parameters. However, these efforts have been limited by the parameter size and the practicality of generating high-performance parameters. In this paper, we propose COND P-DIFF, a novel approach that demonstrates the feasibility of controllable high-performance parameter generation, particularly for LoRA (Low-Rank Adaptation) weights, during the fine-tuning process. Specifically, we employ an autoencoder to extract efficient latent representations for parameters. We then train a conditional latent diffusion model to synthesize high-performing model parameters from random noise based on specific task conditions. Experimental results in both computer vision and natural language processing domains consistently demonstrate that COND P-DIFF can generate high-pe",
    "path": "papers/24/08/2408.01415.json",
    "total_tokens": 555,
    "translated_title": "条件LoRA参数生成技术",
    "translated_abstract": "本文提出了一种名为COND P-DIFF的新方法，该方法显示了对特定任务条件下的高性能LoRA（低秩适应）参数进行控制可生成。我们采用一个自动编码器提取参数的效率潜在表示，并训练了一个条件潜在扩散模型，它基于特定的任务条件从随机噪声中合成具有高表现力的模型参数。无论是计算机视觉还是自然语言处理领域，实验结果均一致表明COND P-DIFF可以在计算机视觉和自然语言处理领域实现高效率参数生成。",
    "tldr": "本文提出了一种通过条件潜在扩散模型在特定任务条件下生成高质量LoRA参数的新方法，该方法在计算机视觉和自然语言处理领域均显示出了高效率。"
}