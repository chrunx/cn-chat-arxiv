{
    "title": "Efficient NeRF Optimization -- Not All Samples Remain Equally Hard",
    "abstract": "arXiv:2408.03193v1 Announce Type: new  Abstract: We propose an application of online hard sample mining for efficient training of Neural Radiance Fields (NeRF). NeRF models produce state-of-the-art quality for many 3D reconstruction and rendering tasks but require substantial computational resources. The encoding of the scene information within the NeRF network parameters necessitates stochastic sampling. We observe that during the training, a major part of the compute time and memory usage is spent on processing already learnt samples, which no longer affect the model update significantly. We identify the backward pass on the stochastic samples as the computational bottleneck during the optimization. We thus perform the first forward pass in inference mode as a relatively low-cost search for hard samples. This is followed by building the computational graph and updating the NeRF network parameters using only the hard samples. To demonstrate the effectiveness of the proposed approach, ",
    "link": "https://arxiv.org/abs/2408.03193",
    "context": "Title: Efficient NeRF Optimization -- Not All Samples Remain Equally Hard\nAbstract: arXiv:2408.03193v1 Announce Type: new  Abstract: We propose an application of online hard sample mining for efficient training of Neural Radiance Fields (NeRF). NeRF models produce state-of-the-art quality for many 3D reconstruction and rendering tasks but require substantial computational resources. The encoding of the scene information within the NeRF network parameters necessitates stochastic sampling. We observe that during the training, a major part of the compute time and memory usage is spent on processing already learnt samples, which no longer affect the model update significantly. We identify the backward pass on the stochastic samples as the computational bottleneck during the optimization. We thus perform the first forward pass in inference mode as a relatively low-cost search for hard samples. This is followed by building the computational graph and updating the NeRF network parameters using only the hard samples. To demonstrate the effectiveness of the proposed approach, ",
    "path": "papers/24/08/2408.03193.json",
    "total_tokens": 394,
    "tldr": "该文章创新性地提出了一种名为在线难样本挖掘的策略，用于提高神经辐射场（NeRF）模型的训练效率。通过观察到在训练过程中，大量计算资源被用于处理已经学会的样本，这意味着这部分样本不再对模型更新产生重要影响，作者识别出随机样本的逆传播是优化过程中的计算瓶颈。因此，文章提出首先使用第一遍前向推理来筛选出\"硬样本\"，只对这些样本构建计算图并更新网络参数。研究展示了该策略能够有效节省训练NeRF模型所需的时间和资源。"
}