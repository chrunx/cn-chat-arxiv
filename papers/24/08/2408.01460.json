{
    "title": "LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models",
    "abstract": "arXiv:2408.01460v1 Announce Type: cross  Abstract: The proliferation of large language models (LLMs) requires robust evaluation of their alignment with local values and ethical standards, especially as existing benchmarks often reflect the cultural, legal, and ideological values of their creators. \\textsc{LocalValueBench}, introduced in this paper, is an extensible benchmark designed to assess LLMs' adherence to Australian values, and provides a framework for regulators worldwide to develop their own LLM benchmarks for local value alignment. Employing a novel typology for ethical reasoning and an interrogation approach, we curated comprehensive questions and utilized prompt engineering strategies to probe LLMs' value alignment. Our evaluation criteria quantified deviations from local values, ensuring a rigorous assessment process. Comparative analysis of three commercial LLMs by USA vendors revealed significant insights into their effectiveness and limitations, demonstrating the critic",
    "link": "https://arxiv.org/abs/2408.01460",
    "context": "Title: LocalValueBench: A Collaboratively Built and Extensible Benchmark for Evaluating Localized Value Alignment and Ethical Safety in Large Language Models\nAbstract: arXiv:2408.01460v1 Announce Type: cross  Abstract: The proliferation of large language models (LLMs) requires robust evaluation of their alignment with local values and ethical standards, especially as existing benchmarks often reflect the cultural, legal, and ideological values of their creators. \\textsc{LocalValueBench}, introduced in this paper, is an extensible benchmark designed to assess LLMs' adherence to Australian values, and provides a framework for regulators worldwide to develop their own LLM benchmarks for local value alignment. Employing a novel typology for ethical reasoning and an interrogation approach, we curated comprehensive questions and utilized prompt engineering strategies to probe LLMs' value alignment. Our evaluation criteria quantified deviations from local values, ensuring a rigorous assessment process. Comparative analysis of three commercial LLMs by USA vendors revealed significant insights into their effectiveness and limitations, demonstrating the critic",
    "path": "papers/24/08/2408.01460.json",
    "total_tokens": 675,
    "translated_title": "本地价值基准：一个合作构建的可扩展的大型语言模型价值对齐和伦理安全评估基准",
    "translated_abstract": "arXiv:2408.01460v1 宣布类型：交叉 摘要：随着大型语言模型（LLMs）的普及，对它们与当地价值观和伦理标准的对齐评估变得越来越重要，尤其是在现有的基准往往反映其创建者的文化、法律和意识形态价值观的背景下。在本文中介绍的\\textsc{LocalValueBench}是一个可扩展的基准，旨在评估大型语言模型与澳大利亚价值观的一致性，并为世界各地的监管机构提供了根据本地价值观对对语言模型的标准制定自己的提案。通过采用一种新的伦理推理类型学和一种质疑方法，我们精心编排了全面的问题，并利用了提示工程策略来探测大型语言模型对本地价值观的一致性。我们的评估标准量化了与本地价值观的偏差，确保了评估过程的严格性。对美国供应商的三款商业LLM的比较分析揭示了它们在实现和限制方面的显著洞察，证明了它们的有效性和局限性，并展示了这一批评视角的重要性和实用性。",
    "tldr": "本地价值基准是一个针对大型语言模型评估其与澳大利亚价值观一致性的可扩展型框架，帮助世界各地的监管机构制定适合自己的评估标准。"
}