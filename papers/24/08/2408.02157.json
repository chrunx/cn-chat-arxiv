{
    "title": "PanoFree: Tuning-Free Holistic Multi-view Image Generation with Cross-view Self-Guidance",
    "abstract": "arXiv:2408.02157v1 Announce Type: new  Abstract: Immersive scene generation, notably panorama creation, benefits significantly from the adaptation of large pre-trained text-to-image (T2I) models for multi-view image generation. Due to the high cost of acquiring multi-view images, tuning-free generation is preferred. However, existing methods are either limited to simple correspondences or require extensive fine-tuning to capture complex ones. We present PanoFree, a novel method for tuning-free multi-view image generation that supports an extensive array of correspondences. PanoFree sequentially generates multi-view images using iterative warping and inpainting, addressing the key issues of inconsistency and artifacts from error accumulation without the need for fine-tuning. It improves error accumulation by enhancing cross-view awareness and refines the warping and inpainting processes via cross-view guidance, risky area estimation and erasing, and symmetric bidirectional guided genera",
    "link": "https://arxiv.org/abs/2408.02157",
    "context": "Title: PanoFree: Tuning-Free Holistic Multi-view Image Generation with Cross-view Self-Guidance\nAbstract: arXiv:2408.02157v1 Announce Type: new  Abstract: Immersive scene generation, notably panorama creation, benefits significantly from the adaptation of large pre-trained text-to-image (T2I) models for multi-view image generation. Due to the high cost of acquiring multi-view images, tuning-free generation is preferred. However, existing methods are either limited to simple correspondences or require extensive fine-tuning to capture complex ones. We present PanoFree, a novel method for tuning-free multi-view image generation that supports an extensive array of correspondences. PanoFree sequentially generates multi-view images using iterative warping and inpainting, addressing the key issues of inconsistency and artifacts from error accumulation without the need for fine-tuning. It improves error accumulation by enhancing cross-view awareness and refines the warping and inpainting processes via cross-view guidance, risky area estimation and erasing, and symmetric bidirectional guided genera",
    "path": "papers/24/08/2408.02157.json",
    "total_tokens": 733,
    "translated_title": "PanoFree: 无需调参的全局多视图图像生成方法，使用跨视角自我指导",
    "translated_abstract": "arXiv:2408.02157v1 新闻类型：新 摘要：沉浸式的场景生成，特别是在创建全景图方面，从为多视图图像生成的大型预训练的文本到图像（T2I）模型受益匪浅。由于获取多视图图像的成本高昂，因此倾向于无调整的生成。然而，现有的方法要么限于简单的对应关系，要么需要进行大量的微调以捕捉复杂的对应关系。我们提出了一种名为PanoFree的无需调参的全局多视图图像生成方法，该方法支持广泛的不同对应关系的生成。PanoFree使用迭代变形和上色技术，不依赖于微调，解决了由于累积误差导致的不一致性和 artifacts 的问题。通过增强跨视角感知和通过跨视角指导、风险区域估计和擦除以及对称双向引导生成的进步，它改进了累积误差的状况。它还通过在进化过程中修正变形和上色过程来细化这些过程，同时最小化了那些在生成初期出现的不匹配。通过将多视角感知纳入迭代过程，PanoFree无需求助于任何形式的微调或预训练权重，就可以生成稳定而一致的、与多视角数据兼容的全景图像。",
    "tldr": "PanoFree是一种无需调参的全景图像生成方法，通过迭代变形和上色技术，无需微调即可解决多视角图形生成中的累积误差问题。",
    "en_tdlr": "PanoFree is a tuning-free panorama image generation method that addresses accumulated errors in multi-view graphic generation through iterative warping and inpainting techniques without fine-tuning."
}