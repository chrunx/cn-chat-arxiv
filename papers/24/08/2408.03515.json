{
    "title": "A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems",
    "abstract": "arXiv:2408.03515v1 Announce Type: new  Abstract: The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot's understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings",
    "link": "https://arxiv.org/abs/2408.03515",
    "context": "Title: A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems\nAbstract: arXiv:2408.03515v1 Announce Type: new  Abstract: The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot's understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings",
    "path": "papers/24/08/2408.03515.json",
    "total_tokens": 321,
    "tldr": "该文章揭示了当大型语言模型集成到移动机器人系统中时，多模态提示注入攻击可能导致的导航性能和安全风险，并探讨了如何通过制定更安全的提示策略来缓解这类威胁。"
}