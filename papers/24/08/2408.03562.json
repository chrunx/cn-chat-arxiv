{
    "title": "A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case",
    "abstract": "arXiv:2408.03562v1 Announce Type: cross  Abstract: This research compares large language model (LLM) fine-tuning methods, including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning (RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally compared LLM evaluation methods including End to End (E2E) benchmark method of \"Golden Answers\", traditional natural language processing (NLP) metrics, RAG Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation, using the travel chatbot use case. The travel dataset was sourced from the the Reddit API by requesting posts from travel-related subreddits to get travel-related conversation prompts and personalized travel experiences, and augmented for each fine-tuning method. We used two pretrained LLMs utilized for fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to the two pretrained models. The inferences from these models are extensively evaluated against the aforem",
    "link": "https://arxiv.org/abs/2408.03562",
    "context": "Title: A Comparison of LLM Finetuning Methods & Evaluation Metrics with Travel Chatbot Use Case\nAbstract: arXiv:2408.03562v1 Announce Type: cross  Abstract: This research compares large language model (LLM) fine-tuning methods, including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning (RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally compared LLM evaluation methods including End to End (E2E) benchmark method of \"Golden Answers\", traditional natural language processing (NLP) metrics, RAG Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation, using the travel chatbot use case. The travel dataset was sourced from the the Reddit API by requesting posts from travel-related subreddits to get travel-related conversation prompts and personalized travel experiences, and augmented for each fine-tuning method. We used two pretrained LLMs utilized for fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to the two pretrained models. The inferences from these models are extensively evaluated against the aforem",
    "path": "papers/24/08/2408.03562.json",
    "total_tokens": 509,
    "tldr": "该文章对比了LLM微调方法，包括量化低秩适配器(QLoRA)、检索增强训练(RAFT)和人类反馈强化学习(RLHF)，以及评估方法，如“黄金答案”端到端基准方法、传统NLP指标、RAG评估(Ragas)、OpenAI GPT-4评估指标和人类评估，使用了一个旅行聊天机器人用例。研究使用了从Reddit API获取的旅游相关子版块帖子组成的旅游数据集，用以提供旅游相关对话提示和个人旅游体验，然后对每种微调方法进行增强。研究使用了两种预训练的LLM，LLaMA 2 7B和Mistral 7B，对这两种模型应用了QLoRA和RAFT。模型推断结果被广泛地用于与上述评估方法进行比较。"
}