{
    "title": "Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in Autonomous Driving",
    "abstract": "arXiv:2408.03516v1 Announce Type: cross  Abstract: This paper introduces a novel method for open-vocabulary 3D scene understanding in autonomous driving by combining Language Embedded 3D Gaussians with Large Language Models (LLMs) for enhanced inference. We propose utilizing LLMs to generate contextually relevant canonical phrases for segmentation and scene interpretation. Our method leverages the contextual and semantic capabilities of LLMs to produce a set of canonical phrases, which are then compared with the language features embedded in the 3D Gaussians. This LLM-guided approach significantly improves zero-shot scene understanding and detection of objects of interest, even in the most challenging or unfamiliar environments. Experimental results on the WayveScenes101 dataset demonstrate that our approach surpasses state-of-the-art methods in terms of accuracy and flexibility for open-vocabulary object detection and segmentation. This work represents a significant advancement toward",
    "link": "https://arxiv.org/abs/2408.03516",
    "context": "Title: Leveraging LLMs for Enhanced Open-Vocabulary 3D Scene Understanding in Autonomous Driving\nAbstract: arXiv:2408.03516v1 Announce Type: cross  Abstract: This paper introduces a novel method for open-vocabulary 3D scene understanding in autonomous driving by combining Language Embedded 3D Gaussians with Large Language Models (LLMs) for enhanced inference. We propose utilizing LLMs to generate contextually relevant canonical phrases for segmentation and scene interpretation. Our method leverages the contextual and semantic capabilities of LLMs to produce a set of canonical phrases, which are then compared with the language features embedded in the 3D Gaussians. This LLM-guided approach significantly improves zero-shot scene understanding and detection of objects of interest, even in the most challenging or unfamiliar environments. Experimental results on the WayveScenes101 dataset demonstrate that our approach surpasses state-of-the-art methods in terms of accuracy and flexibility for open-vocabulary object detection and segmentation. This work represents a significant advancement toward",
    "path": "papers/24/08/2408.03516.json",
    "total_tokens": 380,
    "tldr": "该文章提出了一种利用大型语言模型（LLMs）结合3D场景理解和自动驾驶的开放词汇方法，通过生成语境相关的标准短语来改进推理、分割和场景解释。这种方法通过将语言特征编码到3D高斯分布中，有效提高了在陌生环境中对感兴趣物体的检测精度，同时在处理未知词汇时表现出色，对于自动驾驶环境下的开放词汇物体检测和分割具有显著的提升效果。"
}