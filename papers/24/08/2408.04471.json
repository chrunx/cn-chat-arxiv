{
    "title": "What could go wrong? Discovering and describing failure modes in computer vision",
    "abstract": "arXiv:2408.04471v1 Announce Type: new  Abstract: Deep learning models are effective, yet brittle. Even carefully trained, their behavior tends to be hard to predict when confronted with out-of-distribution samples. In this work, our goal is to propose a simple yet effective solution to predict and describe via natural language potential failure modes of computer vision models. Given a pretrained model and a set of samples, our aim is to find sentences that accurately describe the visual conditions in which the model underperforms. In order to study this important topic and foster future research on it, we formalize the problem of Language-Based Error Explainability (LBEE) and propose a set of metrics to evaluate and compare different methods for this task. We propose solutions that operate in a joint vision-and-language embedding space, and can characterize through language descriptions model failures caused, e.g., by objects unseen during training or adverse visual conditions. We expe",
    "link": "https://arxiv.org/abs/2408.04471",
    "context": "Title: What could go wrong? Discovering and describing failure modes in computer vision\nAbstract: arXiv:2408.04471v1 Announce Type: new  Abstract: Deep learning models are effective, yet brittle. Even carefully trained, their behavior tends to be hard to predict when confronted with out-of-distribution samples. In this work, our goal is to propose a simple yet effective solution to predict and describe via natural language potential failure modes of computer vision models. Given a pretrained model and a set of samples, our aim is to find sentences that accurately describe the visual conditions in which the model underperforms. In order to study this important topic and foster future research on it, we formalize the problem of Language-Based Error Explainability (LBEE) and propose a set of metrics to evaluate and compare different methods for this task. We propose solutions that operate in a joint vision-and-language embedding space, and can characterize through language descriptions model failures caused, e.g., by objects unseen during training or adverse visual conditions. We expe",
    "path": "papers/24/08/2408.04471.json",
    "total_tokens": 335,
    "tldr": "该文章提出了一种简单有效的方案，能够预测并使用自然语言描述计算机视觉模型遇到潜在失败模式时的性能。这有助于开发者理解和测试新环境的适用性，同时也为未来在这一领域的研究奠定了基础。"
}