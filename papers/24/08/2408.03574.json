{
    "title": "Teach CLIP to Develop a Number Sense for Ordinal Regression",
    "abstract": "arXiv:2408.03574v1 Announce Type: new  Abstract: Ordinal regression is a fundamental problem within the field of computer vision, with customised well-trained models on specific tasks. While pre-trained vision-language models (VLMs) have exhibited impressive performance on various vision tasks, their potential for ordinal regression has received less exploration. In this study, we first investigate CLIP's potential for ordinal regression, from which we expect the model could generalise to different ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP fails on this task, since current VLMs have a well-documented limitation of encapsulating compositional concepts such as number sense. We propose a simple yet effective method called NumCLIP to improve the quantitative understanding of VLMs. We disassemble the exact image to number-specific text matching problem into coarse classification and fine prediction stages. We discretize and phrase each numerical bin with common lan",
    "link": "https://arxiv.org/abs/2408.03574",
    "context": "Title: Teach CLIP to Develop a Number Sense for Ordinal Regression\nAbstract: arXiv:2408.03574v1 Announce Type: new  Abstract: Ordinal regression is a fundamental problem within the field of computer vision, with customised well-trained models on specific tasks. While pre-trained vision-language models (VLMs) have exhibited impressive performance on various vision tasks, their potential for ordinal regression has received less exploration. In this study, we first investigate CLIP's potential for ordinal regression, from which we expect the model could generalise to different ordinal regression tasks and scenarios. Unfortunately, vanilla CLIP fails on this task, since current VLMs have a well-documented limitation of encapsulating compositional concepts such as number sense. We propose a simple yet effective method called NumCLIP to improve the quantitative understanding of VLMs. We disassemble the exact image to number-specific text matching problem into coarse classification and fine prediction stages. We discretize and phrase each numerical bin with common lan",
    "path": "papers/24/08/2408.03574.json",
    "total_tokens": 331,
    "tldr": "该文章提出了一种名为NumCLIP的方法，通过将数字感知分解为粗略的分类和精确预测阶段，改进了VLM在视觉方面对数字理解的局限性，实现了在数字排序任务中的创新突破。"
}