{
    "title": "PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting Network",
    "abstract": "arXiv:2408.01137v1 Announce Type: new  Abstract: We present an advanced study on more challenging high-resolution salient object detection (HRSOD) from both dataset and network framework perspectives. To compensate for the lack of HRSOD dataset, we thoughtfully collect a large-scale high resolution salient object detection dataset, called UHRSD, containing 5,920 images from real-world complex scenarios at 4K-8K resolutions. All the images are finely annotated in pixel-level, far exceeding previous low-resolution SOD datasets. Aiming at overcoming the contradiction between the sampling depth and the receptive field size in the past methods, we propose a novel one-stage framework for HR-SOD task using pyramid grafting mechanism. In general, transformer-based and CNN-based backbones are adopted to extract features from different resolution images independently and then these features are grafted from transformer branch to CNN branch. An attention-based Cross-Model Grafting Module (CMGM) i",
    "link": "https://arxiv.org/abs/2408.01137",
    "context": "Title: PGNeXt: High-Resolution Salient Object Detection via Pyramid Grafting Network\nAbstract: arXiv:2408.01137v1 Announce Type: new  Abstract: We present an advanced study on more challenging high-resolution salient object detection (HRSOD) from both dataset and network framework perspectives. To compensate for the lack of HRSOD dataset, we thoughtfully collect a large-scale high resolution salient object detection dataset, called UHRSD, containing 5,920 images from real-world complex scenarios at 4K-8K resolutions. All the images are finely annotated in pixel-level, far exceeding previous low-resolution SOD datasets. Aiming at overcoming the contradiction between the sampling depth and the receptive field size in the past methods, we propose a novel one-stage framework for HR-SOD task using pyramid grafting mechanism. In general, transformer-based and CNN-based backbones are adopted to extract features from different resolution images independently and then these features are grafted from transformer branch to CNN branch. An attention-based Cross-Model Grafting Module (CMGM) i",
    "path": "papers/24/08/2408.01137.json",
    "total_tokens": 727,
    "translated_title": "PGNeXt：基于金字塔嫁接网络的超高分辨率显著对象检测",
    "translated_abstract": "我们提出了一种先进的研究，专注于更高难度的超高分辨率显著对象检测（UHRSD），从数据集和网络框架两个角度进行考量。为了弥补过去高分辨率显著对象检测（HRSOD）数据集的空缺，我们细心收集了一个大规模的高分辨率显著对象检测数据集，即UHRSD数据集，包含来自复杂现实世界场景的5,920张图片，分辨率达到了4K-8K级别。所有的图片均进行了精细的像素级别标注，远远超出了先前低分辨率SOD数据集的水平。为了解决过去方法中采样深度与感受野大小之间的矛盾，我们提出了一种针对HR-SOD任务的全新单阶段框架，采用了金字塔嫁接机制。总的来说，该框架采用了基于Transformer和CNN的骨干网络独立提取不同分辨率图像的特征，然后将这些特征从Transformer分支嫁接到CNN分支。设计了一种基于注意力的跨模型嫁接模块（CMGM），通过学习不同模型的强关联愿意，克服传统方法的局限性。",
    "tldr": "论文提出了一种名为PGNeXt的全新单阶段框架，该框架通过结合Transformer和CNN网络提取特征，解决了高分辨率显著对象检测中的采样深度与感受野大小之间的矛盾，有效提高了检测的准确性。"
}