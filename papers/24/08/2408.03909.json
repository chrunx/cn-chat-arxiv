{
    "title": "LaFA: Latent Feature Attacks on Non-negative Matrix Factorization",
    "abstract": "arXiv:2408.03909v1 Announce Type: cross  Abstract: As Machine Learning (ML) applications rapidly grow, concerns about adversarial attacks compromising their reliability have gained significant attention. One unsupervised ML method known for its resilience to such attacks is Non-negative Matrix Factorization (NMF), an algorithm that decomposes input data into lower-dimensional latent features. However, the introduction of powerful computational tools such as Pytorch enables the computation of gradients of the latent features with respect to the original data, raising concerns about NMF's reliability. Interestingly, naively deriving the adversarial loss for NMF as in the case of ML would result in the reconstruction loss, which can be shown theoretically to be an ineffective attacking objective. In this work, we introduce a novel class of attacks in NMF termed Latent Feature Attacks (LaFA), which aim to manipulate the latent features produced by the NMF process. Our method utilizes the F",
    "link": "https://arxiv.org/abs/2408.03909",
    "context": "Title: LaFA: Latent Feature Attacks on Non-negative Matrix Factorization\nAbstract: arXiv:2408.03909v1 Announce Type: cross  Abstract: As Machine Learning (ML) applications rapidly grow, concerns about adversarial attacks compromising their reliability have gained significant attention. One unsupervised ML method known for its resilience to such attacks is Non-negative Matrix Factorization (NMF), an algorithm that decomposes input data into lower-dimensional latent features. However, the introduction of powerful computational tools such as Pytorch enables the computation of gradients of the latent features with respect to the original data, raising concerns about NMF's reliability. Interestingly, naively deriving the adversarial loss for NMF as in the case of ML would result in the reconstruction loss, which can be shown theoretically to be an ineffective attacking objective. In this work, we introduce a novel class of attacks in NMF termed Latent Feature Attacks (LaFA), which aim to manipulate the latent features produced by the NMF process. Our method utilizes the F",
    "path": "papers/24/08/2408.03909.json",
    "total_tokens": 330,
    "tldr": "该文章提出了一个名为Latent Feature Attacks（LaFA）的全新攻击方法，旨在针对Non-negative Matrix Factorization（NMF）算法中的潜在特征进行操纵，以质疑该算法的安全性。"
}