{
    "title": "Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study",
    "abstract": "arXiv:2408.01961v1 Announce Type: cross  Abstract: Popular and news media often portray teenagers with sensationalism, as both a risk to society and at risk from society. As AI begins to absorb some of the epistemic functions of traditional media, we study how teenagers in two countries speaking two languages: 1) are depicted by AI, and 2) how they would prefer to be depicted. Specifically, we study the biases about teenagers learned by static word embeddings (SWEs) and generative language models (GLMs), comparing these with the perspectives of adolescents living in the U.S. and Nepal. We find English-language SWEs associate teenagers with societal problems, and more than 50% of the 1,000 words most associated with teenagers in the pretrained GloVe SWE reflect such problems. Given prompts about teenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss societal problems, most commonly violence, but also drug use, mental illness, and sexual taboo. Nepali models, while n",
    "link": "https://arxiv.org/abs/2408.01961",
    "context": "Title: Representation Bias of Adolescents in AI: A Bilingual, Bicultural Study\nAbstract: arXiv:2408.01961v1 Announce Type: cross  Abstract: Popular and news media often portray teenagers with sensationalism, as both a risk to society and at risk from society. As AI begins to absorb some of the epistemic functions of traditional media, we study how teenagers in two countries speaking two languages: 1) are depicted by AI, and 2) how they would prefer to be depicted. Specifically, we study the biases about teenagers learned by static word embeddings (SWEs) and generative language models (GLMs), comparing these with the perspectives of adolescents living in the U.S. and Nepal. We find English-language SWEs associate teenagers with societal problems, and more than 50% of the 1,000 words most associated with teenagers in the pretrained GloVe SWE reflect such problems. Given prompts about teenagers, 30% of outputs from GPT2-XL and 29% from LLaMA-2-7B GLMs discuss societal problems, most commonly violence, but also drug use, mental illness, and sexual taboo. Nepali models, while n",
    "path": "papers/24/08/2408.01961.json",
    "total_tokens": 742,
    "translated_title": "《人工智能中青少年代表性的偏差：跨语言跨文化研究》",
    "translated_abstract": "本文研究了新闻媒体对青少年的常见描绘，这些描绘往往带有夸大和负面色彩，将青少年视作对社会构成风险，同时也需要社会保护的群体。随着人工智能开始承担部分传统媒体的功能，本文探讨了技术是如何反映对青少年的描绘以及对他们的潜在偏见。论文将注意力集中于两种不同语言背景中的青少年群体：美国和尼泊尔。研究结果显示，静态词嵌入（SWEs）和生成语言模型（GLMs）在描述青少年时存在着偏见。在英语语言的SWEs中，青少年与社会上的一些问题相挂钩。在预训练的GloVe SWEs中，与青少年最为相关的1000个单词中，超过50%与这些社会问题相关。在使用GPT2-XL和LLaMA-2-7B GLMs进行的语言生成任务中，超过30%的输出涉及到社会问题，例如暴力、药物滥用、心理健康问题以及性禁忌等。尼泊尔语的模型同样显示出了类似的现象。通过对青少年群体自身的视角进行分析，特别强调了青少年希望得到更积极、平衡的描绘。",
    "tldr": "论文发现英尼两种语言的AI倾向将青少年描绘成社会问题的一部分，而青少年自己更希望被展示出作为成长中个体所面临的正常挑战。"
}