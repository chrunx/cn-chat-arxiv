{
    "title": "Unveiling the Power of Sparse Neural Networks for Feature Selection",
    "abstract": "arXiv:2408.04583v1 Announce Type: cross  Abstract: Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient feature selection. Leveraging the dynamic sparse training (DST) algorithms within SNNs has demonstrated promising feature selection capabilities while drastically reducing computational overheads. Despite these advancements, several critical aspects remain insufficiently explored for feature selection. Questions persist regarding the choice of the DST algorithm for network training, the choice of metric for ranking features/neurons, and the comparative performance of these methods across diverse datasets when compared to dense networks. This paper addresses these gaps by presenting a comprehensive systematic analysis of feature selection with sparse neural networks. Moreover, we introduce a novel metric considering sparse neural network characteristics, which is designed to quantify feature importance within the context of SNNs. Our findings show that feature se",
    "link": "https://arxiv.org/abs/2408.04583",
    "context": "Title: Unveiling the Power of Sparse Neural Networks for Feature Selection\nAbstract: arXiv:2408.04583v1 Announce Type: cross  Abstract: Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient feature selection. Leveraging the dynamic sparse training (DST) algorithms within SNNs has demonstrated promising feature selection capabilities while drastically reducing computational overheads. Despite these advancements, several critical aspects remain insufficiently explored for feature selection. Questions persist regarding the choice of the DST algorithm for network training, the choice of metric for ranking features/neurons, and the comparative performance of these methods across diverse datasets when compared to dense networks. This paper addresses these gaps by presenting a comprehensive systematic analysis of feature selection with sparse neural networks. Moreover, we introduce a novel metric considering sparse neural network characteristics, which is designed to quantify feature importance within the context of SNNs. Our findings show that feature se",
    "path": "papers/24/08/2408.04583.json",
    "total_tokens": 350,
    "tldr": "该文章提出了一种新的系统性分析方法来研究稀疏神经网络在特征选择方面的应用，特别探讨了动态稀疏训练算法在特征选择中的作用，并引入了一个新的特征重要性指标来衡量稀疏神经网络中的特征。研究表明，稀疏神经网络在特征选择方面展现出潜在的效用，尤其是与传统密集网络相比，可以显著减少计算开销，同时在多种数据集上具有竞争力。"
}