{
    "title": "Visual Grounding for Object-Level Generalization in Reinforcement Learning",
    "abstract": "arXiv:2408.01942v1 Announce Type: cross  Abstract: Generalization is a pivotal challenge for agents following natural language instructions. To approach this goal, we leverage a vision-language model (VLM) for visual grounding and transfer its vision-language knowledge into reinforcement learning (RL) for object-centric tasks, which makes the agent capable of zero-shot generalization to unseen objects and instructions. By visual grounding, we obtain an object-grounded confidence map for the target object indicated in the instruction. Based on this map, we introduce two routes to transfer VLM knowledge into RL. Firstly, we propose an object-grounded intrinsic reward function derived from the confidence map to more effectively guide the agent towards the target object. Secondly, the confidence map offers a more unified, accessible task representation for the agent's policy, compared to language embeddings. This enables the agent to process unseen objects and instructions through comprehe",
    "link": "https://arxiv.org/abs/2408.01942",
    "context": "Title: Visual Grounding for Object-Level Generalization in Reinforcement Learning\nAbstract: arXiv:2408.01942v1 Announce Type: cross  Abstract: Generalization is a pivotal challenge for agents following natural language instructions. To approach this goal, we leverage a vision-language model (VLM) for visual grounding and transfer its vision-language knowledge into reinforcement learning (RL) for object-centric tasks, which makes the agent capable of zero-shot generalization to unseen objects and instructions. By visual grounding, we obtain an object-grounded confidence map for the target object indicated in the instruction. Based on this map, we introduce two routes to transfer VLM knowledge into RL. Firstly, we propose an object-grounded intrinsic reward function derived from the confidence map to more effectively guide the agent towards the target object. Secondly, the confidence map offers a more unified, accessible task representation for the agent's policy, compared to language embeddings. This enables the agent to process unseen objects and instructions through comprehe",
    "path": "papers/24/08/2408.01942.json",
    "total_tokens": 415,
    "tldr": "该文章将视觉-语言模型（VLM）的视觉 grounding 能力应用于强化学习（RL），以实现对未见过的对象和指令的零样本泛化。通过视觉 grounding，作者获得了一个与指令中指示的目标物体相对应的对象实体置信图，并提出了两种方法来将VLM的知识转移到RL中：一是通过基于置信图设计了一种对象定向的内在奖励函数，以更有效地引导代理朝向目标物体；二是使用置信图为代理的策略提供了比语言嵌入更加统一和可访问的任务表示，从而使得代理能够通过对比处理未见过的物体和指令。"
}