{
    "title": "Visual Grounding for Object-Level Generalization in Reinforcement Learning",
    "abstract": "arXiv:2408.01942v1 Announce Type: new  Abstract: Generalization is a pivotal challenge for agents following natural language instructions. To approach this goal, we leverage a vision-language model (VLM) for visual grounding and transfer its vision-language knowledge into reinforcement learning (RL) for object-centric tasks, which makes the agent capable of zero-shot generalization to unseen objects and instructions. By visual grounding, we obtain an object-grounded confidence map for the target object indicated in the instruction. Based on this map, we introduce two routes to transfer VLM knowledge into RL. Firstly, we propose an object-grounded intrinsic reward function derived from the confidence map to more effectively guide the agent towards the target object. Secondly, the confidence map offers a more unified, accessible task representation for the agent's policy, compared to language embeddings. This enables the agent to process unseen objects and instructions through comprehens",
    "link": "https://arxiv.org/abs/2408.01942",
    "context": "Title: Visual Grounding for Object-Level Generalization in Reinforcement Learning\nAbstract: arXiv:2408.01942v1 Announce Type: new  Abstract: Generalization is a pivotal challenge for agents following natural language instructions. To approach this goal, we leverage a vision-language model (VLM) for visual grounding and transfer its vision-language knowledge into reinforcement learning (RL) for object-centric tasks, which makes the agent capable of zero-shot generalization to unseen objects and instructions. By visual grounding, we obtain an object-grounded confidence map for the target object indicated in the instruction. Based on this map, we introduce two routes to transfer VLM knowledge into RL. Firstly, we propose an object-grounded intrinsic reward function derived from the confidence map to more effectively guide the agent towards the target object. Secondly, the confidence map offers a more unified, accessible task representation for the agent's policy, compared to language embeddings. This enables the agent to process unseen objects and instructions through comprehens",
    "path": "papers/24/08/2408.01942.json",
    "total_tokens": 623,
    "translated_title": "基于视觉的强化学习中对象级别概括的实现",
    "translated_abstract": "在这项工作中，我们研究了指导基于自然语言指令的代理进行概括的问题。为了解决这个问题，我们利用了一种视觉语言模型（VLM）来进行视觉对齐，并将这种视觉语言知识转移到强化学习（RL）中，使得代理能够在未见过的新对象和指令上进行零样本概括。通过视觉对齐，我们获得了指示指令中目标对象的具体置信图。基于该图，我们提出了两种将VLM知识转移到RL中的方法。首先，我们提出了基于置信图的对象对齐内在奖励函数，以更有效地引导代理接近目标对象。其次，置信图为代理的策略提供了一个更加统一和可访问的任务表示，相对于语言嵌入。这种表示能力使得代理能够通过更有效的途径处理未见过的新对象和指令。",
    "tldr": "这项研究通过视觉对齐和基于VLM的内在奖励函数，提升了在强化学习中指导代理进行未见过新对象的零样本概括的效率。"
}