{
    "title": "Symmetric Graph Contrastive Learning against Noisy Views for Recommendation",
    "abstract": "arXiv:2408.02691v1 Announce Type: cross  Abstract: Graph Contrastive Learning (GCL) leverages data augmentation techniques to produce contrasting views, enhancing the accuracy of recommendation systems through learning the consistency between contrastive views. However, existing augmentation methods, such as directly perturbing interaction graph (e.g., node/edge dropout), may interfere with the original connections and generate poor contrasting views, resulting in sub-optimal performance. In this paper, we define the views that share only a small amount of information with the original graph due to poor data augmentation as noisy views (i.e., the last 20% of the views with a cosine similarity value less than 0.1 to the original view). We demonstrate through detailed experiments that noisy views will significantly degrade recommendation performance. Further, we propose a model-agnostic Symmetric Graph Contrastive Learning (SGCL) method with theoretical guarantees to address this issue. ",
    "link": "https://arxiv.org/abs/2408.02691",
    "context": "Title: Symmetric Graph Contrastive Learning against Noisy Views for Recommendation\nAbstract: arXiv:2408.02691v1 Announce Type: cross  Abstract: Graph Contrastive Learning (GCL) leverages data augmentation techniques to produce contrasting views, enhancing the accuracy of recommendation systems through learning the consistency between contrastive views. However, existing augmentation methods, such as directly perturbing interaction graph (e.g., node/edge dropout), may interfere with the original connections and generate poor contrasting views, resulting in sub-optimal performance. In this paper, we define the views that share only a small amount of information with the original graph due to poor data augmentation as noisy views (i.e., the last 20% of the views with a cosine similarity value less than 0.1 to the original view). We demonstrate through detailed experiments that noisy views will significantly degrade recommendation performance. Further, we propose a model-agnostic Symmetric Graph Contrastive Learning (SGCL) method with theoretical guarantees to address this issue. ",
    "path": "papers/24/08/2408.02691.json",
    "total_tokens": 346,
    "tldr": "该文章提出了一个名为Symmetric Graph Contrastive Learning（SGCL）的模型，用于推荐系统。该方法通过理论上的保证，确保了数据增广的对比视图不会因为失去原有的连接信息而导致的性能下降，有效提升了推荐系统的准确率。"
}