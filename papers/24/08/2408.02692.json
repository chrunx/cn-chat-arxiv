{
    "title": "Attention is all you need for an improved CNN-based flash flood susceptibility modeling. The case of the ungauged Rheraya watershed, Morocco",
    "abstract": "arXiv:2408.02692v1 Announce Type: cross  Abstract: Effective flood hazard management requires evaluating and predicting flash flood susceptibility. Convolutional neural networks (CNNs) are commonly used for this task but face issues like gradient explosion and overfitting. This study explores the use of an attention mechanism, specifically the convolutional block attention module (CBAM), to enhance CNN models for flash flood susceptibility in the ungauged Rheraya watershed, a flood prone region. We used ResNet18, DenseNet121, and Xception as backbone architectures, integrating CBAM at different locations. Our dataset included 16 conditioning factors and 522 flash flood inventory points. Performance was evaluated using accuracy, precision, recall, F1-score, and the area under the curve (AUC) of the receiver operating characteristic (ROC). Results showed that CBAM significantly improved model performance, with DenseNet121 incorporating CBAM in each convolutional block achieving the best ",
    "link": "https://arxiv.org/abs/2408.02692",
    "context": "Title: Attention is all you need for an improved CNN-based flash flood susceptibility modeling. The case of the ungauged Rheraya watershed, Morocco\nAbstract: arXiv:2408.02692v1 Announce Type: cross  Abstract: Effective flood hazard management requires evaluating and predicting flash flood susceptibility. Convolutional neural networks (CNNs) are commonly used for this task but face issues like gradient explosion and overfitting. This study explores the use of an attention mechanism, specifically the convolutional block attention module (CBAM), to enhance CNN models for flash flood susceptibility in the ungauged Rheraya watershed, a flood prone region. We used ResNet18, DenseNet121, and Xception as backbone architectures, integrating CBAM at different locations. Our dataset included 16 conditioning factors and 522 flash flood inventory points. Performance was evaluated using accuracy, precision, recall, F1-score, and the area under the curve (AUC) of the receiver operating characteristic (ROC). Results showed that CBAM significantly improved model performance, with DenseNet121 incorporating CBAM in each convolutional block achieving the best ",
    "path": "papers/24/08/2408.02692.json",
    "total_tokens": 453,
    "tldr": "该文章采用注意力机制，特别是卷积块注意模块（CBAM），来改进了使用CNNs（卷积神经网络）对摩洛哥鲁拉亚水系未定理流域的洪水敏感性进行预测的能力。通过在流行的CNN模型，如ResNet18、DenseNet121和Xception中分别使用了CBAM，研究者发现这种注意力机制在提高模型的准确度、精确度、召回率和F1得分方面表现显著，特别是在DenseNet121模型中，CBAM在每个卷积块中均得到整合，实现了最佳的ROC曲线下面积（AUC）。"
}