{
    "title": "Body of Her: A Preliminary Study on End-to-End Humanoid Agent",
    "abstract": "arXiv:2408.02879v1 Announce Type: new  Abstract: Interactive virtual humanoid agent is a crucial interface with the physical world. A relatively complete humanoid agent first needs to have face and body, then possess both verbal and non-verbal (such as eye contact, facial expression, lip motion, gesture, and manipulation) abilities, and finally, it is capable of real-time duplex communication, e.g., the ability to actively interrupt conversations. Most prior systems typically only consider a subset of these elements, leaving a gap from realistic humanoid agent. In this work, we propose a real-time, duplex, interactive end-to-end network capable of modeling realistic agent behaviors, including speech, full-body movements for talking, responding, idling, and manipulation. This system is a multimodal model integrating audio and visual inputs, extended from a pre-trained large language model (LLM). We collect approximately 200,000 hours of audio, around 130,000 hours of video data, and abo",
    "link": "https://arxiv.org/abs/2408.02879",
    "context": "Title: Body of Her: A Preliminary Study on End-to-End Humanoid Agent\nAbstract: arXiv:2408.02879v1 Announce Type: new  Abstract: Interactive virtual humanoid agent is a crucial interface with the physical world. A relatively complete humanoid agent first needs to have face and body, then possess both verbal and non-verbal (such as eye contact, facial expression, lip motion, gesture, and manipulation) abilities, and finally, it is capable of real-time duplex communication, e.g., the ability to actively interrupt conversations. Most prior systems typically only consider a subset of these elements, leaving a gap from realistic humanoid agent. In this work, we propose a real-time, duplex, interactive end-to-end network capable of modeling realistic agent behaviors, including speech, full-body movements for talking, responding, idling, and manipulation. This system is a multimodal model integrating audio and visual inputs, extended from a pre-trained large language model (LLM). We collect approximately 200,000 hours of audio, around 130,000 hours of video data, and abo",
    "path": "papers/24/08/2408.02879.json",
    "total_tokens": 359,
    "tldr": "该文章提出了一种能够模拟现实人物行为的全端到端网络，包括言语和非言语的交流能力，能够进行实时双工交流，填补了先前系统存在的现实人类代理的空白。"
}