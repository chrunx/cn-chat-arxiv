{
    "title": "Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves",
    "abstract": "arXiv:2408.00768v1 Announce Type: new  Abstract: Gathering data and identifying events in various traffic situations remains an essential challenge for the systematic evaluation of a perception system's performance. Analyzing large-scale, typically unstructured, multi-modal, time series data obtained from video, radar, and LiDAR is computationally demanding, particularly when meta-information or annotations are missing. We compare Optical Flow (OF) and Deep Learning (DL) to feed computationally efficient event detection via space-filling curves on video data from a forward-facing, in-vehicle camera. Our first approach leverages unexpected disturbances in the OF field from vehicle surroundings; the second approach is a DL model trained on human visual attention to predict a driver's gaze to spot potential event locations. We feed these results to a space-filling curve to reduce dimensionality and achieve computationally efficient event retrieval. We systematically evaluate our concept b",
    "link": "https://arxiv.org/abs/2408.00768",
    "context": "Title: Comparing Optical Flow and Deep Learning to Enable Computationally Efficient Traffic Event Detection with Space-Filling Curves\nAbstract: arXiv:2408.00768v1 Announce Type: new  Abstract: Gathering data and identifying events in various traffic situations remains an essential challenge for the systematic evaluation of a perception system's performance. Analyzing large-scale, typically unstructured, multi-modal, time series data obtained from video, radar, and LiDAR is computationally demanding, particularly when meta-information or annotations are missing. We compare Optical Flow (OF) and Deep Learning (DL) to feed computationally efficient event detection via space-filling curves on video data from a forward-facing, in-vehicle camera. Our first approach leverages unexpected disturbances in the OF field from vehicle surroundings; the second approach is a DL model trained on human visual attention to predict a driver's gaze to spot potential event locations. We feed these results to a space-filling curve to reduce dimensionality and achieve computationally efficient event retrieval. We systematically evaluate our concept b",
    "path": "papers/24/08/2408.00768.json",
    "total_tokens": 844,
    "translated_title": "使用空间 filling curves 对比光流和深度学习实现计算高效的交通事件检测",
    "translated_abstract": "我们面临着在视频、雷达和激光雷达等交通数据中识别事件和收集数据的挑战，这对评价感知系统的性能至关重要。这类数据通常是无结构的、多模态的、时间序列的，且缺乏元数据或注释。本文比较了光流和深度学习在视频数据（来自车辆前向摄像头）中实现计算高效的交通事件检测的能力。我们的方法是利用车辆周围光流场的干扰来发现潜在的事件，而另一种方法是通过训练深度学习模型预测驾驶员的视线，以预测潜在事件的位置。我们将这些结果输送到空间填满曲线上，以降低维度并实现计算上的效率。我们通过标准的实验，针对在不同场景下检测事件的有效性，验证了本概念的效力。计算效率的评估取决于算法的执行时间，总内存消耗以及空间解构的时间。结果表明，本概念所展示的算法可以比传统的基于光流的方法更快地找到事件，并且能够在达到良好的检测精度时，更快地完成计算密集型操作。Our approach is designed to serve as an early warning or an auxiliary system that can provide real-time feedback to drivers or autonomous vehicles by identifying potential hazards or sudden events in the road ahead, improving situational awareness and potentially enhancing safety. In summary, this paper presents a novel framework for computationally efficient traffic event detection, which relies on optical flow, deep learning, and space-filling curves, offering a promising solution for the autonomous driving industry to achieve real-time event detection with minimal computational resources.",
    "tldr": "本文提出了一种结合光流、深度学习和空间填满曲线的框架，实现了对车辆前向摄像头捕获的视频数据中交通事件的实时、高效检测。该框架有助于为驾驶员或自动驾驶车辆提供实时反馈，识别前方道路潜在的威胁或突发事件，提高驾驶情况感知，并可能提高安全性。"
}