{
    "title": "Global-Local Progressive Integration Network for Blind Image Quality Assessment",
    "abstract": "arXiv:2408.03885v1 Announce Type: new  Abstract: Vision transformers (ViTs) excel in computer vision for modeling long-term dependencies, yet face two key challenges for image quality assessment (IQA): discarding fine details during patch embedding, and requiring extensive training data due to lack of inductive biases. In this study, we propose a Global-Local progressive INTegration network for IQA, called GlintIQA, to address these issues through three key components: 1) Hybrid feature extraction combines ViT-based global feature extractor (VGFE) and convolutional neural networks (CNNs)-based local feature extractor (CLFE) to capture global coarse-grained features and local fine-grained features, respectively. The incorporation of CNNs mitigates the patch-level information loss and inductive bias constraints inherent to ViT architectures. 2) Progressive feature integration leverages diverse kernel sizes in embedding to spatially align coarse- and fine-grained features, and progressive",
    "link": "https://arxiv.org/abs/2408.03885",
    "context": "Title: Global-Local Progressive Integration Network for Blind Image Quality Assessment\nAbstract: arXiv:2408.03885v1 Announce Type: new  Abstract: Vision transformers (ViTs) excel in computer vision for modeling long-term dependencies, yet face two key challenges for image quality assessment (IQA): discarding fine details during patch embedding, and requiring extensive training data due to lack of inductive biases. In this study, we propose a Global-Local progressive INTegration network for IQA, called GlintIQA, to address these issues through three key components: 1) Hybrid feature extraction combines ViT-based global feature extractor (VGFE) and convolutional neural networks (CNNs)-based local feature extractor (CLFE) to capture global coarse-grained features and local fine-grained features, respectively. The incorporation of CNNs mitigates the patch-level information loss and inductive bias constraints inherent to ViT architectures. 2) Progressive feature integration leverages diverse kernel sizes in embedding to spatially align coarse- and fine-grained features, and progressive",
    "path": "papers/24/08/2408.03885.json",
    "total_tokens": 432,
    "tldr": "该文章提出了一种名为GlInSNet的盲图像质量评估网络，它结合了全局和局部特征提取器，以同时捕捉图像的粗粒度和细粒度信息。通过将基于视觉变换器的全局特征提取器与基于卷积神经网络的局部特征提取器相结合，GlInSNet有效地解决了视觉变换器在处理图像细节和从有限数据集中学习方面的局限性。此外，文章还介绍了一种迭代特征融合机制，该机制能够将粗粒度和细粒度特征进行有效融合，从而提高了评估的准确性。总体而言，GlInSNet通过整合全局和局部的信息，提供了一种更强大的图像质量评估方法。"
}