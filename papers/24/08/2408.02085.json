{
    "title": "Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models",
    "abstract": "arXiv:2408.02085v1 Announce Type: new  Abstract: Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each",
    "link": "https://arxiv.org/abs/2408.02085",
    "context": "Title: Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models\nAbstract: arXiv:2408.02085v1 Announce Type: new  Abstract: Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each",
    "path": "papers/24/08/2408.02085.json",
    "total_tokens": 738,
    "translated_title": "标题：释放数据巨浪的力量：用于语言模型指令训练的数据评价与选择综合调查",
    "translated_abstract": "摘要：arXiv:2408.02085v1 公告类型：新文摘要：指令训练在使大型语言模型（LLMs）与人类喜好保持一致方面扮演着关键角色。尽管存在大量的开放式指令数据集，但盲目地在所有现有指令上训练一个LLM可能并不理想且不实用。为了确定最有利的训练数据点，自然语言处理（NLP）和深度学习领域已经提出了数据评估和选择的方法。然而，在指令训练的背景下，仍然存在一个知识差距，即哪些数据评估指标可以应用，以及它们是如何融入选择机制的。为了填补这一空白，我们提出了对用于指令训练的LLMs的数据评估和选择现有文献的全面回顾。我们系统地对所有适用的方法进行了分类，并将其分为基于质量的、基于多样性的和基于重要性的三类，其中细化了精细粒度的分类体系。对于每种的评估方法和它们的实际应用，我们都进行了详细的分析和对比。此外，我们还发现了未来研究可能的空白领域，提出了未来研究的方向。通过对现有方法和新兴技术的综合评估，我们相信可以为指导语言模型的最优数据驱动训练提供有价值的见解和策略。",
    "tldr": "本研究综述了评估与选择用于语言模型指令训练的数据方法的现有文献，揭示了不同评估方法的实际应用及未来研究的可能性，旨在为最优的数据驱动训练提供有价值的见解和策略。",
    "en_tdlr": "This study reviews the existing literature on data evaluation and selection methods for instruction tuning of language models, highlighting the practical applications of various assessment methods and potential future research areas, aiming to provide valuable insights and strategies for optimal data-driven training."
}