{
    "title": "REVISION: Rendering Tools Enable Spatial Fidelity in Vision-Language Models",
    "abstract": "arXiv:2408.02231v1 Announce Type: new  Abstract: Text-to-Image (T2I) and multimodal large language models (MLLMs) have been adopted in solutions for several computer vision and multimodal learning tasks. However, it has been found that such vision-language models lack the ability to correctly reason over spatial relationships. To tackle this shortcoming, we develop the REVISION framework which improves spatial fidelity in vision-language models. REVISION is a 3D rendering based pipeline that generates spatially accurate synthetic images, given a textual prompt. REVISION is an extendable framework, which currently supports 100+ 3D assets, 11 spatial relationships, all with diverse camera perspectives and backgrounds. Leveraging images from REVISION as additional guidance in a training-free manner consistently improves the spatial consistency of T2I models across all spatial relationships, achieving competitive performance on the VISOR and T2I-CompBench benchmarks. We also design RevQA, ",
    "link": "https://arxiv.org/abs/2408.02231",
    "context": "Title: REVISION: Rendering Tools Enable Spatial Fidelity in Vision-Language Models\nAbstract: arXiv:2408.02231v1 Announce Type: new  Abstract: Text-to-Image (T2I) and multimodal large language models (MLLMs) have been adopted in solutions for several computer vision and multimodal learning tasks. However, it has been found that such vision-language models lack the ability to correctly reason over spatial relationships. To tackle this shortcoming, we develop the REVISION framework which improves spatial fidelity in vision-language models. REVISION is a 3D rendering based pipeline that generates spatially accurate synthetic images, given a textual prompt. REVISION is an extendable framework, which currently supports 100+ 3D assets, 11 spatial relationships, all with diverse camera perspectives and backgrounds. Leveraging images from REVISION as additional guidance in a training-free manner consistently improves the spatial consistency of T2I models across all spatial relationships, achieving competitive performance on the VISOR and T2I-CompBench benchmarks. We also design RevQA, ",
    "path": "papers/24/08/2408.02231.json",
    "total_tokens": 390,
    "tldr": "该文章开发了一种名为REVISION的框架，该框架通过3D渲染 pipeline 生成准确的合成图像，改善了视觉语言模型在空间关系推理方面的缺陷。REVISION支持多种3D资产、空间关系和视角，显著提高了文本-图像模型在预测空间关系时的准确度，并在VISOR和T2I-CompBench基准测试中取得了优异成绩。"
}