{
    "title": "Set2Seq Transformer: Learning Permutation Aware Set Representations of Artistic Sequences",
    "abstract": "arXiv:2408.03404v1 Announce Type: new  Abstract: We propose Set2Seq Transformer, a novel sequential multiple instance architecture, that learns to rank permutation aware set representations of sequences. First, we illustrate that learning temporal position-aware representations of discrete timesteps can greatly improve static visual multiple instance learning methods that do not regard temporality and concentrate almost exclusively on visual content analysis. We further demonstrate the significant advantages of end-to-end sequential multiple instance learning, integrating visual content and temporal information in a multimodal manner. As application we focus on fine art analysis related tasks. To that end, we show that our Set2Seq Transformer can leverage visual set and temporal position-aware representations for modelling visual artists' oeuvres for predicting artistic success. Finally, through extensive quantitative and qualitative evaluation using a novel dataset, WikiArt-Seq2Rank, ",
    "link": "https://arxiv.org/abs/2408.03404",
    "context": "Title: Set2Seq Transformer: Learning Permutation Aware Set Representations of Artistic Sequences\nAbstract: arXiv:2408.03404v1 Announce Type: new  Abstract: We propose Set2Seq Transformer, a novel sequential multiple instance architecture, that learns to rank permutation aware set representations of sequences. First, we illustrate that learning temporal position-aware representations of discrete timesteps can greatly improve static visual multiple instance learning methods that do not regard temporality and concentrate almost exclusively on visual content analysis. We further demonstrate the significant advantages of end-to-end sequential multiple instance learning, integrating visual content and temporal information in a multimodal manner. As application we focus on fine art analysis related tasks. To that end, we show that our Set2Seq Transformer can leverage visual set and temporal position-aware representations for modelling visual artists' oeuvres for predicting artistic success. Finally, through extensive quantitative and qualitative evaluation using a novel dataset, WikiArt-Seq2Rank, ",
    "path": "papers/24/08/2408.03404.json",
    "total_tokens": 380,
    "tldr": "该文章提出Set2Seq Transformer，这是一种新的序列多实例架构，能够学习和排名感知顺序的集合表示，这为非时序重点的静态视觉多实例学习方法带来了显著改进。通过在多模态中整合视觉内容和时间信息，该架构展示了在模式识别任务中应用序列多实例学习的巨大优势。在专注于对艺术家作品进行分析的实验中，该文章展示了Set2Seq Transformer如何预测艺术成就，并为这一任务提供了一个创新的数据集——WikiArt-Seq2Rank。"
}