{
    "title": "ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling",
    "abstract": "arXiv:2408.04102v1 Announce Type: new  Abstract: Recognizing and disentangling visual attributes from objects is a foundation to many computer vision applications. While large vision language representations like CLIP had largely resolved the task of zero-shot object recognition, zero-shot visual attribute recognition remains a challenge because CLIP's contrastively-learned vision-language representation cannot effectively capture object-attribute dependencies. In this paper, we target this weakness and propose a sentence generation-based retrieval formulation for attribute recognition that is novel in 1) explicitly modeling a to-be-measured and retrieved object-attribute relation as a conditional probability graph, which converts the recognition problem into a dependency-sensitive language-modeling problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this reformulation and naturally distilling its knowledge of image-object-attribute relations to use towards attri",
    "link": "https://arxiv.org/abs/2408.04102",
    "context": "Title: ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling\nAbstract: arXiv:2408.04102v1 Announce Type: new  Abstract: Recognizing and disentangling visual attributes from objects is a foundation to many computer vision applications. While large vision language representations like CLIP had largely resolved the task of zero-shot object recognition, zero-shot visual attribute recognition remains a challenge because CLIP's contrastively-learned vision-language representation cannot effectively capture object-attribute dependencies. In this paper, we target this weakness and propose a sentence generation-based retrieval formulation for attribute recognition that is novel in 1) explicitly modeling a to-be-measured and retrieved object-attribute relation as a conditional probability graph, which converts the recognition problem into a dependency-sensitive language-modeling problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this reformulation and naturally distilling its knowledge of image-object-attribute relations to use towards attri",
    "path": "papers/24/08/2408.04102.json",
    "total_tokens": 353,
    "tldr": "该文章提出了一种名为ArtVLM的方法，通过采用大型预训练的视觉语言模型（VLM），实现了在零样本条件下对视觉属性的识别。这种方法通过改造一种条件概率图模型，将识别任务转化为依赖性敏感的语言建模问题，有效解决了之前在视觉语言模型中未能捕捉到的对象属性关系问题。"
}