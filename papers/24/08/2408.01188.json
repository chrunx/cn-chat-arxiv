{
    "title": "Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems",
    "abstract": "arXiv:2408.01188v1 Announce Type: new  Abstract: Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as it enables learning at runtime without the need for a model of the environment or predefined actions. However, most applications of RL in AS, such as those based on Q-learning, can only optimize one objective, making it necessary in multi-objective systems to combine multiple objectives in a single objective function with predefined weights. A number of Multi-Objective Reinforcement Learning (MORL) techniques exist but they have mostly been applied in RL benchmarks rather than real-world AS systems. In this work, we use a MORL technique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers exemplar, a self-adaptive server, to find the optimal configuration for runtime performance optimization. We compare DWN to two single-objective optimization implementations: {\\epsilon}-greedy algorithm and Deep Q-Networks. Our initial evaluation shows that DW",
    "link": "https://arxiv.org/abs/2408.01188",
    "context": "Title: Multi-Objective Deep Reinforcement Learning for Optimisation in Autonomous Systems\nAbstract: arXiv:2408.01188v1 Announce Type: new  Abstract: Reinforcement Learning (RL) is used extensively in Autonomous Systems (AS) as it enables learning at runtime without the need for a model of the environment or predefined actions. However, most applications of RL in AS, such as those based on Q-learning, can only optimize one objective, making it necessary in multi-objective systems to combine multiple objectives in a single objective function with predefined weights. A number of Multi-Objective Reinforcement Learning (MORL) techniques exist but they have mostly been applied in RL benchmarks rather than real-world AS systems. In this work, we use a MORL technique called Deep W-Learning (DWN) and apply it to the Emergent Web Servers exemplar, a self-adaptive server, to find the optimal configuration for runtime performance optimization. We compare DWN to two single-objective optimization implementations: {\\epsilon}-greedy algorithm and Deep Q-Networks. Our initial evaluation shows that DW",
    "path": "papers/24/08/2408.01188.json",
    "total_tokens": 717,
    "translated_title": "多目标深度强化学习在自主系统中的优化",
    "translated_abstract": "arXiv:2408.01188v1 公告类型：新  摘要：在自主系统（AS）中，强化学习（RL）因其能在运行时学习而不需要环境模型或预定义动作而得到了广泛使用。然而，AS中RL的许多应用，例如基于Q学习的应用，只能优化一个目标，因此在具有多个目标的系统（如多目标强化学习（MORL）中，需要将多个目标在单个目标函数中以预先定义的权重结合。存在多种MORL技术，但它们大多数只在RL基准测试中应用，而不是在真实的自主系统中。本工作中，我们使用了名为Deep W-Learning（DWN）的多目标强化学习技术，并在诸如自适应服务器这样的新兴Web服务器示例中对其进行应用，以找到在运行时性能优化方面的理想配置。我们将DWN与两种单一目标优化实现进行了比较：ε-贪婪算法和深度Q网络。我们的初步评估显示，DW",
    "tldr": "本文采用了名为Deep W-Learning（DWN）的多目标强化学习技术，将其应用于新兴Web服务器示例，以在运行时找到最佳性能优化配置，并与两种单一目标优化实现（ε-贪婪算法和深度Q网络）进行了对比。",
    "en_tdlr": "In this study, we apply the Multi-Objective Reinforcement Learning technique Deep W-Learning (DWN) to the Embedded Web Servers exemplar for runtime performance optimization, comparing it with two single-objective optimization implementations: the epsilon-greedy algorithm and Deep Q-Networks."
}