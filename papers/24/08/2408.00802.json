{
    "title": "Leveraging LLM Reasoning Enhances Personalized Recommender Systems",
    "abstract": "arXiv:2408.00802v1 Announce Type: cross  Abstract: Recent advancements have showcased the potential of Large Language Models (LLMs) in executing reasoning tasks, particularly facilitated by Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve clear, definitive answers and logical chains of thought, the application of LLM reasoning in recommendation systems (RecSys) presents a distinct challenge. RecSys tasks revolve around subjectivity and personalized preferences, an under-explored domain in utilizing LLMs' reasoning capabilities. Our study explores several aspects to better understand reasoning for RecSys and demonstrate how task quality improves by utilizing LLM reasoning in both zero-shot and finetuning settings. Additionally, we propose RecSAVER (Recommender Systems Automatic Verification and Evaluation of Reasoning) to automatically assess the quality of LLM reasoning responses without the requirement of curated gold references or human raters. We show ",
    "link": "https://arxiv.org/abs/2408.00802",
    "context": "Title: Leveraging LLM Reasoning Enhances Personalized Recommender Systems\nAbstract: arXiv:2408.00802v1 Announce Type: cross  Abstract: Recent advancements have showcased the potential of Large Language Models (LLMs) in executing reasoning tasks, particularly facilitated by Chain-of-Thought (CoT) prompting. While tasks like arithmetic reasoning involve clear, definitive answers and logical chains of thought, the application of LLM reasoning in recommendation systems (RecSys) presents a distinct challenge. RecSys tasks revolve around subjectivity and personalized preferences, an under-explored domain in utilizing LLMs' reasoning capabilities. Our study explores several aspects to better understand reasoning for RecSys and demonstrate how task quality improves by utilizing LLM reasoning in both zero-shot and finetuning settings. Additionally, we propose RecSAVER (Recommender Systems Automatic Verification and Evaluation of Reasoning) to automatically assess the quality of LLM reasoning responses without the requirement of curated gold references or human raters. We show ",
    "path": "papers/24/08/2408.00802.json",
    "total_tokens": 664,
    "translated_title": "利用LLM推理增强个性化推荐系统",
    "translated_abstract": "arXiv:2408.00802v1 通告类型：交叉  翻译：最近的技术进步显示了大语言模型(LLM)在执行推理任务方面的潜力，特别是在CoT(Chain-of-Thought，思想链)提示方面的应用。虽然像算术推理这样的任务涉及明确的、明确的答案和逻辑推理，LLM推理在推荐系统(RecSys)中的应用是一个未得到充分探索的领域。我们的研究探讨了几方面的问题，以更好地理解RecSys中的推理，并展示了在零射程和微调设置中使用LLM推理是如何提高任务质量的。此外，我们还提出了RecSAVER（推荐系统自动验证和评价推理），这是一种自动评估LLM推理响应质量的方法，无需使用经 curated 黄金参考或人类评分器。我们展示了",
    "tldr": "本研究利用LLM推理增强个性化推荐系统，证明了在零射程和微调设置中使用LLM推理能够提高任务质量。我们还提出了RecSAVER方法，这是一种自动评价LLM推理响应质量的工具。"
}