{
    "title": "Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs",
    "abstract": "arXiv:2408.01417v1 Announce Type: cross  Abstract: Humans spontaneously use increasingly efficient language as interactions progress, by adapting and forming ad-hoc conventions. This phenomenon has been studied extensively using reference games, showing properties of human language that go beyond relaying intents. It remains unexplored whether multimodal large language models (MLLMs) similarly increase communication efficiency during interactions, and what mechanisms they may adopt for this purpose. We introduce ICCA, an automated framework to evaluate such conversational adaptation as an in-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and observe that while they may understand the increasingly efficient language of their interlocutor, they do not spontaneously make their own language more efficient over time. This latter ability can only be elicited in some models (e.g., GPT-4) with heavy-handed prompting. This shows that this property of linguistic interacti",
    "link": "https://arxiv.org/abs/2408.01417",
    "context": "Title: Talk Less, Interact Better: Evaluating In-context Conversational Adaptation in Multimodal LLMs\nAbstract: arXiv:2408.01417v1 Announce Type: cross  Abstract: Humans spontaneously use increasingly efficient language as interactions progress, by adapting and forming ad-hoc conventions. This phenomenon has been studied extensively using reference games, showing properties of human language that go beyond relaying intents. It remains unexplored whether multimodal large language models (MLLMs) similarly increase communication efficiency during interactions, and what mechanisms they may adopt for this purpose. We introduce ICCA, an automated framework to evaluate such conversational adaptation as an in-context behavior in MLLMs. We evaluate several state-of-the-art MLLMs, and observe that while they may understand the increasingly efficient language of their interlocutor, they do not spontaneously make their own language more efficient over time. This latter ability can only be elicited in some models (e.g., GPT-4) with heavy-handed prompting. This shows that this property of linguistic interacti",
    "path": "papers/24/08/2408.01417.json",
    "total_tokens": 662,
    "translated_title": "\"少说话，多互动：在多模态LLM中评估上下文对话适应性\"",
    "translated_abstract": "\"在本文中，我们研究了人类如何在互动过程中自发地使用越来越高效的言语，通过调整和形成即兴约定。这种现象已经在参考游戏中得到了广泛的研究，显示出人类语言的一些特性，这些特性超出了传达意图的范围。至今尚未探讨的是，多模态大型语言模型(MLLM)是否会像人类一样在互动中提高沟通效率，以及它们可能采用哪些机制来实现这一目标。我们介绍了一个自动框架ICCA，用于评估MLLM在互动中的对话适应性作为一种内在行为。我们评估了几种最先进的多模态语言模型，并观察到尽管它们可能理解他们的对话者的言语变得越来越高效，但它们并不能像人类那样在互动过程中自发地使自己的语言变得更加高效。后者能力只能在某些模型(例如GPT-4)中通过被动的提示方式激发出来。这表明了这种自然语言交互的特性还没有完全被当前的模型所掌握。\"",
    "tldr": "\"我们的研究揭示了多模态语言模型在对话过程中缺乏自适应和形成即兴约定的能力，这些能力是沟通效率提高的关键。\""
}