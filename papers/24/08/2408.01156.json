{
    "title": "TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation",
    "abstract": "arXiv:2408.01156v1 Announce Type: cross  Abstract: T-cell receptors (TCRs) play a crucial role in the immune system by recognizing and binding to specific antigens presented by infected or cancerous cells. Understanding the sequence patterns of TCRs is essential for developing targeted immune therapies and designing effective vaccines. Language models, such as auto-regressive transformers, offer a powerful solution to this problem by learning the probability distributions of TCR repertoires, enabling the generation of new TCR sequences that inherit the underlying patterns of the repertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only transformer architecture, designed to uncover and replicate sequence patterns in TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring sequence probability distributions measured by Pearson correlation coefficient. Furthermore, by leveraging Reinforcement Learning(RL), we adapted the distribution of TCR sequences t",
    "link": "https://arxiv.org/abs/2408.01156",
    "context": "Title: TCR-GPT: Integrating Autoregressive Model and Reinforcement Learning for T-Cell Receptor Repertoires Generation\nAbstract: arXiv:2408.01156v1 Announce Type: cross  Abstract: T-cell receptors (TCRs) play a crucial role in the immune system by recognizing and binding to specific antigens presented by infected or cancerous cells. Understanding the sequence patterns of TCRs is essential for developing targeted immune therapies and designing effective vaccines. Language models, such as auto-regressive transformers, offer a powerful solution to this problem by learning the probability distributions of TCR repertoires, enabling the generation of new TCR sequences that inherit the underlying patterns of the repertoire. We introduce TCR-GPT, a probabilistic model built on a decoder-only transformer architecture, designed to uncover and replicate sequence patterns in TCR repertoires. TCR-GPT demonstrates an accuracy of 0.953 in inferring sequence probability distributions measured by Pearson correlation coefficient. Furthermore, by leveraging Reinforcement Learning(RL), we adapted the distribution of TCR sequences t",
    "path": "papers/24/08/2408.01156.json",
    "total_tokens": 782,
    "translated_title": "TCR-GPT: 结合自回归模型和强化学习的方法来生成T细胞受体库",
    "translated_abstract": "arXiv:2408.01156v1 公告类型：交叉 摘要：T细胞受体（TCRs）在免疫系统中发挥着重要作用，通过识别并结合由感染或癌性细胞呈现的特定抗原。了解TCR的序列模式对于开发针对免疫治疗的策略和设计有效的疫苗至关重要。语言模型，如自回归转换器，提供了一种强大的解决方案，通过学习TCR库的潜在概率分布，从而生成新的TCR序列，这些序列继承了库中潜在的序列模式。在本文中，我们提出了TCR-GPT，一个基于仅含解码器的Transformer结构的经济模型，旨在揭示和复制TCR库中的序列模式。TCR-GPT在通过皮尔森相关系数测量的概率分布推断精度方面表现出色，其精确度达到了0.953。此外，通过利用强化学习，我们已经调整了TCR序列的分布，以保证在人源化TCRs（Hu-TCRs）的序列生成中推广自回归模型的学习效果。强化学习使得TCR-GPT能够针对特定的序列空间设计出更适合的模型，提高了生成的TCR序列和实际Hu-TCRs之间的接近度，并且能够在多维特征空间中生成更多样化的序列。实验表明，使用强化学习的TCR-GPT模型在模拟实验和真实TCR数据集上的性能都得到了显著提升。",
    "tldr": "TCR-GPT模型通过使用自回归模型和强化学习结合的方法，提高了生成T细胞受体序列的准确性，并在人源化TCRs的序列生成中取得了良好的效果。",
    "en_tdlr": "TCR-GPT, a model integrating auto-regressive models with reinforcement learning, enhances the accuracy of generating T-cell receptor sequences and demonstrates effectiveness in producing humanized TCR sequences."
}