{
    "title": "TextIM: Part-aware Interactive Motion Synthesis from Text",
    "abstract": "arXiv:2408.03302v1 Announce Type: new  Abstract: In this work, we propose TextIM, a novel framework for synthesizing TEXT-driven human Interactive Motions, with a focus on the precise alignment of part-level semantics. Existing methods often overlook the critical roles of interactive body parts and fail to adequately capture and align part-level semantics, resulting in inaccuracies and even erroneous movement outcomes. To address these issues, TextIM utilizes a decoupled conditional diffusion framework to enhance the detailed alignment between interactive movements and corresponding semantic intents from textual descriptions. Our approach leverages large language models, functioning as a human brain, to identify interacting human body parts and to comprehend interaction semantics to generate complicated and subtle interactive motion. Guided by the refined movements of the interacting parts, TextIM further extends these movements into a coherent whole-body motion. We design a spatial co",
    "link": "https://arxiv.org/abs/2408.03302",
    "context": "Title: TextIM: Part-aware Interactive Motion Synthesis from Text\nAbstract: arXiv:2408.03302v1 Announce Type: new  Abstract: In this work, we propose TextIM, a novel framework for synthesizing TEXT-driven human Interactive Motions, with a focus on the precise alignment of part-level semantics. Existing methods often overlook the critical roles of interactive body parts and fail to adequately capture and align part-level semantics, resulting in inaccuracies and even erroneous movement outcomes. To address these issues, TextIM utilizes a decoupled conditional diffusion framework to enhance the detailed alignment between interactive movements and corresponding semantic intents from textual descriptions. Our approach leverages large language models, functioning as a human brain, to identify interacting human body parts and to comprehend interaction semantics to generate complicated and subtle interactive motion. Guided by the refined movements of the interacting parts, TextIM further extends these movements into a coherent whole-body motion. We design a spatial co",
    "path": "papers/24/08/2408.03302.json",
    "total_tokens": 314,
    "tldr": "该文章提出了一种名为TextIM的框架，该框架利用条件扩散模型和大型语言模型，能够精确地将文本描述中的交互身体部位和交互含义对齐，生成更加精确和自然的交互动作。"
}