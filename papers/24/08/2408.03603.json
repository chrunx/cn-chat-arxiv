{
    "title": "EnJa: Ensemble Jailbreak on Large Language Models",
    "abstract": "arXiv:2408.03603v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) are increasingly being deployed in safety-critical applications, their vulnerability to potential jailbreaks -- malicious prompts that can disable the safety mechanism of LLMs -- has attracted growing research attention. While alignment methods have been proposed to protect LLMs from jailbreaks, many have found that aligned LLMs can still be jailbroken by carefully crafted malicious prompts, producing content that violates policy regulations. Existing jailbreak attacks on LLMs can be categorized into prompt-level methods which make up stories/logic to circumvent safety alignment and token-level attack methods which leverage gradient methods to find adversarial tokens. In this work, we introduce the concept of Ensemble Jailbreak and explore methods that can integrate prompt-level and token-level jailbreak into a more powerful hybrid jailbreak attack. Specifically, we propose a novel EnJa attack to hide ha",
    "link": "https://arxiv.org/abs/2408.03603",
    "context": "Title: EnJa: Ensemble Jailbreak on Large Language Models\nAbstract: arXiv:2408.03603v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) are increasingly being deployed in safety-critical applications, their vulnerability to potential jailbreaks -- malicious prompts that can disable the safety mechanism of LLMs -- has attracted growing research attention. While alignment methods have been proposed to protect LLMs from jailbreaks, many have found that aligned LLMs can still be jailbroken by carefully crafted malicious prompts, producing content that violates policy regulations. Existing jailbreak attacks on LLMs can be categorized into prompt-level methods which make up stories/logic to circumvent safety alignment and token-level attack methods which leverage gradient methods to find adversarial tokens. In this work, we introduce the concept of Ensemble Jailbreak and explore methods that can integrate prompt-level and token-level jailbreak into a more powerful hybrid jailbreak attack. Specifically, we propose a novel EnJa attack to hide ha",
    "path": "papers/24/08/2408.03603.json",
    "total_tokens": 331,
    "tldr": "该文章提出了一个名为Ensemble Jailbreak的创新攻击方法，该方法结合了现有攻击中的故事/逻辑绕过和梯度精确攻击，旨在对大型语言模型实施更强大的混合攻击，从而绕过当前的安全机制。"
}