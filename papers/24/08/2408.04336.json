{
    "title": "KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination",
    "abstract": "arXiv:2408.04336v1 Announce Type: new  Abstract: Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI field, which aims to learn an agent to cooperate with an unseen partner in training environments or even novel environments. In recent years, a popular ZSC solution paradigm has been deep reinforcement learning (DRL) combined with advanced self-play or population-based methods to enhance the neural policy's ability to handle unseen partners. Despite some success, these approaches usually rely on black-box neural networks as the policy function. However, neural networks typically lack interpretability and logic, making the learned policies difficult for partners (e.g., humans) to understand and limiting their generalization ability. These shortcomings hinder the application of reinforcement learning methods in diverse cooperative scenarios.We suggest to represent the agent's policy with an interpretable program. Unlike neural networks, programs contain stable log",
    "link": "https://arxiv.org/abs/2408.04336",
    "context": "Title: KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination\nAbstract: arXiv:2408.04336v1 Announce Type: new  Abstract: Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI field, which aims to learn an agent to cooperate with an unseen partner in training environments or even novel environments. In recent years, a popular ZSC solution paradigm has been deep reinforcement learning (DRL) combined with advanced self-play or population-based methods to enhance the neural policy's ability to handle unseen partners. Despite some success, these approaches usually rely on black-box neural networks as the policy function. However, neural networks typically lack interpretability and logic, making the learned policies difficult for partners (e.g., humans) to understand and limiting their generalization ability. These shortcomings hinder the application of reinforcement learning methods in diverse cooperative scenarios.We suggest to represent the agent's policy with an interpretable program. Unlike neural networks, programs contain stable log",
    "path": "papers/24/08/2408.04336.json",
    "total_tokens": 337,
    "tldr": "该文章提出KnowPC（知识驱动的程序化强化学习）框架，它能够通过向程序注入领域知识来解决零样本合作问题，使得学习到的策略既可以形成明确的逻辑表示，又可以在新的环境和合作者面前表现出良好的泛化能力。"
}