{
    "title": "Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs",
    "abstract": "arXiv:2408.01355v2 Announce Type: replace  Abstract: Multi-modal Large Language Models (MLLMs) have demonstrated remarkable performance on various visual-language understanding and generation tasks. However, MLLMs occasionally generate content inconsistent with the given images, which is known as \"hallucination\". Prior works primarily center on evaluating hallucination using standard, unperturbed benchmarks, which overlook the prevalent occurrence of perturbed inputs in real-world scenarios-such as image cropping or blurring-that are critical for a comprehensive assessment of MLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI, the first benchmark designed to evaluate Hallucination in MLLMs within Perturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios, containing 1,260 perturbed images from 11 object types. Each image is accompanied by detailed annotations, which include fine-grained hallucination types, such as existence, attribute, and",
    "link": "https://arxiv.org/abs/2408.01355",
    "context": "Title: Hallu-PI: Evaluating Hallucination in Multi-modal Large Language Models within Perturbed Inputs\nAbstract: arXiv:2408.01355v2 Announce Type: replace  Abstract: Multi-modal Large Language Models (MLLMs) have demonstrated remarkable performance on various visual-language understanding and generation tasks. However, MLLMs occasionally generate content inconsistent with the given images, which is known as \"hallucination\". Prior works primarily center on evaluating hallucination using standard, unperturbed benchmarks, which overlook the prevalent occurrence of perturbed inputs in real-world scenarios-such as image cropping or blurring-that are critical for a comprehensive assessment of MLLMs' hallucination. In this paper, to bridge this gap, we propose Hallu-PI, the first benchmark designed to evaluate Hallucination in MLLMs within Perturbed Inputs. Specifically, Hallu-PI consists of seven perturbed scenarios, containing 1,260 perturbed images from 11 object types. Each image is accompanied by detailed annotations, which include fine-grained hallucination types, such as existence, attribute, and",
    "path": "papers/24/08/2408.01355.json",
    "total_tokens": 396,
    "tldr": "该文章提出了一个名为Hallu-PI的基准测试，用于评估多模态大型语言模型在人为图像扰动下的想象能力。这种方法考虑到了现实世界中常见的不一致情况，如图像裁剪或模糊，并且包括了7种不同的操纵情景，共1260张带有精细标注的图像，为评估这些模型在给定图像上的想象力提供了更全面的视角。"
}