{
    "title": "VLG-CBM: Training Concept Bottleneck Models with Vision-Language Guidance",
    "abstract": "arXiv:2408.01432v1 Announce Type: new  Abstract: Concept Bottleneck Models (CBMs) provide interpretable prediction by introducing an intermediate Concept Bottleneck Layer (CBL), which encodes human-understandable concepts to explain models' decision. Recent works proposed to utilize Large Language Models (LLMs) and pre-trained Vision-Language Models (VLMs) to automate the training of CBMs, making it more scalable and automated. However, existing approaches still fall short in two aspects: First, the concepts predicted by CBL often mismatch the input image, raising doubts about the faithfulness of interpretation. Second, it has been shown that concept values encode unintended information: even a set of random concepts could achieve comparable test accuracy to state-of-the-art CBMs. To address these critical limitations, in this work, we propose a novel framework called Vision-Language-Guided Concept Bottleneck Model (VLG-CBM) to enable faithful interpretability with the benefits of boos",
    "link": "https://arxiv.org/abs/2408.01432",
    "context": "Title: VLG-CBM: Training Concept Bottleneck Models with Vision-Language Guidance\nAbstract: arXiv:2408.01432v1 Announce Type: new  Abstract: Concept Bottleneck Models (CBMs) provide interpretable prediction by introducing an intermediate Concept Bottleneck Layer (CBL), which encodes human-understandable concepts to explain models' decision. Recent works proposed to utilize Large Language Models (LLMs) and pre-trained Vision-Language Models (VLMs) to automate the training of CBMs, making it more scalable and automated. However, existing approaches still fall short in two aspects: First, the concepts predicted by CBL often mismatch the input image, raising doubts about the faithfulness of interpretation. Second, it has been shown that concept values encode unintended information: even a set of random concepts could achieve comparable test accuracy to state-of-the-art CBMs. To address these critical limitations, in this work, we propose a novel framework called Vision-Language-Guided Concept Bottleneck Model (VLG-CBM) to enable faithful interpretability with the benefits of boos",
    "path": "papers/24/08/2408.01432.json",
    "total_tokens": 358,
    "tldr": "该文章提出的VLG-CBM框架通过结合视觉-语言指导，实现了CBM（概念瓶颈模型）的训练，解决了概念解释不准确和概念内含噪声的问题，从而提供了更加可信的图像解释。"
}