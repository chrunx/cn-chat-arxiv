{
    "title": "e-Health CSIRO at RRG24: Entropy-Augmented Self-Critical Sequence Training for Radiology Report Generation",
    "abstract": "arXiv:2408.03500v1 Announce Type: new  Abstract: The Shared Task on Large-Scale Radiology Report Generation (RRG24) aims to expedite the development of assistive systems for interpreting and reporting on chest X-ray (CXR) images. This task challenges participants to develop models that generate the findings and impression sections of radiology reports from CXRs from a patient's study, using five different datasets. This paper outlines the e-Health CSIRO team's approach, which achieved multiple first-place finishes in RRG24. The core novelty of our approach lies in the addition of entropy regularisation to self-critical sequence training, to maintain a higher entropy in the token distribution. This prevents overfitting to common phrases and ensures a broader exploration of the vocabulary during training, essential for handling the diversity of the radiology reports in the RRG24 datasets. Our model is available on Hugging Face https://huggingface.co/aehrc/cxrmate-rrg24.",
    "link": "https://arxiv.org/abs/2408.03500",
    "context": "Title: e-Health CSIRO at RRG24: Entropy-Augmented Self-Critical Sequence Training for Radiology Report Generation\nAbstract: arXiv:2408.03500v1 Announce Type: new  Abstract: The Shared Task on Large-Scale Radiology Report Generation (RRG24) aims to expedite the development of assistive systems for interpreting and reporting on chest X-ray (CXR) images. This task challenges participants to develop models that generate the findings and impression sections of radiology reports from CXRs from a patient's study, using five different datasets. This paper outlines the e-Health CSIRO team's approach, which achieved multiple first-place finishes in RRG24. The core novelty of our approach lies in the addition of entropy regularisation to self-critical sequence training, to maintain a higher entropy in the token distribution. This prevents overfitting to common phrases and ensures a broader exploration of the vocabulary during training, essential for handling the diversity of the radiology reports in the RRG24 datasets. Our model is available on Hugging Face https://huggingface.co/aehrc/cxrmate-rrg24.",
    "path": "papers/24/08/2408.03500.json",
    "total_tokens": 413,
    "tldr": "该文章描述了一种名为e-Health CSIRO的团队在Radiology Report Generation 24 (RRG24)共享任务中取得多个第一名的方法，该方法通过在self-critical sequence training中添加entropy regularization来增强模型的表现，以保持 token 分布的更高熵。这种创新方法有助于模型探索报告多样性的广泛词汇，从而有效应对RRG24数据集中报告的多样性。"
}