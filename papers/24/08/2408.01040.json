{
    "title": "Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix",
    "abstract": "arXiv:2408.01040v1 Announce Type: cross  Abstract: In computer vision, the vision transformer (ViT) has increasingly superseded the convolutional neural network (CNN) for improved accuracy and robustness. However, ViT's large model sizes and high sample complexity make it difficult to train on resource-constrained edge devices. Split learning (SL) emerges as a viable solution, leveraging server-side resources to train ViTs while utilizing private data from distributed devices. However, SL requires additional information exchange for weight updates between the device and the server, which can be exposed to various attacks on private training data. To mitigate the risk of data breaches in classification tasks, inspired from the CutMix regularization, we propose a novel privacy-preserving SL framework that injects Gaussian noise into smashed data and mixes randomly chosen patches of smashed data across clients, coined DP-CutMixSL. Our analysis demonstrates that DP-CutMixSL is a differenti",
    "link": "https://arxiv.org/abs/2408.01040",
    "context": "Title: Privacy-Preserving Split Learning with Vision Transformers using Patch-Wise Random and Noisy CutMix\nAbstract: arXiv:2408.01040v1 Announce Type: cross  Abstract: In computer vision, the vision transformer (ViT) has increasingly superseded the convolutional neural network (CNN) for improved accuracy and robustness. However, ViT's large model sizes and high sample complexity make it difficult to train on resource-constrained edge devices. Split learning (SL) emerges as a viable solution, leveraging server-side resources to train ViTs while utilizing private data from distributed devices. However, SL requires additional information exchange for weight updates between the device and the server, which can be exposed to various attacks on private training data. To mitigate the risk of data breaches in classification tasks, inspired from the CutMix regularization, we propose a novel privacy-preserving SL framework that injects Gaussian noise into smashed data and mixes randomly chosen patches of smashed data across clients, coined DP-CutMixSL. Our analysis demonstrates that DP-CutMixSL is a differenti",
    "path": "papers/24/08/2408.01040.json",
    "total_tokens": 652,
    "translated_title": "使用随机和噪杂切混分式 vision transformers 的隐私保护分成学习",
    "translated_abstract": "arXiv:2408.01040v1 公告类型: 交叉 摘要：在计算机视觉领域，vision transformer（ViT）由于其提高的准确性和鲁棒性逐渐超过了卷积神经网络（CNN）。然而，ViT的大模型尺寸和高样本复杂度使得在资源受限的边缘设备上训练变得困难。分成学习（SL）作为一种可行的解决方案，利用服务器端的资源来训练ViT，同时利用分布在设备上的私有数据。然而，SL在设备与服务器之间进行权重更新时需要额外的信息交换，这可能会暴露于各种训练数据隐私攻击中。为了在分类任务中减少数据泄露的风险，受CutMix正则化的启发，我们提出了一个全新的隐私保护SL框架，它向颠簸数据中注入高斯噪声，并在客户端的随机选择的颠簸数据块之间进行混合，被称为DP-CutMixSL。我们的分析显示，DP-CutMixSL是一种不同的方法，可以提高训练数据的隐私保护水平，同时保持分类任务的准确性。",
    "tldr": "本文提出了一种全新的隐私保护分成学习框架，通过在随机选择的颠簸数据块之间进行高斯噪声混合，提高了训练数据的隐私保护水平，同时保持了分类任务的准确性。"
}