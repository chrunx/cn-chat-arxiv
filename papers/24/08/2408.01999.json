{
    "title": "Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response",
    "abstract": "arXiv:2408.01999v1 Announce Type: cross  Abstract: This research focused on enhancing post-incident malware forensic investigation using reinforcement learning RL. We proposed an advanced MDP post incident malware forensics investigation model and framework to expedite post incident forensics. We then implement our RL Malware Investigation Model based on structured MDP within the proposed framework. To identify malware artefacts, the RL agent acquires and examines forensics evidence files, iteratively improving its capabilities using Q Table and temporal difference learning. The Q learning algorithm significantly improved the agent ability to identify malware. An epsilon greedy exploration strategy and Q learning updates enabled efficient learning and decision making. Our experimental testing revealed that optimal learning rates depend on the MDP environment complexity, with simpler environments benefiting from higher rates for quicker convergence and complex ones requiring lower rates",
    "link": "https://arxiv.org/abs/2408.01999",
    "context": "Title: Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response\nAbstract: arXiv:2408.01999v1 Announce Type: cross  Abstract: This research focused on enhancing post-incident malware forensic investigation using reinforcement learning RL. We proposed an advanced MDP post incident malware forensics investigation model and framework to expedite post incident forensics. We then implement our RL Malware Investigation Model based on structured MDP within the proposed framework. To identify malware artefacts, the RL agent acquires and examines forensics evidence files, iteratively improving its capabilities using Q Table and temporal difference learning. The Q learning algorithm significantly improved the agent ability to identify malware. An epsilon greedy exploration strategy and Q learning updates enabled efficient learning and decision making. Our experimental testing revealed that optimal learning rates depend on the MDP environment complexity, with simpler environments benefiting from higher rates for quicker convergence and complex ones requiring lower rates",
    "path": "papers/24/08/2408.01999.json",
    "total_tokens": 371,
    "tldr": "该文章提出了一种基于强化学习的先进模型和框架，用于在网络攻击后快速有效地进行恶意软件调查。研究人员通过在结构化马尔可夫决策过程（MDP）中实现其提出的强化学习恶意软件调查模型，并使用Q表格和时间差学习迭代地改进其能力。通过实验测试，结果显示，学习率的选择取决于环境的复杂性，环境越简单，学习率越高，收敛速度越快，而复杂环境则需要更低的学习率以实现高效的学习和决策。"
}