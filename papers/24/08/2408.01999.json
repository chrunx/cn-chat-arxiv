{
    "title": "Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response",
    "abstract": "arXiv:2408.01999v1 Announce Type: cross  Abstract: This research focused on enhancing post-incident malware forensic investigation using reinforcement learning RL. We proposed an advanced MDP post incident malware forensics investigation model and framework to expedite post incident forensics. We then implement our RL Malware Investigation Model based on structured MDP within the proposed framework. To identify malware artefacts, the RL agent acquires and examines forensics evidence files, iteratively improving its capabilities using Q Table and temporal difference learning. The Q learning algorithm significantly improved the agent ability to identify malware. An epsilon greedy exploration strategy and Q learning updates enabled efficient learning and decision making. Our experimental testing revealed that optimal learning rates depend on the MDP environment complexity, with simpler environments benefiting from higher rates for quicker convergence and complex ones requiring lower rates",
    "link": "https://arxiv.org/abs/2408.01999",
    "context": "Title: Reinforcement Learning for an Efficient and Effective Malware Investigation during Cyber Incident Response\nAbstract: arXiv:2408.01999v1 Announce Type: cross  Abstract: This research focused on enhancing post-incident malware forensic investigation using reinforcement learning RL. We proposed an advanced MDP post incident malware forensics investigation model and framework to expedite post incident forensics. We then implement our RL Malware Investigation Model based on structured MDP within the proposed framework. To identify malware artefacts, the RL agent acquires and examines forensics evidence files, iteratively improving its capabilities using Q Table and temporal difference learning. The Q learning algorithm significantly improved the agent ability to identify malware. An epsilon greedy exploration strategy and Q learning updates enabled efficient learning and decision making. Our experimental testing revealed that optimal learning rates depend on the MDP environment complexity, with simpler environments benefiting from higher rates for quicker convergence and complex ones requiring lower rates",
    "path": "papers/24/08/2408.01999.json",
    "total_tokens": 351,
    "tldr": "该文章提出了一种基于强化学习的方法，用于在网络安全事件响应期间提高恶意软件调查的效率和效果。通过构建一种先进的马尔可夫决策过程（MDP）模型和框架，研究者开发了一个能够通过迭代学习改进查证能力的恶意软件调查代理。这种代理能够利用Q表格和广义递推学习算法来识别和分析取证文件，以便更高效地找到恶意软件痕迹。"
}