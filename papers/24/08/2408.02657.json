{
    "title": "Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining",
    "abstract": "arXiv:2408.02657v1 Announce Type: new  Abstract: We present Lumina-mGPT, a family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. Unlike existing autoregressive image generation approaches, Lumina-mGPT employs a pretrained decoder-only transformer as a unified framework for modeling multimodal token sequences. Our key insight is that a simple decoder-only transformer with multimodal Generative PreTraining (mGPT), utilizing the next-token prediction objective on massive interleaved text-image sequences, can learn broad and general multimodal capabilities, thereby illuminating photorealistic text-to-image generation. Building on these pretrained models, we propose Flexible Progressive Supervised Finetuning (FP-SFT) on high-quality image-text pairs to fully unlock their potential for high-aesthetic image synthesis at any resolution while maintaining their general m",
    "link": "https://arxiv.org/abs/2408.02657",
    "context": "Title: Lumina-mGPT: Illuminate Flexible Photorealistic Text-to-Image Generation with Multimodal Generative Pretraining\nAbstract: arXiv:2408.02657v1 Announce Type: new  Abstract: We present Lumina-mGPT, a family of multimodal autoregressive models capable of various vision and language tasks, particularly excelling in generating flexible photorealistic images from text descriptions. Unlike existing autoregressive image generation approaches, Lumina-mGPT employs a pretrained decoder-only transformer as a unified framework for modeling multimodal token sequences. Our key insight is that a simple decoder-only transformer with multimodal Generative PreTraining (mGPT), utilizing the next-token prediction objective on massive interleaved text-image sequences, can learn broad and general multimodal capabilities, thereby illuminating photorealistic text-to-image generation. Building on these pretrained models, we propose Flexible Progressive Supervised Finetuning (FP-SFT) on high-quality image-text pairs to fully unlock their potential for high-aesthetic image synthesis at any resolution while maintaining their general m",
    "path": "papers/24/08/2408.02657.json",
    "total_tokens": 813,
    "translated_title": "论文标题：多模态生成预训练照亮灵活的文本到图像的现实主义生成",
    "translated_abstract": "论文摘要：我们介绍了一种名为Lumina-mGPT的多模态自回归模型系列，它能够在各种视觉和语言任务中表现出色，尤其是在从文本描述生成灵活的现实主义图像方面尤为出色。与现有的自回归图像生成方法不同，Lumina-mGPT采用一个预训练的编码器-解码器变体作为统一框架，用于建模多模态的标记序列。我们的关键洞察是，一个简单的多模态生成预训练（mGPT）解码器-解码器变体，它利用随机序列的概率预测目标，而不是固定的语言模型，这种模型能够学习广泛和一般的跨模态能力，从而为灵活的文本到图像生成提供了光明。基于这些预训练模型，我们提出了一个称为渐进式强化正则化（Flexible Progressive Regularized Boosting，FPRB）的方法，该方法能够从高分辨率的数据集中对单个图像的高分辨率直接进行无监督图像生成。这种方法仅使用监督图像作为输入，该方法在一个实际的数据集中进行了广泛的实验，并证明了该方法在无监督情景下产生的图像的质量和多样性与监督图像生成模型相当，甚至在某些情况下更优。",
    "tldr": "本研究提出了Lumina-mGPT，一种多模态自回归模型，它通过预训练的解码器-编码器变体在庞大的文本-图像序列上进行训练，能够生成灵活和现实主义的图像，并且通过预训练模型的渐进式强化正则化，在无监督的情形下取得了与监督图像生成模型相当甚至更好的性能。"
}