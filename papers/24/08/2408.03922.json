{
    "title": "FMiFood: Multi-modal Contrastive Learning for Food Image Classification",
    "abstract": "arXiv:2408.03922v1 Announce Type: new  Abstract: Food image classification is the fundamental step in image-based dietary assessment, which aims to estimate participants' nutrient intake from eating occasion images. A common challenge of food images is the intra-class diversity and inter-class similarity, which can significantly hinder classification performance. To address this issue, we introduce a novel multi-modal contrastive learning framework called FMiFood, which learns more discriminative features by integrating additional contextual information, such as food category text descriptions, to enhance classification accuracy. Specifically, we propose a flexible matching technique that improves the similarity matching between text and image embeddings to focus on multiple key information. Furthermore, we incorporate the classification objectives into the framework and explore the use of GPT-4 to enrich the text descriptions and provide more detailed context. Our method demonstrates ",
    "link": "https://arxiv.org/abs/2408.03922",
    "context": "Title: FMiFood: Multi-modal Contrastive Learning for Food Image Classification\nAbstract: arXiv:2408.03922v1 Announce Type: new  Abstract: Food image classification is the fundamental step in image-based dietary assessment, which aims to estimate participants' nutrient intake from eating occasion images. A common challenge of food images is the intra-class diversity and inter-class similarity, which can significantly hinder classification performance. To address this issue, we introduce a novel multi-modal contrastive learning framework called FMiFood, which learns more discriminative features by integrating additional contextual information, such as food category text descriptions, to enhance classification accuracy. Specifically, we propose a flexible matching technique that improves the similarity matching between text and image embeddings to focus on multiple key information. Furthermore, we incorporate the classification objectives into the framework and explore the use of GPT-4 to enrich the text descriptions and provide more detailed context. Our method demonstrates ",
    "path": "papers/24/08/2408.03922.json",
    "total_tokens": 302,
    "tldr": "该文章提出了一种名为FMiFood的全新多模态对比学习框架，该框架通过结合额外的文本描述等环境信息，有效提高了食物图像分类的准确率。"
}