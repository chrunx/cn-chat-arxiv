{
    "title": "Supervised Image Translation from Visible to Infrared Domain for Object Detection",
    "abstract": "arXiv:2408.01843v1 Announce Type: new  Abstract: This study aims to learn a translation from visible to infrared imagery, bridging the domain gap between the two modalities so as to improve accuracy on downstream tasks including object detection. Previous approaches attempt to perform bi-domain feature fusion through iterative optimization or end-to-end deep convolutional networks. However, we pose the problem as similar to that of image translation, adopting a two-stage training strategy with a Generative Adversarial Network and an object detection model. The translation model learns a conversion that preserves the structural detail of visible images while preserving the texture and other characteristics of infrared images. Images so generated are used to train standard object detection frameworks including Yolov5, Mask and Faster RCNN. We also investigate the usefulness of integrating a super-resolution step into our pipeline to further improve model accuracy, and achieve an improvem",
    "link": "https://arxiv.org/abs/2408.01843",
    "context": "Title: Supervised Image Translation from Visible to Infrared Domain for Object Detection\nAbstract: arXiv:2408.01843v1 Announce Type: new  Abstract: This study aims to learn a translation from visible to infrared imagery, bridging the domain gap between the two modalities so as to improve accuracy on downstream tasks including object detection. Previous approaches attempt to perform bi-domain feature fusion through iterative optimization or end-to-end deep convolutional networks. However, we pose the problem as similar to that of image translation, adopting a two-stage training strategy with a Generative Adversarial Network and an object detection model. The translation model learns a conversion that preserves the structural detail of visible images while preserving the texture and other characteristics of infrared images. Images so generated are used to train standard object detection frameworks including Yolov5, Mask and Faster RCNN. We also investigate the usefulness of integrating a super-resolution step into our pipeline to further improve model accuracy, and achieve an improvem",
    "path": "papers/24/08/2408.01843.json",
    "total_tokens": 351,
    "tldr": "该文章提出了一种监督式的可见光到红外图像的翻译方法，旨在通过两阶段的训练策略，结合生成对抗网络和对象检测模型，缓解可见光与红外图像之间的域差距，提高了包括对象检测在内的下游任务的准确性。此外，文章还探讨了在翻译过程中集成超分辨率步骤以进一步增强模型精度的可能性，并达到了改进的目标。"
}