{
    "title": "SceneMotion: From Agent-Centric Embeddings to Scene-Wide Forecasts",
    "abstract": "arXiv:2408.01537v1 Announce Type: cross  Abstract: Self-driving vehicles rely on multimodal motion forecasts to effectively interact with their environment and plan safe maneuvers. We introduce SceneMotion, an attention-based model for forecasting scene-wide motion modes of multiple traffic agents. Our model transforms local agent-centric embeddings into scene-wide forecasts using a novel latent context module. This module learns a scene-wide latent space from multiple agent-centric embeddings, enabling joint forecasting and interaction modeling. The competitive performance in the Waymo Open Interaction Prediction Challenge demonstrates the effectiveness of our approach. Moreover, we cluster future waypoints in time and space to quantify the interaction between agents. We merge all modes and analyze each mode independently to determine which clusters are resolved through interaction or result in conflict. Our implementation is available at: https://github.com/kit-mrt/future-motion",
    "link": "https://arxiv.org/abs/2408.01537",
    "context": "Title: SceneMotion: From Agent-Centric Embeddings to Scene-Wide Forecasts\nAbstract: arXiv:2408.01537v1 Announce Type: cross  Abstract: Self-driving vehicles rely on multimodal motion forecasts to effectively interact with their environment and plan safe maneuvers. We introduce SceneMotion, an attention-based model for forecasting scene-wide motion modes of multiple traffic agents. Our model transforms local agent-centric embeddings into scene-wide forecasts using a novel latent context module. This module learns a scene-wide latent space from multiple agent-centric embeddings, enabling joint forecasting and interaction modeling. The competitive performance in the Waymo Open Interaction Prediction Challenge demonstrates the effectiveness of our approach. Moreover, we cluster future waypoints in time and space to quantify the interaction between agents. We merge all modes and analyze each mode independently to determine which clusters are resolved through interaction or result in conflict. Our implementation is available at: https://github.com/kit-mrt/future-motion",
    "path": "papers/24/08/2408.01537.json",
    "total_tokens": 644,
    "translated_title": "SceneMotion: 从Agent-Centric嵌入到场景级预测",
    "translated_abstract": "arXiv:2408.01537v1 公告类型: cross",
    "tldr": "SceneMotion模型通过使用一个新的潜在上下文模块将局部agent-centric嵌入转换为全景级预测，在Waymo Open Interaction Prediction Challenge中表现出色。",
    "en_tdlr": "SceneMotion, a model based on attention, effectively forecasts scene-wide motion modes of multiple traffic agents, showcasing competitive performance in the Waymo Open Interaction Prediction Challenge."
}