{
    "title": "NAVINACT: Combining Navigation and Imitation Learning for Bootstrapping Reinforcement Learning",
    "abstract": "arXiv:2408.04054v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has shown remarkable progress in simulation environments, yet its application to real-world robotic tasks remains limited due to challenges in exploration and generalisation. To address these issues, we introduce NAVINACT, a framework that chooses when the robot should use classical motion planning-based navigation and when it should learn a policy. To further improve the efficiency in exploration, we use imitation data to bootstrap the exploration. NAVINACT dynamically switches between two modes of operation: navigating to a waypoint using classical techniques when away from the objects and reinforcement learning for fine-grained manipulation control when about to interact with objects. NAVINACT consists of a multi-head architecture composed of ModeNet for mode classification, NavNet for waypoint prediction, and InteractNet for precise manipulation. By combining the strengths of RL and Imitation Learning (IL)",
    "link": "https://arxiv.org/abs/2408.04054",
    "context": "Title: NAVINACT: Combining Navigation and Imitation Learning for Bootstrapping Reinforcement Learning\nAbstract: arXiv:2408.04054v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has shown remarkable progress in simulation environments, yet its application to real-world robotic tasks remains limited due to challenges in exploration and generalisation. To address these issues, we introduce NAVINACT, a framework that chooses when the robot should use classical motion planning-based navigation and when it should learn a policy. To further improve the efficiency in exploration, we use imitation data to bootstrap the exploration. NAVINACT dynamically switches between two modes of operation: navigating to a waypoint using classical techniques when away from the objects and reinforcement learning for fine-grained manipulation control when about to interact with objects. NAVINACT consists of a multi-head architecture composed of ModeNet for mode classification, NavNet for waypoint prediction, and InteractNet for precise manipulation. By combining the strengths of RL and Imitation Learning (IL)",
    "path": "papers/24/08/2408.04054.json",
    "total_tokens": 361,
    "tldr": "该文章的创新贡献在于提出NAVINACT框架，该框架能够自动选择何时使用经典导航方法进行探索，何时利用模仿学习从特定数据集中进行强化学习，以提高探索效率。这种动态切换的模式解决了在真实世界中应用强化学习时面临的探索和泛化难题，对于提高机器人任务执行能力具有重要意义。"
}