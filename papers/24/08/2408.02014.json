{
    "title": "Unsupervised Representation Learning by Balanced Self Attention Matching",
    "abstract": "arXiv:2408.02014v1 Announce Type: new  Abstract: Many leading self-supervised methods for unsupervised representation learning, in particular those for embedding image features, are built on variants of the instance discrimination task, whose optimization is known to be prone to instabilities that can lead to feature collapse. Different techniques have been devised to circumvent this issue, including the use of negative pairs with different contrastive losses, the use of external memory banks, and breaking of symmetry by using separate encoding networks with possibly different structures. Our method, termed BAM, rather than directly matching features of different views (augmentations) of input images, is based on matching their self-attention vectors, which are the distributions of similarities to the entire set of augmented images of a batch. We obtain rich representations and avoid feature collapse by minimizing a loss that matches these distributions to their globally balanced and e",
    "link": "https://arxiv.org/abs/2408.02014",
    "context": "Title: Unsupervised Representation Learning by Balanced Self Attention Matching\nAbstract: arXiv:2408.02014v1 Announce Type: new  Abstract: Many leading self-supervised methods for unsupervised representation learning, in particular those for embedding image features, are built on variants of the instance discrimination task, whose optimization is known to be prone to instabilities that can lead to feature collapse. Different techniques have been devised to circumvent this issue, including the use of negative pairs with different contrastive losses, the use of external memory banks, and breaking of symmetry by using separate encoding networks with possibly different structures. Our method, termed BAM, rather than directly matching features of different views (augmentations) of input images, is based on matching their self-attention vectors, which are the distributions of similarities to the entire set of augmented images of a batch. We obtain rich representations and avoid feature collapse by minimizing a loss that matches these distributions to their globally balanced and e",
    "path": "papers/24/08/2408.02014.json",
    "total_tokens": 303,
    "tldr": "该文章提出了一种基于平衡自注意力匹配的无监督表示学习方法，有效避免了特征坍缩问题，并为图像特征的无监督学习提供了一种新的途径。"
}