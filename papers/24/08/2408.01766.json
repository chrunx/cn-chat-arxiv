{
    "title": "MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action Recognition",
    "abstract": "arXiv:2408.01766v1 Announce Type: new  Abstract: Driver action recognition, aiming to accurately identify drivers' behaviours, is crucial for enhancing driver-vehicle interactions and ensuring driving safety. Unlike general action recognition, drivers' environments are often challenging, being gloomy and dark, and with the development of sensors, various cameras such as IR and depth cameras have emerged for analyzing drivers' behaviors. Therefore, in this paper, we propose a novel multimodal fusion transformer, named MultiFuser, which identifies cross-modal interrelations and interactions among multimodal car cabin videos and adaptively integrates different modalities for improved representations. Specifically, MultiFuser comprises layers of Bi-decomposed Modules to model spatiotemporal features, with a modality synthesizer for multimodal features integration. Each Bi-decomposed Module includes a Modal Expertise ViT block for extracting modality-specific features and a Patch-wise Adapt",
    "link": "https://arxiv.org/abs/2408.01766",
    "context": "Title: MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action Recognition\nAbstract: arXiv:2408.01766v1 Announce Type: new  Abstract: Driver action recognition, aiming to accurately identify drivers' behaviours, is crucial for enhancing driver-vehicle interactions and ensuring driving safety. Unlike general action recognition, drivers' environments are often challenging, being gloomy and dark, and with the development of sensors, various cameras such as IR and depth cameras have emerged for analyzing drivers' behaviors. Therefore, in this paper, we propose a novel multimodal fusion transformer, named MultiFuser, which identifies cross-modal interrelations and interactions among multimodal car cabin videos and adaptively integrates different modalities for improved representations. Specifically, MultiFuser comprises layers of Bi-decomposed Modules to model spatiotemporal features, with a modality synthesizer for multimodal features integration. Each Bi-decomposed Module includes a Modal Expertise ViT block for extracting modality-specific features and a Patch-wise Adapt",
    "path": "papers/24/08/2408.01766.json",
    "total_tokens": 604,
    "translated_title": "MultiFuser: 多模态融合变换器用于增强驾驶员行为识别",
    "translated_abstract": "驾驶员行为识别对于提高驾驶员与车辆之间的互动和安全驾驶至关重要。与一般的动作识别不同，驾驶员的环境往往很困难，光线昏暗，随着传感器的发展，各种摄像头，如红外和深度摄像头，被用于分析驾驶员的行为。因此，在这篇论文中，我们提出了一个新颖的多模态融合变换器，名为MultiFuser，它能够识别不同模态之间的相互关系和相互作用，并在驾驶员车厢视频中集成多种模态，从而得到改进的表示。具体来说，MultiFuser包括分层的事件分解模块来建模时空特征，以及一种模态合成器用于集成多模态特征。每个事件分解模块包括一个用于提取特定于模态的特征模块和一个基于图块的适应模块。",
    "tldr": "MultiFuser是一个多模态融合变换器，用于增强驾驶员行为识别，通过事件分解模块和模态合成器集成多种摄像头数据来提升表示力。"
}