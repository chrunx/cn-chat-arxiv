{
    "title": "MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action Recognition",
    "abstract": "arXiv:2408.01766v1 Announce Type: new  Abstract: Driver action recognition, aiming to accurately identify drivers' behaviours, is crucial for enhancing driver-vehicle interactions and ensuring driving safety. Unlike general action recognition, drivers' environments are often challenging, being gloomy and dark, and with the development of sensors, various cameras such as IR and depth cameras have emerged for analyzing drivers' behaviors. Therefore, in this paper, we propose a novel multimodal fusion transformer, named MultiFuser, which identifies cross-modal interrelations and interactions among multimodal car cabin videos and adaptively integrates different modalities for improved representations. Specifically, MultiFuser comprises layers of Bi-decomposed Modules to model spatiotemporal features, with a modality synthesizer for multimodal features integration. Each Bi-decomposed Module includes a Modal Expertise ViT block for extracting modality-specific features and a Patch-wise Adapt",
    "link": "https://arxiv.org/abs/2408.01766",
    "context": "Title: MultiFuser: Multimodal Fusion Transformer for Enhanced Driver Action Recognition\nAbstract: arXiv:2408.01766v1 Announce Type: new  Abstract: Driver action recognition, aiming to accurately identify drivers' behaviours, is crucial for enhancing driver-vehicle interactions and ensuring driving safety. Unlike general action recognition, drivers' environments are often challenging, being gloomy and dark, and with the development of sensors, various cameras such as IR and depth cameras have emerged for analyzing drivers' behaviors. Therefore, in this paper, we propose a novel multimodal fusion transformer, named MultiFuser, which identifies cross-modal interrelations and interactions among multimodal car cabin videos and adaptively integrates different modalities for improved representations. Specifically, MultiFuser comprises layers of Bi-decomposed Modules to model spatiotemporal features, with a modality synthesizer for multimodal features integration. Each Bi-decomposed Module includes a Modal Expertise ViT block for extracting modality-specific features and a Patch-wise Adapt",
    "path": "papers/24/08/2408.01766.json",
    "total_tokens": 331,
    "tldr": "该文章提出了一种名为MultiFuser的全新多模态融合Transformer模型，该模型能够识别和利用多模态车内视频中的交互关系，并通过自适应的多模态特征融合提高了驾驶员行为识别的准确性。"
}