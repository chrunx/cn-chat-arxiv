{
    "title": "GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS",
    "abstract": "arXiv:2408.01584v1 Announce Type: new  Abstract: Multi-agent learning algorithms have been successful at generating superhuman planning in a wide variety of games but have had little impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at this scale, we present GPUDrive, a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine that can generate over a million steps of experience per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. We show that using GPUDrive we are able to effectively train reinforcement learning agents over many scenes in the Waymo Motion dataset, yielding highly effective goal-reaching agents in minutes for individual scenes and generally c",
    "link": "https://arxiv.org/abs/2408.01584",
    "context": "Title: GPUDrive: Data-driven, multi-agent driving simulation at 1 million FPS\nAbstract: arXiv:2408.01584v1 Announce Type: new  Abstract: Multi-agent learning algorithms have been successful at generating superhuman planning in a wide variety of games but have had little impact on the design of deployed multi-agent planners. A key bottleneck in applying these techniques to multi-agent planning is that they require billions of steps of experience. To enable the study of multi-agent planning at this scale, we present GPUDrive, a GPU-accelerated, multi-agent simulator built on top of the Madrona Game Engine that can generate over a million steps of experience per second. Observation, reward, and dynamics functions are written directly in C++, allowing users to define complex, heterogeneous agent behaviors that are lowered to high-performance CUDA. We show that using GPUDrive we are able to effectively train reinforcement learning agents over many scenes in the Waymo Motion dataset, yielding highly effective goal-reaching agents in minutes for individual scenes and generally c",
    "path": "papers/24/08/2408.01584.json",
    "total_tokens": 400,
    "tldr": "该文章介绍了GPUDrive，一款基于Madrona Game Engine的GPU加速多agent模拟器，每秒可以生成超过一百万步的经验。通过直接在C++中编写观察、奖励和动态函数，用户可以定义复杂的异构agent行为，并将其优化为高效率的CUDA。通过这种方式，文章证明了GPUDrive能够有效地在Waymo Motion数据集上训练强化学习agent，仅需数分钟即可在单个场景中产生有效目标寻求agent，并且在一般情况下达到更高的训练效率。"
}