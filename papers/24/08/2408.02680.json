{
    "title": "Recording First-person Experiences to Build a New Type of Foundation Model",
    "abstract": "arXiv:2408.02680v1 Announce Type: new  Abstract: Foundation models have had a big impact in recent years and billions of dollars are being invested in them in the current AI boom. The more popular ones, such as Chat-GPT, are trained on large amounts of Internet data. However, it is becoming apparent that this data is likely to be exhausted soon, and technology companies are looking for new sources of data to train the next generation of foundation models.   Reinforcement learning, RAG, prompt engineering and cognitive modelling are often used to fine-tune and augment the behaviour of foundation models. These techniques have been used to replicate people, such as Caryn Marjorie. These chatbots are not based on people's actual emotional and physiological responses to their environment, so they are, at best, a surface-level approximation to the characters they are imitating.   To address these issues, we have developed a recording rig that captures what the wearer is seeing and hearing as",
    "link": "https://arxiv.org/abs/2408.02680",
    "context": "Title: Recording First-person Experiences to Build a New Type of Foundation Model\nAbstract: arXiv:2408.02680v1 Announce Type: new  Abstract: Foundation models have had a big impact in recent years and billions of dollars are being invested in them in the current AI boom. The more popular ones, such as Chat-GPT, are trained on large amounts of Internet data. However, it is becoming apparent that this data is likely to be exhausted soon, and technology companies are looking for new sources of data to train the next generation of foundation models.   Reinforcement learning, RAG, prompt engineering and cognitive modelling are often used to fine-tune and augment the behaviour of foundation models. These techniques have been used to replicate people, such as Caryn Marjorie. These chatbots are not based on people's actual emotional and physiological responses to their environment, so they are, at best, a surface-level approximation to the characters they are imitating.   To address these issues, we have developed a recording rig that captures what the wearer is seeing and hearing as",
    "path": "papers/24/08/2408.02680.json",
    "total_tokens": 354,
    "tldr": "该文章介绍了如何使用一个专门设计的录音装置来记录佩戴者的视觉和听觉体验，并用于构建新型的基础模型。通过这种方法，可以创建出更接近真实人物情感和生理反应的基础模型，从而提高AI技术的逼真度和自然交互能力。"
}