{
    "title": "Task-oriented Sequential Grounding in 3D Scenes",
    "abstract": "arXiv:2408.04034v1 Announce Type: new  Abstract: Grounding natural language in physical 3D environments is essential for the advancement of embodied artificial intelligence. Current datasets and models for 3D visual grounding predominantly focus on identifying and localizing objects from static, object-centric descriptions. These approaches do not adequately address the dynamic and sequential nature of task-oriented grounding necessary for practical applications. In this work, we propose a new task: Task-oriented Sequential Grounding in 3D scenes, wherein an agent must follow detailed step-by-step instructions to complete daily activities by locating a sequence of target objects in indoor scenes. To facilitate this task, we introduce SG3D, a large-scale dataset containing 22,346 tasks with 112,236 steps across 4,895 real-world 3D scenes. The dataset is constructed using a combination of RGB-D scans from various 3D scene datasets and an automated task generation pipeline, followed by hu",
    "link": "https://arxiv.org/abs/2408.04034",
    "context": "Title: Task-oriented Sequential Grounding in 3D Scenes\nAbstract: arXiv:2408.04034v1 Announce Type: new  Abstract: Grounding natural language in physical 3D environments is essential for the advancement of embodied artificial intelligence. Current datasets and models for 3D visual grounding predominantly focus on identifying and localizing objects from static, object-centric descriptions. These approaches do not adequately address the dynamic and sequential nature of task-oriented grounding necessary for practical applications. In this work, we propose a new task: Task-oriented Sequential Grounding in 3D scenes, wherein an agent must follow detailed step-by-step instructions to complete daily activities by locating a sequence of target objects in indoor scenes. To facilitate this task, we introduce SG3D, a large-scale dataset containing 22,346 tasks with 112,236 steps across 4,895 real-world 3D scenes. The dataset is constructed using a combination of RGB-D scans from various 3D scene datasets and an automated task generation pipeline, followed by hu",
    "path": "papers/24/08/2408.04034.json",
    "total_tokens": 430,
    "tldr": "该文章提出了一种新的任务——在3D场景中进行任务导向的顺序定位，其中代理必须遵循详细的逐步指示，在室内场景中找到一系列目标对象以完成日常活动。文章还介绍了SG3D，一个包含22346个任务、112236个步骤的大型数据集，这些任务分布在4895个真实世界3D场景中。该数据集通过结合来自各种3D场景的数据集的RGB-D扫描和自动化任务生成管道以及人工验证，为3D视觉定位的真实和动态需求提供了进一步研究的基础。"
}