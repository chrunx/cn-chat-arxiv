{
    "title": "Balanced Residual Distillation Learning for 3D Point Cloud Class-Incremental Semantic Segmentation",
    "abstract": "arXiv:2408.01356v1 Announce Type: new  Abstract: Class-incremental learning (CIL) thrives due to its success in processing the influx of information by learning from continuously added new classes while preventing catastrophic forgetting about the old ones. It is essential for the performance breakthrough of CIL to effectively refine past knowledge from the base model and balance it with new learning. However, such an issue has not yet been considered in current research. In this work, we explore the potential of CIL from these perspectives and propose a novel balanced residual distillation framework (BRD-CIL) to push the performance bar of CIL to a new higher level. Specifically, BRD-CIL designs a residual distillation learning strategy, which can dynamically expand the network structure to capture the residuals between the base and target models, effectively refining the past knowledge. Furthermore, BRD-CIL designs a balanced pseudo-label learning strategy by generating a guidance ma",
    "link": "https://arxiv.org/abs/2408.01356",
    "context": "Title: Balanced Residual Distillation Learning for 3D Point Cloud Class-Incremental Semantic Segmentation\nAbstract: arXiv:2408.01356v1 Announce Type: new  Abstract: Class-incremental learning (CIL) thrives due to its success in processing the influx of information by learning from continuously added new classes while preventing catastrophic forgetting about the old ones. It is essential for the performance breakthrough of CIL to effectively refine past knowledge from the base model and balance it with new learning. However, such an issue has not yet been considered in current research. In this work, we explore the potential of CIL from these perspectives and propose a novel balanced residual distillation framework (BRD-CIL) to push the performance bar of CIL to a new higher level. Specifically, BRD-CIL designs a residual distillation learning strategy, which can dynamically expand the network structure to capture the residuals between the base and target models, effectively refining the past knowledge. Furthermore, BRD-CIL designs a balanced pseudo-label learning strategy by generating a guidance ma",
    "path": "papers/24/08/2408.01356.json",
    "total_tokens": 755,
    "translated_title": "平衡残差蒸馏学习方法在3D点云分类式增量语义分割中的应用",
    "translated_abstract": "arXiv:2408.01356v1 公告类型：新发布  摘要：由于能够在不断增加的新类别中有效处理信息的涌入，并且不会忘记旧知识造成的灾难性遗忘，因此分类式增量学习（CIL）取得了成功。目前的研究尚未考虑目前研究中CIL的性能突破，有效地细化来自基础模型的知识和平衡新的学习是一个问题。在我们的工作中，我们探索了CIL的潜力，并提出了一个基于平衡残差蒸馏框架（BRD-CIL）的新方法，以推动CIL的性能到一个新的更高水平。特别是，BRD-CIL设计了一种残差蒸馏学习策略，它可以通过生成指导矩阵来动态扩展网络结构，捕捉基础和目标模型之间残差的指导矩阵，有效地细化过去的知识。此外，BRD-CIL设计了一种平衡的伪标签学习策略，通过生成指导矩阵来帮助学习算法对类别进行精确定位，同时确保新旧知识之间的平衡。我们通过大量的实验证实了BRD-CIL的有效性，它能够有效地克服CIL中遇到的各种挑战，并显著提高3D点云语义分割的性能。",
    "tldr": "该研究提出了一种新的平衡残差蒸馏框架（BRD-CIL），通过动态扩展网络结构和平衡的伪标签学习，有效地提高了3D点云分类式增量语义分割的性能。",
    "en_tdlr": "This research proposes a novel Balanced Residual Distillation for Class-Incremental Semantic Segmentation (BRD-CIL) framework, which efficiently improves the performance of 3D point cloud classification-incremental semantic segmentation by dynamically expanding the network architecture and balancing pseudo-label learning."
}