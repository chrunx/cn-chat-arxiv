{
    "title": "Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting",
    "abstract": "arXiv:2408.00161v2 Announce Type: replace-cross  Abstract: Recent work in behavioral testing for natural language processing (NLP) models, such as Checklist, is inspired by related paradigms in software engineering testing. They allow evaluation of general linguistic capabilities and domain understanding, hence can help evaluate conceptual soundness and identify model weaknesses. However, a major challenge is the creation of test cases. The current packages rely on semi-automated approach using manual development which requires domain expertise and can be time consuming. This paper introduces an automated approach to develop test cases by exploiting the power of large language models and statistical techniques. It clusters the text representations to carefully construct meaningful groups and then apply prompting techniques to automatically generate Minimal Functionality Tests (MFT). The well-known Amazon Reviews corpus is used to demonstrate our approach. We analyze the behavioral test",
    "link": "https://arxiv.org/abs/2408.00161",
    "context": "Title: Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting\nAbstract: arXiv:2408.00161v2 Announce Type: replace-cross  Abstract: Recent work in behavioral testing for natural language processing (NLP) models, such as Checklist, is inspired by related paradigms in software engineering testing. They allow evaluation of general linguistic capabilities and domain understanding, hence can help evaluate conceptual soundness and identify model weaknesses. However, a major challenge is the creation of test cases. The current packages rely on semi-automated approach using manual development which requires domain expertise and can be time consuming. This paper introduces an automated approach to develop test cases by exploiting the power of large language models and statistical techniques. It clusters the text representations to carefully construct meaningful groups and then apply prompting techniques to automatically generate Minimal Functionality Tests (MFT). The well-known Amazon Reviews corpus is used to demonstrate our approach. We analyze the behavioral test",
    "path": "papers/24/08/2408.00161.json",
    "total_tokens": 330,
    "tldr": "该文章提出了一种自动生成自然语言处理行为测试用例的方法，通过结合聚类技术和提示技术，无需领域专家即可高效生成具有最小功能性测试的用例，从而为评估自然语言处理模型的语义能力和识别模型弱点提供了一种新的自动化方式。"
}