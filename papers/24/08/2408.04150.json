{
    "title": "Decorrelating Structure via Adapters Makes Ensemble Learning Practical for Semi-supervised Learning",
    "abstract": "arXiv:2408.04150v1 Announce Type: new  Abstract: In computer vision, traditional ensemble learning methods exhibit either a low training efficiency or the limited performance to enhance the reliability of deep neural networks. In this paper, we propose a lightweight, loss-function-free, and architecture-agnostic ensemble learning by the Decorrelating Structure via Adapters (DSA) for various visual tasks. Concretely, the proposed DSA leverages the structure-diverse adapters to decorrelate multiple prediction heads without any tailed regularization or loss. This allows DSA to be easily extensible to architecture-agnostic networks for a range of computer vision tasks. Importantly, the theoretically analysis shows that the proposed DSA has a lower bias and variance than that of the single head based method (which is adopted by most of the state of art approaches). Consequently, the DSA makes deep networks reliable and robust for the various real-world challenges, \\textit{e.g.}, data corrup",
    "link": "https://arxiv.org/abs/2408.04150",
    "context": "Title: Decorrelating Structure via Adapters Makes Ensemble Learning Practical for Semi-supervised Learning\nAbstract: arXiv:2408.04150v1 Announce Type: new  Abstract: In computer vision, traditional ensemble learning methods exhibit either a low training efficiency or the limited performance to enhance the reliability of deep neural networks. In this paper, we propose a lightweight, loss-function-free, and architecture-agnostic ensemble learning by the Decorrelating Structure via Adapters (DSA) for various visual tasks. Concretely, the proposed DSA leverages the structure-diverse adapters to decorrelate multiple prediction heads without any tailed regularization or loss. This allows DSA to be easily extensible to architecture-agnostic networks for a range of computer vision tasks. Importantly, the theoretically analysis shows that the proposed DSA has a lower bias and variance than that of the single head based method (which is adopted by most of the state of art approaches). Consequently, the DSA makes deep networks reliable and robust for the various real-world challenges, \\textit{e.g.}, data corrup",
    "path": "papers/24/08/2408.04150.json",
    "total_tokens": 352,
    "tldr": "该文章提出了一种轻量级、无需额外损失函数且对架构不敏感的集成学习方法，通过使用能够正则化模型结构的结构相关的适配器在半监督学习中实现有效的集成学习。"
}