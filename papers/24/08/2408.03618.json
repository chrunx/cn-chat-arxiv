{
    "title": "A Logical Fallacy-Informed Framework for Argument Generation",
    "abstract": "arXiv:2408.03618v1 Announce Type: cross  Abstract: Despite the remarkable performance of Large Language Models (LLMs), they still struggle with generating logically sound arguments, resulting in potential risks such as spreading misinformation. An important factor contributing to LLMs' suboptimal performance in generating coherent arguments is their oversight of logical fallacies. To address this issue, we introduce FIPO, a fallacy-informed framework that leverages preference optimization methods to steer LLMs toward logically sound arguments. FIPO includes a classification loss, to capture the fine-grained information on fallacy categories. Our results on argumentation datasets show that our method reduces the fallacy errors by up to 17.5%. Furthermore, our human evaluation results indicate that the quality of the generated arguments by our method significantly outperforms the fine-tuned baselines, as well as prior preference optimization methods, such as DPO. These findings highlight",
    "link": "https://arxiv.org/abs/2408.03618",
    "context": "Title: A Logical Fallacy-Informed Framework for Argument Generation\nAbstract: arXiv:2408.03618v1 Announce Type: cross  Abstract: Despite the remarkable performance of Large Language Models (LLMs), they still struggle with generating logically sound arguments, resulting in potential risks such as spreading misinformation. An important factor contributing to LLMs' suboptimal performance in generating coherent arguments is their oversight of logical fallacies. To address this issue, we introduce FIPO, a fallacy-informed framework that leverages preference optimization methods to steer LLMs toward logically sound arguments. FIPO includes a classification loss, to capture the fine-grained information on fallacy categories. Our results on argumentation datasets show that our method reduces the fallacy errors by up to 17.5%. Furthermore, our human evaluation results indicate that the quality of the generated arguments by our method significantly outperforms the fine-tuned baselines, as well as prior preference optimization methods, such as DPO. These findings highlight",
    "path": "papers/24/08/2408.03618.json",
    "total_tokens": 329,
    "tldr": "该文章提出了一个基于逻辑谬误的Argument Generation框架，通过引入偏好优化方法和逻辑谬误的校正，显著提升了大型语言模型生成逻辑上连贯和正确论点的能力，并提高了由人类评价的生成论点的质量。"
}