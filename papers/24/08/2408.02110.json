{
    "title": "AvatarPose: Avatar-guided 3D Pose Estimation of Close Human Interaction from Sparse Multi-view Videos",
    "abstract": "arXiv:2408.02110v1 Announce Type: new  Abstract: Despite progress in human motion capture, existing multi-view methods often face challenges in estimating the 3D pose and shape of multiple closely interacting people. This difficulty arises from reliance on accurate 2D joint estimations, which are hard to obtain due to occlusions and body contact when people are in close interaction. To address this, we propose a novel method leveraging the personalized implicit neural avatar of each individual as a prior, which significantly improves the robustness and precision of this challenging pose estimation task. Concretely, the avatars are efficiently reconstructed via layered volume rendering from sparse multi-view videos. The reconstructed avatar prior allows for the direct optimization of 3D poses based on color and silhouette rendering loss, bypassing the issues associated with noisy 2D detections. To handle interpenetration, we propose a collision loss on the overlapping shape regions of a",
    "link": "https://arxiv.org/abs/2408.02110",
    "context": "Title: AvatarPose: Avatar-guided 3D Pose Estimation of Close Human Interaction from Sparse Multi-view Videos\nAbstract: arXiv:2408.02110v1 Announce Type: new  Abstract: Despite progress in human motion capture, existing multi-view methods often face challenges in estimating the 3D pose and shape of multiple closely interacting people. This difficulty arises from reliance on accurate 2D joint estimations, which are hard to obtain due to occlusions and body contact when people are in close interaction. To address this, we propose a novel method leveraging the personalized implicit neural avatar of each individual as a prior, which significantly improves the robustness and precision of this challenging pose estimation task. Concretely, the avatars are efficiently reconstructed via layered volume rendering from sparse multi-view videos. The reconstructed avatar prior allows for the direct optimization of 3D poses based on color and silhouette rendering loss, bypassing the issues associated with noisy 2D detections. To handle interpenetration, we propose a collision loss on the overlapping shape regions of a",
    "path": "papers/24/08/2408.02110.json",
    "total_tokens": 402,
    "tldr": "该文章提出了一种名为AvatarPose的方法，通过利用个人化的隐变量神经角色模型作为先验，从稀疏的多视图视频中实现了对紧密交流的多人3D姿态估计的显著提升。该方法绕过了依赖于粗略的2D关节估计的问题，而是直接优化3D姿态，基于颜色和轮廓渲染损失，从而提高了在紧密交流中姿态估计的准确性。这种方法能够有效地解决因重叠姿态导致的障碍物剔除问题，通过在重叠形状区域上应用碰撞损失。"
}