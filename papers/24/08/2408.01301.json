{
    "title": "A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment",
    "abstract": "arXiv:2408.01301v1 Announce Type: cross  Abstract: Artificial intelligence (AI) has revolutionized decision-making processes and systems throughout society and, in particular, has emerged as a significant technology in high-impact scenarios of national interest. Yet, despite AI's impressive predictive capabilities in controlled settings, it still suffers from a range of practical setbacks preventing its widespread use in various critical scenarios. In particular, it is generally unclear if a given AI system's predictions can be trusted by decision-makers in downstream applications. To address the need for more transparent, robust, and trustworthy AI systems, a suite of tools has been developed to quantify the uncertainty of AI predictions and, more generally, enable AI to \"self-assess\" the reliability of its predictions. In this manuscript, we categorize methods for AI self-assessment along several key dimensions and provide guidelines for selecting and designing the appropriate method",
    "link": "https://arxiv.org/abs/2408.01301",
    "context": "Title: A Decision-driven Methodology for Designing Uncertainty-aware AI Self-Assessment\nAbstract: arXiv:2408.01301v1 Announce Type: cross  Abstract: Artificial intelligence (AI) has revolutionized decision-making processes and systems throughout society and, in particular, has emerged as a significant technology in high-impact scenarios of national interest. Yet, despite AI's impressive predictive capabilities in controlled settings, it still suffers from a range of practical setbacks preventing its widespread use in various critical scenarios. In particular, it is generally unclear if a given AI system's predictions can be trusted by decision-makers in downstream applications. To address the need for more transparent, robust, and trustworthy AI systems, a suite of tools has been developed to quantify the uncertainty of AI predictions and, more generally, enable AI to \"self-assess\" the reliability of its predictions. In this manuscript, we categorize methods for AI self-assessment along several key dimensions and provide guidelines for selecting and designing the appropriate method",
    "path": "papers/24/08/2408.01301.json",
    "total_tokens": 625,
    "translated_title": "一种基于决策的为设计不确定性的AI自我评估方法",
    "translated_abstract": "arXiv:2408.01301v1 公告类型: 交叉  翻译摘要: 人工智能(AI)已经革命化了社会的决策制定过程，特别是在具有重大影响力的场景中，它已经成为一项关键技术。尽管AI在受控环境下的预测能力令人印象深刻，但在各种关键场景中，它仍面临一系列实际障碍，阻碍了其在广泛应用中的使用。特别是，对于决策者而言，通常不清楚给定的AI系统在其下游应用中是否可信的预测。为了应对对更具透明度、韧性和可信度AI系统的需求，开发了一套工具，用于量化AI预测的不确定性，更广泛地说，使AI能够“自我评估”其预测的可靠性。在本论文中，我们将AI自我评估的方法按照几个关键维度进行分类，并提供了选择和设计适当方法的指南。",
    "tldr": "本文介绍了旨在提高AI预测透明度、可靠性和可信度的一系列工具和方法，为AI如何自我评估其预测的可靠性提供了指导。",
    "en_tdlr": "This paper introduces a suite of tools and methods aimed at enhancing the transparency, reliability, and credibility of AI predictions, providing guidance on how AI can self-assess the reliability of its predictions."
}