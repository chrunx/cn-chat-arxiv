{
    "title": "CLIP-based Point Cloud Classification via Point Cloud to Image Translation",
    "abstract": "arXiv:2408.03545v1 Announce Type: new  Abstract: Point cloud understanding is an inherently challenging problem because of the sparse and unordered structure of the point cloud in the 3D space. Recently, Contrastive Vision-Language Pre-training (CLIP) based point cloud classification model i.e. PointCLIP has added a new direction in the point cloud classification research domain. In this method, at first multi-view depth maps are extracted from the point cloud and passed through the CLIP visual encoder. To transfer the 3D knowledge to the network, a small network called an adapter is fine-tuned on top of the CLIP visual encoder. PointCLIP has two limitations. Firstly, the point cloud depth maps lack image information which is essential for tasks like classification and recognition. Secondly, the adapter only relies on the global representation of the multi-view features. Motivated by this observation, we propose a Pretrained Point Cloud to Image Translation Network (PPCITNet) that prod",
    "link": "https://arxiv.org/abs/2408.03545",
    "context": "Title: CLIP-based Point Cloud Classification via Point Cloud to Image Translation\nAbstract: arXiv:2408.03545v1 Announce Type: new  Abstract: Point cloud understanding is an inherently challenging problem because of the sparse and unordered structure of the point cloud in the 3D space. Recently, Contrastive Vision-Language Pre-training (CLIP) based point cloud classification model i.e. PointCLIP has added a new direction in the point cloud classification research domain. In this method, at first multi-view depth maps are extracted from the point cloud and passed through the CLIP visual encoder. To transfer the 3D knowledge to the network, a small network called an adapter is fine-tuned on top of the CLIP visual encoder. PointCLIP has two limitations. Firstly, the point cloud depth maps lack image information which is essential for tasks like classification and recognition. Secondly, the adapter only relies on the global representation of the multi-view features. Motivated by this observation, we propose a Pretrained Point Cloud to Image Translation Network (PPCITNet) that prod",
    "path": "papers/24/08/2408.03545.json",
    "total_tokens": 463,
    "tldr": "该文章提出了一种预训练的点云到图像转换网络（PPCITNet），旨在解决CLIP-based点云分类中存在的局限性。这种方法通过从点云中提取多视图深度图并将其通过CLIP视觉编码器，以及使用一个小型的网络适配器在CLIP视觉编码器上进行微调，来转移点云的3D知识。然而，PPCITNet实现了一种全新的点云到图像转换的机制，将点云转换成一幅多视角的全局图像，从而利用丰富的图像信息进行分类任务。此外，PPCITNet还增加了一个局部注意力模块，可以捕捉点云的局部特征。总的来说，PPCITNet通过结合全局和局部特征，提高CLIP在点云分类中的性能。"
}