{
    "title": "E$^3$NeRF: Efficient Event-Enhanced Neural Radiance Fields from Blurry Images",
    "abstract": "arXiv:2408.01840v1 Announce Type: new  Abstract: Neural Radiance Fields (NeRF) achieve impressive rendering performance by learning volumetric 3D representation from several images of different views. However, it is difficult to reconstruct a sharp NeRF from blurry input as it often occurs in the wild. To solve this problem, we propose a novel Efficient Event-Enhanced NeRF (E$^3$NeRF) by utilizing the combination of RGB images and event streams. To effectively introduce event streams into the neural volumetric representation learning process, we propose an event-enhanced blur rendering loss and an event rendering loss, which guide the network via modeling the real blur process and event generation process, respectively. Specifically, we leverage spatial-temporal information from the event stream to evenly distribute learning attention over temporal blur while simultaneously focusing on blurry texture through the spatial attention. Moreover, a camera pose estimation framework for real-w",
    "link": "https://arxiv.org/abs/2408.01840",
    "context": "Title: E$^3$NeRF: Efficient Event-Enhanced Neural Radiance Fields from Blurry Images\nAbstract: arXiv:2408.01840v1 Announce Type: new  Abstract: Neural Radiance Fields (NeRF) achieve impressive rendering performance by learning volumetric 3D representation from several images of different views. However, it is difficult to reconstruct a sharp NeRF from blurry input as it often occurs in the wild. To solve this problem, we propose a novel Efficient Event-Enhanced NeRF (E$^3$NeRF) by utilizing the combination of RGB images and event streams. To effectively introduce event streams into the neural volumetric representation learning process, we propose an event-enhanced blur rendering loss and an event rendering loss, which guide the network via modeling the real blur process and event generation process, respectively. Specifically, we leverage spatial-temporal information from the event stream to evenly distribute learning attention over temporal blur while simultaneously focusing on blurry texture through the spatial attention. Moreover, a camera pose estimation framework for real-w",
    "path": "papers/24/08/2408.01840.json",
    "total_tokens": 390,
    "tldr": "该文章提出了一种名为E$^3$NeRF的、基于事件增强的神经辐射场的有效方法，该方法可以从模糊图像中高效地学习3D表示。该方法利用RGB图像与事件流相结合，并通过引入一种新的模糊渲染损失和事件渲染损失，有效地整合了事件流信息，以指导网络通过模拟实际模糊过程和事件生成过程进行学习。此外，文章还介绍了一个用于真实场景中相机姿态估算的框架。"
}