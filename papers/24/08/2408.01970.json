{
    "title": "SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning",
    "abstract": "arXiv:2408.01970v1 Announce Type: cross  Abstract: The ability of humans to rapidly learn new knowledge while retaining old memories poses a significant challenge for current deep learning models. To handle this challenge, we draw inspiration from human memory and learning mechanisms and propose the Self-Reflective Complementary Incremental System (SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and Complementary Memory Module (CMM), SR-CIS features a small model for fast inference and a large model for slow deliberation in CIM, enabled by the Confidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient collaboration. CMM consists of task-specific Short-Term Memory (STM) region and a universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank Adaptive (LoRA) and corresponding prototype weights and biases, it instantiates external storage for parameter and representation memory, thus deconstructing the memory module from the infere",
    "link": "https://arxiv.org/abs/2408.01970",
    "context": "Title: SR-CIS: Self-Reflective Incremental System with Decoupled Memory and Reasoning\nAbstract: arXiv:2408.01970v1 Announce Type: cross  Abstract: The ability of humans to rapidly learn new knowledge while retaining old memories poses a significant challenge for current deep learning models. To handle this challenge, we draw inspiration from human memory and learning mechanisms and propose the Self-Reflective Complementary Incremental System (SR-CIS). Comprising the deconstructed Complementary Inference Module (CIM) and Complementary Memory Module (CMM), SR-CIS features a small model for fast inference and a large model for slow deliberation in CIM, enabled by the Confidence-Aware Online Anomaly Detection (CA-OAD) mechanism for efficient collaboration. CMM consists of task-specific Short-Term Memory (STM) region and a universal Long-Term Memory (LTM) region. By setting task-specific Low-Rank Adaptive (LoRA) and corresponding prototype weights and biases, it instantiates external storage for parameter and representation memory, thus deconstructing the memory module from the infere",
    "path": "papers/24/08/2408.01970.json",
    "total_tokens": 758,
    "translated_title": "SR-CIS: 自我反思增量系统与解耦记忆与推理",
    "translated_abstract": "arXiv:2408.01970v1 公告类型：交叉  摘要：人类快速学习新知识同时保留旧记忆的能力为当前的深度学习模型提出了严峻的挑战。为了解决这个问题，我们借鉴了人类记忆和学习的机制，并提出了自反式互补增量系统（SR-CIS）。SR-CIS由解构化的互补推断模块（CIM）和互补记忆模块（CMM）组成，其中CIM通过置信度自适应在线异常检测（CA-OAD）机制实现快速推断和慢速决策的小模型，而CIM则由Confidence-Aware Online Anomaly Detection（CA-OAD）机制实现快速推断和慢速决策的大模型。CMM由任务特定的短期记忆（STM）区域和通用的长期记忆（LTM）区域组成。通过设定任务特定的低秩自适应（LoRA）和相关原型权重和偏差，它为参数和表示记忆建立了外部存储实例，从而解构了记忆模块与推理模块，并实现了记忆的解耦。",
    "tldr": "SR-CIS通过结合小模型快速推理和慢速决策的大模型，并通过CA-OAD机制实现高效协作，提供了一种新的内存与推理解耦的机制，以解决当前深度学习模型在面对人类记忆和学习机制时的挑战。"
}