{
    "title": "Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons",
    "abstract": "arXiv:2408.03247v1 Announce Type: cross  Abstract: In this paper, we investigate whether Large Language Models (LLMs) actively recall or retrieve their internal repositories of factual knowledge when faced with reasoning tasks. Through an analysis of LLMs' internal factual recall at each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness the critical factual associations under certain circumstances. Instead, they tend to opt for alternative, shortcut-like pathways to answer reasoning questions. By manually manipulating the recall process of parametric knowledge in LLMs, we demonstrate that enhancing this recall process directly improves reasoning performance whereas suppressing it leads to notable degradation. Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a powerful technique for addressing complex reasoning tasks. Our findings indicate that CoT can intensify the recall of factual knowledge by encouraging LLMs to engage in orderly and rel",
    "link": "https://arxiv.org/abs/2408.03247",
    "context": "Title: Unveiling Factual Recall Behaviors of Large Language Models through Knowledge Neurons\nAbstract: arXiv:2408.03247v1 Announce Type: cross  Abstract: In this paper, we investigate whether Large Language Models (LLMs) actively recall or retrieve their internal repositories of factual knowledge when faced with reasoning tasks. Through an analysis of LLMs' internal factual recall at each reasoning step via Knowledge Neurons, we reveal that LLMs fail to harness the critical factual associations under certain circumstances. Instead, they tend to opt for alternative, shortcut-like pathways to answer reasoning questions. By manually manipulating the recall process of parametric knowledge in LLMs, we demonstrate that enhancing this recall process directly improves reasoning performance whereas suppressing it leads to notable degradation. Furthermore, we assess the effect of Chain-of-Thought (CoT) prompting, a powerful technique for addressing complex reasoning tasks. Our findings indicate that CoT can intensify the recall of factual knowledge by encouraging LLMs to engage in orderly and rel",
    "path": "papers/24/08/2408.03247.json",
    "total_tokens": 415,
    "tldr": "该文章揭示了大型语言模型在面临推理任务时是否积极调用其内部知识仓库的秘密，通过研究模型在推理每个步骤中知识神经元的激活模式，发现模型未能在某些情况下有效地利用关键的知识关联，而是倾向于采取捷径来回答问题。通过手动调整参数知识在模型中的回忆过程，文章证明了提升模型的知识回忆能力可以显著提高模型的推理性能，而抑制这种回忆则导致性能显著下降。此外，文章还探讨了链式思维（CoT）提示在解决复杂推理任务中的作用，发现CoT可以增强模型对事实知识的回忆，促使模型以有序的方式参与推理。"
}