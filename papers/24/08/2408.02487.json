{
    "title": "A First Look at License Compliance Capability of LLMs in Code Generation",
    "abstract": "arXiv:2408.02487v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have revolutionized code generation, leading to widespread adoption of AI coding tools by developers. However, LLMs can generate license-protected code without providing the necessary license information, leading to potential intellectual property violations during software production. This paper addresses the critical, yet underexplored, issue of license compliance in LLM-generated code by establishing a benchmark to evaluate the ability of LLMs to provide accurate license information for their generated code. To establish this benchmark, we conduct an empirical study to identify a reasonable standard for \"striking similarity\" that excludes the possibility of independent creation, indicating a copy relationship between the LLM output and certain open-source code. Based on this standard, we propose an evaluation benchmark LiCoEval, to evaluate the license compliance capabilities of LLMs. ",
    "link": "https://arxiv.org/abs/2408.02487",
    "context": "Title: A First Look at License Compliance Capability of LLMs in Code Generation\nAbstract: arXiv:2408.02487v1 Announce Type: cross  Abstract: Recent advances in Large Language Models (LLMs) have revolutionized code generation, leading to widespread adoption of AI coding tools by developers. However, LLMs can generate license-protected code without providing the necessary license information, leading to potential intellectual property violations during software production. This paper addresses the critical, yet underexplored, issue of license compliance in LLM-generated code by establishing a benchmark to evaluate the ability of LLMs to provide accurate license information for their generated code. To establish this benchmark, we conduct an empirical study to identify a reasonable standard for \"striking similarity\" that excludes the possibility of independent creation, indicating a copy relationship between the LLM output and certain open-source code. Based on this standard, we propose an evaluation benchmark LiCoEval, to evaluate the license compliance capabilities of LLMs. ",
    "path": "papers/24/08/2408.02487.json",
    "total_tokens": 325,
    "tldr": "该文章创新性地提出了一套评估大型语言模型（LLMs）在代码生成时是否提供正确许可证信息的标准，旨在评估这些模型在生成受版权保护代码时的许可证合规能力，并预防与软件开发过程中的知识产权纠纷。"
}