{
    "title": "TALE: Training-free Cross-domain Image Composition via Adaptive Latent Manipulation and Energy-guided Optimization",
    "abstract": "arXiv:2408.03637v1 Announce Type: new  Abstract: We present TALE, a novel training-free framework harnessing the generative capabilities of text-to-image diffusion models to address the cross-domain image composition task that focuses on flawlessly incorporating user-specified objects into a designated visual contexts regardless of domain disparity. Previous methods often involve either training auxiliary networks or finetuning diffusion models on customized datasets, which are expensive and may undermine the robust textual and visual priors of pre-trained diffusion models. Some recent works attempt to break the barrier by proposing training-free workarounds that rely on manipulating attention maps to tame the denoising process implicitly. However, composing via attention maps does not necessarily yield desired compositional outcomes. These approaches could only retain some semantic information and usually fall short in preserving identity characteristics of input objects or exhibit li",
    "link": "https://arxiv.org/abs/2408.03637",
    "context": "Title: TALE: Training-free Cross-domain Image Composition via Adaptive Latent Manipulation and Energy-guided Optimization\nAbstract: arXiv:2408.03637v1 Announce Type: new  Abstract: We present TALE, a novel training-free framework harnessing the generative capabilities of text-to-image diffusion models to address the cross-domain image composition task that focuses on flawlessly incorporating user-specified objects into a designated visual contexts regardless of domain disparity. Previous methods often involve either training auxiliary networks or finetuning diffusion models on customized datasets, which are expensive and may undermine the robust textual and visual priors of pre-trained diffusion models. Some recent works attempt to break the barrier by proposing training-free workarounds that rely on manipulating attention maps to tame the denoising process implicitly. However, composing via attention maps does not necessarily yield desired compositional outcomes. These approaches could only retain some semantic information and usually fall short in preserving identity characteristics of input objects or exhibit li",
    "path": "papers/24/08/2408.03637.json",
    "total_tokens": 407,
    "tldr": "该文章提出TALE框架，这是一种无需训练的新方法，通过自适应的潜在操纵和能量引导的优化，利用文本到图像扩散模型的生成能力，解决了跨域图像合成问题。该方法能够将用户指定的对象无缝地融入指定场景中，即使这些对象和场景属于不同的领域。它无需训练额外的网络或对扩散模型进行再训练，从而能够保持预训练扩散模型在文本和视觉方面的鲁棒性。此外，该方法通过操纵能量场来改善合成结果，确保了合成过程中视觉效果的连贯性和合理性，展现了在无需训练的情况下进行跨域图像合成的潜力。"
}