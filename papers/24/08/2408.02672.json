{
    "title": "Latent-INR: A Flexible Framework for Implicit Representations of Videos with Discriminative Semantics",
    "abstract": "arXiv:2408.02672v1 Announce Type: new  Abstract: Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes. With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality. However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval. This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression. To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR. We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict th",
    "link": "https://arxiv.org/abs/2408.02672",
    "context": "Title: Latent-INR: A Flexible Framework for Implicit Representations of Videos with Discriminative Semantics\nAbstract: arXiv:2408.02672v1 Announce Type: new  Abstract: Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes. With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality. However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval. This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression. To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR. We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict th",
    "path": "papers/24/08/2408.02672.json",
    "total_tokens": 697,
    "translated_title": "隐式神经网络（INR）: 具有区分性语义的灵活视频隐式表示框架",
    "translated_abstract": "arXiv:2408.02672v1 公告类型: 新  摘要: 隐式神经网络（INRs）已经成为编码各种数据形式（包括图像、视频、音频和场景）的强大表示。对于视频来说，已经提出了许多用于压缩任务的INRs，而且最近的方法在编码时间、存储和重建质量方面有了显著的改进。然而，这些编码的表示缺乏语义含义，因此无法用于任何需要此类属性的下游任务，比如检索。这可能导致INRs在对标传统编解码器时缺乏竞争力，因为它们除了压缩外没有任何显著的优势。为了解决这个问题，我们提出了一种灵活的框架，该框架解耦了视频INR的空间和时间方面。我们通过一组每帧的隐性词汇以及一组专门的视频专有超网络来实现这一点，这样，给定一个隐性词汇，这些超网络就能预测视频的时序特性，从而使得生成的表示不仅压缩能力强，而且具有语义意义，可以用于各种下游任务。",
    "tldr": "本文提出了一种名为Latent-INR的框架，该框架能够生成具有区分性语义的隐式视频表示，同时保持强大的压缩能力，使其适用于各种下游任务。",
    "en_tdlr": "This paper proposes a Latent-INR framework that generates implicit video representations with discriminative semantics, maintaining strong compression capabilities and making them suitable for a variety of downstream tasks."
}