{
    "title": "Latent-INR: A Flexible Framework for Implicit Representations of Videos with Discriminative Semantics",
    "abstract": "arXiv:2408.02672v1 Announce Type: new  Abstract: Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes. With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality. However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval. This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression. To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR. We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict th",
    "link": "https://arxiv.org/abs/2408.02672",
    "context": "Title: Latent-INR: A Flexible Framework for Implicit Representations of Videos with Discriminative Semantics\nAbstract: arXiv:2408.02672v1 Announce Type: new  Abstract: Implicit Neural Networks (INRs) have emerged as powerful representations to encode all forms of data, including images, videos, audios, and scenes. With video, many INRs for video have been proposed for the compression task, and recent methods feature significant improvements with respect to encoding time, storage, and reconstruction quality. However, these encoded representations lack semantic meaning, so they cannot be used for any downstream tasks that require such properties, such as retrieval. This can act as a barrier for adoption of video INRs over traditional codecs as they do not offer any significant edge apart from compression. To alleviate this, we propose a flexible framework that decouples the spatial and temporal aspects of the video INR. We accomplish this with a dictionary of per-frame latents that are learned jointly with a set of video specific hypernetworks, such that given a latent, these hypernetworks can predict th",
    "path": "papers/24/08/2408.02672.json",
    "total_tokens": 357,
    "tldr": "该文章提出了一种灵活的框架Latent-INR，它能够使得视频隐式表示（INR）不仅具有高效的压缩特性，还能够传达出有意义的语义信息，这使得它们不仅可以用于视频压缩，还可以用于视频检索等一系列下游任务。"
}