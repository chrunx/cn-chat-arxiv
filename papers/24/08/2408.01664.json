{
    "title": "SAT3D: Image-driven Semantic Attribute Transfer in 3D",
    "abstract": "arXiv:2408.01664v1 Announce Type: new  Abstract: GAN-based image editing task aims at manipulating image attributes in the latent space of generative models. Most of the previous 2D and 3D-aware approaches mainly focus on editing attributes in images with ambiguous semantics or regions from a reference image, which fail to achieve photographic semantic attribute transfer, such as the beard from a photo of a man. In this paper, we propose an image-driven Semantic Attribute Transfer method in 3D (SAT3D) by editing semantic attributes from a reference image. For the proposed method, the exploration is conducted in the style space of a pre-trained 3D-aware StyleGAN-based generator by learning the correlations between semantic attributes and style code channels. For guidance, we associate each attribute with a set of phrase-based descriptor groups, and develop a Quantitative Measurement Module (QMM) to quantitatively describe the attribute characteristics in images based on descriptor group",
    "link": "https://arxiv.org/abs/2408.01664",
    "context": "Title: SAT3D: Image-driven Semantic Attribute Transfer in 3D\nAbstract: arXiv:2408.01664v1 Announce Type: new  Abstract: GAN-based image editing task aims at manipulating image attributes in the latent space of generative models. Most of the previous 2D and 3D-aware approaches mainly focus on editing attributes in images with ambiguous semantics or regions from a reference image, which fail to achieve photographic semantic attribute transfer, such as the beard from a photo of a man. In this paper, we propose an image-driven Semantic Attribute Transfer method in 3D (SAT3D) by editing semantic attributes from a reference image. For the proposed method, the exploration is conducted in the style space of a pre-trained 3D-aware StyleGAN-based generator by learning the correlations between semantic attributes and style code channels. For guidance, we associate each attribute with a set of phrase-based descriptor groups, and develop a Quantitative Measurement Module (QMM) to quantitatively describe the attribute characteristics in images based on descriptor group",
    "path": "papers/24/08/2408.01664.json",
    "total_tokens": 662,
    "translated_title": "SAT3D:基于图像的3D语义属性转移",
    "translated_abstract": "arXiv:2408.01664v1 Announce Type: 新的摘要: 基于GAN的图像编辑任务旨在在生成模型的潜在空间中对图像属性进行操作。大多数以前的2D和3D感知方法主要关注从参考图像中难以分辨的语义或区域编辑属性，这无法实现摄影风格的语义属性转移，如从一个男人的照片中转移胡须。在本文中，我们提出了一个基于图像的3D语义属性转移方法(SAT3D)，通过从参考图像中编辑语义属性。对于提出的方法，探索是在一个预先训练的3D感知StyleGAN基generator的样式空间中进行的，通过学习与样式代码通道相关的语义属性和样式码之间的相关性。为了指导，我们与一组基于短语的描述符组关联每个属性，并开发了一个定量测量模块(QMM)，以基于描述符组在图像中定量描述属性特征。",
    "tldr": "这项研究提出了一种新的方法，可以基于参考图像在3D环境中实现更准确的语义属性转移，解决了以往方法在语义属性编辑方面的局限性。",
    "en_tdlr": "This research introduces a new method for more accurate semantic attribute transfer in a 3D environment based on a reference image, addressing the limitations of previous methods in editing semantic attributes."
}