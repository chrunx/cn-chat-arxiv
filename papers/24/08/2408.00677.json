{
    "title": "Scaling Backwards: Minimal Synthetic Pre-training?",
    "abstract": "arXiv:2408.00677v2 Announce Type: replace  Abstract: Pre-training and transfer learning are an important building block of current computer vision systems. While pre-training is usually performed on large real-world image datasets, in this paper we ask whether this is truly necessary. To this end, we search for a minimal, purely synthetic pre-training dataset that allows us to achieve performance similar to the 1 million images of ImageNet-1k. We construct such a dataset from a single fractal with perturbations. With this, we contribute three main findings. (i) We show that pre-training is effective even with minimal synthetic images, with performance on par with large-scale pre-training datasets like ImageNet-1k for full fine-tuning. (ii) We investigate the single parameter with which we construct artificial categories for our dataset. We find that while the shape differences can be indistinguishable to humans, they are crucial for obtaining strong performances. (iii) Finally, we inve",
    "link": "https://arxiv.org/abs/2408.00677",
    "context": "Title: Scaling Backwards: Minimal Synthetic Pre-training?\nAbstract: arXiv:2408.00677v2 Announce Type: replace  Abstract: Pre-training and transfer learning are an important building block of current computer vision systems. While pre-training is usually performed on large real-world image datasets, in this paper we ask whether this is truly necessary. To this end, we search for a minimal, purely synthetic pre-training dataset that allows us to achieve performance similar to the 1 million images of ImageNet-1k. We construct such a dataset from a single fractal with perturbations. With this, we contribute three main findings. (i) We show that pre-training is effective even with minimal synthetic images, with performance on par with large-scale pre-training datasets like ImageNet-1k for full fine-tuning. (ii) We investigate the single parameter with which we construct artificial categories for our dataset. We find that while the shape differences can be indistinguishable to humans, they are crucial for obtaining strong performances. (iii) Finally, we inve",
    "path": "papers/24/08/2408.00677.json",
    "total_tokens": 686,
    "translated_title": "逆向扩展：最小合成预训练？",
    "translated_abstract": "arXiv:2408.00677v2 公告类型：替换 摘要：当前计算机视觉系统的一个重要组成部分是预训练和转移学习。虽然预训练通常在大型真实世界图像数据集上进行，但在这篇论文中，我们提出了一个问题：这真的是必要的吗？为此，我们寻找了一个最小化的、纯粹的合成预训练数据集，该数据集允许我们获得与ImageNet-1k类似的性能。我们从一个单一的几何图形中构造了这样一个数据集，并对它进行了扰动。通过这种方式，我们对三个主要发现做出了贡献。(i) 我们展示了即使是在最小的合成图像上进行预训练，对于完全的微调，性能也与像ImageNet-1k这样的大型预训练数据集相当。(ii) 我们研究了我们构造人工类别所需的唯一参数。我们发现，尽管形状差异可能对人类来说难以区分，但对于获得强大的性能至关重要。(iii) 最后，我们研究了如何在合成预训练数据集上使用相同的模型Zero-shot Learning也能取得良好的表现。",
    "tldr": "论文发现即使在最基本的合成图像上进行预训练也能达到与大型数据集类似的性能，证明了预训练即使在假想情境下也有效。",
    "en_tdlr": "This paper shows that pre-training with minimal synthetic images can achieve performance comparable to large-scale datasets like ImageNet-1k, demonstrating the effectiveness of pre-training even in a purely synthetic setting."
}