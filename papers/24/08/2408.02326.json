{
    "title": "Explosive neural networks via higher-order interactions in curved statistical manifolds",
    "abstract": "arXiv:2408.02326v1 Announce Type: cross  Abstract: Higher-order interactions underlie complex phenomena in systems such as biological and artificial neural networks, but their study is challenging due to the lack of tractable standard models. By leveraging the maximum entropy principle in curved statistical manifolds, here we introduce curved neural networks as a class of prototypical models for studying higher-order phenomena. Through exact mean-field descriptions, we show that these curved neural networks implement a self-regulating annealing process that can accelerate memory retrieval, leading to explosive order-disorder phase transitions with multi-stability and hysteresis effects. Moreover, by analytically exploring their memory capacity using the replica trick near ferromagnetic and spin-glass phase boundaries, we demonstrate that these networks enhance memory capacity over the classical associative-memory networks. Overall, the proposed framework provides parsimonious models am",
    "link": "https://arxiv.org/abs/2408.02326",
    "context": "Title: Explosive neural networks via higher-order interactions in curved statistical manifolds\nAbstract: arXiv:2408.02326v1 Announce Type: cross  Abstract: Higher-order interactions underlie complex phenomena in systems such as biological and artificial neural networks, but their study is challenging due to the lack of tractable standard models. By leveraging the maximum entropy principle in curved statistical manifolds, here we introduce curved neural networks as a class of prototypical models for studying higher-order phenomena. Through exact mean-field descriptions, we show that these curved neural networks implement a self-regulating annealing process that can accelerate memory retrieval, leading to explosive order-disorder phase transitions with multi-stability and hysteresis effects. Moreover, by analytically exploring their memory capacity using the replica trick near ferromagnetic and spin-glass phase boundaries, we demonstrate that these networks enhance memory capacity over the classical associative-memory networks. Overall, the proposed framework provides parsimonious models am",
    "path": "papers/24/08/2408.02326.json",
    "total_tokens": 378,
    "tldr": "通过在弯曲统计 manifold 上使用最大化熵原理，本文引入了曲面神经网络作为一类研究更高阶现象的原型模型。研究结果表明，这些曲面神经网络能够实现自我调节退火过程，从而加速记忆检索，导致具有多重稳定性和滞后效应的多相变爆炸行为。此外，通过使用重贴技巧分析其临界附近的记忆容量，本文还发现这些网络比经典关联记忆网络具有更高的记忆容量。总体而言，本文提出的框架为简约模型的研究和更高效记忆检索提供了新的视角。"
}