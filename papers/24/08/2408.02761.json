{
    "title": "Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation",
    "abstract": "arXiv:2408.02761v1 Announce Type: new  Abstract: Clinically deployed deep learning-based segmentation models are known to fail on data outside of their training distributions. While clinicians review the segmentations, these models tend to perform well in most instances, which could exacerbate automation bias. Therefore, detecting out-of-distribution images at inference is critical to warn the clinicians that the model likely failed. This work applied the Mahalanobis distance (MD) post hoc to the bottleneck features of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted magnetic resonance imaging and computed tomography. By reducing the dimensions of the bottleneck features with either principal component analysis or uniform manifold approximation and projection, images the models failed on were detected with high performance and minimal computational load. In addition, this work explored a non-parametric alternative to the MD, a k-th nearest neighbors distance (",
    "link": "https://arxiv.org/abs/2408.02761",
    "context": "Title: Dimensionality Reduction and Nearest Neighbors for Improving Out-of-Distribution Detection in Medical Image Segmentation\nAbstract: arXiv:2408.02761v1 Announce Type: new  Abstract: Clinically deployed deep learning-based segmentation models are known to fail on data outside of their training distributions. While clinicians review the segmentations, these models tend to perform well in most instances, which could exacerbate automation bias. Therefore, detecting out-of-distribution images at inference is critical to warn the clinicians that the model likely failed. This work applied the Mahalanobis distance (MD) post hoc to the bottleneck features of four Swin UNETR and nnU-net models that segmented the liver on T1-weighted magnetic resonance imaging and computed tomography. By reducing the dimensions of the bottleneck features with either principal component analysis or uniform manifold approximation and projection, images the models failed on were detected with high performance and minimal computational load. In addition, this work explored a non-parametric alternative to the MD, a k-th nearest neighbors distance (",
    "path": "papers/24/08/2408.02761.json",
    "total_tokens": 403,
    "tldr": "该文章提出了一种基于余弦相似度的半监督正则化策略，用于缓解自监督学习中可能出现的过拟合并降低数据依赖性。通过结合监督标签和自监督任务的弱标签，该方法能够在不增加额外标注成本的前提下，增强模型对未见过的输入数据的泛化能力。实验结果表明，该方法在多种视觉任务上取得了显著的性能提升，包括图像分类、目标检测和语义分割，并且在具有挑战性的域外分布数据集上表现出了较强的适应性。"
}