{
    "title": "KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving",
    "abstract": "arXiv:2408.02088v1 Announce Type: cross  Abstract: Accurate 3D object detection in autonomous driving is critical yet challenging due to occlusions, varying object scales, and complex urban environments. This paper introduces the RCBEV-KAN algorithm, a pioneering method designed to enhance 3D object detection by fusing multimodal sensor data from cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View (BEV)-based approach, utilizing a Transformer architecture, significantly boosts detection precision and efficiency by seamlessly integrating diverse data sources, improving spatial relationship handling, and optimizing computational processes. Experimental results show that the RCBEV-KAN model demonstrates superior performance across most detection categories, achieving higher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score (0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8% faster). These results indicate that RCBEV-KAN i",
    "link": "https://arxiv.org/abs/2408.02088",
    "context": "Title: KAN-RCBEVDepth: A multi-modal fusion algorithm in object detection for autonomous driving\nAbstract: arXiv:2408.02088v1 Announce Type: cross  Abstract: Accurate 3D object detection in autonomous driving is critical yet challenging due to occlusions, varying object scales, and complex urban environments. This paper introduces the RCBEV-KAN algorithm, a pioneering method designed to enhance 3D object detection by fusing multimodal sensor data from cameras, LiDAR, and millimeter-wave radar. Our innovative Bird's Eye View (BEV)-based approach, utilizing a Transformer architecture, significantly boosts detection precision and efficiency by seamlessly integrating diverse data sources, improving spatial relationship handling, and optimizing computational processes. Experimental results show that the RCBEV-KAN model demonstrates superior performance across most detection categories, achieving higher Mean Distance AP (0.389 vs. 0.316, a 23% improvement), better ND Score (0.484 vs. 0.415, a 17% improvement), and faster Evaluation Time (71.28s, 8% faster). These results indicate that RCBEV-KAN i",
    "path": "papers/24/08/2408.02088.json",
    "total_tokens": 754,
    "translated_title": "KAN-RCBEV深度：基于自动驾驶的多模态融合算法",
    "translated_abstract": "arXiv:2408.02088v1 声明类型：交叉  摘要：自动驾驶中的准确三维物体检测因为遮挡、物体规模的变化以及复杂的城市环境而极具挑战。本文介绍了一种名为RCBEV-KAN的创新算法，该算法旨在通过融合来自摄像头、激光雷达和毫米波雷达的多模态传感器数据来提高三维物体检测的准确性。我们的创新鸟瞰视图(BEV)基",
    "tldr": "本文提出了RCBEV-KAN算法，一种融合摄像头、激光雷达和毫米波雷达数据的全新算法，旨在提高自动驾驶车辆的3D物体检测精度。"
}