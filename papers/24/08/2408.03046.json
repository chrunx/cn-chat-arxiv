{
    "title": "Comb, Prune, Distill: Towards Unified Pruning for Vision Model Compression",
    "abstract": "arXiv:2408.03046v1 Announce Type: new  Abstract: Lightweight and effective models are essential for devices with limited resources, such as intelligent vehicles. Structured pruning offers a promising approach to model compression and efficiency enhancement. However, existing methods often tie pruning techniques to specific model architectures or vision tasks. To address this limitation, we propose a novel unified pruning framework Comb, Prune, Distill (CPD), which addresses both model-agnostic and task-agnostic concerns simultaneously. Our framework employs a combing step to resolve hierarchical layer-wise dependency issues, enabling architecture independence. Additionally, the pruning pipeline adaptively remove parameters based on the importance scoring metrics regardless of vision tasks. To support the model in retaining its learned information, we introduce knowledge distillation during the pruning step. Extensive experiments demonstrate the generalizability of our framework, encomp",
    "link": "https://arxiv.org/abs/2408.03046",
    "context": "Title: Comb, Prune, Distill: Towards Unified Pruning for Vision Model Compression\nAbstract: arXiv:2408.03046v1 Announce Type: new  Abstract: Lightweight and effective models are essential for devices with limited resources, such as intelligent vehicles. Structured pruning offers a promising approach to model compression and efficiency enhancement. However, existing methods often tie pruning techniques to specific model architectures or vision tasks. To address this limitation, we propose a novel unified pruning framework Comb, Prune, Distill (CPD), which addresses both model-agnostic and task-agnostic concerns simultaneously. Our framework employs a combing step to resolve hierarchical layer-wise dependency issues, enabling architecture independence. Additionally, the pruning pipeline adaptively remove parameters based on the importance scoring metrics regardless of vision tasks. To support the model in retaining its learned information, we introduce knowledge distillation during the pruning step. Extensive experiments demonstrate the generalizability of our framework, encomp",
    "path": "papers/24/08/2408.03046.json",
    "total_tokens": 327,
    "tldr": "该文章提出的CPD框架通过集成层次依赖问题解决的“comb”步骤，实现了模型结构无关的层级依赖突破，并通过适应性去除参数和知识蒸馏的方法保证了在去除冗余参数的同时保持了模型的学习信息，从而使模型压缩更加高效和通用。"
}