{
    "title": "Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation",
    "abstract": "arXiv:2408.03533v1 Announce Type: cross  Abstract: We primarily focus on the field of large language models (LLMs) for recommendation, which has been actively explored recently and poses a significant challenge in effectively enhancing recommender systems with logical reasoning abilities and open-world knowledge. Current mainstream efforts mainly center around injecting personalized information from recommendation models into LLMs by customizing input templates or aligning representations between semantic and recommendation spaces at the prediction layer. However, they face three significant limitations: (1) LoRA is mostly used as a core component in existing works, but personalization is not well established in LoRA parameters as the LoRA matrix shared by every user may not cater to different users' characteristics, leading to suboptimal performance. (2) Although lifelong personalized behavior sequences are ideal for personalization, their use raises effectiveness and efficiency issue",
    "link": "https://arxiv.org/abs/2408.03533",
    "context": "Title: Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation\nAbstract: arXiv:2408.03533v1 Announce Type: cross  Abstract: We primarily focus on the field of large language models (LLMs) for recommendation, which has been actively explored recently and poses a significant challenge in effectively enhancing recommender systems with logical reasoning abilities and open-world knowledge. Current mainstream efforts mainly center around injecting personalized information from recommendation models into LLMs by customizing input templates or aligning representations between semantic and recommendation spaces at the prediction layer. However, they face three significant limitations: (1) LoRA is mostly used as a core component in existing works, but personalization is not well established in LoRA parameters as the LoRA matrix shared by every user may not cater to different users' characteristics, leading to suboptimal performance. (2) Although lifelong personalized behavior sequences are ideal for personalization, their use raises effectiveness and efficiency issue",
    "path": "papers/24/08/2408.03533.json",
    "total_tokens": 328,
    "tldr": "该文章提出了一种 lifelong personalized low-rank adaptation (LPALA) 方法，将大规模语言模型应用于推荐系统中，通过在低秩分解的参数上进行 lifetime adaptation，实现了个性化的提高，同时保持了推理效率，从而在推荐系统中实现了更高的个性化水平。"
}