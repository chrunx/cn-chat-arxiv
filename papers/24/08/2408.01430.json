{
    "title": "SUSTechGAN: Image Generation for Object Recognition in Adverse Conditions of Autonomous Driving",
    "abstract": "arXiv:2408.01430v1 Announce Type: cross  Abstract: Autonomous driving significantly benefits from data-driven deep neural networks. However, the data in autonomous driving typically fits the long-tailed distribution, in which the critical driving data in adverse conditions is hard to collect. Although generative adversarial networks (GANs) have been applied to augment data for autonomous driving, generating driving images in adverse conditions is still challenging. In this work, we propose a novel SUSTechGAN with dual attention modules and multi-scale generators to generate driving images for improving object recognition of autonomous driving in adverse conditions. We test the SUSTechGAN and the existing well-known GANs to generate driving images in adverse conditions of rain and night and apply the generated images to retrain object recognition networks. Specifically, we add generated images into the training datasets to retrain the well-known YOLOv5 and evaluate the improvement of th",
    "link": "https://arxiv.org/abs/2408.01430",
    "context": "Title: SUSTechGAN: Image Generation for Object Recognition in Adverse Conditions of Autonomous Driving\nAbstract: arXiv:2408.01430v1 Announce Type: cross  Abstract: Autonomous driving significantly benefits from data-driven deep neural networks. However, the data in autonomous driving typically fits the long-tailed distribution, in which the critical driving data in adverse conditions is hard to collect. Although generative adversarial networks (GANs) have been applied to augment data for autonomous driving, generating driving images in adverse conditions is still challenging. In this work, we propose a novel SUSTechGAN with dual attention modules and multi-scale generators to generate driving images for improving object recognition of autonomous driving in adverse conditions. We test the SUSTechGAN and the existing well-known GANs to generate driving images in adverse conditions of rain and night and apply the generated images to retrain object recognition networks. Specifically, we add generated images into the training datasets to retrain the well-known YOLOv5 and evaluate the improvement of th",
    "path": "papers/24/08/2408.01430.json",
    "total_tokens": 631,
    "translated_title": "深圳科技大学GAN: 改善自动驾驶在不利条件下的对象识别图像生成",
    "translated_abstract": "arXiv:2408.01430v1 宣布类型: 交叉 摘要: 自驾驶车显著受益于基于数据的深度神经网络。然而，自动驾驶车的数据通常符合长尾分布，其中关键的驾驶数据在不利条件下难以收集。尽管生成对抗性网络（GANs）已经被应用到为自动驾驶车添加数据，但生成不利条件下的驾驶图像仍然是一个挑战。在本工作中，我们提出了一种新型的深圳科技大学GAN，它具有双重注意模块和多尺度生成器，用于生成图像以改善在不利条件下的自动驾驶车辆对象识别能力。我们测试了深圳科技大学GAN和现有的知名GAN，以确保在雨天和夜晚等不利条件下生成驾驶图像，并将生成的图像应用到重新训练对象识别网络中。具体来说，我们将生成的图像加入到训练数据集中，重新训练著名的YOLOv5，并评估了图像改进对象识别网络的效果。",
    "tldr": "深圳科技大学提出的GAN模型增强了在不利条件下自动驾驶车辆对象识别的能力，通过生成图像增加了训练数据的多样性。"
}