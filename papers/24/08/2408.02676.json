{
    "title": "On Biases in a UK Biobank-based Retinal Image Classification Model",
    "abstract": "arXiv:2408.02676v1 Announce Type: cross  Abstract: Recent work has uncovered alarming disparities in the performance of machine learning models in healthcare. In this study, we explore whether such disparities are present in the UK Biobank fundus retinal images by training and evaluating a disease classification model on these images. We assess possible disparities across various population groups and find substantial differences despite strong overall performance of the model. In particular, we discover unfair performance for certain assessment centres, which is surprising given the rigorous data standardisation protocol. We compare how these differences emerge and apply a range of existing bias mitigation methods to each one. A key insight is that each disparity has unique properties and responds differently to the mitigation methods. We also find that these methods are largely unable to enhance fairness, highlighting the need for better bias mitigation methods tailored to the specif",
    "link": "https://arxiv.org/abs/2408.02676",
    "context": "Title: On Biases in a UK Biobank-based Retinal Image Classification Model\nAbstract: arXiv:2408.02676v1 Announce Type: cross  Abstract: Recent work has uncovered alarming disparities in the performance of machine learning models in healthcare. In this study, we explore whether such disparities are present in the UK Biobank fundus retinal images by training and evaluating a disease classification model on these images. We assess possible disparities across various population groups and find substantial differences despite strong overall performance of the model. In particular, we discover unfair performance for certain assessment centres, which is surprising given the rigorous data standardisation protocol. We compare how these differences emerge and apply a range of existing bias mitigation methods to each one. A key insight is that each disparity has unique properties and responds differently to the mitigation methods. We also find that these methods are largely unable to enhance fairness, highlighting the need for better bias mitigation methods tailored to the specif",
    "path": "papers/24/08/2408.02676.json",
    "total_tokens": 390,
    "tldr": "该文章发现并分析了英国生物银行数据库中基于眼底图像的疾病分类模型存在的巨大偏差问题，即使在整体模型表现出色的情况下，不同评估中心的个体仍然面临显著的不公平表现。这项研究不仅揭示了数据标准化过程中潜在的歧视问题，而且对比了多种现有偏差缓解方法的适用性，发现针对不同的偏差问题，不同的缓解方法效果差异甚大，这表明需要开发针对特定问题定制化的缓解偏差的方法。研究最终表明，当前的缓解手段在提高模型的公平性方面效果有限，进一步强调了对公平性算法的高要求和继续研究的重要性。"
}