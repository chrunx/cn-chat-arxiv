{
    "title": "Communication-Aware Consistent Edge Selection for Mobile Users and Autonomous Vehicles",
    "abstract": "arXiv:2408.03435v1 Announce Type: cross  Abstract: Offloading time-sensitive, computationally intensive tasks-such as advanced learning algorithms for autonomous driving-from vehicles to nearby edge servers, vehicle-to-infrastructure (V2I) systems, or other collaborating vehicles via vehicle-to-vehicle (V2V) communication enhances service efficiency. However, whence traversing the path to the destination, the vehicle's mobility necessitates frequent handovers among the access points (APs) to maintain continuous and uninterrupted wireless connections to maintain the network's Quality of Service (QoS). These frequent handovers subsequently lead to task migrations among the edge servers associated with the respective APs. This paper addresses the joint problem of task migration and access-point handover by proposing a deep reinforcement learning framework based on the Deep Deterministic Policy Gradient (DDPG) algorithm. A joint allocation method of communication and computation of APs is ",
    "link": "https://arxiv.org/abs/2408.03435",
    "context": "Title: Communication-Aware Consistent Edge Selection for Mobile Users and Autonomous Vehicles\nAbstract: arXiv:2408.03435v1 Announce Type: cross  Abstract: Offloading time-sensitive, computationally intensive tasks-such as advanced learning algorithms for autonomous driving-from vehicles to nearby edge servers, vehicle-to-infrastructure (V2I) systems, or other collaborating vehicles via vehicle-to-vehicle (V2V) communication enhances service efficiency. However, whence traversing the path to the destination, the vehicle's mobility necessitates frequent handovers among the access points (APs) to maintain continuous and uninterrupted wireless connections to maintain the network's Quality of Service (QoS). These frequent handovers subsequently lead to task migrations among the edge servers associated with the respective APs. This paper addresses the joint problem of task migration and access-point handover by proposing a deep reinforcement learning framework based on the Deep Deterministic Policy Gradient (DDPG) algorithm. A joint allocation method of communication and computation of APs is ",
    "path": "papers/24/08/2408.03435.json",
    "total_tokens": 418,
    "tldr": "该文章提出了一种基于深度确定性策略梯度（DDPG）算法的强化学习框架，用于解决在移动车辆中，时间敏感且计算密集型的任务从车辆迁移到附近的边缘服务器、V2I系统或通过V2V通信的其他协作车辆时，频繁的网络访问点（AP）手操作和任务迁移造成的服务效率问题。这种方法旨在通过协同优化通信和计算资源，来提高服务质量，并减少由于频繁切换和网络重连导致的延迟。通过这种方式，该框架有助于保持连续的网络连接，并提高了移动环境中任务执行的效率和稳定性。"
}