{
    "title": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants",
    "abstract": "arXiv:2408.02373v1 Announce Type: new  Abstract: Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields stron",
    "link": "https://arxiv.org/abs/2408.02373",
    "context": "Title: Operationalizing Contextual Integrity in Privacy-Conscious Assistants\nAbstract: arXiv:2408.02373v1 Announce Type: new  Abstract: Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields stron",
    "path": "papers/24/08/2408.02373.json",
    "total_tokens": 307,
    "tldr": "该文章提出将\"上下文完整性\"框架应用于隐私敏感的助手，以指导其信息共享行为遵循隐私保护原则，并通过实验展示了该方法的有效性。"
}