{
    "title": "Operationalizing Contextual Integrity in Privacy-Conscious Assistants",
    "abstract": "arXiv:2408.02373v1 Announce Type: new  Abstract: Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields stron",
    "link": "https://arxiv.org/abs/2408.02373",
    "context": "Title: Operationalizing Contextual Integrity in Privacy-Conscious Assistants\nAbstract: arXiv:2408.02373v1 Announce Type: new  Abstract: Advanced AI assistants combine frontier LLMs and tool access to autonomously perform complex tasks on behalf of users. While the helpfulness of such assistants can increase dramatically with access to user information including emails and documents, this raises privacy concerns about assistants sharing inappropriate information with third parties without user supervision. To steer information-sharing assistants to behave in accordance with privacy expectations, we propose to operationalize $\\textit{contextual integrity}$ (CI), a framework that equates privacy with the appropriate flow of information in a given context. In particular, we design and evaluate a number of strategies to steer assistants' information-sharing actions to be CI compliant. Our evaluation is based on a novel form filling benchmark composed of synthetic data and human annotations, and it reveals that prompting frontier LLMs to perform CI-based reasoning yields stron",
    "path": "papers/24/08/2408.02373.json",
    "total_tokens": 608,
    "translated_title": "《在隐私意识驱动的助手操作上下文完整性》",
    "translated_abstract": "arXiv:2408.02373v1 公告类型：新发布 概要：高级人工智能助手结合了前沿的自然语言模型和工具访问权限，能够在无需用户监督的情况下自动执行复杂的任务。然而，助手有访问用户信息（如电子邮件和文档）的能力，这提高了隐私担忧。为了引导信息共享助手的行为符合隐私期望，本文提出了一种将“上下文完整性”（CI）框架应用于信息流，该框架认为隐私是根据特定上下文适当的信息流动。特别是，我们设计并评估了多种指导助手信息共享行为的CI合规策略。我们的评估基于一个由合成数据和人工注释组成的新的表单填写基准，结果显示，提示前沿的自然语言模型执行CI基础的推理，能够实现更好的合规性。",
    "tldr": "本文提出了一种通过将上下文完整性框架应用于信息流，以指导信息共享助手的行为，实现用户隐私的合规性。",
    "en_tdlr": "This paper proposes a strategy to steer the behavior of information-sharing AI assistants towards compliance with users' privacy expectations by operationalizing the Contextual Integrity framework, which equates privacy with the appropriate flow of information within a given context."
}