{
    "title": "Backward explanations via redefinition of predicates",
    "abstract": "arXiv:2408.02606v1 Announce Type: new  Abstract: History eXplanation based on Predicates (HXP), studies the behavior of a Reinforcement Learning (RL) agent in a sequence of agent's interactions with the environment (a history), through the prism of an arbitrary predicate. To this end, an action importance score is computed for each action in the history. The explanation consists in displaying the most important actions to the user. As the calculation of an action's importance is #W[1]-hard, it is necessary for long histories to approximate the scores, at the expense of their quality. We therefore propose a new HXP method, called Backward-HXP, to provide explanations for these histories without having to approximate scores. Experiments show the ability of B-HXP to summarise long histories.",
    "link": "https://arxiv.org/abs/2408.02606",
    "context": "Title: Backward explanations via redefinition of predicates\nAbstract: arXiv:2408.02606v1 Announce Type: new  Abstract: History eXplanation based on Predicates (HXP), studies the behavior of a Reinforcement Learning (RL) agent in a sequence of agent's interactions with the environment (a history), through the prism of an arbitrary predicate. To this end, an action importance score is computed for each action in the history. The explanation consists in displaying the most important actions to the user. As the calculation of an action's importance is #W[1]-hard, it is necessary for long histories to approximate the scores, at the expense of their quality. We therefore propose a new HXP method, called Backward-HXP, to provide explanations for these histories without having to approximate scores. Experiments show the ability of B-HXP to summarise long histories.",
    "path": "papers/24/08/2408.02606.json",
    "total_tokens": 297,
    "tldr": "该文章提出了一种名为Backward-HXP的新历史解释方法，该方法无需对历史行为进行近似近似，就能够为长期历史提供更准确的解释。"
}