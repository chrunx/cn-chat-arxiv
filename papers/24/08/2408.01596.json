{
    "title": "Trustworthy Machine Learning under Social and Adversarial Data Sources",
    "abstract": "arXiv:2408.01596v1 Announce Type: cross  Abstract: Machine learning has witnessed remarkable breakthroughs in recent years. As machine learning permeates various aspects of daily life, individuals and organizations increasingly interact with these systems, exhibiting a wide range of social and adversarial behaviors. These behaviors may have a notable impact on the behavior and performance of machine learning systems. Specifically, during these interactions, data may be generated by strategic individuals, collected by self-interested data collectors, possibly poisoned by adversarial attackers, and used to create predictors, models, and policies satisfying multiple objectives. As a result, the machine learning systems' outputs might degrade, such as the susceptibility of deep neural networks to adversarial examples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished performance of classic algorithms in the presence of strategic individuals (Ahmadi et al., 2021). Addressing th",
    "link": "https://arxiv.org/abs/2408.01596",
    "context": "Title: Trustworthy Machine Learning under Social and Adversarial Data Sources\nAbstract: arXiv:2408.01596v1 Announce Type: cross  Abstract: Machine learning has witnessed remarkable breakthroughs in recent years. As machine learning permeates various aspects of daily life, individuals and organizations increasingly interact with these systems, exhibiting a wide range of social and adversarial behaviors. These behaviors may have a notable impact on the behavior and performance of machine learning systems. Specifically, during these interactions, data may be generated by strategic individuals, collected by self-interested data collectors, possibly poisoned by adversarial attackers, and used to create predictors, models, and policies satisfying multiple objectives. As a result, the machine learning systems' outputs might degrade, such as the susceptibility of deep neural networks to adversarial examples (Shafahi et al., 2018; Szegedy et al., 2013) and the diminished performance of classic algorithms in the presence of strategic individuals (Ahmadi et al., 2021). Addressing th",
    "path": "papers/24/08/2408.01596.json",
    "total_tokens": 374,
    "tldr": "该文章研究了在社交媒体和对抗性数据源环境中进行可靠机器学习的重要性。文章探讨了如何在数据收集、处理和使用过程中考虑多种社会行为和对抗性攻击，以及这些因素如何影响机器学习模型的性能。文章提出了一种新的方法，旨在创建能够对抗社交和对抗性数据源影响的安全机器学习模型，并将其应用于多种预测、模型和政策制定场景中。"
}