{
    "title": "Generalized Maximum Likelihood Estimation for Perspective-n-Point Problem",
    "abstract": "arXiv:2408.01945v1 Announce Type: cross  Abstract: The Perspective-n-Point (PnP) problem has been widely studied in the literature and applied in various vision-based pose estimation scenarios. However, existing methods ignore the anisotropy uncertainty of observations, as demonstrated in several real-world datasets in this paper. This oversight may lead to suboptimal and inaccurate estimation, particularly in the presence of noisy observations. To this end, we propose a generalized maximum likelihood PnP solver, named GMLPnP, that minimizes the determinant criterion by iterating the GLS procedure to estimate the pose and uncertainty simultaneously. Further, the proposed method is decoupled from the camera model. Results of synthetic and real experiments show that our method achieves better accuracy in common pose estimation scenarios, GMLPnP improves rotation/translation accuracy by 4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best baseline. It is more ac",
    "link": "https://arxiv.org/abs/2408.01945",
    "context": "Title: Generalized Maximum Likelihood Estimation for Perspective-n-Point Problem\nAbstract: arXiv:2408.01945v1 Announce Type: cross  Abstract: The Perspective-n-Point (PnP) problem has been widely studied in the literature and applied in various vision-based pose estimation scenarios. However, existing methods ignore the anisotropy uncertainty of observations, as demonstrated in several real-world datasets in this paper. This oversight may lead to suboptimal and inaccurate estimation, particularly in the presence of noisy observations. To this end, we propose a generalized maximum likelihood PnP solver, named GMLPnP, that minimizes the determinant criterion by iterating the GLS procedure to estimate the pose and uncertainty simultaneously. Further, the proposed method is decoupled from the camera model. Results of synthetic and real experiments show that our method achieves better accuracy in common pose estimation scenarios, GMLPnP improves rotation/translation accuracy by 4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best baseline. It is more ac",
    "path": "papers/24/08/2408.01945.json",
    "total_tokens": 710,
    "translated_title": "仿射n点问题广义最大似然估计",
    "translated_abstract": "arXiv:2408.01945v1 公告类型: 交叉 摘要: 视图n个点(PnP)问题在文献中得到了广泛的研究，并在各种基于视觉的姿态估计场景中得到了应用。然而，本文在几个现实世界的数据集中展示了现有方法的不足之处，这些方法忽略了观测数据的各向异性不确定性。这种忽视可能导致在存在噪声观测值的情况下得出次优和不准确的估计。因此，我们提出了一种广义最大似然PnP求解器，名为GMLPnP，它通过迭代GLS程序来同时估计姿态和不确定性。此外，所提出的方法与相机模型无关。合成和真实实验结果表明，我们的方法在常见的姿态估计情景中取得了更好的精度，与最佳基准方法相比，GMLPnP在TUM-RGBD和KITTI-360数据集上的旋转/平移精度分别提高了4.7%/2.0%和18.6%/18.4%。它对噪声的鲁棒性更好，对参数的估计也更准确。",
    "tldr": "该研究提出了一个广义最大似然估计的PnP求解器，提高了对噪声数据的鲁棒性，并在多种姿势估计场景中提供了更准确的参数估计。"
}