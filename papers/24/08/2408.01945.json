{
    "title": "Generalized Maximum Likelihood Estimation for Perspective-n-Point Problem",
    "abstract": "arXiv:2408.01945v1 Announce Type: cross  Abstract: The Perspective-n-Point (PnP) problem has been widely studied in the literature and applied in various vision-based pose estimation scenarios. However, existing methods ignore the anisotropy uncertainty of observations, as demonstrated in several real-world datasets in this paper. This oversight may lead to suboptimal and inaccurate estimation, particularly in the presence of noisy observations. To this end, we propose a generalized maximum likelihood PnP solver, named GMLPnP, that minimizes the determinant criterion by iterating the GLS procedure to estimate the pose and uncertainty simultaneously. Further, the proposed method is decoupled from the camera model. Results of synthetic and real experiments show that our method achieves better accuracy in common pose estimation scenarios, GMLPnP improves rotation/translation accuracy by 4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best baseline. It is more ac",
    "link": "https://arxiv.org/abs/2408.01945",
    "context": "Title: Generalized Maximum Likelihood Estimation for Perspective-n-Point Problem\nAbstract: arXiv:2408.01945v1 Announce Type: cross  Abstract: The Perspective-n-Point (PnP) problem has been widely studied in the literature and applied in various vision-based pose estimation scenarios. However, existing methods ignore the anisotropy uncertainty of observations, as demonstrated in several real-world datasets in this paper. This oversight may lead to suboptimal and inaccurate estimation, particularly in the presence of noisy observations. To this end, we propose a generalized maximum likelihood PnP solver, named GMLPnP, that minimizes the determinant criterion by iterating the GLS procedure to estimate the pose and uncertainty simultaneously. Further, the proposed method is decoupled from the camera model. Results of synthetic and real experiments show that our method achieves better accuracy in common pose estimation scenarios, GMLPnP improves rotation/translation accuracy by 4.7%/2.0% on TUM-RGBD and 18.6%/18.4% on KITTI-360 dataset compared to the best baseline. It is more ac",
    "path": "papers/24/08/2408.01945.json",
    "total_tokens": 351,
    "tldr": "该文章提出了一种考虑观测不确定性同时估计姿态和不确定性的PnP问题求解方法，该方法的准确性在多种真实世界场景中得到了提升，尤其是在具有噪声数据的应用场景中。"
}