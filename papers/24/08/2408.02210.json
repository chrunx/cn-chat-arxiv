{
    "title": "ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning",
    "abstract": "arXiv:2408.02210v1 Announce Type: new  Abstract: Compositional visual reasoning methods, which translate a complex query into a structured composition of feasible visual tasks, have exhibited a strong potential in complicated multi-modal tasks. Empowered by recent advances in large language models (LLMs), this multi-modal challenge has been brought to a new stage by treating LLMs as few-shot/zero-shot planners, i.e., vision-language (VL) programming. Such methods, despite their numerous merits, suffer from challenges due to LLM planning mistakes or inaccuracy of visual execution modules, lagging behind the non-compositional models. In this work, we devise a \"plug-and-play\" method, ExoViP, to correct errors in both the planning and execution stages through introspective verification. We employ verification modules as \"exoskeletons\" to enhance current VL programming schemes. Specifically, our proposed verification module utilizes a mixture of three sub-verifiers to validate predictions a",
    "link": "https://arxiv.org/abs/2408.02210",
    "context": "Title: ExoViP: Step-by-step Verification and Exploration with Exoskeleton Modules for Compositional Visual Reasoning\nAbstract: arXiv:2408.02210v1 Announce Type: new  Abstract: Compositional visual reasoning methods, which translate a complex query into a structured composition of feasible visual tasks, have exhibited a strong potential in complicated multi-modal tasks. Empowered by recent advances in large language models (LLMs), this multi-modal challenge has been brought to a new stage by treating LLMs as few-shot/zero-shot planners, i.e., vision-language (VL) programming. Such methods, despite their numerous merits, suffer from challenges due to LLM planning mistakes or inaccuracy of visual execution modules, lagging behind the non-compositional models. In this work, we devise a \"plug-and-play\" method, ExoViP, to correct errors in both the planning and execution stages through introspective verification. We employ verification modules as \"exoskeletons\" to enhance current VL programming schemes. Specifically, our proposed verification module utilizes a mixture of three sub-verifiers to validate predictions a",
    "path": "papers/24/08/2408.02210.json",
    "total_tokens": 813,
    "translated_title": "ExoViP: 逐步验证与探索与外骨骼模块结合的构成性视觉推理",
    "translated_abstract": "在这里，arXiv:2408.02210v1 宣布类型为新。摘要：构成性视觉推理方法，能够将复杂的查询转换为可行的视觉任务的结构化组合，已经在复杂的跨模态任务上显示出强大的潜力。在大型语言模型（LLM）的最新进展的推动下，这种多模态挑战已经通过将LLM视为少样本/零样本规划者，即视觉-语言（VL）编程，达到一个新的阶段。尽管这些方法拥有许多优点，但它们也面临挑战，因为LLM规划错误或视觉执行模块的不准确，这使它们落后于非构成性模型。在本工作中，我们提出了“即插即用”的ExoViP方法，通过自我反省的验证来纠正规划和管理阶段中的错误。我们利用验证模块作为“外骨骼”来增强当前的VL编程方案。具体来说，我们提出的验证模块使用了三种子验证器来验证预测的准确性，并确保推理过程的可靠性。我们的方法通过引入外骨骼模块，不仅从错误中恢复，而且在外骨骼模块错误的情况下重新设计决策过程，从而显著提高了VL编程方案的可靠性和准确性。实验结果表明，在多个标准数据集上，ExoViP方法在正确执行指定的视觉任务和处理规划错误方面优于现有的方法。此外，我们演示了ExoViP不仅可以应用于视觉推理，还可以推广到其他多模态任务，从而为视觉语言编程提供了强大的赋能工具。",
    "tldr": "ExoViP是一种新方法，通过验证模块的辅助，能够改善视觉语言编程方案中规划与执行错误的问题，确保任务的正确执行和决策过程的设计。"
}