{
    "title": "Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers",
    "abstract": "arXiv:2408.01705v1 Announce Type: new  Abstract: With the advancement of vision transformers (ViTs) and self-supervised learning (SSL) techniques, pre-trained large ViTs have become the new foundation models for computer vision applications. However, studies have shown that, like convolutional neural networks (CNNs), ViTs are also susceptible to adversarial attacks, where subtle perturbations in the input can fool the model into making false predictions. This paper studies the transferability of such an adversarial vulnerability from a pre-trained ViT model to downstream tasks. We focus on \\emph{sample-wise} transfer attacks and propose a novel attack method termed \\emph{Downstream Transfer Attack (DTA)}. For a given test image, DTA leverages a pre-trained ViT model to craft the adversarial example and then applies the adversarial example to attack a fine-tuned version of the model on a downstream dataset. During the attack, DTA identifies and exploits the most vulnerable layers of the",
    "link": "https://arxiv.org/abs/2408.01705",
    "context": "Title: Downstream Transfer Attack: Adversarial Attacks on Downstream Models with Pre-trained Vision Transformers\nAbstract: arXiv:2408.01705v1 Announce Type: new  Abstract: With the advancement of vision transformers (ViTs) and self-supervised learning (SSL) techniques, pre-trained large ViTs have become the new foundation models for computer vision applications. However, studies have shown that, like convolutional neural networks (CNNs), ViTs are also susceptible to adversarial attacks, where subtle perturbations in the input can fool the model into making false predictions. This paper studies the transferability of such an adversarial vulnerability from a pre-trained ViT model to downstream tasks. We focus on \\emph{sample-wise} transfer attacks and propose a novel attack method termed \\emph{Downstream Transfer Attack (DTA)}. For a given test image, DTA leverages a pre-trained ViT model to craft the adversarial example and then applies the adversarial example to attack a fine-tuned version of the model on a downstream dataset. During the attack, DTA identifies and exploits the most vulnerable layers of the",
    "path": "papers/24/08/2408.01705.json",
    "total_tokens": 378,
    "tldr": "该文章提出了一种名为“下游转移攻击”（DTA）的全新攻击方法，利用预训练的视觉变换器模型生成的样本级对抗样本攻击下游任务中的自适应模型。通过这种方式，即使是同一个输入图片，也可以针对不同的任务生成不同的对抗样本。此方法旨在解决预训练模型在特定下游任务上的对抗性攻击问题。"
}