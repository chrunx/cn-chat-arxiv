{
    "title": "MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from Multi-Cylindrical Panoramas",
    "abstract": "arXiv:2408.01653v1 Announce Type: new  Abstract: We introduce Multi-Cylindrical Panoramic Depth Estimation (MCPDepth), a two-stage framework for omnidirectional depth estimation via stereo matching between multiple cylindrical panoramas. MCPDepth uses cylindrical panoramas for initial stereo matching and then fuses the resulting depth maps across views. A circular attention module is employed to overcome the distortion along the vertical axis. MCPDepth exclusively utilizes standard network components, simplifying deployment to embedded devices and outperforming previous methods that require custom kernels. We theoretically and experimentally compare spherical and cylindrical projections for stereo matching, highlighting the advantages of the cylindrical projection. MCPDepth achieves state-of-the-art performance with an 18.8% reduction in mean absolute error (MAE) for depth on the outdoor synthetic dataset Deep360 and a 19.9% reduction on the indoor real-scene dataset 3D60.",
    "link": "https://arxiv.org/abs/2408.01653",
    "context": "Title: MCPDepth: Omnidirectional Depth Estimation via Stereo Matching from Multi-Cylindrical Panoramas\nAbstract: arXiv:2408.01653v1 Announce Type: new  Abstract: We introduce Multi-Cylindrical Panoramic Depth Estimation (MCPDepth), a two-stage framework for omnidirectional depth estimation via stereo matching between multiple cylindrical panoramas. MCPDepth uses cylindrical panoramas for initial stereo matching and then fuses the resulting depth maps across views. A circular attention module is employed to overcome the distortion along the vertical axis. MCPDepth exclusively utilizes standard network components, simplifying deployment to embedded devices and outperforming previous methods that require custom kernels. We theoretically and experimentally compare spherical and cylindrical projections for stereo matching, highlighting the advantages of the cylindrical projection. MCPDepth achieves state-of-the-art performance with an 18.8% reduction in mean absolute error (MAE) for depth on the outdoor synthetic dataset Deep360 and a 19.9% reduction on the indoor real-scene dataset 3D60.",
    "path": "papers/24/08/2408.01653.json",
    "total_tokens": 428,
    "tldr": "该文章提出了MCPDepth框架，通过在多幅圆柱形全景图之间的立体匹配进行全方位深度估计，并且通过融合不同视角的深度图来提高准确度。该方法使用了一种环形注意力机制来缓解垂直方向上的失真问题，并使用标准网络组件简化了在嵌入式设备上的部署，同时在不需要定制内核的情况下，在3D60和Deep360数据集上显著提高了深度估计的精度，相对于前人方法分别减少了18.8%和19.9%的均方误差。"
}