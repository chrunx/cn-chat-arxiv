{
    "title": "FPT+: A Parameter and Memory Efficient Transfer Learning Method for High-resolution Medical Image Classification",
    "abstract": "arXiv:2408.02426v1 Announce Type: new  Abstract: The success of large-scale pre-trained models has established fine-tuning as a standard method for achieving significant improvements in downstream tasks. However, fine-tuning the entire parameter set of a pre-trained model is costly. Parameter-efficient transfer learning (PETL) has recently emerged as a cost-effective alternative for adapting pre-trained models to downstream tasks. Despite its advantages, the increasing model size and input resolution present challenges for PETL, as the training memory consumption is not reduced as effectively as the parameter usage. In this paper, we introduce Fine-grained Prompt Tuning plus (FPT+), a PETL method designed for high-resolution medical image classification, which significantly reduces memory consumption compared to other PETL methods. FPT+ performs transfer learning by training a lightweight side network and accessing pre-trained knowledge from a large pre-trained model (LPM) through fine",
    "link": "https://arxiv.org/abs/2408.02426",
    "context": "Title: FPT+: A Parameter and Memory Efficient Transfer Learning Method for High-resolution Medical Image Classification\nAbstract: arXiv:2408.02426v1 Announce Type: new  Abstract: The success of large-scale pre-trained models has established fine-tuning as a standard method for achieving significant improvements in downstream tasks. However, fine-tuning the entire parameter set of a pre-trained model is costly. Parameter-efficient transfer learning (PETL) has recently emerged as a cost-effective alternative for adapting pre-trained models to downstream tasks. Despite its advantages, the increasing model size and input resolution present challenges for PETL, as the training memory consumption is not reduced as effectively as the parameter usage. In this paper, we introduce Fine-grained Prompt Tuning plus (FPT+), a PETL method designed for high-resolution medical image classification, which significantly reduces memory consumption compared to other PETL methods. FPT+ performs transfer learning by training a lightweight side network and accessing pre-trained knowledge from a large pre-trained model (LPM) through fine",
    "path": "papers/24/08/2408.02426.json",
    "total_tokens": 334,
    "tldr": "该文章提出了一种名为FPT+的参数和内存高效转移学习方法，用于高分辨率医学图像分类，该方法显著降低了内存消耗，相比其他参数高效转移学习方法更为有效。"
}