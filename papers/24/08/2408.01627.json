{
    "title": "JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Language Model",
    "abstract": "arXiv:2408.01627v1 Announce Type: new  Abstract: In recent years, talking head generation has become a focal point for researchers. Considerable effort is being made to refine lip-sync motion, capture expressive facial expressions, generate natural head poses, and achieve high video quality. However, no single model has yet achieved equivalence across all these metrics. This paper aims to animate a 3D face using Jamba, a hybrid Transformers-Mamba model. Mamba, a pioneering Structured State Space Model (SSM) architecture, was designed to address the constraints of the conventional Transformer architecture. Nevertheless, it has several drawbacks. Jamba merges the advantages of both Transformer and Mamba approaches, providing a holistic solution. Based on the foundational Jamba block, we present JambaTalk to enhance motion variety and speed through multimodal integration. Extensive experiments reveal that our method achieves performance comparable or superior to state-of-the-art models.",
    "link": "https://arxiv.org/abs/2408.01627",
    "context": "Title: JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Language Model\nAbstract: arXiv:2408.01627v1 Announce Type: new  Abstract: In recent years, talking head generation has become a focal point for researchers. Considerable effort is being made to refine lip-sync motion, capture expressive facial expressions, generate natural head poses, and achieve high video quality. However, no single model has yet achieved equivalence across all these metrics. This paper aims to animate a 3D face using Jamba, a hybrid Transformers-Mamba model. Mamba, a pioneering Structured State Space Model (SSM) architecture, was designed to address the constraints of the conventional Transformer architecture. Nevertheless, it has several drawbacks. Jamba merges the advantages of both Transformer and Mamba approaches, providing a holistic solution. Based on the foundational Jamba block, we present JambaTalk to enhance motion variety and speed through multimodal integration. Extensive experiments reveal that our method achieves performance comparable or superior to state-of-the-art models.",
    "path": "papers/24/08/2408.01627.json",
    "total_tokens": 698,
    "translated_title": "JambaTalk:基于混合Transformer-Mamba语言模型的3D说话头像生成",
    "translated_abstract": "arXiv:2408.01627v1 新闻类型：新 Abstract: 近年来，说话头像生成已成为研究人员关注的焦点。人们投入了大量精力来改进唇同步运动、捕捉面部表情、生成自然头部姿态，以及实现高清视频质量。然而，到目前为止，还没有一个模型能够在所有这些指标上实现均衡。本文旨在使用Jamba，一种混合Transformer-Mamba模型的3D脸部动画。Mamba，一个开创性的结构状态空间模型（SSM）架构，被设计用来解决传统Transformer架构的限制。然而，它也有一些缺点。Jamba融合了Transformer和Mamba方法的优势，提供了一个全面的解决方案。基于Jamba的基本块，我们提出了JambaTalk，以通过多模态整合增强动作的多样性和速度。广泛的实验表明，我们的方法达到了与目前最先进模型相媲美或更优的表现。",
    "tldr": "本文介绍了一种名为JambaTalk的3D说话头像生成方法，该方法基于混合Transformer-Mamba语言模型，旨在通过提高动作多样性实现更快的速度，并在与现有最先进模型的比较中取得了出色成绩。"
}