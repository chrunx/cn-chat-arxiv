{
    "title": "Online Temporal Action Localization with Memory-Augmented Transformer",
    "abstract": "arXiv:2408.02957v1 Announce Type: new  Abstract: Online temporal action localization (On-TAL) is the task of identifying multiple action instances given a streaming video. Since existing methods take as input only a video segment of fixed size per iteration, they are limited in considering long-term context and require tuning the segment size carefully. To overcome these limitations, we propose memory-augmented transformer (MATR). MATR utilizes the memory queue that selectively preserves the past segment features, allowing to leverage long-term context for inference. We also propose a novel action localization method that observes the current input segment to predict the end time of the ongoing action and accesses the memory queue to estimate the start time of the action. Our method outperformed existing methods on two datasets, THUMOS14 and MUSES, surpassing not only TAL methods in the online setting but also some offline TAL methods.",
    "link": "https://arxiv.org/abs/2408.02957",
    "context": "Title: Online Temporal Action Localization with Memory-Augmented Transformer\nAbstract: arXiv:2408.02957v1 Announce Type: new  Abstract: Online temporal action localization (On-TAL) is the task of identifying multiple action instances given a streaming video. Since existing methods take as input only a video segment of fixed size per iteration, they are limited in considering long-term context and require tuning the segment size carefully. To overcome these limitations, we propose memory-augmented transformer (MATR). MATR utilizes the memory queue that selectively preserves the past segment features, allowing to leverage long-term context for inference. We also propose a novel action localization method that observes the current input segment to predict the end time of the ongoing action and accesses the memory queue to estimate the start time of the action. Our method outperformed existing methods on two datasets, THUMOS14 and MUSES, surpassing not only TAL methods in the online setting but also some offline TAL methods.",
    "path": "papers/24/08/2408.02957.json",
    "total_tokens": 382,
    "tldr": "该文章提出的记忆增强自注意力模块（MATR）能够利用受限于固定大小的输入视频片段来识别多个动作实例，通过记忆队列保存过去片段的特征来有效利用长期上下文信息，并提出了一种新的动作定位方法来预测动作结束时间和从记忆队列中估计动作开始时间，该方法的性能优于已存在的方法，在THUMOS14和MUSES两个数据集上均取得显著提升，甚至在某些情况下超越了某些传统的动作识别方法。"
}