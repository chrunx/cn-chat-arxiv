{
    "title": "iControl3D: An Interactive System for Controllable 3D Scene Generation",
    "abstract": "arXiv:2408.01678v1 Announce Type: new  Abstract: 3D content creation has long been a complex and time-consuming process, often requiring specialized skills and resources. While recent advancements have allowed for text-guided 3D object and scene generation, they still fall short of providing sufficient control over the generation process, leading to a gap between the user's creative vision and the generated results. In this paper, we present iControl3D, a novel interactive system that empowers users to generate and render customizable 3D scenes with precise control. To this end, a 3D creator interface has been developed to provide users with fine-grained control over the creation process. Technically, we leverage 3D meshes as an intermediary proxy to iteratively merge individual 2D diffusion-generated images into a cohesive and unified 3D scene representation. To ensure seamless integration of 3D meshes, we propose to perform boundary-aware depth alignment before fusing the newly gener",
    "link": "https://arxiv.org/abs/2408.01678",
    "context": "Title: iControl3D: An Interactive System for Controllable 3D Scene Generation\nAbstract: arXiv:2408.01678v1 Announce Type: new  Abstract: 3D content creation has long been a complex and time-consuming process, often requiring specialized skills and resources. While recent advancements have allowed for text-guided 3D object and scene generation, they still fall short of providing sufficient control over the generation process, leading to a gap between the user's creative vision and the generated results. In this paper, we present iControl3D, a novel interactive system that empowers users to generate and render customizable 3D scenes with precise control. To this end, a 3D creator interface has been developed to provide users with fine-grained control over the creation process. Technically, we leverage 3D meshes as an intermediary proxy to iteratively merge individual 2D diffusion-generated images into a cohesive and unified 3D scene representation. To ensure seamless integration of 3D meshes, we propose to perform boundary-aware depth alignment before fusing the newly gener",
    "path": "papers/24/08/2408.01678.json",
    "total_tokens": 419,
    "tldr": "该文章介绍了一个名为iControl3D的交互式系统，该系统能够允许用户在生成和渲染可自定义的3D场景时拥有精确的控制。这一创新在于通过结合3D网格和2D图像生成技术，为用户提供了一个能够精确控制3D场景创建过程的界面。此外，系统还提出了一个边界感知深度对齐的方法，确保了3D物体的无缝融合。通过这些技术，iControl3D实现了可控的3D场景生成的目标，填补了用户创意与生成结果之间控制不足的空白。"
}