{
    "title": "COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark",
    "abstract": "arXiv:2408.02272v1 Announce Type: new  Abstract: Procedural video understanding is gaining attention in the vision and language community. Deep learning-based video analysis requires extensive data. Consequently, existing works often use web videos as training resources, making it challenging to query instructional contents from raw video observations. To address this issue, we propose a new dataset, COM Kitchens. The dataset consists of unedited overhead-view videos captured by smartphones, in which participants performed food preparation based on given recipes. Fixed-viewpoint video datasets often lack environmental diversity due to high camera setup costs. We used modern wide-angle smartphone lenses to cover cooking counters from sink to cooktop in an overhead view, capturing activity without in-person assistance. With this setup, we collected a diverse dataset by distributing smartphones to participants. With this dataset, we propose the novel video-to-text retrieval task Online Re",
    "link": "https://arxiv.org/abs/2408.02272",
    "context": "Title: COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark\nAbstract: arXiv:2408.02272v1 Announce Type: new  Abstract: Procedural video understanding is gaining attention in the vision and language community. Deep learning-based video analysis requires extensive data. Consequently, existing works often use web videos as training resources, making it challenging to query instructional contents from raw video observations. To address this issue, we propose a new dataset, COM Kitchens. The dataset consists of unedited overhead-view videos captured by smartphones, in which participants performed food preparation based on given recipes. Fixed-viewpoint video datasets often lack environmental diversity due to high camera setup costs. We used modern wide-angle smartphone lenses to cover cooking counters from sink to cooktop in an overhead view, capturing activity without in-person assistance. With this setup, we collected a diverse dataset by distributing smartphones to participants. With this dataset, we propose the novel video-to-text retrieval task Online Re",
    "path": "papers/24/08/2408.02272.json",
    "total_tokens": 411,
    "tldr": "该文章提出了一个名为COM Kitchens的未经编辑的俯瞰视角视频数据集，作为视觉-语言基准。该数据集包括智能手机拍摄的不加修饰的俯瞰视角视频，其中参与者根据给定的食谱进行食物准备。通过使用现代宽角智能手机镜头覆盖从水槽到炉灶的烹饪台面，实现了活动的高效捕捉，无需直接协助。通过分发智能手机给参与者，我们搜集到了一个多样化的数据集。文章还提出了一个新颖的视频到文本检索任务Online Recipe Understanding，该任务旨在训练模型在实时环境中理解食谱中的指令。"
}