{
    "title": "COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark",
    "abstract": "arXiv:2408.02272v1 Announce Type: new  Abstract: Procedural video understanding is gaining attention in the vision and language community. Deep learning-based video analysis requires extensive data. Consequently, existing works often use web videos as training resources, making it challenging to query instructional contents from raw video observations. To address this issue, we propose a new dataset, COM Kitchens. The dataset consists of unedited overhead-view videos captured by smartphones, in which participants performed food preparation based on given recipes. Fixed-viewpoint video datasets often lack environmental diversity due to high camera setup costs. We used modern wide-angle smartphone lenses to cover cooking counters from sink to cooktop in an overhead view, capturing activity without in-person assistance. With this setup, we collected a diverse dataset by distributing smartphones to participants. With this dataset, we propose the novel video-to-text retrieval task Online Re",
    "link": "https://arxiv.org/abs/2408.02272",
    "context": "Title: COM Kitchens: An Unedited Overhead-view Video Dataset as a Vision-Language Benchmark\nAbstract: arXiv:2408.02272v1 Announce Type: new  Abstract: Procedural video understanding is gaining attention in the vision and language community. Deep learning-based video analysis requires extensive data. Consequently, existing works often use web videos as training resources, making it challenging to query instructional contents from raw video observations. To address this issue, we propose a new dataset, COM Kitchens. The dataset consists of unedited overhead-view videos captured by smartphones, in which participants performed food preparation based on given recipes. Fixed-viewpoint video datasets often lack environmental diversity due to high camera setup costs. We used modern wide-angle smartphone lenses to cover cooking counters from sink to cooktop in an overhead view, capturing activity without in-person assistance. With this setup, we collected a diverse dataset by distributing smartphones to participants. With this dataset, we propose the novel video-to-text retrieval task Online Re",
    "path": "papers/24/08/2408.02272.json",
    "total_tokens": 680,
    "translated_title": "COM厨房：作为视觉语言基准的未经编辑的上方视角视频数据集",
    "translated_abstract": "arXiv:2408.02272v1 公告类型：新  摘要：在视觉和语言社区中，程序视频理解正得到关注。基于深度学习的视频分析需要大量的数据。因此，现有的工作通常使用网上的视频作为训练资源，这在从原始视频观察中查询指导内容方面造成了挑战。为了解决这个问题，我们提出了一个新的数据集，名为COM厨房。该数据集由智能手机拍摄的未经编辑的上方视角视频组成，参与者根据给出的食谱进行食品准备。由于高额的摄像机设置成本，固定视角的视频数据集通常缺乏环境多样性。我们利用现代的宽视角智能手机镜头覆盖从水槽到炉灶的上方视角烹饪台面，无需人工帮助即可捕捉活动。通过这种设置，我们向参与者分发了智能手机，收集了一个多样化的数据集。凭借这个数据集，我们提出了新型视频到文本检索任务“即时重新体现”和“了解文本的视觉反射”为一体的挑战。",
    "tldr": "本研究提出了一项名为COM厨房的数据集，它是由智能手机拍摄的未经编辑的上方视角烹饪视频组成，旨在帮助深度学习模型在视觉和语言社区中对程序视频进行理解和分析。"
}