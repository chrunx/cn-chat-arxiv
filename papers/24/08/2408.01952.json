{
    "title": "CACE-Net: Co-guidance Attention and Contrastive Enhancement for Effective Audio-Visual Event Localization",
    "abstract": "arXiv:2408.01952v1 Announce Type: new  Abstract: The audio-visual event localization task requires identifying concurrent visual and auditory events from unconstrained videos within a network model, locating them, and classifying their category. The efficient extraction and integration of audio and visual modal information have always been challenging in this field. In this paper, we introduce CACE-Net, which differs from most existing methods that solely use audio signals to guide visual information. We propose an audio-visual co-guidance attention mechanism that allows for adaptive bi-directional cross-modal attentional guidance between audio and visual information, thus reducing inconsistencies between modalities. Moreover, we have observed that existing methods have difficulty distinguishing between similar background and event and lack the fine-grained features for event classification. Consequently, we employ background-event contrast enhancement to increase the discrimination of",
    "link": "https://arxiv.org/abs/2408.01952",
    "context": "Title: CACE-Net: Co-guidance Attention and Contrastive Enhancement for Effective Audio-Visual Event Localization\nAbstract: arXiv:2408.01952v1 Announce Type: new  Abstract: The audio-visual event localization task requires identifying concurrent visual and auditory events from unconstrained videos within a network model, locating them, and classifying their category. The efficient extraction and integration of audio and visual modal information have always been challenging in this field. In this paper, we introduce CACE-Net, which differs from most existing methods that solely use audio signals to guide visual information. We propose an audio-visual co-guidance attention mechanism that allows for adaptive bi-directional cross-modal attentional guidance between audio and visual information, thus reducing inconsistencies between modalities. Moreover, we have observed that existing methods have difficulty distinguishing between similar background and event and lack the fine-grained features for event classification. Consequently, we employ background-event contrast enhancement to increase the discrimination of",
    "path": "papers/24/08/2408.01952.json",
    "total_tokens": 358,
    "tldr": "该文章提出了一种名为CACE-Net的网络模型，它通过双向注意力机制，实现了音频信号和视频信号之间的互 guided 学习，从而提高了模态间数据的匹配效果。同时，该模型还增强了背景事件之间的对比度，使得模型能够更好地分辨相似场景中的背景事件。CACE-Net在音频视觉事件定位任务中取得了显著的性能提升。"
}