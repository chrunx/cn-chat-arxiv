{
    "title": "Rethinking Pre-trained Feature Extractor Selection in Multiple Instance Learning for Whole Slide Image Classification",
    "abstract": "arXiv:2408.01167v1 Announce Type: new  Abstract: Multiple instance learning (MIL) has become a preferred method for classifying gigapixel whole slide images (WSIs), without requiring patch label annotation. The focus of the current MIL research stream is on the embedding-based MIL approach, which involves extracting feature vectors from patches using a pre-trained feature extractor. These feature vectors are then fed into an MIL aggregator for slide-level prediction. Despite prior research suggestions on enhancing the most commonly used ResNet50 supervised model pre-trained on ImageNet-1K, there remains a lack of clear guidance on selecting the optimal feature extractor to maximize WSI performance. This study aims at addressing this gap by examining MIL feature extractors across three dimensions: pre-training dataset, backbone model, and pre-training method. Extensive experiments were carried out on the two public WSI datasets (TCGA-NSCLC and Camelyon16) using four SOTA MIL models. The",
    "link": "https://arxiv.org/abs/2408.01167",
    "context": "Title: Rethinking Pre-trained Feature Extractor Selection in Multiple Instance Learning for Whole Slide Image Classification\nAbstract: arXiv:2408.01167v1 Announce Type: new  Abstract: Multiple instance learning (MIL) has become a preferred method for classifying gigapixel whole slide images (WSIs), without requiring patch label annotation. The focus of the current MIL research stream is on the embedding-based MIL approach, which involves extracting feature vectors from patches using a pre-trained feature extractor. These feature vectors are then fed into an MIL aggregator for slide-level prediction. Despite prior research suggestions on enhancing the most commonly used ResNet50 supervised model pre-trained on ImageNet-1K, there remains a lack of clear guidance on selecting the optimal feature extractor to maximize WSI performance. This study aims at addressing this gap by examining MIL feature extractors across three dimensions: pre-training dataset, backbone model, and pre-training method. Extensive experiments were carried out on the two public WSI datasets (TCGA-NSCLC and Camelyon16) using four SOTA MIL models. The",
    "path": "papers/24/08/2408.01167.json",
    "total_tokens": 1053,
    "translated_title": "重思面向多实例学习在整张切片图像分类中的预训练特征提取器选择",
    "translated_abstract": "arXiv:2408.01167v1 通告类型: 新摘要: 对于在没有需要切片标签注释的情况下对百万像素整张切片图像 (WSIs) 进行分类，多实例学习 (MIL) 已成为一个受到青睐的方法。当前的多实例学习研究热潮集中在基于嵌入的学习方法上，该方法涉及到使用预先在 ImageNet-1K 上训练的 ResNet50 监督模型提取切片块的特征向量。这些特征向量然后被馈送到一个多实例聚合器以对整个切片进行级别预测。尽管有前导研究建议增强在 ImageNet-1K 上预训练的热门 ResNet50 模型的性能，但仍然缺乏对选择最佳特征提取器以最大化 WSI 性能的明确指导。本研究旨在通过评估基于四项最先进的 MIL 模型在两个公共 WSIs 数据集 (TCGA-NSCLC 和 Camelyon16) 上的三维度特征提取器来填补这一空白：预训练数据集、骨干模型和预训练方法。在四个 SOTA MIL 模型上进行了广泛的实验。这些特征向量然后被馈送到一个多实例聚合器以对整个切片进行级别预测。尽管有前主导研究建议增强在 ImageNet-1K 上预训练的热门 ResNet50 模型的性能，但仍然缺乏对选择最佳特征提取器以最大化 WSI 性能的明确指导。本研究旨在通过评估基于四项最先进的 MIL 模型在两个公共 WSIs 数据集 (TCGA-NSCLC 和 Camelyon16) 上的三维度特征提取器来填补这一空白：预训练数据集、骨干模型和预训练方法。在四个 SOTA MIL 模型上进行了广泛的实验。这些特征向量然后被馈送到一个多实例聚合器以对整个切片进行级别预测。尽管有前主导研究建议增强在 ImageNet-1K 上预训练的热门 ResNet50 模型的性能，但仍然缺乏对选择最佳特征提取器以最大化 WSI 性能的明确指导。本研究旨在通过评估基于四项最先进的 MIL 模型在两个公共 WSIs 数据集 (TCGA-NSCLC 和 Camelyon16) 上的三维度特征提取器来填补这一空白：预训练数据集、骨干模型和预训练方法。在四个 SOTA MIL 模型上进行了广泛的实验。",
    "tldr": "本文研究了在无须进行切片标签注释的情况下，通过多实例学习对整张切片图像进行分类的预训练特征提取器的选择问题。研究对比了多种不同类型的预训练特征提取器，并针对TCGA-NSCLC和Camelyon16两个公共数据集进行了广泛的实验。"
}