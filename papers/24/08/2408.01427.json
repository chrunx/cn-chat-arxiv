{
    "title": "Siamese Transformer Networks for Few-shot Image Classification",
    "abstract": "arXiv:2408.01427v1 Announce Type: new  Abstract: Humans exhibit remarkable proficiency in visual classification tasks, accurately recognizing and classifying new images with minimal examples. This ability is attributed to their capacity to focus on details and identify common features between previously seen and new images. In contrast, existing few-shot image classification methods often emphasize either global features or local features, with few studies considering the integration of both. To address this limitation, we propose a novel approach based on the Siamese Transformer Network (STN). Our method employs two parallel branch networks utilizing the pre-trained Vision Transformer (ViT) architecture to extract global and local features, respectively. Specifically, we implement the ViT-Small network architecture and initialize the branch networks with pre-trained model parameters obtained through self-supervised learning. We apply the Euclidean distance measure to the global featur",
    "link": "https://arxiv.org/abs/2408.01427",
    "context": "Title: Siamese Transformer Networks for Few-shot Image Classification\nAbstract: arXiv:2408.01427v1 Announce Type: new  Abstract: Humans exhibit remarkable proficiency in visual classification tasks, accurately recognizing and classifying new images with minimal examples. This ability is attributed to their capacity to focus on details and identify common features between previously seen and new images. In contrast, existing few-shot image classification methods often emphasize either global features or local features, with few studies considering the integration of both. To address this limitation, we propose a novel approach based on the Siamese Transformer Network (STN). Our method employs two parallel branch networks utilizing the pre-trained Vision Transformer (ViT) architecture to extract global and local features, respectively. Specifically, we implement the ViT-Small network architecture and initialize the branch networks with pre-trained model parameters obtained through self-supervised learning. We apply the Euclidean distance measure to the global featur",
    "path": "papers/24/08/2408.01427.json",
    "total_tokens": 666,
    "translated_title": "Siamese Transformer 网络对于少样本图像分类",
    "translated_abstract": "arXiv:2408.01427v1 宣布类型: 新 摘要: 人类在视觉分类任务中表现出非凡的效率，能够准确识别和分类新图像，需要的示例很少。这种能力归功于他们能够专注于细节并识别之前看到的和新图像之间的共同特征。相比之下，现有的少样本图像分类方法往往侧重于全局特征或局部特征，很少有研究考虑这两种特征的整合。为了解决这个限制，我们提出了一种基于 Siamese Transformer 网络(STN)的新方法。我们的方法使用两个并行分支网络，利用预训练的视觉Transformer(ViT)架构来提取全局和局部特征。特别是，我们实现了一个使用ViT-Small网络架构的网络，并使用通过自我监督学习获得预训练的模型参数对分支网络进行初始化。我们采用了欧氏距离度量来对全局特征和局部特征进行量化，并将两者结合起来，以提高少数样本图像分类的性能。在多个公开数据集上的实验结果表明，与现有的先进方法相比，我们的方法在相应少样本和单一样本条件下均取得了显著的提升。",
    "tldr": "本研究提出了基于Siamese Transformer的网络，通过提取全局和局部特征，结合了Euclidean distance measure，在少样本图像分类任务中取得了显著提升。",
    "en_tdlr": "This study proposes a Siamese Transformer network that enhances few-shot image classification by extracting global and local features and combining them using the Euclidean distance measure."
}