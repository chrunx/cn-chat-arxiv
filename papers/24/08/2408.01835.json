{
    "title": "TS-SAM: Fine-Tuning Segment-Anything Model for Downstream Tasks",
    "abstract": "arXiv:2408.01835v1 Announce Type: new  Abstract: Adapter based fine-tuning has been studied for improving the performance of SAM on downstream tasks. However, there is still a significant performance gap between fine-tuned SAMs and domain-specific models. To reduce the gap, we propose Two-Stream SAM (TS-SAM). On the one hand, inspired by the side network in Parameter-Efficient Fine-Tuning (PEFT), we designed a lightweight Convolutional Side Adapter (CSA), which integrates the powerful features from SAM into side network training for comprehensive feature fusion. On the other hand, in line with the characteristics of segmentation tasks, we designed Multi-scale Refinement Module (MRM) and Feature Fusion Decoder (FFD) to keep both the detailed and semantic features. Extensive experiments on ten public datasets from three tasks demonstrate that TS-SAM not only significantly outperforms the recently proposed SAM-Adapter and SSOM, but achieves competitive performance with the SOTA domain-spe",
    "link": "https://arxiv.org/abs/2408.01835",
    "context": "Title: TS-SAM: Fine-Tuning Segment-Anything Model for Downstream Tasks\nAbstract: arXiv:2408.01835v1 Announce Type: new  Abstract: Adapter based fine-tuning has been studied for improving the performance of SAM on downstream tasks. However, there is still a significant performance gap between fine-tuned SAMs and domain-specific models. To reduce the gap, we propose Two-Stream SAM (TS-SAM). On the one hand, inspired by the side network in Parameter-Efficient Fine-Tuning (PEFT), we designed a lightweight Convolutional Side Adapter (CSA), which integrates the powerful features from SAM into side network training for comprehensive feature fusion. On the other hand, in line with the characteristics of segmentation tasks, we designed Multi-scale Refinement Module (MRM) and Feature Fusion Decoder (FFD) to keep both the detailed and semantic features. Extensive experiments on ten public datasets from three tasks demonstrate that TS-SAM not only significantly outperforms the recently proposed SAM-Adapter and SSOM, but achieves competitive performance with the SOTA domain-spe",
    "path": "papers/24/08/2408.01835.json",
    "total_tokens": 439,
    "tldr": "该文章提出了一种名为TS-SAM的模型，它通过在下游任务中使用基于适配器的精细调节方法来改善SAM模型的性能。为了缩小与领域特定模型之间的性能差距，作者提出了一种名为多流SAM（TS-SAM）的架构，该架构结合了一种轻量级的卷积侧适配器和一种多尺度细化模块，以此整合强大的特征并与侧网络训练相结合，同时保持细节和语义特征。实验结果表明，TS-SAM在多种任务上的表现优于现有的SAM-Adapter和SSOM，并接近当前最先进的领域特定模型。"
}