{
    "title": "PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy",
    "abstract": "arXiv:2408.02412v1 Announce Type: cross  Abstract: Convolutional Neural Networks (CNNs), a prominent type of Deep Neural Networks (DNNs), have emerged as a state-of-the-art solution for solving machine learning tasks. To improve the performance and energy efficiency of CNN inference, the employment of specialized hardware accelerators is prevalent. However, CNN accelerators still face performance- and energy-efficiency challenges due to high off-chip memory (DRAM) access latency and energy, which are especially crucial for latency- and energy-constrained embedded applications. Moreover, different DRAM architectures have different profiles of access latency and energy, thus making it challenging to optimize them for high performance and energy-efficient CNN accelerators. To address this, we present PENDRAM, a novel design space exploration methodology that enables high-performance and energy-efficient CNN acceleration through a generalized DRAM data mapping policy. Specifically, it expl",
    "link": "https://arxiv.org/abs/2408.02412",
    "context": "Title: PENDRAM: Enabling High-Performance and Energy-Efficient Processing of Deep Neural Networks through a Generalized DRAM Data Mapping Policy\nAbstract: arXiv:2408.02412v1 Announce Type: cross  Abstract: Convolutional Neural Networks (CNNs), a prominent type of Deep Neural Networks (DNNs), have emerged as a state-of-the-art solution for solving machine learning tasks. To improve the performance and energy efficiency of CNN inference, the employment of specialized hardware accelerators is prevalent. However, CNN accelerators still face performance- and energy-efficiency challenges due to high off-chip memory (DRAM) access latency and energy, which are especially crucial for latency- and energy-constrained embedded applications. Moreover, different DRAM architectures have different profiles of access latency and energy, thus making it challenging to optimize them for high performance and energy-efficient CNN accelerators. To address this, we present PENDRAM, a novel design space exploration methodology that enables high-performance and energy-efficient CNN acceleration through a generalized DRAM data mapping policy. Specifically, it expl",
    "path": "papers/24/08/2408.02412.json",
    "total_tokens": 706,
    "translated_title": "论文标题：PENDRAM：通过泛化DRAM数据映射策略实现深度神经网络的高性能和能效处理",
    "translated_abstract": "论文摘要：卷积神经网络（CNNs）是深度神经网络（DNNs）中的一种流行类型，已经被证明是解决机器学习任务的关键。为了提高CNN推理的性能和能效，专用的硬件加速器变得越来越流行。然而，CNN加速器仍然面临性能和能效问题，因为离散内存（DRAM）的访问延迟和能耗很高，这对于那些对延迟和能源有严格限制的嵌入式应用程序尤其重要。此外，不同的DRAM架构有不同的访问延迟和能耗特征，这使得为高能效和高性能CNN加速器优化它们变得复杂。为了解决这个问题，我们提出了PENDRAM，一种新的设计空间探索方法，它通过泛化DRAM数据映射策略为CNN加速提供了高性能和能效。尤其是，它通过泛化DRAM数据映射策略为CNN加速提供了高性能和能效。这种方法允许在不牺牲性能和能效的情况下实现DRAM的高效访问，从而为各种类似的任务提供了坚实的基础，包括但不限于图像和视频处理。",
    "tldr": "论文的主要贡献是将通用DRAM数据映射策略引入深度学习中，以提高深度神经网络的性能和能效，为加速器的设计提供了新方法。"
}