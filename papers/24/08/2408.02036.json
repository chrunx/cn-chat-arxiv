{
    "title": "LEGO: Self-Supervised Representation Learning for Scene Text Images",
    "abstract": "arXiv:2408.02036v1 Announce Type: new  Abstract: In recent years, significant progress has been made in scene text recognition by data-driven methods. However, due to the scarcity of annotated real-world data, the training of these methods predominantly relies on synthetic data. The distribution gap between synthetic and real data constrains the further performance improvement of these methods in real-world applications. To tackle this problem, a highly promising approach is to utilize massive amounts of unlabeled real data for self-supervised training, which has been widely proven effective in many NLP and CV tasks. Nevertheless, generic self-supervised methods are unsuitable for scene text images due to their sequential nature. To address this issue, we propose a Local Explicit and Global Order-aware self-supervised representation learning method (LEGO) that accounts for the characteristics of scene text images. Inspired by the human cognitive process of learning words, which involve",
    "link": "https://arxiv.org/abs/2408.02036",
    "context": "Title: LEGO: Self-Supervised Representation Learning for Scene Text Images\nAbstract: arXiv:2408.02036v1 Announce Type: new  Abstract: In recent years, significant progress has been made in scene text recognition by data-driven methods. However, due to the scarcity of annotated real-world data, the training of these methods predominantly relies on synthetic data. The distribution gap between synthetic and real data constrains the further performance improvement of these methods in real-world applications. To tackle this problem, a highly promising approach is to utilize massive amounts of unlabeled real data for self-supervised training, which has been widely proven effective in many NLP and CV tasks. Nevertheless, generic self-supervised methods are unsuitable for scene text images due to their sequential nature. To address this issue, we propose a Local Explicit and Global Order-aware self-supervised representation learning method (LEGO) that accounts for the characteristics of scene text images. Inspired by the human cognitive process of learning words, which involve",
    "path": "papers/24/08/2408.02036.json",
    "total_tokens": 766,
    "translated_title": "LEGO: 自监督代表学习方法在场景文本图像中的应用",
    "translated_abstract": "arXiv:2408.02036v1 公告类型：新  翻译摘要：近年来，基于数据的场景文本识别方法取得了重大进展。然而，由于标注的真实世界数据稀缺，这些方法的训练主要依赖于合成数据。合成和真实数据分布之间的差距限制了这些方法在实际应用中的进一步性能提升。为了解决这个问题，使用大量未标注的真实数据进行自监督训练是一种很有潜力的方法，这种方法在许多NLP和CV任务中被广泛证明是有效的。然而，由于场景文本图像的序列特性，对场景文本图像自监督训练的通用方法并不适用。为了解决这个问题，我们提出了一个Local Explicit and Global Order-aware self-supervised representation learning method（LEGO），它考虑了场景文本图像的特。受人类学习单词过程的启发，这个过程涉及高级的认知动机，我们的方法通过创造性地引入一系列自监督任务，成功地捕捉了场景文本图像的复杂结构。例如，我们的方法利用来自场景文本图像的不同角度和视角的信息，用以高效地捕捉文本文本的几何结构。此外，我们的方法还考虑了文本直连续性和文本块中单词之间的顺序关系，通过这些特性，我们能够提高场景文本识别在真实世界数据集上的性能，尤其是在一些难以编辑的文本图像上。为了增强场景文本识别方法的通用性和有效性，我们的方法不仅适用于特定的文本识别方法，还能为许多基于深度学习的机器视觉任务提供新的视角和有力工具。",
    "tldr": "我们提出了一种名为LEGO的自监督方法，用于学习场景文本图像的表示，通过创造性任务捕捉复杂结构，提升文本识别能力，适用于多种深度学习机器视觉任务。"
}