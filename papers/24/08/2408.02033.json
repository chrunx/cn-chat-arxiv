{
    "title": "Enhancing Human Action Recognition and Violence Detection Through Deep Learning Audiovisual Fusion",
    "abstract": "arXiv:2408.02033v1 Announce Type: new  Abstract: This paper proposes a hybrid fusion-based deep learning approach based on two different modalities, audio and video, to improve human activity recognition and violence detection in public places. To take advantage of audiovisual fusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning (HFBDL) are used and compared. Since the objective is to detect and recognize human violence in public places, Real-life violence situation (RLVS) dataset is expanded and used. Simulating results of HFBDL show 96.67\\% accuracy on validation data, which is more accurate than the other state-of-the-art methods on this dataset. To showcase our model's ability in real-world scenarios, another dataset of 54 sounded videos of both violent and non-violent situations was recorded. The model could successfully detect 52 out of 54 videos correctly. The proposed method shows a promising performance on real scenarios. Thus, it can be used for hum",
    "link": "https://arxiv.org/abs/2408.02033",
    "context": "Title: Enhancing Human Action Recognition and Violence Detection Through Deep Learning Audiovisual Fusion\nAbstract: arXiv:2408.02033v1 Announce Type: new  Abstract: This paper proposes a hybrid fusion-based deep learning approach based on two different modalities, audio and video, to improve human activity recognition and violence detection in public places. To take advantage of audiovisual fusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning (HFBDL) are used and compared. Since the objective is to detect and recognize human violence in public places, Real-life violence situation (RLVS) dataset is expanded and used. Simulating results of HFBDL show 96.67\\% accuracy on validation data, which is more accurate than the other state-of-the-art methods on this dataset. To showcase our model's ability in real-world scenarios, another dataset of 54 sounded videos of both violent and non-violent situations was recorded. The model could successfully detect 52 out of 54 videos correctly. The proposed method shows a promising performance on real scenarios. Thus, it can be used for hum",
    "path": "papers/24/08/2408.02033.json",
    "total_tokens": 384,
    "tldr": "该文章提出了一种基于深度学习技术的视听融合方法，使用包含音频和视频的数据集，提高了公共场所的人行动作识别和暴力检测能力。通过对比不同类型的融合方法，该研究展示了其方法在真实公共场合模拟场景中的高准确率，并在一个包含54个实际视频的场景中成功识别了暴力和非暴力事件。"
}