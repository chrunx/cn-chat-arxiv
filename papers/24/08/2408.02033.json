{
    "title": "Enhancing Human Action Recognition and Violence Detection Through Deep Learning Audiovisual Fusion",
    "abstract": "arXiv:2408.02033v1 Announce Type: new  Abstract: This paper proposes a hybrid fusion-based deep learning approach based on two different modalities, audio and video, to improve human activity recognition and violence detection in public places. To take advantage of audiovisual fusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning (HFBDL) are used and compared. Since the objective is to detect and recognize human violence in public places, Real-life violence situation (RLVS) dataset is expanded and used. Simulating results of HFBDL show 96.67\\% accuracy on validation data, which is more accurate than the other state-of-the-art methods on this dataset. To showcase our model's ability in real-world scenarios, another dataset of 54 sounded videos of both violent and non-violent situations was recorded. The model could successfully detect 52 out of 54 videos correctly. The proposed method shows a promising performance on real scenarios. Thus, it can be used for hum",
    "link": "https://arxiv.org/abs/2408.02033",
    "context": "Title: Enhancing Human Action Recognition and Violence Detection Through Deep Learning Audiovisual Fusion\nAbstract: arXiv:2408.02033v1 Announce Type: new  Abstract: This paper proposes a hybrid fusion-based deep learning approach based on two different modalities, audio and video, to improve human activity recognition and violence detection in public places. To take advantage of audiovisual fusion, late fusion, intermediate fusion, and hybrid fusion-based deep learning (HFBDL) are used and compared. Since the objective is to detect and recognize human violence in public places, Real-life violence situation (RLVS) dataset is expanded and used. Simulating results of HFBDL show 96.67\\% accuracy on validation data, which is more accurate than the other state-of-the-art methods on this dataset. To showcase our model's ability in real-world scenarios, another dataset of 54 sounded videos of both violent and non-violent situations was recorded. The model could successfully detect 52 out of 54 videos correctly. The proposed method shows a promising performance on real scenarios. Thus, it can be used for hum",
    "path": "papers/24/08/2408.02033.json",
    "total_tokens": 688,
    "translated_title": "增强通过深度学习视听融合的人体动作识别和暴力检测",
    "translated_abstract": "这篇论文提出了一个基于两种不同媒体数据的融合型深度学习方法，即音频和视频，旨在提高在公共场所的人体活动识别和暴力检测能力。为了利用视听融合，使用了基于深度学习的晚期融合、中期融合和混合融合技术，并进行了比较。由于目标是在公共场所检测和识别暴力，我们对“现实生活暴力情景”(RLVS)数据集进行了扩展，并用于实验。对HFBDL（混合融合型深度学习）的模拟结果显示，在验证数据上达到了96.67%的准确率，比此数据集上的其他先进的方法要精确得多。为了展示模型在真实世界场景中的能力，我们还录制了54段有声音的视频，既有暴力场景也有非暴力场景。模型成功正确地识别了其中的52段视频。提出的这种方法在真实场景中展示了令人印象深刻的性能，因此，它可以用于人类行动识别和暴力检测的工业应用。我们的方法在视觉和音频数据上实现了高效的融合，显著提高了暴力检测的准确性。",
    "tldr": "本文提出了一种基于深度学习视听融合的混合融合技术，显著提高了在公共场所的人体动作识别和暴力检测的准确性。",
    "en_tdlr": "This paper introduces a novel deep learning audiovisual fusion approach that enhances human action recognition and violence detection in public spaces, achieving high accuracy through comprehensive data analysis and fusion techniques."
}