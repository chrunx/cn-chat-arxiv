{
    "title": "Sketch2Scene: Automatic Generation of Interactive 3D Game Scenes from User's Casual Sketches",
    "abstract": "arXiv:2408.04567v1 Announce Type: new  Abstract: 3D Content Generation is at the heart of many computer graphics applications, including video gaming, film-making, virtual and augmented reality, etc. This paper proposes a novel deep-learning based approach for automatically generating interactive and playable 3D game scenes, all from the user's casual prompts such as a hand-drawn sketch. Sketch-based input offers a natural, and convenient way to convey the user's design intention in the content creation process. To circumvent the data-deficient challenge in learning (i.e. the lack of large training data of 3D scenes), our method leverages a pre-trained 2D denoising diffusion model to generate a 2D image of the scene as the conceptual guidance. In this process, we adopt the isometric projection mode to factor out unknown camera poses while obtaining the scene layout. From the generated isometric image, we use a pre-trained image understanding method to segment the image into meaningful ",
    "link": "https://arxiv.org/abs/2408.04567",
    "context": "Title: Sketch2Scene: Automatic Generation of Interactive 3D Game Scenes from User's Casual Sketches\nAbstract: arXiv:2408.04567v1 Announce Type: new  Abstract: 3D Content Generation is at the heart of many computer graphics applications, including video gaming, film-making, virtual and augmented reality, etc. This paper proposes a novel deep-learning based approach for automatically generating interactive and playable 3D game scenes, all from the user's casual prompts such as a hand-drawn sketch. Sketch-based input offers a natural, and convenient way to convey the user's design intention in the content creation process. To circumvent the data-deficient challenge in learning (i.e. the lack of large training data of 3D scenes), our method leverages a pre-trained 2D denoising diffusion model to generate a 2D image of the scene as the conceptual guidance. In this process, we adopt the isometric projection mode to factor out unknown camera poses while obtaining the scene layout. From the generated isometric image, we use a pre-trained image understanding method to segment the image into meaningful ",
    "path": "papers/24/08/2408.04567.json",
    "total_tokens": 424,
    "tldr": "该文章提出了一种自动生成交互式3D游戏场景的方法，使用户可以通过简单的手绘草图来创建场景。方法首先使用预训练的2D去噪扩散模型生成场景的2D概念图像，并通过等距投影模式来忽略未知相机位置，从而获取场景布局。随后，通过预训练的图像理解技术对图像进行分割，并生成具有特定功能的设计草图。最终，这种方法将设计草图转换为完整的3D游戏场景，实现了用户与虚拟环境的高效互动。"
}