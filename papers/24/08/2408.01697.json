{
    "title": "Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization",
    "abstract": "arXiv:2408.01697v1 Announce Type: cross  Abstract: Graph out-of-distribution (OOD) generalization remains a major challenge in graph learning since graph neural networks (GNNs) often suffer from severe performance degradation under distribution shifts. Invariant learning, aiming to extract invariant features across varied distributions, has recently emerged as a promising approach for OOD generation. Despite the great success of invariant learning in OOD problems for Euclidean data (i.e., images), the exploration within graph data remains constrained by the complex nature of graphs. Existing studies, such as data augmentation or causal intervention, either suffer from disruptions to invariance during the graph manipulation process or face reliability issues due to a lack of supervised signals for causal parts. In this work, we propose a novel framework, called Invariant Graph Learning based on Information bottleneck theory (InfoIGL), to extract the invariant features of graphs and enha",
    "link": "https://arxiv.org/abs/2408.01697",
    "context": "Title: Invariant Graph Learning Meets Information Bottleneck for Out-of-Distribution Generalization\nAbstract: arXiv:2408.01697v1 Announce Type: cross  Abstract: Graph out-of-distribution (OOD) generalization remains a major challenge in graph learning since graph neural networks (GNNs) often suffer from severe performance degradation under distribution shifts. Invariant learning, aiming to extract invariant features across varied distributions, has recently emerged as a promising approach for OOD generation. Despite the great success of invariant learning in OOD problems for Euclidean data (i.e., images), the exploration within graph data remains constrained by the complex nature of graphs. Existing studies, such as data augmentation or causal intervention, either suffer from disruptions to invariance during the graph manipulation process or face reliability issues due to a lack of supervised signals for causal parts. In this work, we propose a novel framework, called Invariant Graph Learning based on Information bottleneck theory (InfoIGL), to extract the invariant features of graphs and enha",
    "path": "papers/24/08/2408.01697.json",
    "total_tokens": 325,
    "tldr": "该文章提出的InfoIGL框架通过结合信息瓶颈理论在图数据中实现了对不变特征的有效提取，这对于解决图神经网络在分布外生成过程中面临的性能急剧下降问题具有重要意义。"
}