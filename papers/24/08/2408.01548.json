{
    "title": "Trainable Pointwise Decoder Module for Point Cloud Segmentation",
    "abstract": "arXiv:2408.01548v1 Announce Type: new  Abstract: Point cloud segmentation (PCS) aims to make per-point predictions and enables robots and autonomous driving cars to understand the environment. The range image is a dense representation of a large-scale outdoor point cloud, and segmentation models built upon the image commonly execute efficiently. However, the projection of the point cloud onto the range image inevitably leads to dropping points because, at each image coordinate, only one point is kept despite multiple points being projected onto the same location. More importantly, it is challenging to assign correct predictions to the dropped points that belong to the classes different from the kept point class. Besides, existing post-processing methods, such as K-nearest neighbor (KNN) search and kernel point convolution (KPConv), cannot be trained with the models in an end-to-end manner or cannot process varying-density outdoor point clouds well, thereby enabling the models to achiev",
    "link": "https://arxiv.org/abs/2408.01548",
    "context": "Title: Trainable Pointwise Decoder Module for Point Cloud Segmentation\nAbstract: arXiv:2408.01548v1 Announce Type: new  Abstract: Point cloud segmentation (PCS) aims to make per-point predictions and enables robots and autonomous driving cars to understand the environment. The range image is a dense representation of a large-scale outdoor point cloud, and segmentation models built upon the image commonly execute efficiently. However, the projection of the point cloud onto the range image inevitably leads to dropping points because, at each image coordinate, only one point is kept despite multiple points being projected onto the same location. More importantly, it is challenging to assign correct predictions to the dropped points that belong to the classes different from the kept point class. Besides, existing post-processing methods, such as K-nearest neighbor (KNN) search and kernel point convolution (KPConv), cannot be trained with the models in an end-to-end manner or cannot process varying-density outdoor point clouds well, thereby enabling the models to achiev",
    "path": "papers/24/08/2408.01548.json",
    "total_tokens": 711,
    "translated_title": "自训练点值解码器模块用于点云分割",
    "translated_abstract": "arXiv:2408.01548v1 公告类型：新  摘要：点云分割（PCS）旨在进行点对点预测，并允许机器人和自动驾驶汽车理解其环境。范围图像是大范围室外点云的密集表示，基于图像的分割模型运行效率通常较高。然而，点云投射到范围图像上时，不可避免地会丢失点因为，在每个图像坐标上，尽管多个点被投射到同一个位置，但只有一个点被保留。更重要的是，很难为掉落的点分配正确的预测，这些点属于与保留点类不同的类。此外，现有的一些后处理方法，如K-最近邻（KNN）搜索和核点卷积（KPConv），无法与模型以端到端的方式进行训练，或者无法很好地处理密度不同的室外点云，从而使模型难以达到最佳性能。为此，本文提出一个自训练解码器模块，该模块可以处理具有不同密度的点云，并在保留点周围学习自适应点值之间的转换以预测掉落的点类别，从而大大提高了点云分割的性能。",
    "tldr": "本文提出的一个自训练解码器模块旨在改善点云分割，尤其是在处理低密度点云时。它能够学习适应性点值转换，预测因投影而丢失的点类别，从而提高性能。",
    "en_tdlr": "This paper presents a trainable Pointwise Decoder Module that enhances point cloud segmentation, especially in handling low-density point clouds by learning adaptive pointwise conversions to predict the categories of dropped points missed by image projection, thus improving performance."
}