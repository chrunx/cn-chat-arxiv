{
    "title": "MultiViPerFrOG: A Globally Optimized Multi-Viewpoint Perception Framework for Camera Motion and Tissue Deformation",
    "abstract": "arXiv:2408.04367v1 Announce Type: new  Abstract: Reconstructing the 3D shape of a deformable environment from the information captured by a moving depth camera is highly relevant to surgery. The underlying challenge is the fact that simultaneously estimating camera motion and tissue deformation in a fully deformable scene is an ill-posed problem, especially from a single arbitrarily moving viewpoint. Current solutions are often organ-specific and lack the robustness required to handle large deformations. Here we propose a multi-viewpoint global optimization framework that can flexibly integrate the output of low-level perception modules (data association, depth, and relative scene flow) with kinematic and scene-modeling priors to jointly estimate multiple camera motions and absolute scene flow. We use simulated noisy data to show three practical examples that successfully constrain the convergence to a unique solution. Overall, our method shows robustness to combined noisy input measur",
    "link": "https://arxiv.org/abs/2408.04367",
    "context": "Title: MultiViPerFrOG: A Globally Optimized Multi-Viewpoint Perception Framework for Camera Motion and Tissue Deformation\nAbstract: arXiv:2408.04367v1 Announce Type: new  Abstract: Reconstructing the 3D shape of a deformable environment from the information captured by a moving depth camera is highly relevant to surgery. The underlying challenge is the fact that simultaneously estimating camera motion and tissue deformation in a fully deformable scene is an ill-posed problem, especially from a single arbitrarily moving viewpoint. Current solutions are often organ-specific and lack the robustness required to handle large deformations. Here we propose a multi-viewpoint global optimization framework that can flexibly integrate the output of low-level perception modules (data association, depth, and relative scene flow) with kinematic and scene-modeling priors to jointly estimate multiple camera motions and absolute scene flow. We use simulated noisy data to show three practical examples that successfully constrain the convergence to a unique solution. Overall, our method shows robustness to combined noisy input measur",
    "path": "papers/24/08/2408.04367.json",
    "total_tokens": 372,
    "tldr": "该文章提出了一种名为MultiViPerFrOG的全球优化多视角感知框架，该框架能够从移动深度相机捕获的信息中有效地重建3D场景的形状，特别是在处理组织变形时。该框架能够同时估计多个摄像机的运动和场景的绝对流，并通过结合低级感知模块的输出和先验知识，成功解决单视角下同时估计相机运动和组织变形的问题。"
}