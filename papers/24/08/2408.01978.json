{
    "title": "AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial Contrastive Prompt Tuning",
    "abstract": "arXiv:2408.01978v1 Announce Type: new  Abstract: Deep neural networks (DNNs) are known to be vulnerable to adversarial attacks even under a black-box setting where the adversary can only query the model. Particularly, query-based black-box adversarial attacks estimate adversarial gradients based on the returned probability vectors of the target model for a sequence of queries. During this process, the queries made to the target model are intermediate adversarial examples crafted at the previous attack step, which share high similarities in the pixel space. Motivated by this observation, stateful detection methods have been proposed to detect and reject query-based attacks. While demonstrating promising results, these methods either have been evaded by more advanced attacks or suffer from low efficiency in terms of the number of shots (queries) required to detect different attacks. Arguably, the key challenge here is to assign high similarity scores for any two intermediate adversarial ",
    "link": "https://arxiv.org/abs/2408.01978",
    "context": "Title: AdvQDet: Detecting Query-Based Adversarial Attacks with Adversarial Contrastive Prompt Tuning\nAbstract: arXiv:2408.01978v1 Announce Type: new  Abstract: Deep neural networks (DNNs) are known to be vulnerable to adversarial attacks even under a black-box setting where the adversary can only query the model. Particularly, query-based black-box adversarial attacks estimate adversarial gradients based on the returned probability vectors of the target model for a sequence of queries. During this process, the queries made to the target model are intermediate adversarial examples crafted at the previous attack step, which share high similarities in the pixel space. Motivated by this observation, stateful detection methods have been proposed to detect and reject query-based attacks. While demonstrating promising results, these methods either have been evaded by more advanced attacks or suffer from low efficiency in terms of the number of shots (queries) required to detect different attacks. Arguably, the key challenge here is to assign high similarity scores for any two intermediate adversarial ",
    "path": "papers/24/08/2408.01978.json",
    "total_tokens": 338,
    "tldr": "该文章提出了一种新型的查询基黑盒攻击检测方法AdvQDet，通过对抗性对比提尝技巧动态调整提示，有效捕获了基于查询的对抗性攻击，尤其是在检测此类攻击时的效率得到了显著提升。"
}