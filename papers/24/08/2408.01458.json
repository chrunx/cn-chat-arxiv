{
    "title": "Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance",
    "abstract": "arXiv:2408.01458v1 Announce Type: cross  Abstract: Calls for engagement with the public in Artificial Intelligence (AI) research, development, and governance are increasing, leading to the use of surveys to capture people's values, perceptions, and experiences related to AI. In this paper, we critically examine the state of human participant surveys associated with these topics. Through both a reflexive analysis of a survey pilot spanning six countries and a systematic literature review of 44 papers featuring public surveys related to AI, we explore prominent perspectives and methodological nuances associated with surveys to date. We find that public surveys on AI topics are vulnerable to specific Western knowledge, values, and assumptions in their design, including in their positioning of ethical concepts and societal values, lack sufficient critical discourse surrounding deployment strategies, and demonstrate inconsistent forms of transparency in their reporting. Based on our finding",
    "link": "https://arxiv.org/abs/2408.01458",
    "context": "Title: Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance\nAbstract: arXiv:2408.01458v1 Announce Type: cross  Abstract: Calls for engagement with the public in Artificial Intelligence (AI) research, development, and governance are increasing, leading to the use of surveys to capture people's values, perceptions, and experiences related to AI. In this paper, we critically examine the state of human participant surveys associated with these topics. Through both a reflexive analysis of a survey pilot spanning six countries and a systematic literature review of 44 papers featuring public surveys related to AI, we explore prominent perspectives and methodological nuances associated with surveys to date. We find that public surveys on AI topics are vulnerable to specific Western knowledge, values, and assumptions in their design, including in their positioning of ethical concepts and societal values, lack sufficient critical discourse surrounding deployment strategies, and demonstrate inconsistent forms of transparency in their reporting. Based on our finding",
    "path": "papers/24/08/2408.01458.json",
    "total_tokens": 659,
    "translated_title": "调查有害吗？反思人工智能研究、发展和治理中的调查使用方式",
    "translated_abstract": "arXiv:2408.01458v1 宣布类型：交叉  摘要：呼吁与公众在人工智能（AI）研究、发展和治理中的接触，导致使用调查来捕获与AI相关的人们对其价值、观念和经历的看法。在本论文中，我们对与这些话题相关的公众调查状况进行了批判性审视。通过对我们开展的一个覆盖六个国家的调查试点的自我反思分析以及对我们确定的人工智能相关44篇论文中包含的调查的系统文献回顾，我们探讨了关于AI的调查到目前为止所涉及的普遍观点和研究方法学上的微妙之处。我们发现，AI领域的公众调查在设计上容易受到特定于西方的知识、价值观和假设的损害，包括在它们对伦理概念和社会价值的定位中，以及在它们对部署策略的相关负面讨论中缺乏足够的批判性对话，以及它们在报告中的透明度不一。根据我们的发现，我们提出了在全球化和多元化的人工智能技术和观念的背景下，设计调查和文化有别的受众时需要更加敏感的建议。",
    "tldr": "本文批评了人工智能领域的公众调查，指出这些调查容易受到西方知识和价值观的影响，并建议在全球化的背景下设计更敏感的调查方法。"
}