{
    "title": "Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance",
    "abstract": "arXiv:2408.01458v1 Announce Type: cross  Abstract: Calls for engagement with the public in Artificial Intelligence (AI) research, development, and governance are increasing, leading to the use of surveys to capture people's values, perceptions, and experiences related to AI. In this paper, we critically examine the state of human participant surveys associated with these topics. Through both a reflexive analysis of a survey pilot spanning six countries and a systematic literature review of 44 papers featuring public surveys related to AI, we explore prominent perspectives and methodological nuances associated with surveys to date. We find that public surveys on AI topics are vulnerable to specific Western knowledge, values, and assumptions in their design, including in their positioning of ethical concepts and societal values, lack sufficient critical discourse surrounding deployment strategies, and demonstrate inconsistent forms of transparency in their reporting. Based on our finding",
    "link": "https://arxiv.org/abs/2408.01458",
    "context": "Title: Surveys Considered Harmful? Reflecting on the Use of Surveys in AI Research, Development, and Governance\nAbstract: arXiv:2408.01458v1 Announce Type: cross  Abstract: Calls for engagement with the public in Artificial Intelligence (AI) research, development, and governance are increasing, leading to the use of surveys to capture people's values, perceptions, and experiences related to AI. In this paper, we critically examine the state of human participant surveys associated with these topics. Through both a reflexive analysis of a survey pilot spanning six countries and a systematic literature review of 44 papers featuring public surveys related to AI, we explore prominent perspectives and methodological nuances associated with surveys to date. We find that public surveys on AI topics are vulnerable to specific Western knowledge, values, and assumptions in their design, including in their positioning of ethical concepts and societal values, lack sufficient critical discourse surrounding deployment strategies, and demonstrate inconsistent forms of transparency in their reporting. Based on our finding",
    "path": "papers/24/08/2408.01458.json",
    "total_tokens": 364,
    "tldr": "该文章指出，在人工智能研究、发展和治理领域中，尽管公众参与的概念越来越受重视，但当前用于收集人们对于人工智能看法、感知和经历的调查存在局限性。这些调查往往带有西方知识、价值观和假设的偏见，可能导致设计上对伦理概念和社会价值观的理解有所偏差，以及对于部署策略的讨论缺乏批判性。此外，调查结果的报告往往缺乏透明度。"
}