{
    "title": "Segmentation Style Discovery: Application to Skin Lesion Images",
    "abstract": "arXiv:2408.02787v1 Announce Type: new  Abstract: Variability in medical image segmentation, arising from annotator preferences, expertise, and their choice of tools, has been well documented. While the majority of multi-annotator segmentation approaches focus on modeling annotator-specific preferences, they require annotator-segmentation correspondence. In this work, we introduce the problem of segmentation style discovery, and propose StyleSeg, a segmentation method that learns plausible, diverse, and semantically consistent segmentation styles from a corpus of image-mask pairs without any knowledge of annotator correspondence. StyleSeg consistently outperforms competing methods on four publicly available skin lesion segmentation (SLS) datasets. We also curate ISIC-MultiAnnot, the largest multi-annotator SLS dataset with annotator correspondence, and our results show a strong alignment, using our newly proposed measure AS2, between the predicted styles and annotator preferences. The c",
    "link": "https://arxiv.org/abs/2408.02787",
    "context": "Title: Segmentation Style Discovery: Application to Skin Lesion Images\nAbstract: arXiv:2408.02787v1 Announce Type: new  Abstract: Variability in medical image segmentation, arising from annotator preferences, expertise, and their choice of tools, has been well documented. While the majority of multi-annotator segmentation approaches focus on modeling annotator-specific preferences, they require annotator-segmentation correspondence. In this work, we introduce the problem of segmentation style discovery, and propose StyleSeg, a segmentation method that learns plausible, diverse, and semantically consistent segmentation styles from a corpus of image-mask pairs without any knowledge of annotator correspondence. StyleSeg consistently outperforms competing methods on four publicly available skin lesion segmentation (SLS) datasets. We also curate ISIC-MultiAnnot, the largest multi-annotator SLS dataset with annotator correspondence, and our results show a strong alignment, using our newly proposed measure AS2, between the predicted styles and annotator preferences. The c",
    "path": "papers/24/08/2408.02787.json",
    "total_tokens": 374,
    "tldr": "该文章提出了StyleSeg方法，该方法通过学习多样化的分割风格，在没有任何标注者对应知识的情况下，从皮肤病变图像及其掩膜对中提高分割性能。该方法在四个公开的皮肤病变分割数据集上表现出了优于其他方法的性能，并且对最大的多标注者皮肤病变分割数据集（ISIC-MultiAnnot）进行了情感一致性的预测，并揭示了预测风格与标注者偏好之间的强相关性。"
}