{
    "title": "EXAONE 3.0 7.8B Instruction Tuned Language Model",
    "abstract": "arXiv:2408.03541v1 Announce Type: cross  Abstract: We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family of Large Language Models (LLMs) developed by LG AI Research. Among different model sizes, we publicly release the 7.8B instruction-tuned model to promote open research and innovations. Through extensive evaluations across a wide range of public and in-house benchmarks, EXAONE 3.0 demonstrates highly competitive real-world performance with instruction-following capability against other state-of-the-art open models of similar size. Our comparative analysis shows that EXAONE 3.0 excels particularly in Korean, while achieving compelling performance across general tasks and complex reasoning. With its strong real-world effectiveness and bilingual proficiency, we hope that EXAONE keeps contributing to advancements in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",
    "link": "https://arxiv.org/abs/2408.03541",
    "context": "Title: EXAONE 3.0 7.8B Instruction Tuned Language Model\nAbstract: arXiv:2408.03541v1 Announce Type: cross  Abstract: We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family of Large Language Models (LLMs) developed by LG AI Research. Among different model sizes, we publicly release the 7.8B instruction-tuned model to promote open research and innovations. Through extensive evaluations across a wide range of public and in-house benchmarks, EXAONE 3.0 demonstrates highly competitive real-world performance with instruction-following capability against other state-of-the-art open models of similar size. Our comparative analysis shows that EXAONE 3.0 excels particularly in Korean, while achieving compelling performance across general tasks and complex reasoning. With its strong real-world effectiveness and bilingual proficiency, we hope that EXAONE keeps contributing to advancements in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct",
    "path": "papers/24/08/2408.03541.json",
    "total_tokens": 457,
    "tldr": "该文章中，EXAONE 3.0 7.8B 指令微调语言模型作为LG AI Research开发的第一个同类的大型语言模型，是公开模型的首个实例，主要创新在于其在指令遵循能力上与其他类似大小开放模型的竞争中展现出高水平的实际性能。特别是，其在 Korean 语言方面的卓越表现以及跨多种任务和复杂推理中的显著性能，强调了其在真实世界应用中的有效性。此外，其双语能力的展现标志着其在专家级人工智能领域的贡献可能持续增长。该模型通过 GitHub 上的 Hugging Face Co 公开提供了 20B 版本，进一步推动了开放研究和创新。"
}