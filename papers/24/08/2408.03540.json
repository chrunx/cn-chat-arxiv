{
    "title": "PoseMamba: Monocular 3D Human Pose Estimation with Bidirectional Global-Local Spatio-Temporal State Space Model",
    "abstract": "arXiv:2408.03540v1 Announce Type: new  Abstract: Transformers have significantly advanced the field of 3D human pose estimation (HPE). However, existing transformer-based methods primarily use self-attention mechanisms for spatio-temporal modeling, leading to a quadratic complexity, unidirectional modeling of spatio-temporal relationships, and insufficient learning of spatial-temporal correlations. Recently, the Mamba architecture, utilizing the state space model (SSM), has exhibited superior long-range modeling capabilities in a variety of vision tasks with linear complexity. In this paper, we propose PoseMamba, a novel purely SSM-based approach with linear complexity for 3D human pose estimation in monocular video. Specifically, we propose a bidirectional global-local spatio-temporal SSM block that comprehensively models human joint relations within individual frames as well as temporal correlations across frames. Within this bidirectional global-local spatio-temporal SSM block, we i",
    "link": "https://arxiv.org/abs/2408.03540",
    "context": "Title: PoseMamba: Monocular 3D Human Pose Estimation with Bidirectional Global-Local Spatio-Temporal State Space Model\nAbstract: arXiv:2408.03540v1 Announce Type: new  Abstract: Transformers have significantly advanced the field of 3D human pose estimation (HPE). However, existing transformer-based methods primarily use self-attention mechanisms for spatio-temporal modeling, leading to a quadratic complexity, unidirectional modeling of spatio-temporal relationships, and insufficient learning of spatial-temporal correlations. Recently, the Mamba architecture, utilizing the state space model (SSM), has exhibited superior long-range modeling capabilities in a variety of vision tasks with linear complexity. In this paper, we propose PoseMamba, a novel purely SSM-based approach with linear complexity for 3D human pose estimation in monocular video. Specifically, we propose a bidirectional global-local spatio-temporal SSM block that comprehensively models human joint relations within individual frames as well as temporal correlations across frames. Within this bidirectional global-local spatio-temporal SSM block, we i",
    "path": "papers/24/08/2408.03540.json",
    "total_tokens": 400,
    "tldr": "该文章提出了PoseMamba，一个基于线性复杂度的纯状态空间模型（SSM）方法，用于单目视频中的3D人类姿势估计。该方法通过一个双向全局-局部空间-时间SSM块来全面建模单个帧内的关节关系以及帧之间的时序关联，从而克服了现有基于自注意力机制的3D人类姿势估计方法的局限性，如空间-时间建模的单一方向性和空间-时间关联学习的不足。"
}