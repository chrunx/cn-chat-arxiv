{
    "title": "Spatial-temporal Graph Convolutional Networks with Diversified Transformation for Dynamic Graph Representation Learning",
    "abstract": "arXiv:2408.02704v1 Announce Type: cross  Abstract: Dynamic graphs (DG) are often used to describe evolving interactions between nodes in real-world applications. Temporal patterns are a natural feature of DGs and are also key to representation learning. However, existing dynamic GCN models are mostly composed of static GCNs and sequence modules, which results in the separation of spatiotemporal information and cannot effectively capture complex temporal patterns in DGs. To address this problem, this study proposes a spatial-temporal graph convolutional networks with diversified transformation (STGCNDT), which includes three aspects: a) constructing a unified graph tensor convolutional network (GTCN) using tensor M-products without the need to represent spatiotemporal information separately; b) introducing three transformation schemes in GTCN to model complex temporal patterns to aggregate temporal information; and c) constructing an ensemble of diversified transformation schemes to obt",
    "link": "https://arxiv.org/abs/2408.02704",
    "context": "Title: Spatial-temporal Graph Convolutional Networks with Diversified Transformation for Dynamic Graph Representation Learning\nAbstract: arXiv:2408.02704v1 Announce Type: cross  Abstract: Dynamic graphs (DG) are often used to describe evolving interactions between nodes in real-world applications. Temporal patterns are a natural feature of DGs and are also key to representation learning. However, existing dynamic GCN models are mostly composed of static GCNs and sequence modules, which results in the separation of spatiotemporal information and cannot effectively capture complex temporal patterns in DGs. To address this problem, this study proposes a spatial-temporal graph convolutional networks with diversified transformation (STGCNDT), which includes three aspects: a) constructing a unified graph tensor convolutional network (GTCN) using tensor M-products without the need to represent spatiotemporal information separately; b) introducing three transformation schemes in GTCN to model complex temporal patterns to aggregate temporal information; and c) constructing an ensemble of diversified transformation schemes to obt",
    "path": "papers/24/08/2408.02704.json",
    "total_tokens": 340,
    "tldr": "该文章提出了一种名为STGCNDT的空间-时间图卷积神经网络，通过构建统一的图张量卷积网络并引入三种不同类型的变换方案，能够高效且集中地处理和提取复杂动态图的时空信息。"
}