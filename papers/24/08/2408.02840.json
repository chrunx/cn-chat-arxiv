{
    "title": "GAReT: Cross-view Video Geolocalization with Adapters and Auto-Regressive Transformers",
    "abstract": "arXiv:2408.02840v1 Announce Type: new  Abstract: Cross-view video geo-localization (CVGL) aims to derive GPS trajectories from street-view videos by aligning them with aerial-view images. Despite their promising performance, current CVGL methods face significant challenges. These methods use camera and odometry data, typically absent in real-world scenarios. They utilize multiple adjacent frames and various encoders for feature extraction, resulting in high computational costs. Moreover, these approaches independently predict each street-view frame's location, resulting in temporally inconsistent GPS trajectories. To address these challenges, in this work, we propose GAReT, a fully transformer-based method for CVGL that does not require camera and odometry data. We introduce GeoAdapter, a transformer-adapter module designed to efficiently aggregate image-level representations and adapt them for video inputs. Specifically, we train a transformer encoder on video frames and aerial images",
    "link": "https://arxiv.org/abs/2408.02840",
    "context": "Title: GAReT: Cross-view Video Geolocalization with Adapters and Auto-Regressive Transformers\nAbstract: arXiv:2408.02840v1 Announce Type: new  Abstract: Cross-view video geo-localization (CVGL) aims to derive GPS trajectories from street-view videos by aligning them with aerial-view images. Despite their promising performance, current CVGL methods face significant challenges. These methods use camera and odometry data, typically absent in real-world scenarios. They utilize multiple adjacent frames and various encoders for feature extraction, resulting in high computational costs. Moreover, these approaches independently predict each street-view frame's location, resulting in temporally inconsistent GPS trajectories. To address these challenges, in this work, we propose GAReT, a fully transformer-based method for CVGL that does not require camera and odometry data. We introduce GeoAdapter, a transformer-adapter module designed to efficiently aggregate image-level representations and adapt them for video inputs. Specifically, we train a transformer encoder on video frames and aerial images",
    "path": "papers/24/08/2408.02840.json",
    "total_tokens": 361,
    "tldr": "该文章提出了GAReT方法，通过使用地理适配器(GeoAdapter)和自回归变换器(Auto-Regressive Transformers)，实现了无需相机和里程计数据的跨视角视频地理定位，解决了现有CVGL方法面临的数据获取困难、计算效率低以及预测结果时间不一致等问题。"
}