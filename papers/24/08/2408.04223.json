{
    "title": "VideoQA in the Era of LLMs: An Empirical Study",
    "abstract": "arXiv:2408.04223v1 Announce Type: new  Abstract: Video Large Language Models (Video-LLMs) are flourishing and has advanced many video-language tasks. As a golden testbed, Video Question Answering (VideoQA) plays pivotal role in Video-LLM developing. This work conducts a timely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to elucidate their success and failure modes, and provide insights towards more human-like video understanding and question answering. Our analyses demonstrate that Video-LLMs excel in VideoQA; they can correlate contextual cues and generate plausible responses to questions about varied video contents. However, models falter in handling video temporality, both in reasoning about temporal content ordering and grounding QA-relevant temporal moments. Moreover, the models behave unintuitively - they are unresponsive to adversarial video perturbations while being sensitive to simple variations of candidate answers and questions. Also, they do not neces",
    "link": "https://arxiv.org/abs/2408.04223",
    "context": "Title: VideoQA in the Era of LLMs: An Empirical Study\nAbstract: arXiv:2408.04223v1 Announce Type: new  Abstract: Video Large Language Models (Video-LLMs) are flourishing and has advanced many video-language tasks. As a golden testbed, Video Question Answering (VideoQA) plays pivotal role in Video-LLM developing. This work conducts a timely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to elucidate their success and failure modes, and provide insights towards more human-like video understanding and question answering. Our analyses demonstrate that Video-LLMs excel in VideoQA; they can correlate contextual cues and generate plausible responses to questions about varied video contents. However, models falter in handling video temporality, both in reasoning about temporal content ordering and grounding QA-relevant temporal moments. Moreover, the models behave unintuitively - they are unresponsive to adversarial video perturbations while being sensitive to simple variations of candidate answers and questions. Also, they do not neces",
    "path": "papers/24/08/2408.04223.json",
    "total_tokens": 406,
    "tldr": "该文章通过实证研究，探究了大型语言模型（LLMs）在视频处理中的表现，尤其是视频问答（VideoQA）任务。研究揭示了这些模型在处理视频内容和回答问题方面的优势，但也指出了其在处理视频中的时间性方面存在的不足。此外，文章还发现，即使在面对简单的干扰和问题的细微变化时，这些模型也未能表现出更为自然的行为。总的来说，这项研究为video-llms在视频理解和问答方面的表现提供了深入的见解，并为改进这些模型以更接近人类水平的能力提供了指导。"
}