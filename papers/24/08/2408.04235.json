{
    "title": "LLDif: Diffusion Models for Low-light Emotion Recognition",
    "abstract": "arXiv:2408.04235v1 Announce Type: new  Abstract: This paper introduces LLDif, a novel diffusion-based facial expression recognition (FER) framework tailored for extremely low-light (LL) environments. Images captured under such conditions often suffer from low brightness and significantly reduced contrast, presenting challenges to conventional methods. These challenges include poor image quality that can significantly reduce the accuracy of emotion recognition. LLDif addresses these issues with a novel two-stage training process that combines a Label-aware CLIP (LA-CLIP), an embedding prior network (PNET), and a transformer-based network adept at handling the noise of low-light images. The first stage involves LA-CLIP generating a joint embedding prior distribution (EPD) to guide the LLformer in label recovery. In the second stage, the diffusion model (DM) refines the EPD inference, ultilising the compactness of EPD for precise predictions. Experimental evaluations on various LL-FER dat",
    "link": "https://arxiv.org/abs/2408.04235",
    "context": "Title: LLDif: Diffusion Models for Low-light Emotion Recognition\nAbstract: arXiv:2408.04235v1 Announce Type: new  Abstract: This paper introduces LLDif, a novel diffusion-based facial expression recognition (FER) framework tailored for extremely low-light (LL) environments. Images captured under such conditions often suffer from low brightness and significantly reduced contrast, presenting challenges to conventional methods. These challenges include poor image quality that can significantly reduce the accuracy of emotion recognition. LLDif addresses these issues with a novel two-stage training process that combines a Label-aware CLIP (LA-CLIP), an embedding prior network (PNET), and a transformer-based network adept at handling the noise of low-light images. The first stage involves LA-CLIP generating a joint embedding prior distribution (EPD) to guide the LLformer in label recovery. In the second stage, the diffusion model (DM) refines the EPD inference, ultilising the compactness of EPD for precise predictions. Experimental evaluations on various LL-FER dat",
    "path": "papers/24/08/2408.04235.json",
    "total_tokens": 338,
    "tldr": "该文章介绍了LLDif，一个专门为低光照面部表情识别问题设计的扩散模型框架。通过两种训练策略结合，高效地将低光照图像中的噪点转化为清晰的表情识别结果。"
}