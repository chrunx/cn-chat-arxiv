{
    "title": "Metareasoning in uncertain environments: a meta-BAMDP framework",
    "abstract": "arXiv:2408.01253v1 Announce Type: new  Abstract: In decision-making scenarios, \\textit{reasoning} can be viewed as an algorithm $P$ that makes a choice of an action $a^* \\in \\mathcal{A}$, aiming to optimize some outcome such as maximizing the value function of a Markov decision process (MDP). However, executing $P$ itself may bear some costs (time, energy, limited capacity, etc.) and needs to be considered alongside explicit utility obtained by making the choice in the underlying decision problem. Such costs need to be taken into account in order to accurately model human behavior, as well as optimizing AI planning, as all physical systems are bound to face resource constraints. Finding the right $P$ can itself be framed as an optimization problem over the space of reasoning processes $P$, generally referred to as \\textit{metareasoning}. Conventionally, human metareasoning models assume that the agent knows the transition and reward distributions of the underlying MDP. This paper gener",
    "link": "https://arxiv.org/abs/2408.01253",
    "context": "Title: Metareasoning in uncertain environments: a meta-BAMDP framework\nAbstract: arXiv:2408.01253v1 Announce Type: new  Abstract: In decision-making scenarios, \\textit{reasoning} can be viewed as an algorithm $P$ that makes a choice of an action $a^* \\in \\mathcal{A}$, aiming to optimize some outcome such as maximizing the value function of a Markov decision process (MDP). However, executing $P$ itself may bear some costs (time, energy, limited capacity, etc.) and needs to be considered alongside explicit utility obtained by making the choice in the underlying decision problem. Such costs need to be taken into account in order to accurately model human behavior, as well as optimizing AI planning, as all physical systems are bound to face resource constraints. Finding the right $P$ can itself be framed as an optimization problem over the space of reasoning processes $P$, generally referred to as \\textit{metareasoning}. Conventionally, human metareasoning models assume that the agent knows the transition and reward distributions of the underlying MDP. This paper gener",
    "path": "papers/24/08/2408.01253.json",
    "total_tokens": 808,
    "translated_title": "不确定性环境中的元推理：基于BAMDP框架的元推理方法",
    "translated_abstract": "arXiv:2408.01253v1 公告类型：新  翻译摘要：在决策制定场景中，可以认为“推理”是一种算法$P$，该算法选择一个动作$a^* \\in \\mathcal{A}$，旨在优化一些结果，如最大化马尔可夫决策过程（MDP）的价值函数。然而，执行$P$本身可能涉及到一些成本（时间、能量、有限的能力等），并且需要在考虑与执行选择在下的决策问题直接获得的实用价值。这样的成本需要在准确建模人类行为以及优化人工A计划时被考虑进去，因为所有物理系统都面临着资源限制。找到正确的$P$本身可以被看作是在推理过程$P$空间中进行优化的问题，通常被称作“元推理”。传统上，人类元推理模型假设代理知道底层MDP的转移和奖励分布。本文提出了一种新的元推理框架，该框架在代理人对所面临的MDP的一阶概率分布不完全了解的情况下，能够动态地优化推理过程的选择。该框架以贝叶斯马尔可夫决策过程(BAMDP)为基础，但去掉了代理人对MDP模型参数知识的前提假设，提出了\\textit{meta-BAMDP}（元BAMDP）框架，并通过计算模型的优化为代理人提供了执行策略，该执行策略可以在不完全了解环境概率模型的情况下提高性能。此外，本文通过实验演示了该方法的有效性。",
    "tldr": "本文提出了一种新的元推理框架，该框架在代理人不完全了解所面临的MDP的概率分布时，能够动态地优化推理过程的选择，提高了代理人在资源受限环境中的决策能力。"
}