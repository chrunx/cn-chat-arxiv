{
    "title": "AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation",
    "abstract": "arXiv:2408.01708v1 Announce Type: new  Abstract: Recently, transformer-based models have demonstrated remarkable performance on audio-visual segmentation (AVS) tasks. However, their expensive computational cost makes real-time inference impractical. By characterizing attention maps of the network, we identify two key obstacles in AVS models: 1) attention dissipation, corresponding to the over-concentrated attention weights by Softmax within restricted frames, and 2) inefficient, burdensome transformer decoder, caused by narrow focus patterns in early stages. In this paper, we introduce AVESFormer, the first real-time Audio-Visual Efficient Segmentation transformer that achieves fast, efficient and light-weight simultaneously. Our model leverages an efficient prompt query generator to correct the behaviour of cross-attention. Additionally, we propose ELF decoder to bring greater efficiency by facilitating convolutions suitable for local features to reduce computational burdens. Extensiv",
    "link": "https://arxiv.org/abs/2408.01708",
    "context": "Title: AVESFormer: Efficient Transformer Design for Real-Time Audio-Visual Segmentation\nAbstract: arXiv:2408.01708v1 Announce Type: new  Abstract: Recently, transformer-based models have demonstrated remarkable performance on audio-visual segmentation (AVS) tasks. However, their expensive computational cost makes real-time inference impractical. By characterizing attention maps of the network, we identify two key obstacles in AVS models: 1) attention dissipation, corresponding to the over-concentrated attention weights by Softmax within restricted frames, and 2) inefficient, burdensome transformer decoder, caused by narrow focus patterns in early stages. In this paper, we introduce AVESFormer, the first real-time Audio-Visual Efficient Segmentation transformer that achieves fast, efficient and light-weight simultaneously. Our model leverages an efficient prompt query generator to correct the behaviour of cross-attention. Additionally, we propose ELF decoder to bring greater efficiency by facilitating convolutions suitable for local features to reduce computational burdens. Extensiv",
    "path": "papers/24/08/2408.01708.json",
    "total_tokens": 627,
    "translated_title": "AVESFormer：实时音频视觉分割的高效变换器设计",
    "translated_abstract": "arXiv:2408.01708v1 公告类型：新  翻译摘要：最近，基于transformer的模型在音频视觉分割（AVS）任务上展示了出色的性能。然而，它们的计算成本高昂，使得实时推理在实际中不可行。通过分析网络的注意图，我们识别出AVS模型的两个关键障碍：1）注意损耗，对应于在受限框架内由Softmax导致的注意力权值的过度集中，以及2）不高效的、沉重的变换器解码器，是由早期阶段出现的不广泛关注模式引起的。在这篇论文中，我们介绍了AVESFormer，这是第一个同时实现快速、高效和轻量级的实时音频视觉有效分割transformer模型。我们的模型采用高效的提示查询生成器来纠正跨注意力行为。此外，我们还提出了一种ELF解码器，通过促进适合局部特征的卷积，减少计算负担，从而实现更大效率。进行了广泛",
    "tldr": "AVESFormer是一个高效的音频视觉变换器模型，实现了实时、高效和轻量级的AVS任务。"
}