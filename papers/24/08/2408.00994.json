{
    "title": "ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models",
    "abstract": "arXiv:2408.00994v1 Announce Type: cross  Abstract: This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g., time/space performance, robustness, maintainability) requirements. However, textual descriptions can either express requirements verbosely or may even omit some of them. We introduce ARCHCODE, a novel framework that leverages in-context learning to organize requirements observed in descriptions and to extrapolate unexpressed requirements from them. ARCHCODE generates requirements from given descriptions, conditioning them to produce code snippets and test cases. Each test case is tailored to one of the requirements, allowing for the ranking of code snippets based on the compliance of their execution results with the requirements. Public benchmar",
    "link": "https://arxiv.org/abs/2408.00994",
    "context": "Title: ArchCode: Incorporating Software Requirements in Code Generation with Large Language Models\nAbstract: arXiv:2408.00994v1 Announce Type: cross  Abstract: This paper aims to extend the code generation capability of large language models (LLMs) to automatically manage comprehensive software requirements from given textual descriptions. Such requirements include both functional (i.e. achieving expected behavior for inputs) and non-functional (e.g., time/space performance, robustness, maintainability) requirements. However, textual descriptions can either express requirements verbosely or may even omit some of them. We introduce ARCHCODE, a novel framework that leverages in-context learning to organize requirements observed in descriptions and to extrapolate unexpressed requirements from them. ARCHCODE generates requirements from given descriptions, conditioning them to produce code snippets and test cases. Each test case is tailored to one of the requirements, allowing for the ranking of code snippets based on the compliance of their execution results with the requirements. Public benchmar",
    "path": "papers/24/08/2408.00994.json",
    "total_tokens": 683,
    "translated_title": "ArchCode：将软件需求融入大型语言模型生成的代码中",
    "translated_abstract": "arXiv:2408.00994v1 公告类型：交叉 摘要：本文旨在将大型语言模型（LLM）的代码生成能力扩展到能够自动处理从给定文本描述中给出的全面软件需求。这些需求包括功能性（即对输入执行预期行为）和非功能性要求（例如，时间/空间性能、鲁棒性、可维护性）。然而，文本描述要么可能冗长地表达要求，要么甚至可能省略一些要求。我们介绍ARCHCODE，一个全新的框架，它利用“在上下文中学习”的原理来组织从描述中观察到的需求，并从这些描述中推断出未表达的需求。ARCHCODE从给出的描述中生成需求，并对它们进行条件处理，以产生代码片段和测试用例。每个测试用例都针对一个要求，允许根据代码片段执行结果与要求的符合性对代码片段进行排名。公共基准测试结果表明，ARCHCODE在处理复杂软件需求和生成高质量代码方面优于现有的方法。未来的工作将集中于实现ARCHCODE在真实世界软件工程环境中的应用和评估。",
    "tldr": "本文介绍了ARCHCODE框架，该框架利用大型语言模型通过在上下文中学习的方式，组织并推断软件需求，从而提升代码生成质量。",
    "en_tdlr": "This paper introduces the ARCHCODE framework, which utilizes large language models through in-context learning to organize and infer software requirements, thereby improving the quality of code generation."
}