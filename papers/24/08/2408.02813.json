{
    "title": "Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense",
    "abstract": "arXiv:2408.02813v1 Announce Type: cross  Abstract: Federated Learning (FL) is an emerging distributed machine learning paradigm that allows multiple clients to collaboratively train a global model without sharing private local data. However, FL systems are vulnerable to attacks from malicious clients, who can degrade the global model performance through data poisoning and model poisoning. Existing defense methods typically focus on a single type of attack, such as Byzantine attacks or backdoor attacks, and are often ineffective against potential data poisoning attacks like label flipping and label shuffling. Additionally, these methods often lack accuracy and robustness in detecting and handling malicious updates. To address these issues, we propose a novel method based on model confidence scores, which evaluates the uncertainty of client model updates to detect and defend against malicious clients. Our approach is comprehensively effective for both model poisoning and data poisoning a",
    "link": "https://arxiv.org/abs/2408.02813",
    "context": "Title: Mitigating Malicious Attacks in Federated Learning via Confidence-aware Defense\nAbstract: arXiv:2408.02813v1 Announce Type: cross  Abstract: Federated Learning (FL) is an emerging distributed machine learning paradigm that allows multiple clients to collaboratively train a global model without sharing private local data. However, FL systems are vulnerable to attacks from malicious clients, who can degrade the global model performance through data poisoning and model poisoning. Existing defense methods typically focus on a single type of attack, such as Byzantine attacks or backdoor attacks, and are often ineffective against potential data poisoning attacks like label flipping and label shuffling. Additionally, these methods often lack accuracy and robustness in detecting and handling malicious updates. To address these issues, we propose a novel method based on model confidence scores, which evaluates the uncertainty of client model updates to detect and defend against malicious clients. Our approach is comprehensively effective for both model poisoning and data poisoning a",
    "path": "papers/24/08/2408.02813.json",
    "total_tokens": 356,
    "tldr": "该文章提出了一种基于模型信心分数的方法，用于评估客户端模型更新的不确定性，从而检测并防御恶意客户端的攻击。这种方法能够有效地应对模型中毒和数据中毒等多种恶意攻击，并提高了对潜在数据中毒攻击的检测和处理能力，如标签翻转和标签混乱。此外，该方法能够适当地平衡精度和鲁棒性，从而在对抗不同类型的攻击时保持较高的检测准确率。"
}