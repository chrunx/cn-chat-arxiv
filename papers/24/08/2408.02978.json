{
    "title": "ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval",
    "abstract": "arXiv:2408.02978v1 Announce Type: cross  Abstract: E-commerce is increasingly multimedia-enriched, with products exhibited in a broad-domain manner as images, short videos, or live stream promotions. A unified and vectorized cross-domain production representation is essential. Due to large intra-product variance and high inter-product similarity in the broad-domain scenario, a visual-only representation is inadequate. While Automatic Speech Recognition (ASR) text derived from the short or live-stream videos is readily accessible, how to de-noise the excessively noisy text for multimodal representation learning is mostly untouched. We propose ASR-enhanced Multimodal Product Representation Learning (AMPere). In order to extract product-specific information from the raw ASR text, AMPere uses an easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text, together with visual data, is then fed into a multi-branch network to generate compact multimodal embeddings. Extensive exp",
    "link": "https://arxiv.org/abs/2408.02978",
    "context": "Title: ASR-enhanced Multimodal Representation Learning for Cross-Domain Product Retrieval\nAbstract: arXiv:2408.02978v1 Announce Type: cross  Abstract: E-commerce is increasingly multimedia-enriched, with products exhibited in a broad-domain manner as images, short videos, or live stream promotions. A unified and vectorized cross-domain production representation is essential. Due to large intra-product variance and high inter-product similarity in the broad-domain scenario, a visual-only representation is inadequate. While Automatic Speech Recognition (ASR) text derived from the short or live-stream videos is readily accessible, how to de-noise the excessively noisy text for multimodal representation learning is mostly untouched. We propose ASR-enhanced Multimodal Product Representation Learning (AMPere). In order to extract product-specific information from the raw ASR text, AMPere uses an easy-to-implement LLM-based ASR text summarizer. The LLM-summarized text, together with visual data, is then fed into a multi-branch network to generate compact multimodal embeddings. Extensive exp",
    "path": "papers/24/08/2408.02978.json",
    "total_tokens": 382,
    "tldr": "该文章提出的ASR-enhanced Multimodal Product Representation Learning（AMPere）方法通过使用基于LLM的ASR文本摘要器简化从噪声ASR文本中提取产品相关信息的过程，并将其与视觉数据联合输入到一个多分支网络中，以生成紧凑的跨域产品 multimodal 表示。"
}