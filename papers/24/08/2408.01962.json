{
    "title": "The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations",
    "abstract": "arXiv:2408.01962v1 Announce Type: cross  Abstract: Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an int",
    "link": "https://arxiv.org/abs/2408.01962",
    "context": "Title: The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations\nAbstract: arXiv:2408.01962v1 Announce Type: cross  Abstract: Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an int",
    "path": "papers/24/08/2408.01962.json",
    "total_tokens": 390,
    "tldr": "该文章探讨了开放式生成模型在以人为本的数据科学工作中的影响，以事实核查机构为案例研究对象。文章特别关注了开放式生成模型在打击网络谣言和促进数据科学领域工作的透明度和可重复性方面的作用，并且分析了这些模型在不同组织和行业中的实际应用情况。通过研究事实核查机构如何利用开放式模型来分析大量信息并且保持工作的客观性，文章揭示了生成性AI对社会的影响，为AI在社会层面的研究提供了新的视角。"
}