{
    "title": "The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations",
    "abstract": "arXiv:2408.01962v1 Announce Type: cross  Abstract: Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an int",
    "link": "https://arxiv.org/abs/2408.01962",
    "context": "Title: The Implications of Open Generative Models in Human-Centered Data Science Work: A Case Study with Fact-Checking Organizations\nAbstract: arXiv:2408.01962v1 Announce Type: cross  Abstract: Calls to use open generative language models in academic research have highlighted the need for reproducibility and transparency in scientific research. However, the impact of generative AI extends well beyond academia, as corporations and public interest organizations have begun integrating these models into their data science pipelines. We expand this lens to include the impact of open models on organizations, focusing specifically on fact-checking organizations, which use AI to observe and analyze large volumes of circulating misinformation, yet must also ensure the reproducibility and impartiality of their work. We wanted to understand where fact-checking organizations use open models in their data science pipelines; what motivates their use of open models or proprietary models; and how their use of open or proprietary models can inform research on the societal impact of generative AI. To answer these questions, we conducted an int",
    "path": "papers/24/08/2408.01962.json",
    "total_tokens": 677,
    "translated_title": "开放生成模型在以人为本的数据科学工作中的影响：基于事实核查组织的案例研究",
    "translated_abstract": "arXiv:2408.01962v1 公告类型：交叉 摘要：呼吁在学术研究中使用开放的生成语言模型，强调了科学研究可重复性和透明性的需求。然而，生成性AI的影响远不止于学术界，因为企业和公共利益组织也开始将这些模型融入到他们的数据科学流中。我们扩大了这个视角，包括开放模型对组织的影</p>",
    "tldr": "本研究探讨了开放生成模型对以人为本的数据科学工作，特别是事实核查组织的具体影响，并分析了这些组织在数据科学流程中使用开放模型的动机及其对AI生成社会影响的潜在影响。"
}