{
    "title": "Network Fission Ensembles for Low-Cost Self-Ensembles",
    "abstract": "arXiv:2408.02301v1 Announce Type: new  Abstract: Recent ensemble learning methods for image classification have been shown to improve classification accuracy with low extra cost. However, they still require multiple trained models for ensemble inference, which eventually becomes a significant burden when the model size increases. In this paper, we propose a low-cost ensemble learning and inference, called Network Fission Ensembles (NFE), by converting a conventional network itself into a multi-exit structure. Starting from a given initial network, we first prune some of the weights to reduce the training burden. We then group the remaining weights into several sets and create multiple auxiliary paths using each set to construct multi-exits. We call this process Network Fission. Through this, multiple outputs can be obtained from a single network, which enables ensemble learning. Since this process simply changes the existing network structure to multi-exits without using additional net",
    "link": "https://arxiv.org/abs/2408.02301",
    "context": "Title: Network Fission Ensembles for Low-Cost Self-Ensembles\nAbstract: arXiv:2408.02301v1 Announce Type: new  Abstract: Recent ensemble learning methods for image classification have been shown to improve classification accuracy with low extra cost. However, they still require multiple trained models for ensemble inference, which eventually becomes a significant burden when the model size increases. In this paper, we propose a low-cost ensemble learning and inference, called Network Fission Ensembles (NFE), by converting a conventional network itself into a multi-exit structure. Starting from a given initial network, we first prune some of the weights to reduce the training burden. We then group the remaining weights into several sets and create multiple auxiliary paths using each set to construct multi-exits. We call this process Network Fission. Through this, multiple outputs can be obtained from a single network, which enables ensemble learning. Since this process simply changes the existing network structure to multi-exits without using additional net",
    "path": "papers/24/08/2408.02301.json",
    "total_tokens": 690,
    "translated_title": "论文标题：低成本自我孤立集的网络分裂方法",
    "translated_abstract": "arXiv: 2408.02301v1 公告类型：新  摘要：近年来，用于图像分类的集成学习方法已显示出能够在不增加额外成本的情况下提高分类精度。然而，它们仍然需要在集成推理中使用多个训练模型，当模型大小增加时，这最终将成为一项重大负担。在本文中，我们提出了一个低成本集成学习和推理的方法，称为Network Fission Ensembles（NFE），通过将传统的网络自身转化为多出口结构。从一个给定的初始网络开始，我们首先剪枝一些权重以减少训练负担。然后，我们将剩余的权重分组为若干组，并为每组创建多个辅助路径以构造多出口。我们称这一过程为Network Fission。通过这种方式，可以从单个网络中获得多个输出，这使得集成学习成为可能。由于这个过程仅将现有网络的结构改变为多出口，而不需要使用额外的网络结构，因此实现了高效地创建多个输出。此外，通过使用预测概率的上采样的集成策略，可以进一步提高分类精度。实验表明，该方法在提高分类准确率的同时，没有显著增加训练成本。",
    "tldr": "论文提出了一种名为Network Fission Ensembles的低成本集成学习与推论方法，通过在单个网络中生成多个输出来实现集成，消除了多重模型带来的成本。"
}