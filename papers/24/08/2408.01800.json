{
    "title": "MiniCPM-V: A GPT-4V Level MLLM on Your Phone",
    "abstract": "arXiv:2408.01800v1 Announce Type: new  Abstract: The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain preventing MLLMs from being practical in real-world applications. The most notable challenge comes from the huge cost of running an MLLM with a massive number of parameters and extensive computation. As a result, most MLLMs need to be deployed on high-performing cloud servers, which greatly limits their application scopes such as mobile, offline, energy-sensitive, and privacy-protective scenarios. In this work, we present MiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By integrating the latest MLLM techniques in architecture, pretraining and alignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1) Strong performance, outperforming GPT-4V-1106, Gemini Pro and Claud",
    "link": "https://arxiv.org/abs/2408.01800",
    "context": "Title: MiniCPM-V: A GPT-4V Level MLLM on Your Phone\nAbstract: arXiv:2408.01800v1 Announce Type: new  Abstract: The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain preventing MLLMs from being practical in real-world applications. The most notable challenge comes from the huge cost of running an MLLM with a massive number of parameters and extensive computation. As a result, most MLLMs need to be deployed on high-performing cloud servers, which greatly limits their application scopes such as mobile, offline, energy-sensitive, and privacy-protective scenarios. In this work, we present MiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By integrating the latest MLLM techniques in architecture, pretraining and alignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1) Strong performance, outperforming GPT-4V-1106, Gemini Pro and Claud",
    "path": "papers/24/08/2408.01800.json",
    "total_tokens": 426,
    "tldr": "该文章提出的MiniCPM-V系列MLLMs实现了在终端设备上的高效部署，通过先进的架构、预训练和校准技术，显著降低了运行大型语言模型的成本，使其在移动、离线、能源敏感和隐私保护等场景中的应用成为可能，特别是在与GPT-4V-1106、Gemini Pro和Claud相比时，MiniCPM-Llama3-V 2.5在性能上表现出众。"
}