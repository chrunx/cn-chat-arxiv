{
    "title": "MiniCPM-V: A GPT-4V Level MLLM on Your Phone",
    "abstract": "arXiv:2408.01800v1 Announce Type: new  Abstract: The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain preventing MLLMs from being practical in real-world applications. The most notable challenge comes from the huge cost of running an MLLM with a massive number of parameters and extensive computation. As a result, most MLLMs need to be deployed on high-performing cloud servers, which greatly limits their application scopes such as mobile, offline, energy-sensitive, and privacy-protective scenarios. In this work, we present MiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By integrating the latest MLLM techniques in architecture, pretraining and alignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1) Strong performance, outperforming GPT-4V-1106, Gemini Pro and Claud",
    "link": "https://arxiv.org/abs/2408.01800",
    "context": "Title: MiniCPM-V: A GPT-4V Level MLLM on Your Phone\nAbstract: arXiv:2408.01800v1 Announce Type: new  Abstract: The recent surge of Multimodal Large Language Models (MLLMs) has fundamentally reshaped the landscape of AI research and industry, shedding light on a promising path toward the next AI milestone. However, significant challenges remain preventing MLLMs from being practical in real-world applications. The most notable challenge comes from the huge cost of running an MLLM with a massive number of parameters and extensive computation. As a result, most MLLMs need to be deployed on high-performing cloud servers, which greatly limits their application scopes such as mobile, offline, energy-sensitive, and privacy-protective scenarios. In this work, we present MiniCPM-V, a series of efficient MLLMs deployable on end-side devices. By integrating the latest MLLM techniques in architecture, pretraining and alignment, the latest MiniCPM-Llama3-V 2.5 has several notable features: (1) Strong performance, outperforming GPT-4V-1106, Gemini Pro and Claud",
    "path": "papers/24/08/2408.01800.json",
    "total_tokens": 851,
    "translated_title": "MiniCPM-V: 一款可在您手机上运行的GPT-4V级别的MLLM",
    "translated_abstract": "arXiv:2408.01800v1 宣布类型：新  摘要：最近的多模态大型语言模型（MLLM）的兴起彻底改变了人工智能研究和行业的发展，并照亮了一条通往下一个人工智能里程碑的道路。然而，阻止MLLM在现实世界应用中变得实用的重大挑战仍然存在。最大的挑战之一来自于运行具有大量参数的MLLM所需的高昂成本和大量的计算需求。因此，大多数MLLM需要在高性能的云服务器上运行，这极大地限制了它们的应用范围，如移动、离线、能源敏感和隐私保护的场景。在这项工作中，我们推出了MiniCPM-V系列，这是一款可以在设备端部署的效率MLLM。通过在架构、预训练和校准方面集成最新的MLLM技术，最新的MiniCPM-Llama3-V 2.5具有以下特点：（1）强大的性能，超过了GPT-4V-1106、Gemini Pro和Claudrat’s Pluribus。（2）高效能，大大降低了模型运行的能耗和成本。（3）易部署，可以被轻松地集成到现有的移动应用程序中，为用户提供高质量的语言理解和生成能力，同时保护用户的隐私和数据安全。",
    "tldr": "MiniCPM-V是一款能实现在手机上运行的强大且高效的多模态大型语言模型，它在性能上超越了GPT-4V-1106，Gemini Pro和Claudrat's Pluribus，并且大大减少了能耗和成本，可以为移动应用提供高质量的语言理解和生成能力，同时也保护了用户隐私和数据安全。",
    "en_tdlr": "MiniCPM-V is an efficient multimodal large language model that performs beyond GPT-4V-1106, Gemini Pro, and Claudrat's Pluribus, significantly reducing energy consumption and costs, and offers high-quality language understanding and generation capabilities for mobile apps, all while safeguarding user privacy and data security."
}