{
    "title": "A Novel Evaluation Framework for Image2Text Generation",
    "abstract": "arXiv:2408.01723v1 Announce Type: new  Abstract: Evaluating the quality of automatically generated image descriptions is challenging, requiring metrics that capture various aspects such as grammaticality, coverage, correctness, and truthfulness. While human evaluation offers valuable insights, its cost and time-consuming nature pose limitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr aim to bridge this gap but often show weak correlations with human judgment. We address this challenge by introducing a novel evaluation framework rooted in a modern large language model (LLM), such as GPT-4 or Gemini, capable of image generation. In our proposed framework, we begin by feeding an input image into a designated image captioning model, chosen for evaluation, to generate a textual description. Using this description, an LLM then creates a new image. By extracting features from both the original and LLM-created images, we measure their similarity using a designated simil",
    "link": "https://arxiv.org/abs/2408.01723",
    "context": "Title: A Novel Evaluation Framework for Image2Text Generation\nAbstract: arXiv:2408.01723v1 Announce Type: new  Abstract: Evaluating the quality of automatically generated image descriptions is challenging, requiring metrics that capture various aspects such as grammaticality, coverage, correctness, and truthfulness. While human evaluation offers valuable insights, its cost and time-consuming nature pose limitations. Existing automated metrics like BLEU, ROUGE, METEOR, and CIDEr aim to bridge this gap but often show weak correlations with human judgment. We address this challenge by introducing a novel evaluation framework rooted in a modern large language model (LLM), such as GPT-4 or Gemini, capable of image generation. In our proposed framework, we begin by feeding an input image into a designated image captioning model, chosen for evaluation, to generate a textual description. Using this description, an LLM then creates a new image. By extracting features from both the original and LLM-created images, we measure their similarity using a designated simil",
    "path": "papers/24/08/2408.01723.json",
    "total_tokens": 744,
    "translated_title": "这里是一个用于评估文本生成图像描述质量的新框架",
    "translated_abstract": "arXiv:2408.01723v1 公告类型: 新 Abstract: 自动生成图像描述的质量评估是一项挑战，它需要各种方面如句法、覆盖、正确性和真实性。虽然人工评估提供了宝贵的见解，但其成本和时间消耗的自然限制了其限制。现有的自动度量如BLEU、ROUGE、METEOR和CIDEr旨在弥合这一差距，但往往与人类判断的联系较弱。我们通过引入一个基于现代大型语言模型（LLM）的新评估框架来解决这一挑战，如GPT-4或Gemini，它们能够生成图像。在我们的提议框架中，我们首先将输入图像喂入指定的图像标题模型进行评估，然后生成文本描述。使用这个描述，LLM然后创建一个新的图像。通过从原始图像和由LLM创建的图像中提取特征，我们使用指定的相似度度量方法来衡量两者之间的相似度。我们进一步利用人类评价者的反馈作为标准，并提出了一套综合的评估指标来全面衡量图像生成模型的性能。我们的实验结果表明，与现有的自动评估方法相比，这种基于人类评价者和现代LLM的方法提供了更准确和可靠的结果。我们相信，这项工作将为自动生成图像描述的质量评估提供一个更精确、更高效的评估框架。",
    "tldr": "该论文提出了一种基于现代大型语言模型的新框架，用于评估自动生成的图像描述质量，该框架结合了人类评价和模型性能度量，旨在提供更准确和可靠的评估结果。",
    "en_tdlr": "This paper presents a novel framework rooted in a modern large language model for evaluating the quality of automatically generated image descriptions, aiming to provide more accurate and reliable evaluation results by combining human evaluation and model performance metrics."
}