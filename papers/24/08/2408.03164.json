{
    "title": "Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study",
    "abstract": "arXiv:2408.03164v1 Announce Type: new  Abstract: Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced convolution method that allows enlarging the receptive fields (RF) without increasing the number of parameters, like the dilated convolution, yet without imposing a regular grid. DCLS has been shown to outperform the standard and dilated convolutions on several computer vision benchmarks. Here, we show that, in addition, DCLS increases the models' interpretability, defined as the alignment with human visual strategies. To quantify it, we use the Spearman correlation between the models' GradCAM heatmaps and the ClickMe dataset heatmaps, which reflect human visual attention. We took eight reference models - ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and 36) - and drop-in replaced the standard convolution layers with DCLS ones. This improved the interpretability score in seven of them. Moreover, we observed that Grad-CAM generated random he",
    "link": "https://arxiv.org/abs/2408.03164",
    "context": "Title: Dilated Convolution with Learnable Spacings makes visual models more aligned with humans: a Grad-CAM study\nAbstract: arXiv:2408.03164v1 Announce Type: new  Abstract: Dilated Convolution with Learnable Spacing (DCLS) is a recent advanced convolution method that allows enlarging the receptive fields (RF) without increasing the number of parameters, like the dilated convolution, yet without imposing a regular grid. DCLS has been shown to outperform the standard and dilated convolutions on several computer vision benchmarks. Here, we show that, in addition, DCLS increases the models' interpretability, defined as the alignment with human visual strategies. To quantify it, we use the Spearman correlation between the models' GradCAM heatmaps and the ClickMe dataset heatmaps, which reflect human visual attention. We took eight reference models - ResNet50, ConvNeXt (T, S and B), CAFormer, ConvFormer, and FastViT (sa 24 and 36) - and drop-in replaced the standard convolution layers with DCLS ones. This improved the interpretability score in seven of them. Moreover, we observed that Grad-CAM generated random he",
    "path": "papers/24/08/2408.03164.json",
    "total_tokens": 452,
    "tldr": "该文章展示了使用可学习间隔的空间膨胀卷积（DCLS）的方法，这种方法不仅在计算机视觉基准测试中超越了标准和膨胀卷积，还在提升模型的可解释性方面取得了显著进步。可解释性通过与人类视觉策略的对应关系来衡量，即通过比较基于模型的GradCAM热图与反映人类视觉注意度的ClickMe数据集热图之间的Spearman相关系数来评估。该方法在多个基准模型中得到了应用，并提高了模型的可解释性评分，表明DCLS增加了模型与人类视觉策略的一致性。"
}