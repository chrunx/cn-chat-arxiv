{
    "title": "MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture Generation",
    "abstract": "arXiv:2408.03312v1 Announce Type: new  Abstract: Recent advancements in the field of Diffusion Transformers have substantially improved the generation of high-quality 2D images, 3D videos, and 3D shapes. However, the effectiveness of the Transformer architecture in the domain of co-speech gesture generation remains relatively unexplored, as prior methodologies have predominantly employed the Convolutional Neural Network (CNNs) or simple a few transformer layers. In an attempt to bridge this research gap, we introduce a novel Masked Diffusion Transformer for co-speech gesture generation, referred to as MDT-A2G, which directly implements the denoising process on gesture sequences. To enhance the contextual reasoning capability of temporally aligned speech-driven gestures, we incorporate a novel Masked Diffusion Transformer. This model employs a mask modeling scheme specifically designed to strengthen temporal relation learning among sequence gestures, thereby expediting the learning proc",
    "link": "https://arxiv.org/abs/2408.03312",
    "context": "Title: MDT-A2G: Exploring Masked Diffusion Transformers for Co-Speech Gesture Generation\nAbstract: arXiv:2408.03312v1 Announce Type: new  Abstract: Recent advancements in the field of Diffusion Transformers have substantially improved the generation of high-quality 2D images, 3D videos, and 3D shapes. However, the effectiveness of the Transformer architecture in the domain of co-speech gesture generation remains relatively unexplored, as prior methodologies have predominantly employed the Convolutional Neural Network (CNNs) or simple a few transformer layers. In an attempt to bridge this research gap, we introduce a novel Masked Diffusion Transformer for co-speech gesture generation, referred to as MDT-A2G, which directly implements the denoising process on gesture sequences. To enhance the contextual reasoning capability of temporally aligned speech-driven gestures, we incorporate a novel Masked Diffusion Transformer. This model employs a mask modeling scheme specifically designed to strengthen temporal relation learning among sequence gestures, thereby expediting the learning proc",
    "path": "papers/24/08/2408.03312.json",
    "total_tokens": 378,
    "tldr": "该文章提出了一种名为MDT-A2G的新型Masked Diffusion Transformer模型，用于同步手势生成。该模型采用了一种特殊的Masked Diffusion Transformer架构，能够在不依赖CNNs的情况下，通过模式掩码来加强动作序列中的时间关联学习，从而加速了同步手势生成的学习过程，并通过直接实施于手势序列的退火过程来提高整个任务的质量。"
}