{
    "title": "Designing Extremely Memory-Efficient CNNs for On-device Vision Tasks",
    "abstract": "arXiv:2408.03663v1 Announce Type: new  Abstract: In this paper, we introduce a memory-efficient CNN (convolutional neural network), which enables resource-constrained low-end embedded and IoT devices to perform on-device vision tasks, such as image classification and object detection, using extremely low memory, i.e., only 63 KB on ImageNet classification. Based on the bottleneck block of MobileNet, we propose three design principles that significantly curtail the peak memory usage of a CNN so that it can fit the limited KB memory of the low-end device. First, 'input segmentation' divides an input image into a set of patches, including the central patch overlapped with the others, reducing the size (and memory requirement) of a large input image. Second, 'patch tunneling' builds independent tunnel-like paths consisting of multiple bottleneck blocks per patch, penetrating through the entire model from an input patch to the last layer of the network, maintaining lightweight memory usage ",
    "link": "https://arxiv.org/abs/2408.03663",
    "context": "Title: Designing Extremely Memory-Efficient CNNs for On-device Vision Tasks\nAbstract: arXiv:2408.03663v1 Announce Type: new  Abstract: In this paper, we introduce a memory-efficient CNN (convolutional neural network), which enables resource-constrained low-end embedded and IoT devices to perform on-device vision tasks, such as image classification and object detection, using extremely low memory, i.e., only 63 KB on ImageNet classification. Based on the bottleneck block of MobileNet, we propose three design principles that significantly curtail the peak memory usage of a CNN so that it can fit the limited KB memory of the low-end device. First, 'input segmentation' divides an input image into a set of patches, including the central patch overlapped with the others, reducing the size (and memory requirement) of a large input image. Second, 'patch tunneling' builds independent tunnel-like paths consisting of multiple bottleneck blocks per patch, penetrating through the entire model from an input patch to the last layer of the network, maintaining lightweight memory usage ",
    "path": "papers/24/08/2408.03663.json",
    "total_tokens": 440,
    "tldr": "该文章提出了一种极低内存消耗的CNN模型，该模型使得资源有限的低端嵌入式和物联网设备能够在极其有限的63KB内存下执行包括图像分类和物体检测在内的本地视觉任务。通过结合MobileNet的瓶颈块设计原理，作者提出了三个主要的设计原则，这些原则大大减少了对CNN峰值内存的消耗，使得模型能够适应设备上有限的KB内存。文章通过将输入图像分割为一系列小块并构建独立的小块传输路径，从而有效降低了内存需求，并为每块构建了多个瓶颈块组成的隧道路径，实现了在保持轻量级内存消耗的同时，从输入块到模型最后一层的穿透性连接。"
}