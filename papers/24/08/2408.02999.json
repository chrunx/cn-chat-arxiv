{
    "title": "LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning",
    "abstract": "arXiv:2408.02999v1 Announce Type: cross  Abstract: The emergence of intelligence in large language models (LLMs) has inspired investigations into their integration into automata learning. This paper introduces the probabilistic Minimally Adequate Teacher (pMAT) formulation, which leverages a probabilistic oracle that could give persistent errors randomly during answering the membership queries for deterministic finite automata (DFA) learning. Given the tendency of LLMs to produce hallucinatory content, we have developed techniques to improve answer accuracy and ensure the correctness of the learned automata. We propose the $\\mathtt{Discrimination}$ prompt as well as the $\\mathtt{Verification}$ prompt and explore their advantages over common prompts. Additionally, we compare DFA learning performance between the TTT algorithm and common active learning algorithms. To address the exponential number of persistent errors, we implement a dynamic query cache refinement algorithm that identifi",
    "link": "https://arxiv.org/abs/2408.02999",
    "context": "Title: LLMs as Probabilistic Minimally Adequate Teachers for DFA Learning\nAbstract: arXiv:2408.02999v1 Announce Type: cross  Abstract: The emergence of intelligence in large language models (LLMs) has inspired investigations into their integration into automata learning. This paper introduces the probabilistic Minimally Adequate Teacher (pMAT) formulation, which leverages a probabilistic oracle that could give persistent errors randomly during answering the membership queries for deterministic finite automata (DFA) learning. Given the tendency of LLMs to produce hallucinatory content, we have developed techniques to improve answer accuracy and ensure the correctness of the learned automata. We propose the $\\mathtt{Discrimination}$ prompt as well as the $\\mathtt{Verification}$ prompt and explore their advantages over common prompts. Additionally, we compare DFA learning performance between the TTT algorithm and common active learning algorithms. To address the exponential number of persistent errors, we implement a dynamic query cache refinement algorithm that identifi",
    "path": "papers/24/08/2408.02999.json",
    "total_tokens": 397,
    "tldr": "该文章介绍了利用大型语言模型（LLMs）作为概率性最小适当教师（pMAT）的新框架，用于在DFA（确定性有限自动机）学习过程中进行错误概率性的随机分布，并为大概率产生错误的情况下提供了应对策略。通过利用LLMs可能出现的错误特性，提出了改进的提示和方法来提高学习效率和模型准确性。此外，该研究还对比了TTT算法和其他常见主动学习算法在DFA学习中的性能差异，并且为了解决可能导致的错误数量爆炸问题，该研究还引入了一种动态查询缓存算法来优化查询过程。"
}