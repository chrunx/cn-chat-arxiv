{
    "title": "Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting",
    "abstract": "arXiv:2408.01423v1 Announce Type: cross  Abstract: Large Language Models (LLMs) exhibit remarkable proficiency in addressing a diverse array of tasks within the Natural Language Processing (NLP) domain, with various prompt design strategies significantly augmenting their capabilities. However, these prompts, while beneficial, each possess inherent limitations. The primary prompt design methodologies are twofold: The first, exemplified by the Chain of Thought (CoT), involves manually crafting prompts specific to individual datasets, hence termed Expert-Designed Prompts (EDPs). Once these prompts are established, they are unalterable, and their effectiveness is capped by the expertise of the human designers. When applied to LLMs, the static nature of EDPs results in a uniform approach to both simple and complex problems within the same dataset, leading to the inefficient use of tokens for straightforward issues. The second method involves prompts autonomously generated by the LLM, known ",
    "link": "https://arxiv.org/abs/2408.01423",
    "context": "Title: Prompt Recursive Search: A Living Framework with Adaptive Growth in LLM Auto-Prompting\nAbstract: arXiv:2408.01423v1 Announce Type: cross  Abstract: Large Language Models (LLMs) exhibit remarkable proficiency in addressing a diverse array of tasks within the Natural Language Processing (NLP) domain, with various prompt design strategies significantly augmenting their capabilities. However, these prompts, while beneficial, each possess inherent limitations. The primary prompt design methodologies are twofold: The first, exemplified by the Chain of Thought (CoT), involves manually crafting prompts specific to individual datasets, hence termed Expert-Designed Prompts (EDPs). Once these prompts are established, they are unalterable, and their effectiveness is capped by the expertise of the human designers. When applied to LLMs, the static nature of EDPs results in a uniform approach to both simple and complex problems within the same dataset, leading to the inefficient use of tokens for straightforward issues. The second method involves prompts autonomously generated by the LLM, known ",
    "path": "papers/24/08/2408.01423.json",
    "total_tokens": 875,
    "translated_title": "递归提示搜索：在LLM自动提示中具有自适应增长的生命框架",
    "translated_abstract": "arXiv:2408.01423v1 公告类型：交叉 摘要：大型语言模型（LLMs）在自然语言处理（NLP）领域执行了一系列不同任务，其中各种提示设计策略显著提升了它们的性能。然而，这些提示本身存在固有局限性。主要的提示设计方法有两种：第一种，例如链式思想（CoT），涉及针对特定数据集手动设计提示，因此称为专家设计提示（EDPs）。一旦这些提示确立，它们就是不可改变的，并且它们的效果上限由人类设计者的专业知识决定。当将这些静态EDPs应用于LLMs时，对于同一数据集中的简单和复杂问题，都会采取统一的方法，导致文本模式对简单问题的使用效率低下。第二种方法涉及由LLM自主生成的提示，此类提示被称为自助式生成提示（AGPs）。传统的AGPs通过自适应性维持LLMs在各种情况下的性能，但其灵活性仍然受到局限，特别是对于离标准模式偏差的聚类问题。此外，AGPs不区分问题的复杂性和简单性，导致在相对简单的问题上使用的提示长度比实际需求要长，而在复杂的任务上发挥作用较弱。为此，本文提出了递归提示搜索（RRS）框架，该框架通过调整提示调用来适应问题复杂性，自适应地扩展提示集。递归搜索一方面通过深度学习模型识别不同类型的任务复杂性，另一方面通过调整提示参数，提供对LLM局部能力增强的动态提示机制。这种机制的作用是优化提示使用效率，并增加LLM在非标准问题上的响应能力。通过实验验证，在多个具有不同复杂性的基准数据集上，我们展示了RRS框架的优越性能，证明其在简化复杂的问题处理和强化对非标准问题的处理能力方面超过了现有的专家设计提示和自助式生成提示策略。",
    "tldr": "本文提出了一种递归提示搜索框架，该框架通过自适应地扩展提示集并调整提示调用，以优化提示使用效率和增强大型语言模型在处理复杂和非标准问题时的能力。"
}