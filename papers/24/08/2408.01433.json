{
    "title": "Evaluating and Enhancing Trustworthiness of LLMs in Perception Tasks",
    "abstract": "arXiv:2408.01433v1 Announce Type: new  Abstract: Today's advanced driver assistance systems (ADAS), like adaptive cruise control or rear collision warning, are finding broader adoption across vehicle classes. Integrating such advanced, multimodal Large Language Models (LLMs) on board a vehicle, which are capable of processing text, images, audio, and other data types, may have the potential to greatly enhance passenger comfort. Yet, an LLM's hallucinations are still a major challenge to be addressed. In this paper, we systematically assessed potential hallucination detection strategies for such LLMs in the context of object detection in vision-based data on the example of pedestrian detection and localization. We evaluate three hallucination detection strategies applied to two state-of-the-art LLMs, the proprietary GPT-4V and the open LLaVA, on two datasets (Waymo/US and PREPER CITY/Sweden). Our results show that these LLMs can describe a traffic situation to an impressive level of det",
    "link": "https://arxiv.org/abs/2408.01433",
    "context": "Title: Evaluating and Enhancing Trustworthiness of LLMs in Perception Tasks\nAbstract: arXiv:2408.01433v1 Announce Type: new  Abstract: Today's advanced driver assistance systems (ADAS), like adaptive cruise control or rear collision warning, are finding broader adoption across vehicle classes. Integrating such advanced, multimodal Large Language Models (LLMs) on board a vehicle, which are capable of processing text, images, audio, and other data types, may have the potential to greatly enhance passenger comfort. Yet, an LLM's hallucinations are still a major challenge to be addressed. In this paper, we systematically assessed potential hallucination detection strategies for such LLMs in the context of object detection in vision-based data on the example of pedestrian detection and localization. We evaluate three hallucination detection strategies applied to two state-of-the-art LLMs, the proprietary GPT-4V and the open LLaVA, on two datasets (Waymo/US and PREPER CITY/Sweden). Our results show that these LLMs can describe a traffic situation to an impressive level of det",
    "path": "papers/24/08/2408.01433.json",
    "total_tokens": 371,
    "tldr": "该文章创新性地评估并提升了大型语言模型（LLMs）在感知任务中的可靠性，特别是在复杂交通场景视觉数据分析中的应用，通过分析两种先进的LLMs，即GPT-4V和LLaVA在两种不同数据集上的性能，有效提升了车辆高级辅助驾驶系统的准确性。"
}