{
    "title": "Evaluating and Enhancing Trustworthiness of LLMs in Perception Tasks",
    "abstract": "arXiv:2408.01433v1 Announce Type: cross  Abstract: Today's advanced driver assistance systems (ADAS), like adaptive cruise control or rear collision warning, are finding broader adoption across vehicle classes. Integrating such advanced, multimodal Large Language Models (LLMs) on board a vehicle, which are capable of processing text, images, audio, and other data types, may have the potential to greatly enhance passenger comfort. Yet, an LLM's hallucinations are still a major challenge to be addressed. In this paper, we systematically assessed potential hallucination detection strategies for such LLMs in the context of object detection in vision-based data on the example of pedestrian detection and localization. We evaluate three hallucination detection strategies applied to two state-of-the-art LLMs, the proprietary GPT-4V and the open LLaVA, on two datasets (Waymo/US and PREPER CITY/Sweden). Our results show that these LLMs can describe a traffic situation to an impressive level of d",
    "link": "https://arxiv.org/abs/2408.01433",
    "context": "Title: Evaluating and Enhancing Trustworthiness of LLMs in Perception Tasks\nAbstract: arXiv:2408.01433v1 Announce Type: cross  Abstract: Today's advanced driver assistance systems (ADAS), like adaptive cruise control or rear collision warning, are finding broader adoption across vehicle classes. Integrating such advanced, multimodal Large Language Models (LLMs) on board a vehicle, which are capable of processing text, images, audio, and other data types, may have the potential to greatly enhance passenger comfort. Yet, an LLM's hallucinations are still a major challenge to be addressed. In this paper, we systematically assessed potential hallucination detection strategies for such LLMs in the context of object detection in vision-based data on the example of pedestrian detection and localization. We evaluate three hallucination detection strategies applied to two state-of-the-art LLMs, the proprietary GPT-4V and the open LLaVA, on two datasets (Waymo/US and PREPER CITY/Sweden). Our results show that these LLMs can describe a traffic situation to an impressive level of d",
    "path": "papers/24/08/2408.01433.json",
    "total_tokens": 437,
    "tldr": "该文章系统评估了大型语言模型在感知任务中的可信度，特别是指出了其在视觉数据中的对象检测能力，如在行人检测和定位方面的表现。通过实验展示了三种不同的错误检测策略，并应用于两款先进的语言模型GPT-4V和LLaVA，分别在Waymo/US和PREPER CITY/Sweden两个数据集上进行了测试。结果显示，尽管这些模型在描述交通情况时表现出很高的水平，但在实际的错误检测方面还存在着一定的挑战。总而言之，该研究为提高大型语言模型在感知任务中的准确性和可靠性提供了重要的见解和方向。"
}