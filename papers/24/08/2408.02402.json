{
    "title": "Enhancing AI-based Generation of Software Exploits with Contextual Information",
    "abstract": "arXiv:2408.02402v1 Announce Type: cross  Abstract: This practical experience report explores Neural Machine Translation (NMT) models' capability to generate offensive security code from natural language (NL) descriptions, highlighting the significance of contextual understanding and its impact on model performance. Our study employs a dataset comprising real shellcodes to evaluate the models across various scenarios, including missing information, necessary context, and unnecessary context. The experiments are designed to assess the models' resilience against incomplete descriptions, their proficiency in leveraging context for enhanced accuracy, and their ability to discern irrelevant information. The findings reveal that the introduction of contextual data significantly improves performance. However, the benefits of additional context diminish beyond a certain point, indicating an optimal level of contextual information for model training. Moreover, the models demonstrate an ability t",
    "link": "https://arxiv.org/abs/2408.02402",
    "context": "Title: Enhancing AI-based Generation of Software Exploits with Contextual Information\nAbstract: arXiv:2408.02402v1 Announce Type: cross  Abstract: This practical experience report explores Neural Machine Translation (NMT) models' capability to generate offensive security code from natural language (NL) descriptions, highlighting the significance of contextual understanding and its impact on model performance. Our study employs a dataset comprising real shellcodes to evaluate the models across various scenarios, including missing information, necessary context, and unnecessary context. The experiments are designed to assess the models' resilience against incomplete descriptions, their proficiency in leveraging context for enhanced accuracy, and their ability to discern irrelevant information. The findings reveal that the introduction of contextual data significantly improves performance. However, the benefits of additional context diminish beyond a certain point, indicating an optimal level of contextual information for model training. Moreover, the models demonstrate an ability t",
    "path": "papers/24/08/2408.02402.json",
    "total_tokens": 621,
    "translated_title": "利用上下文信息增强基于AI的软件漏洞产生技术",
    "tldr": "本文研究了NMT模型在生成软件漏洞代码中的上下文信息作用，通过实验评估了模型在不同信息量下的表现，并指出最优的上下文信息量，展示了模型辨识和利用上下文信息的能力。",
    "en_tdlr": "This study evaluates the impact of contextual information on AI-based generation of software exploit code by neural machine translation (NMT) models, demonstrating their ability to leverage necessary context for enhanced accuracy and their resilience against missing or irrelevant information."
}