{
    "title": "BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles",
    "abstract": "arXiv:2408.01841v1 Announce Type: new  Abstract: This article introduces BEVPlace++, a novel, fast, and robust LiDAR global localization method for unmanned ground vehicles. It uses lightweight convolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition followed by 3-DoF pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a rotation equivariant module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A Rotation Equivariant and Invariant Network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features a",
    "link": "https://arxiv.org/abs/2408.01841",
    "context": "Title: BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles\nAbstract: arXiv:2408.01841v1 Announce Type: new  Abstract: This article introduces BEVPlace++, a novel, fast, and robust LiDAR global localization method for unmanned ground vehicles. It uses lightweight convolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition followed by 3-DoF pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a rotation equivariant module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A Rotation Equivariant and Invariant Network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features a",
    "path": "papers/24/08/2408.01841.json",
    "total_tokens": 527,
    "tldr": "该文章创新性地提出BEVPlace++，一种在无人地面车辆上使用的快速、鲁棒且轻量级的激光雷达全局定位方法。该方法采用卷积神经网络（CNNs）对激光雷达数据生成的鸟瞰视图（BEV）图像进行处理，以通过Place Recognition和3个自由度（DoF）姿态估计实现准确的全局定位。研究显示，CNN能够有效提取来自BEV图像的独特特征，同时能够有效地匹配两张具有较大平移量的BEV图像的keypoints。基于这一发现，文章设计了一个旋转等变模块（REM）来提取独特的特征并增强了对旋转变化鲁棒性。进一步地，通过将REM和描述符生成器NetVLAD串联，构建了一个旋转等变和不变的网络（REIN），从而生成旋转等变的局部特征，同时保持了对旋转不变性的敏感性。实验验证了该方法的快速性和精度，表明它在实现高精度全局定位的同时，还保持了较快的计算速度和较强的鲁棒性。"
}