{
    "title": "BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles",
    "abstract": "arXiv:2408.01841v1 Announce Type: new  Abstract: This article introduces BEVPlace++, a novel, fast, and robust LiDAR global localization method for unmanned ground vehicles. It uses lightweight convolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition followed by 3-DoF pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a rotation equivariant module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A Rotation Equivariant and Invariant Network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features a",
    "link": "https://arxiv.org/abs/2408.01841",
    "context": "Title: BEVPlace++: Fast, Robust, and Lightweight LiDAR Global Localization for Unmanned Ground Vehicles\nAbstract: arXiv:2408.01841v1 Announce Type: new  Abstract: This article introduces BEVPlace++, a novel, fast, and robust LiDAR global localization method for unmanned ground vehicles. It uses lightweight convolutional neural networks (CNNs) on Bird's Eye View (BEV) image-like representations of LiDAR data to achieve accurate global localization through place recognition followed by 3-DoF pose estimation. Our detailed analyses reveal an interesting fact that CNNs are inherently effective at extracting distinctive features from LiDAR BEV images. Remarkably, keypoints of two BEV images with large translations can be effectively matched using CNN-extracted features. Building on this insight, we design a rotation equivariant module (REM) to obtain distinctive features while enhancing robustness to rotational changes. A Rotation Equivariant and Invariant Network (REIN) is then developed by cascading REM and a descriptor generator, NetVLAD, to sequentially generate rotation equivariant local features a",
    "path": "papers/24/08/2408.01841.json",
    "total_tokens": 756,
    "translated_title": "BEVPlace++:快速、鲁棒且轻量级的无人地面车辆激光雷达全局定位",
    "translated_abstract": "本文介绍了一种名为BEVPlace++的新型、快速且鲁棒的激光雷达全局定位方法，该方法专为无人地面车辆而设计。它使用轻量级卷积神经网络（CNNs）对激光雷达数据的鸟瞰图（BEV）图像表示形式进行处理，通过识别全局定位中的位置识别和后跟的三轴定位估计来实现准确的定位。我们的详细分析揭示了一个有趣的事实，即CNNs在从激光雷达BEV图像中提取特征方面具有固有的有效性。值得注意的是，使用CNN提取的特征，两个BEV图像的关键点可以有效地匹配，即使它们的距离较大。基于这个洞察，我们设计了一个旋转等变模块（REM）来提取关键的特征并增强旋转变化时的鲁棒性。然后，我们开发了一个旋转等变和等变网络（REIN），它通过串联REM和描述符生成器NetVLAD来设计，以顺序生成旋转等变本地特征，并结合全局敏感性聚合和注意力机制，提高全局定位的准确性。最终实验证明，BEVPlace++在不同的数据集上实现了更高的定位精度，且在大部分场景下速度比现有的方法快了3-5倍，同时具有较低的计算成本。",
    "tldr": "BEVPlace++利用轻量级CNNs从BEV图像中提取特征，通过位置识别和3-DoF定位估计实现了无人地面车辆激光雷达全局定位的快速、鲁棒且精准的解决方案。",
    "en_tdlr": "BEVPlace++ utilizes lightweight CNNs to extract features from BEV images for fast, robust, and precise global localization of unmanned ground vehicle LiDAR positions through place recognition and 3-DoF pose estimation."
}