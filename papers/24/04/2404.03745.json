{
    "title": "Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations",
    "abstract": "arXiv:2404.03745v2 Announce Type: replace-cross  Abstract: The widespread adoption and transformative effects of large language models (LLMs) have sparked concerns regarding their capacity to produce inaccurate and fictitious content, referred to as `hallucinations'. Given the potential risks associated with hallucinations, humans should be able to identify them. This research aims to understand the human perception of LLM hallucinations by systematically varying the degree of hallucination (genuine, minor hallucination, major hallucination) and examining its interaction with warning (i.e., a warning of potential inaccuracies: absent vs. present). Participants (N=419) from Prolific rated the perceived accuracy and engaged with content (e.g., like, dislike, share) in a Q/A format. Participants ranked content as truthful in the order of genuine, minor hallucination, and major hallucination, and user engagement behaviors mirrored this pattern. More importantly, we observed that warning im",
    "link": "https://arxiv.org/abs/2404.03745",
    "context": "Title: Fakes of Varying Shades: How Warning Affects Human Perception and Engagement Regarding LLM Hallucinations\nAbstract: arXiv:2404.03745v2 Announce Type: replace-cross  Abstract: The widespread adoption and transformative effects of large language models (LLMs) have sparked concerns regarding their capacity to produce inaccurate and fictitious content, referred to as `hallucinations'. Given the potential risks associated with hallucinations, humans should be able to identify them. This research aims to understand the human perception of LLM hallucinations by systematically varying the degree of hallucination (genuine, minor hallucination, major hallucination) and examining its interaction with warning (i.e., a warning of potential inaccuracies: absent vs. present). Participants (N=419) from Prolific rated the perceived accuracy and engaged with content (e.g., like, dislike, share) in a Q/A format. Participants ranked content as truthful in the order of genuine, minor hallucination, and major hallucination, and user engagement behaviors mirrored this pattern. More importantly, we observed that warning im",
    "path": "papers/24/04/2404.03745.json",
    "total_tokens": 338,
    "tldr": "该文章通过研究不同程度谎言和警告信息对社会接受度及所作反应的影响，揭示了紧急警告信息的重要性。"
}