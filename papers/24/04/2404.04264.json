{
    "title": "Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs",
    "abstract": "arXiv:2404.04264v3 Announce Type: replace-cross  Abstract: Despite the superb performance in many tasks, large language models (LLMs) bear the risk of generating hallucination or even wrong answers when confronted with tasks that demand the accuracy of knowledge. The issue becomes even more noticeable when addressing logic queries that require multiple logic reasoning steps. On the other hand, knowledge graph (KG) based question answering methods are capable of accurately identifying the correct answers with the help of knowledge graph, yet its accuracy could quickly deteriorate when the knowledge graph itself is sparse and incomplete. It remains a critical challenge on how to integrate knowledge graph reasoning with LLMs in a mutually beneficial way so as to mitigate both the hallucination problem of LLMs as well as the incompleteness issue of knowledge graphs. In this paper, we propose 'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs with knowledge grap",
    "link": "https://arxiv.org/abs/2404.04264",
    "context": "Title: Logic Query of Thoughts: Guiding Large Language Models to Answer Complex Logic Queries with Knowledge Graphs\nAbstract: arXiv:2404.04264v3 Announce Type: replace-cross  Abstract: Despite the superb performance in many tasks, large language models (LLMs) bear the risk of generating hallucination or even wrong answers when confronted with tasks that demand the accuracy of knowledge. The issue becomes even more noticeable when addressing logic queries that require multiple logic reasoning steps. On the other hand, knowledge graph (KG) based question answering methods are capable of accurately identifying the correct answers with the help of knowledge graph, yet its accuracy could quickly deteriorate when the knowledge graph itself is sparse and incomplete. It remains a critical challenge on how to integrate knowledge graph reasoning with LLMs in a mutually beneficial way so as to mitigate both the hallucination problem of LLMs as well as the incompleteness issue of knowledge graphs. In this paper, we propose 'Logic-Query-of-Thoughts' (LGOT) which is the first of its kind to combine LLMs with knowledge grap",
    "path": "papers/24/04/2404.04264.json",
    "total_tokens": 689,
    "translated_title": "《思维查询逻辑：借助知识图谱引导大型语言模型回答复杂逻辑查询》",
    "translated_abstract": "arXiv:2404.04264v3 Announce Type: replace-cross 概要：尽管在许多任务中表现出色，大型语言模型（LLMs）在面对需要知识准确性的任务时，可能会生成误导性的信息甚至错误的答案。当应对需要多步逻辑推理的逻辑查询时，这个问题就更明显了。相反，基于知识图（KG）的问答方法在知识图的帮助下能够准确地识别正确的答案，但是当知识图本身不完整时，其准确性会迅速下降。如何在相互受益的方式中整合知识图谱推理与LLM以减轻LLM的误导性问题以及知识图的不完整问题，这仍然是一个关键挑战。在本文中，我们提出了“思维查询逻辑”（LGOT），这是第一个将LLMS与知识图结合在一起的方法，以解决上述问题。这为LLMs和知识图中的知识集成提供了新的视角，并具有解决复杂逻辑查询的能力。我们通过实验证明，LGOT能够显著提高问答系统的准确性和可靠性，同时减少错误答案的概率。",
    "tldr": "LGOT通过结合大型语言模型与知识图谱，解决了逻辑查询中的误导性问题及知识图的不完整性问题，提升了问答系统准确性。",
    "en_tdlr": "LGOT, a novel model integrating large language models with knowledge graphs, addresses the issue of misleading answers and graph insufficiency, significantly improving the accuracy of question answering systems."
}