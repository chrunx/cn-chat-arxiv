{
    "title": "Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales",
    "abstract": "arXiv:2404.11129v2 Announce Type: replace  Abstract: The remarkable performance of Multimodal Large Language Models (MLLMs) has unequivocally demonstrated their proficient understanding capabilities in handling a wide array of visual tasks. Nevertheless, the opaque nature of their black-box reasoning processes persists as an enigma, rendering them uninterpretable and struggling with hallucination. Their ability to execute intricate compositional reasoning tasks is also constrained, culminating in a stagnation of learning progression for these models. In this work, we introduce Fact, a novel paradigm designed to generate multimodal rationales that are faithful, concise, and transferable for teaching MLLMs. This paradigm utilizes verifiable visual programming to generate executable code guaranteeing faithfulness and precision. Subsequently, through a series of operations including pruning, merging, and bridging, the rationale enhances its conciseness. Furthermore, we filter rationales th",
    "link": "https://arxiv.org/abs/2404.11129",
    "context": "Title: Fact :Teaching MLLMs with Faithful, Concise and Transferable Rationales\nAbstract: arXiv:2404.11129v2 Announce Type: replace  Abstract: The remarkable performance of Multimodal Large Language Models (MLLMs) has unequivocally demonstrated their proficient understanding capabilities in handling a wide array of visual tasks. Nevertheless, the opaque nature of their black-box reasoning processes persists as an enigma, rendering them uninterpretable and struggling with hallucination. Their ability to execute intricate compositional reasoning tasks is also constrained, culminating in a stagnation of learning progression for these models. In this work, we introduce Fact, a novel paradigm designed to generate multimodal rationales that are faithful, concise, and transferable for teaching MLLMs. This paradigm utilizes verifiable visual programming to generate executable code guaranteeing faithfulness and precision. Subsequently, through a series of operations including pruning, merging, and bridging, the rationale enhances its conciseness. Furthermore, we filter rationales th",
    "path": "papers/24/04/2404.11129.json",
    "total_tokens": 323,
    "tldr": "该文章提供了一种名为 Fact 的创新方法，通过生成可靠的视觉编程代码来制作精确、紧凑、可转移的多模态注释，旨在改进 MLLM 的学习过程。"
}