{
    "title": "Getting it Right: Improving Spatial Consistency in Text-to-Image Models",
    "abstract": "arXiv:2404.01197v2 Announce Type: replace  Abstract: One of the key shortcomings in current text-to-image (T2I) models is their inability to consistently generate images which faithfully follow the spatial relationships specified in the text prompt. In this paper, we offer a comprehensive investigation of this limitation, while also developing datasets and methods that support algorithmic solutions to improve spatial reasoning in T2I models. We find that spatial relationships are under-represented in the image descriptions found in current vision-language datasets. To alleviate this data bottleneck, we create SPRIGHT, the first spatially focused, large-scale dataset, by re-captioning 6 million images from 4 widely used vision datasets and through a 3-fold evaluation and analysis pipeline, show that SPRIGHT improves the proportion of spatial relationships in existing datasets. We show the efficacy of SPRIGHT data by showing that using only $\\sim$0.25% of SPRIGHT results in a 22% improve",
    "link": "https://arxiv.org/abs/2404.01197",
    "context": "Title: Getting it Right: Improving Spatial Consistency in Text-to-Image Models\nAbstract: arXiv:2404.01197v2 Announce Type: replace  Abstract: One of the key shortcomings in current text-to-image (T2I) models is their inability to consistently generate images which faithfully follow the spatial relationships specified in the text prompt. In this paper, we offer a comprehensive investigation of this limitation, while also developing datasets and methods that support algorithmic solutions to improve spatial reasoning in T2I models. We find that spatial relationships are under-represented in the image descriptions found in current vision-language datasets. To alleviate this data bottleneck, we create SPRIGHT, the first spatially focused, large-scale dataset, by re-captioning 6 million images from 4 widely used vision datasets and through a 3-fold evaluation and analysis pipeline, show that SPRIGHT improves the proportion of spatial relationships in existing datasets. We show the efficacy of SPRIGHT data by showing that using only $\\sim$0.25% of SPRIGHT results in a 22% improve",
    "path": "papers/24/04/2404.01197.json",
    "total_tokens": 376,
    "tldr": "该文章提出了一种改进文本到图像模型中空间一致性的方法，通过创建SPRIGHT——一个用于描述6百万图像的专门用于空间描述的大数据集，并发现使用SPRIGHT数据集的一小部分（约0.25%）就可以显著提高22%的空间关系描述的比例，从而提升模型的空间推理能力。"
}