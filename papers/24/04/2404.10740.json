{
    "title": "N-Agent Ad Hoc Teamwork",
    "abstract": "arXiv:2404.10740v2 Announce Type: replace  Abstract: Current approaches to learning cooperative multi-agent behaviors assume relatively restrictive settings. In standard fully cooperative multi-agent reinforcement learning, the learning algorithm controls $\\textit{all}$ agents in the scenario, while in ad hoc teamwork, the learning algorithm usually assumes control over only a $\\textit{single}$ agent in the scenario. However, many cooperative settings in the real world are much less restrictive. For example, in an autonomous driving scenario, a company might train its cars with the same learning algorithm, yet once on the road, these cars must cooperate with cars from another company. Towards expanding the class of scenarios that cooperative learning methods may optimally address, we introduce $N$-agent ad hoc teamwork (NAHT), where a set of autonomous agents must interact and cooperate with dynamically varying numbers and types of teammates. This paper formalizes the problem, and prop",
    "link": "https://arxiv.org/abs/2404.10740",
    "context": "Title: N-Agent Ad Hoc Teamwork\nAbstract: arXiv:2404.10740v2 Announce Type: replace  Abstract: Current approaches to learning cooperative multi-agent behaviors assume relatively restrictive settings. In standard fully cooperative multi-agent reinforcement learning, the learning algorithm controls $\\textit{all}$ agents in the scenario, while in ad hoc teamwork, the learning algorithm usually assumes control over only a $\\textit{single}$ agent in the scenario. However, many cooperative settings in the real world are much less restrictive. For example, in an autonomous driving scenario, a company might train its cars with the same learning algorithm, yet once on the road, these cars must cooperate with cars from another company. Towards expanding the class of scenarios that cooperative learning methods may optimally address, we introduce $N$-agent ad hoc teamwork (NAHT), where a set of autonomous agents must interact and cooperate with dynamically varying numbers and types of teammates. This paper formalizes the problem, and prop",
    "path": "papers/24/04/2404.10740.json",
    "total_tokens": 607,
    "translated_title": "N多代理随机团队协作",
    "translated_abstract": "arXiv:2404.10740v2 公告类型：替换 摘要：当前学习合作多代理行为的方法假设相对限制性的设置。在标准完全合作多代理强化学习中，学习算法控制场景中的所有代理，而在随机团队工作中，学习算法通常假设只控制场景中单个代理。然而，现实世界中的许多合作情形远不那么严格。例如，在自动驾驶场景中，一家公司可能用相同的学习算法训练其车辆，但一旦上路，这些车辆必须与另一家公司车辆合作。为了扩展可以优化地处理合作学习方法的场景类别，我们引入了N代理随机团队工作（NAHT），其中一组自治代理必须与具有动态变化数量的动态类型队友互动并合作。本文正式表述了这一问题，并提出了一系列的理论和算法来解决这一挑战。",
    "tldr": "该论文研究了在动态变化队友数量和类型的环境中，N个自治代理如何进行合作的问题，并提出了相应的理论和算法以解决这一挑战。",
    "en_tdlr": "This paper explores how N autonomous agents cooperate in a dynamic environment with varying numbers and types of teammates, and introduces theoretical and algorithmic approaches to address this challenge."
}