{
    "title": "Distributionally Robust Policy and Lyapunov-Certificate Learning",
    "abstract": "arXiv:2404.03017v2 Announce Type: replace-cross  Abstract: This article presents novel methods for synthesizing distributionally robust stabilizing neural controllers and certificates for control systems under model uncertainty. A key challenge in designing controllers with stability guarantees for uncertain systems is the accurate determination of and adaptation to shifts in model parametric uncertainty during online deployment. We tackle this with a novel distributionally robust formulation of the Lyapunov derivative chance constraint ensuring a monotonic decrease of the Lyapunov certificate. To avoid the computational complexity involved in dealing with the space of probability measures, we identify a sufficient condition in the form of deterministic convex constraints that ensures the Lyapunov derivative constraint is satisfied. We integrate this condition into a loss function for training a neural network-based controller and show that, for the resulting closed-loop system, the gl",
    "link": "https://arxiv.org/abs/2404.03017",
    "context": "Title: Distributionally Robust Policy and Lyapunov-Certificate Learning\nAbstract: arXiv:2404.03017v2 Announce Type: replace-cross  Abstract: This article presents novel methods for synthesizing distributionally robust stabilizing neural controllers and certificates for control systems under model uncertainty. A key challenge in designing controllers with stability guarantees for uncertain systems is the accurate determination of and adaptation to shifts in model parametric uncertainty during online deployment. We tackle this with a novel distributionally robust formulation of the Lyapunov derivative chance constraint ensuring a monotonic decrease of the Lyapunov certificate. To avoid the computational complexity involved in dealing with the space of probability measures, we identify a sufficient condition in the form of deterministic convex constraints that ensures the Lyapunov derivative constraint is satisfied. We integrate this condition into a loss function for training a neural network-based controller and show that, for the resulting closed-loop system, the gl",
    "path": "papers/24/04/2404.03017.json",
    "total_tokens": 704,
    "translated_title": "分布式鲁棒策略和Lyapunov证书学习",
    "translated_abstract": "本文介绍了一套新型方法，用于合成具有模型不确定性的在线部署期间能够准确确定和适应模型参数不确定性的鲁棒稳定神经控制器和控制系统的稳定性证书。在设计具有稳定性保证的不确定性系统的控制器时，一个关键挑战是如何准确地确定在线部署期间模型参数不确定性的变化并对这些变化作出适应。我们通过一个新颖的Lyapunov导数机会约束的分布鲁棒形式来应对这一挑战，该形式确保Lyapunov证书的递减性。为了避免处理概率度量空间的高计算复杂性，我们识别出一种足够条件，形式为确定性凸约束，可以确保Lyapunov导数约束的满足。我们将这一条件集成到训练神经网络控制器的一个损失函数中，并展示了对于由此得到的闭环系统，Lyapunov导数是在闭环系统中满足的。此外，我们还提出了一个基于Lyapunov反向传播的新优化算法，该算法能够在不确定性参数集上遍历。通过仿真，我们展示了一种按需设计的分布式鲁棒神经控制器能够对系统进行有效的控制。",
    "tldr": "本论文提出了一种新的方法来合成对模型不确定性的变化能够适应的鲁棒神经控制器和证书。通过确保Lyapunov导数的递减性来保证了闭环系统的稳定性，并通过Lyapunov反向传播算法解决了计算复杂性问题。通过仿真，展示了该方法的有效性。"
}