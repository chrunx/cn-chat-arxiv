{
    "title": "BlenderAlchemy: Editing 3D Graphics with Vision-Language Models",
    "abstract": "arXiv:2404.17672v3 Announce Type: replace  Abstract: Graphics design is important for various applications, including movie production and game design. To create a high-quality scene, designers usually need to spend hours in software like Blender, in which they might need to interleave and repeat operations, such as connecting material nodes, hundreds of times. Moreover, slightly different design goals may require completely different sequences, making automation difficult. In this paper, we propose a system that leverages Vision-Language Models (VLMs), like GPT-4V, to intelligently search the design action space to arrive at an answer that can satisfy a user's intent. Specifically, we design a vision-based edit generator and state evaluator to work together to find the correct sequence of actions to achieve the goal. Inspired by the role of visual imagination in the human design process, we supplement the visual reasoning capabilities of VLMs with \"imagined\" reference images from imag",
    "link": "https://arxiv.org/abs/2404.17672",
    "context": "Title: BlenderAlchemy: Editing 3D Graphics with Vision-Language Models\nAbstract: arXiv:2404.17672v3 Announce Type: replace  Abstract: Graphics design is important for various applications, including movie production and game design. To create a high-quality scene, designers usually need to spend hours in software like Blender, in which they might need to interleave and repeat operations, such as connecting material nodes, hundreds of times. Moreover, slightly different design goals may require completely different sequences, making automation difficult. In this paper, we propose a system that leverages Vision-Language Models (VLMs), like GPT-4V, to intelligently search the design action space to arrive at an answer that can satisfy a user's intent. Specifically, we design a vision-based edit generator and state evaluator to work together to find the correct sequence of actions to achieve the goal. Inspired by the role of visual imagination in the human design process, we supplement the visual reasoning capabilities of VLMs with \"imagined\" reference images from imag",
    "path": "papers/24/04/2404.17672.json",
    "total_tokens": 346,
    "tldr": "该文章提出了一种名为BlenderAlchemy的系统，它使用Vision-Language Models（VLMs）如GPT-4V，通过汇聚视觉信息和自然语言指令，搜索并生成优化设计的精确序列行动，大大提高了3D图形设计效率。"
}