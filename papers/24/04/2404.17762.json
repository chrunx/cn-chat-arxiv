{
    "title": "Large Multi-modality Model Assisted AI-Generated Image Quality Assessment",
    "abstract": "arXiv:2404.17762v2 Announce Type: replace  Abstract: Traditional deep neural network (DNN)-based image quality assessment (IQA) models leverage convolutional neural networks (CNN) or Transformer to learn the quality-aware feature representation, achieving commendable performance on natural scene images. However, when applied to AI-Generated images (AGIs), these DNN-based IQA models exhibit subpar performance. This situation is largely due to the semantic inaccuracies inherent in certain AGIs caused by uncontrollable nature of the generation process. Thus, the capability to discern semantic content becomes crucial for assessing the quality of AGIs. Traditional DNN-based IQA models, constrained by limited parameter complexity and training data, struggle to capture complex fine-grained semantic features, making it challenging to grasp the existence and coherence of semantic content of the entire image. To address the shortfall in semantic content perception of current IQA models, we intro",
    "link": "https://arxiv.org/abs/2404.17762",
    "context": "Title: Large Multi-modality Model Assisted AI-Generated Image Quality Assessment\nAbstract: arXiv:2404.17762v2 Announce Type: replace  Abstract: Traditional deep neural network (DNN)-based image quality assessment (IQA) models leverage convolutional neural networks (CNN) or Transformer to learn the quality-aware feature representation, achieving commendable performance on natural scene images. However, when applied to AI-Generated images (AGIs), these DNN-based IQA models exhibit subpar performance. This situation is largely due to the semantic inaccuracies inherent in certain AGIs caused by uncontrollable nature of the generation process. Thus, the capability to discern semantic content becomes crucial for assessing the quality of AGIs. Traditional DNN-based IQA models, constrained by limited parameter complexity and training data, struggle to capture complex fine-grained semantic features, making it challenging to grasp the existence and coherence of semantic content of the entire image. To address the shortfall in semantic content perception of current IQA models, we intro",
    "path": "papers/24/04/2404.17762.json",
    "total_tokens": 670,
    "translated_title": "使用大型多模态模型辅助的AI生成图像质量评估方法",
    "translated_abstract": "arXiv:2404.17762v2 公告类型：替换摘要：传统基于深度神经网络（DNN）的图像质量评估（IQA）模型利用卷积神经网络（CNN）或Transformer来学习质量的特征表示，在自然场景图像上的性能表现出色。然而，当应用于AI生成的图像（AGI）时，这些基于DNN的IQA模型表现出较低的性能。这种情况很大程度上是由于某些AGI固有的语义不准确，这由图像生成过程的不确定性所引起。因此，对于评估AGI的质量，能够分辨出语义内容变得至关重要。由于有限的参数复杂性和训练数据，传统基于DNN的IQA模型在捕捉复杂的精细语义特征方面遇到困难，这使得它们难以把握整个图像的语义内容的存在和一致性。为了解决当前IQA模型在语义内容感知方面的不足，我们引入了一种利用大型多模态模型来增强AI图像质量的评估能力的方法。",
    "tldr": "研究人员开发了一种利用大型多模态模型以更好地评估AI生成图像质量的替代方法，弥补了传统基于DNN的IQA模型在处理复杂语义特征时的不足。"
}