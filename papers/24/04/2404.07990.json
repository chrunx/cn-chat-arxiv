{
    "title": "OpenBias: Open-set Bias Detection in Text-to-Image Generative Models",
    "abstract": "arXiv:2404.07990v2 Announce Type: replace  Abstract: Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previou",
    "link": "https://arxiv.org/abs/2404.07990",
    "context": "Title: OpenBias: Open-set Bias Detection in Text-to-Image Generative Models\nAbstract: arXiv:2404.07990v2 Announce Type: replace  Abstract: Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previou",
    "path": "papers/24/04/2404.07990.json",
    "total_tokens": 802,
    "translated_title": "开放偏见：文本到图像生成模型中的开放集偏差检测",
    "translated_abstract": "arXiv:2404.07990v2 公告类型：替换  摘要：文本到图像生成模型正变得越来越受欢迎，并且对普通大众越来越可访问。随着这些模型的大规模部署，深入探究它们的稳定性和公平性变得至关重要，以避免传播和延续任何类型的偏见。然而，现有的工作集中在检测预先定义的有限集偏差，限制研究局限于众所周知的概念。在本文中，我们挑战文本到图像生成模型中的开放集偏差检测问题，提出OpenBias，一个新的管道，可以在没有访问任何预编译集合的情况下识别和量化偏见的严重性。OpenBias由三个阶段组成。在第一个阶段，我们利用大型语言模型（LLM）基于一组提示提出偏差。其次，目标生成模型使用相同的提示集生成图像。最后，一个视觉问答模型识别先前提议偏差的程度。我们对11个类别的自然语言描述（包括“人种”、“性别”和“经济状态”）进行实验，证明了OpenBias能够检测模型生成的图像中的开放集偏差。我们的方法不仅解决了现有工作无法处理的开放集问题，而且能够提供有关模型中实际存在的偏见的定量证据。",
    "tldr": "本文提出OpenBias，一个检测文本到图像生成模型中开放集偏见的系统，无需预先定义的偏差集合，利用大型语言模型和视觉问答模型来识别和量化这些模型可能存在的偏差，解决了现有方法无法处理开放集偏差的问题，提供定量证据。",
    "en_tdlr": "This paper introduces OpenBias, a system for detecting open-set biases in text-to-image generative models, which requires no precompiled bias sets. Using large language models and a vision question answering (VQA) model, OpenBias can identify and quantify the biases in these models, addressing the issue of open-set detection that existing methods cannot tackle, and providing quantitive evidence of the biases present in the models."
}