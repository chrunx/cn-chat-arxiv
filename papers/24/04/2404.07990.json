{
    "title": "OpenBias: Open-set Bias Detection in Text-to-Image Generative Models",
    "abstract": "arXiv:2404.07990v2 Announce Type: replace  Abstract: Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previou",
    "link": "https://arxiv.org/abs/2404.07990",
    "context": "Title: OpenBias: Open-set Bias Detection in Text-to-Image Generative Models\nAbstract: arXiv:2404.07990v2 Announce Type: replace  Abstract: Text-to-image generative models are becoming increasingly popular and accessible to the general public. As these models see large-scale deployments, it is necessary to deeply investigate their safety and fairness to not disseminate and perpetuate any kind of biases. However, existing works focus on detecting closed sets of biases defined a priori, limiting the studies to well-known concepts. In this paper, we tackle the challenge of open-set bias detection in text-to-image generative models presenting OpenBias, a new pipeline that identifies and quantifies the severity of biases agnostically, without access to any precompiled set. OpenBias has three stages. In the first phase, we leverage a Large Language Model (LLM) to propose biases given a set of captions. Secondly, the target generative model produces images using the same set of captions. Lastly, a Vision Question Answering model recognizes the presence and extent of the previou",
    "path": "papers/24/04/2404.07990.json",
    "total_tokens": 386,
    "tldr": "该文章提出了OpenBias框架，这是一种能够对文本到图像生成模型的开放性偏见进行检测和严重程度评估的新方法，无需预先定义的偏见集合。它通过利用大型语言模型提出偏见，目标生成模型生成图像，以及视觉问答模型识别偏见的存在和程度，展现了其在处理大型模型可能存在的不可预见偏见问题上的创新性和实用性。"
}