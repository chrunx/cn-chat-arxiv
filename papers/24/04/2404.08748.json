{
    "title": "Multi-Branch Generative Models for Multichannel Imaging with an Application to PET/CT Synergistic Reconstruction",
    "abstract": "arXiv:2404.08748v2 Announce Type: replace-cross  Abstract: This paper presents a novel approach for learned synergistic reconstruction of medical images using multi-branch generative models. Leveraging variational autoencoders (VAEs), our model learns from pairs of images simultaneously, enabling effective denoising and reconstruction. Synergistic image reconstruction is achieved by incorporating the trained models in a regularizer that evaluates the distance between the images and the model. We demonstrate the efficacy of our approach on both Modified National Institute of Standards and Technology (MNIST) and positron emission tomography (PET)/computed tomography (CT) datasets, showcasing improved image quality for low-dose imaging. Despite challenges such as patch decomposition and model limitations, our results underscore the potential of generative models for enhancing medical imaging reconstruction.",
    "link": "https://arxiv.org/abs/2404.08748",
    "context": "Title: Multi-Branch Generative Models for Multichannel Imaging with an Application to PET/CT Synergistic Reconstruction\nAbstract: arXiv:2404.08748v2 Announce Type: replace-cross  Abstract: This paper presents a novel approach for learned synergistic reconstruction of medical images using multi-branch generative models. Leveraging variational autoencoders (VAEs), our model learns from pairs of images simultaneously, enabling effective denoising and reconstruction. Synergistic image reconstruction is achieved by incorporating the trained models in a regularizer that evaluates the distance between the images and the model. We demonstrate the efficacy of our approach on both Modified National Institute of Standards and Technology (MNIST) and positron emission tomography (PET)/computed tomography (CT) datasets, showcasing improved image quality for low-dose imaging. Despite challenges such as patch decomposition and model limitations, our results underscore the potential of generative models for enhancing medical imaging reconstruction.",
    "path": "papers/24/04/2404.08748.json",
    "total_tokens": 571,
    "translated_title": "多分支生成模型在多通道成像中的应用，特别是在PET/CT协同重建中的应用",
    "translated_abstract": "这篇论文提出了一个使用多分支生成模型的新型医学图像协同重建方法。通过结合可变自编码器（VAEs），我们的模型能够在同一时间处理成对的图像，从而实现有效的去噪和重建。协同图像重建是通过在我们的模型中纳入一个评价图像与模型距离的正规化器来实现的。我们在MNIST和Positron Emission Tomography（PET）/Computed Tomography（CT）数据集上展示了我们的方法的有效性，证明了在低剂量成像方面的图像质量提升。尽管存在诸如块分解和模型限制等挑战，我们的结果强调了生成模型在提高医学成像重建方面的潜力。",
    "tldr": "论文提出了一种多分支生成模型，用于提高PET/CT协同成像的质量，特别是在低剂量成像方面。",
    "en_tdlr": "This paper introduces a novel multi-branch generative model for enhancing the quality of PET/CT synergistic imaging, particularly in low-dose scenarios."
}