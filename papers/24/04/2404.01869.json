{
    "title": "Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey",
    "abstract": "arXiv:2404.01869v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans. However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain. This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior. This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes. Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses. Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training d",
    "link": "https://arxiv.org/abs/2404.01869",
    "context": "Title: Beyond Accuracy: Evaluating the Reasoning Behavior of Large Language Models -- A Survey\nAbstract: arXiv:2404.01869v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) have recently shown impressive performance on tasks involving reasoning, leading to a lively debate on whether these models possess reasoning capabilities similar to humans. However, despite these successes, the depth of LLMs' reasoning abilities remains uncertain. This uncertainty partly stems from the predominant focus on task performance, measured through shallow accuracy metrics, rather than a thorough investigation of the models' reasoning behavior. This paper seeks to address this gap by providing a comprehensive review of studies that go beyond task accuracy, offering deeper insights into the models' reasoning processes. Furthermore, we survey prevalent methodologies to evaluate the reasoning behavior of LLMs, emphasizing current trends and efforts towards more nuanced reasoning analyses. Our review suggests that LLMs tend to rely on surface-level patterns and correlations in their training d",
    "path": "papers/24/04/2404.01869.json",
    "total_tokens": 363,
    "tldr": "该文章详细介绍了如何评估大型语言模型（LLMs）的推理行为，并强调了对这些模型进行更为全面的认知测试的必要性。文章通过研究，展示了对LLMs的推理行为进行深入分析的不同方法和趋势，以及这些模型在推理过程中可能遇到的局限性和挑战。通过对现有研究的总结和评论，作者提出了对LLMs推理能力的更全面理解，揭示了在评估这些系统的认知能力时应该关注的重点。"
}