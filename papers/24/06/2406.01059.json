{
    "title": "VIP: Versatile Image Outpainting Empowered by Multimodal Large Language Model",
    "abstract": "arXiv:2406.01059v2 Announce Type: replace  Abstract: In this paper, we focus on resolving the problem of image outpainting, which aims to extrapolate the surrounding parts given the center contents of an image. Although recent works have achieved promising performance, the lack of versatility and customization hinders their practical applications in broader scenarios. Therefore, this work presents a novel image outpainting framework that is capable of customizing the results according to the requirement of users. First of all, we take advantage of a Multimodal Large Language Model (MLLM) that automatically extracts and organizes the corresponding textual descriptions of the masked and unmasked part of a given image. Accordingly, the obtained text prompts are introduced to endow our model with the capacity to customize the outpainting results. In addition, a special Cross-Attention module, namely Center-Total-Surrounding (CTS), is elaborately designed to enhance further the the interact",
    "link": "https://arxiv.org/abs/2406.01059",
    "context": "Title: VIP: Versatile Image Outpainting Empowered by Multimodal Large Language Model\nAbstract: arXiv:2406.01059v2 Announce Type: replace  Abstract: In this paper, we focus on resolving the problem of image outpainting, which aims to extrapolate the surrounding parts given the center contents of an image. Although recent works have achieved promising performance, the lack of versatility and customization hinders their practical applications in broader scenarios. Therefore, this work presents a novel image outpainting framework that is capable of customizing the results according to the requirement of users. First of all, we take advantage of a Multimodal Large Language Model (MLLM) that automatically extracts and organizes the corresponding textual descriptions of the masked and unmasked part of a given image. Accordingly, the obtained text prompts are introduced to endow our model with the capacity to customize the outpainting results. In addition, a special Cross-Attention module, namely Center-Total-Surrounding (CTS), is elaborately designed to enhance further the the interact",
    "path": "papers/24/06/2406.01059.json",
    "total_tokens": 696,
    "translated_title": "VIP: 多模态大型语言模型增强的无界图像描摹",
    "translated_abstract": "arXiv:2406.01059v2 公告类型：替换 摘要：本文针对图像无界描摹问题进行了研究，该问题旨在给定中心图像内容时，延伸周边图像区域。尽管最近的工作已经取得了显著的性能，但缺乏适用性和定制化能力阻碍了其在更广泛场景中的实际应用。因此，本文提出了一种新的图像无界描摹框架，它能够根据用户的需求定制结果。首先，我们利用了一种多模态大型语言模型（MLLM），该模型能够自动提取并组织给定图像的遮罩部分和非遮罩部分的相应文本描述。因此，所获得的文本提示被介绍给我们的模型，以赋予其定制无界描摹结果的能力。此外，精心设计的特殊交叉注意力模块——“中心-总量-周边”（CTS），进一步增强了……",
    "tldr": "本文提出了一个基于多模态大型语言模型的图像无界描摹框架，能够根据用户需求定制结果。引入了一种特殊的交叉注意力模块，促进了中心和周边图像区域的交互。"
}