{
    "title": "Long and Short Guidance in Score identity Distillation for One-Step Text-to-Image Generation",
    "abstract": "arXiv:2406.01561v3 Announce Type: replace  Abstract: Diffusion-based text-to-image generation models trained on extensive text-image pairs have shown the capacity to generate photorealistic images consistent with textual descriptions. However, a significant limitation of these models is their slow sample generation, which requires iterative refinement through the same network. In this paper, we enhance Score identity Distillation (SiD) by developing long and short classifier-free guidance (LSG) to efficiently distill pretrained Stable Diffusion models without using real training data. SiD aims to optimize a model-based explicit score matching loss, utilizing a score-identity-based approximation alongside the proposed LSG for practical computation. By training exclusively with fake images synthesized with its one-step generator, SiD equipped with LSG rapidly improves FID and CLIP scores, achieving state-of-the-art FID performance while maintaining a competitive CLIP score. Specifically,",
    "link": "https://arxiv.org/abs/2406.01561",
    "context": "Title: Long and Short Guidance in Score identity Distillation for One-Step Text-to-Image Generation\nAbstract: arXiv:2406.01561v3 Announce Type: replace  Abstract: Diffusion-based text-to-image generation models trained on extensive text-image pairs have shown the capacity to generate photorealistic images consistent with textual descriptions. However, a significant limitation of these models is their slow sample generation, which requires iterative refinement through the same network. In this paper, we enhance Score identity Distillation (SiD) by developing long and short classifier-free guidance (LSG) to efficiently distill pretrained Stable Diffusion models without using real training data. SiD aims to optimize a model-based explicit score matching loss, utilizing a score-identity-based approximation alongside the proposed LSG for practical computation. By training exclusively with fake images synthesized with its one-step generator, SiD equipped with LSG rapidly improves FID and CLIP scores, achieving state-of-the-art FID performance while maintaining a competitive CLIP score. Specifically,",
    "path": "papers/24/06/2406.01561.json",
    "total_tokens": 335,
    "tldr": "该文章提出了一种名为长期和短期无监督分类器指导的长和短指导策略，用于基于分对的文本到图像生成模型，显著提高了训练效率并提升了生成质量和速度。"
}