{
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "abstract": "arXiv:2406.06399v3 Announce Type: replace-cross  Abstract: We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and expl",
    "link": "https://arxiv.org/abs/2406.06399",
    "context": "Title: Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\nAbstract: arXiv:2406.06399v3 Announce Type: replace-cross  Abstract: We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and expl",
    "path": "papers/24/06/2406.06399.json",
    "total_tokens": 672,
    "translated_title": "我们应该微调还是RAG？评估不同适应LLM对话的技巧",
    "translated_abstract": "arXiv:2406.06399v3 声明类型：替换交叉摘要：我们研究了大型语言模型（LLM）在人类机器对话中响应生成任务的局限性。在文献中，对于不同类型的对话（例如开放域对话）已经提出了多种技术。然而，这些技术的评价在基础LLM、对话类型和评价指标方面都受到了限制。在这项工作中，我们对不同的LLM适应技术进行了广泛分析，这些技术在应用于不同类型的对话时进行了应用。我们选择了两个基础LLM，即Llama-2和Mistral，以及四种对话类型：开放域对话、知识赋能对话、任务导向对话和问答对话。我们在每个对话类型的特定数据集上评估了适用于in-context学习的内部知识集成技术。我们在评估和探索各种可能性的同时，使用了一致性评估和探索策略。",
    "tldr": "文章研究了大型语言模型在对话生成任务中的局限性，对比了在context学习与微调等不同适应技术在不同对话类型中的性能差异。"
}