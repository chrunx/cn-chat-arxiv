{
    "title": "Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue",
    "abstract": "arXiv:2406.06399v3 Announce Type: replace-cross  Abstract: We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and expl",
    "link": "https://arxiv.org/abs/2406.06399",
    "context": "Title: Should We Fine-Tune or RAG? Evaluating Different Techniques to Adapt LLMs for Dialogue\nAbstract: arXiv:2406.06399v3 Announce Type: replace-cross  Abstract: We study the limitations of Large Language Models (LLMs) for the task of response generation in human-machine dialogue. Several techniques have been proposed in the literature for different dialogue types (e.g., Open-Domain). However, the evaluations of these techniques have been limited in terms of base LLMs, dialogue types and evaluation metrics. In this work, we extensively analyze different LLM adaptation techniques when applied to different dialogue types. We have selected two base LLMs, Llama-2 and Mistral, and four dialogue types Open-Domain, Knowledge-Grounded, Task-Oriented, and Question Answering. We evaluate the performance of in-context learning and fine-tuning techniques across datasets selected for each dialogue type. We assess the impact of incorporating external knowledge to ground the generation in both scenarios of Retrieval-Augmented Generation (RAG) and gold knowledge. We adopt consistent evaluation and expl",
    "path": "papers/24/06/2406.06399.json",
    "total_tokens": 434,
    "tldr": "该文章对用于对话生成任务的Large Language Models（LLMs）进行了深入分析，探讨了不同对话类型（如开放域对话）中不同训练技术的局限性。研究比较了Llama-2和Mistral两种基础LLM在不同对话类型下的性能差异，同时也测试了在结合外部知识的情况下，检索增强生成(RAG)技术与基于黄金知识的方法的性能。评估包括了在对话生成中的内嵌学习方法和精细调整技术的差异。通过针对各个对话类型的数据集进行选定和评估，文章对不同的LLM适应技术提供了详细的比较和分析。"
}