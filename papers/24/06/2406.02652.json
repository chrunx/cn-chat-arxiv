{
    "title": "RepCNN: Micro-sized, Mighty Models for Wakeword Detection",
    "abstract": "arXiv:2406.02652v2 Announce Type: replace-cross  Abstract: Always-on machine learning models require a very low memory and compute footprint. Their restricted parameter count limits the model's capacity to learn, and the effectiveness of the usual training algorithms to find the best parameters. Here we show that a small convolutional model can be better trained by first refactoring its computation into a larger redundant multi-branched architecture. Then, for inference, we algebraically re-parameterize the trained model into the single-branched form with fewer parameters for a lower memory footprint and compute cost. Using this technique, we show that our always-on wake-word detector model, RepCNN, provides a good trade-off between latency and accuracy during inference. RepCNN re-parameterized models are 43% more accurate than a uni-branch convolutional model while having the same runtime. RepCNN also meets the accuracy of complex architectures like BC-ResNet, while having 2x lesser p",
    "link": "https://arxiv.org/abs/2406.02652",
    "context": "Title: RepCNN: Micro-sized, Mighty Models for Wakeword Detection\nAbstract: arXiv:2406.02652v2 Announce Type: replace-cross  Abstract: Always-on machine learning models require a very low memory and compute footprint. Their restricted parameter count limits the model's capacity to learn, and the effectiveness of the usual training algorithms to find the best parameters. Here we show that a small convolutional model can be better trained by first refactoring its computation into a larger redundant multi-branched architecture. Then, for inference, we algebraically re-parameterize the trained model into the single-branched form with fewer parameters for a lower memory footprint and compute cost. Using this technique, we show that our always-on wake-word detector model, RepCNN, provides a good trade-off between latency and accuracy during inference. RepCNN re-parameterized models are 43% more accurate than a uni-branch convolutional model while having the same runtime. RepCNN also meets the accuracy of complex architectures like BC-ResNet, while having 2x lesser p",
    "path": "papers/24/06/2406.02652.json",
    "total_tokens": 672,
    "translated_title": "RepCNN: 微小模型为唤醒词检测",
    "translated_abstract": "arXiv:2406.02652v2 公告类型：替换交叉  摘要：始终运行的机器学习模型需要极低的存储和计算开销。它们的限制性参数数量限制了模型学习的能力，以及传统训练算法找到最佳参数的有效性。在这里，我们展示了一个小型的卷积模型可以通过首先将其计算重新构成为一种更大型且分支更多的架构来进行更好的训练。然后，在进行推理时，我们将训练过的模型重新参数化为单分支形式，参数更少，以便具有更低的内存足迹和计算成本。使用这种技术，我们展示了我们的始终在线唤醒词检测模型RepCNN，在推理过程中提供了很好的性能平衡。与具有相同运行时的单分支卷积模型相比，RepCNN重新参数化的模型准确度提高了43%。同时，RepCNN在准确性方面达到了复杂架构如BC-ResNet的水平，但参数数量少了一半。",
    "tldr": "本文提出了RepCNN模型，这是一种轻量级的卷积模型，通过重新架构和重新参数化技术，在保持低内存和计算开销的同时，显著提高了唤醒词检测的准确性。",
    "en_tdlr": "This paper introduces the RepCNN model, a lightweight convolutional model that significantly improves the accuracy of wake-word detection while maintaining low memory and computational overhead through re-architecting and re-parameterization techniques."
}