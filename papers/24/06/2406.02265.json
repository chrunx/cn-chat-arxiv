{
    "title": "Understanding Retrieval Robustness for Retrieval-Augmented Image Captioning",
    "abstract": "arXiv:2406.02265v3 Announce Type: replace  Abstract: Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far from perfect in practice: the retrieved information can sometimes mislead the model, resulting in incorrect generation and worse performance. In this paper, we analyze the robustness of a retrieval-augmented captioning model SmallCap. Our analysis shows that the model is sensitive to tokens that appear in the majority of the retrieved captions, and the input attribution shows that those tokens are likely copied into the generated output. Given these findings, we propose to train the model by sampling retrieved captions from more diverse sets. This decreases the chance that the model learns to copy majority tokens, and improves both in-domain ",
    "link": "https://arxiv.org/abs/2406.02265",
    "context": "Title: Understanding Retrieval Robustness for Retrieval-Augmented Image Captioning\nAbstract: arXiv:2406.02265v3 Announce Type: replace  Abstract: Recent advances in retrieval-augmented models for image captioning highlight the benefit of retrieving related captions for efficient, lightweight models with strong domain-transfer capabilities. While these models demonstrate the success of retrieval augmentation, retrieval models are still far from perfect in practice: the retrieved information can sometimes mislead the model, resulting in incorrect generation and worse performance. In this paper, we analyze the robustness of a retrieval-augmented captioning model SmallCap. Our analysis shows that the model is sensitive to tokens that appear in the majority of the retrieved captions, and the input attribution shows that those tokens are likely copied into the generated output. Given these findings, we propose to train the model by sampling retrieved captions from more diverse sets. This decreases the chance that the model learns to copy majority tokens, and improves both in-domain ",
    "path": "papers/24/06/2406.02265.json",
    "total_tokens": 382,
    "tldr": "该文章探讨了检索增强的图像 Captioning 模型在实践中存在的不稳定性问题，即模型可能因获取的误导性信息而产生错误。通过分析SmallCap模型，作者发现模型容易受到频繁出现在检索结果中的单词的影响，而这些单词也倾向于被模型复制到生成的描述中。为此，作者提出了一种解决方法，即通过从更具多样性的检索结果中采样，来减少模型学习复制高频单词的概率，从而提高了模型在类似领域任务中的性能。"
}