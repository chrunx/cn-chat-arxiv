{
    "title": "InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection",
    "abstract": "arXiv:2406.16464v3 Announce Type: replace-cross  Abstract: The prevalence of sarcasm in social media, conveyed through text-image combinations, presents significant challenges for sentiment analysis and intention mining. Existing multi-modal sarcasm detection methods have been proven to overestimate performance, as they struggle to effectively capture the intricate sarcastic cues that arise from the interaction between an image and text. To address these issues, we propose InterCLIP-MEP, a novel framework for multi-modal sarcasm detection. Specifically, we introduce an Interactive CLIP (InterCLIP) as the backbone to extract text-image representations, enhancing them by embedding cross-modality information directly within each encoder, thereby improving the representations to capture text-image interactions better. Furthermore, an efficient training strategy is designed to adapt InterCLIP for our proposed Memory-Enhanced Predictor (MEP). MEP uses a dynamic, fixed-length dual-channel mem",
    "link": "https://arxiv.org/abs/2406.16464",
    "context": "Title: InterCLIP-MEP: Interactive CLIP and Memory-Enhanced Predictor for Multi-modal Sarcasm Detection\nAbstract: arXiv:2406.16464v3 Announce Type: replace-cross  Abstract: The prevalence of sarcasm in social media, conveyed through text-image combinations, presents significant challenges for sentiment analysis and intention mining. Existing multi-modal sarcasm detection methods have been proven to overestimate performance, as they struggle to effectively capture the intricate sarcastic cues that arise from the interaction between an image and text. To address these issues, we propose InterCLIP-MEP, a novel framework for multi-modal sarcasm detection. Specifically, we introduce an Interactive CLIP (InterCLIP) as the backbone to extract text-image representations, enhancing them by embedding cross-modality information directly within each encoder, thereby improving the representations to capture text-image interactions better. Furthermore, an efficient training strategy is designed to adapt InterCLIP for our proposed Memory-Enhanced Predictor (MEP). MEP uses a dynamic, fixed-length dual-channel mem",
    "path": "papers/24/06/2406.16464.json",
    "total_tokens": 695,
    "translated_title": "InterCLIP-MEP：交互式CLIP和增强记忆预测器在多模态 sarcasm 检测中的应用",
    "translated_abstract": "arXiv:2406.16464v3 公告类型：替换交叉 摘要：社交媒体上 sarcasm 的普遍存在，通过文字和图像的组合表达，为情感分析和意图挖掘带来了巨大挑战。现有的多模态 sarcasm 检测方法已经证明存在高估性能的问题，因为它们很难有效地捕捉到文字和图像之间互动产生的精细 sarcastic 线索。为了解决这些问题，我们提出了 InterCLIP-MEP，一个用于多模态 sarcasm 检测的全新框架。特别是，我们引入了交互式 CLIP（InterCLIP）作为骨干，提取文字图像表示，通过在每个编码器中直接嵌入跨模态信息，从而改善了表示，更好地捕捉文字和图像之间的互动。此外，我们还设计了一种有效的培训策略，为了适应我们提出的增强记忆预测器（MEP）调整InterCLIP。MEP使用一个动态的、固定长度的双通道记忆系统来增强对 sarcasm 的检测，并且准确率大幅度提升。",
    "tldr": "InterCLIP-MEP 框架使用交互式 CLIP 和增强的记忆预测器改进了对社交媒体上多模态 sarcasm 的检测效果。",
    "en_tdlr": "The InterCLIP-MEP framework improves multi-modal sarcasm detection on social media by enhancing interactive CLIP representations with a dynamic, fixed-length dual-channel memory system."
}