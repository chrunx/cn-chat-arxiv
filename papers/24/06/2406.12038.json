{
    "title": "Soft Prompting for Unlearning in Large Language Models",
    "abstract": "arXiv:2406.12038v2 Announce Type: replace-cross  Abstract: The widespread popularity of Large Language Models (LLMs), partly due to their unique ability to perform in-context learning, has also brought to light the importance of ethical and safety considerations when deploying these pre-trained models. In this work, we focus on investigating machine unlearning for LLMs motivated by data protection regulations. In contrast to the growing literature on fine-tuning methods to achieve unlearning, we focus on a comparatively lightweight alternative called soft prompting to realize the unlearning of a subset of training data. With losses designed to enforce forgetting as well as utility preservation, our framework \\textbf{S}oft \\textbf{P}rompting for \\textbf{U}n\\textbf{l}earning (SPUL) learns prompt tokens that can be appended to an arbitrary query to induce unlearning of specific examples at inference time without updating LLM parameters. We conduct a rigorous evaluation of the proposed met",
    "link": "https://arxiv.org/abs/2406.12038",
    "context": "Title: Soft Prompting for Unlearning in Large Language Models\nAbstract: arXiv:2406.12038v2 Announce Type: replace-cross  Abstract: The widespread popularity of Large Language Models (LLMs), partly due to their unique ability to perform in-context learning, has also brought to light the importance of ethical and safety considerations when deploying these pre-trained models. In this work, we focus on investigating machine unlearning for LLMs motivated by data protection regulations. In contrast to the growing literature on fine-tuning methods to achieve unlearning, we focus on a comparatively lightweight alternative called soft prompting to realize the unlearning of a subset of training data. With losses designed to enforce forgetting as well as utility preservation, our framework \\textbf{S}oft \\textbf{P}rompting for \\textbf{U}n\\textbf{l}earning (SPUL) learns prompt tokens that can be appended to an arbitrary query to induce unlearning of specific examples at inference time without updating LLM parameters. We conduct a rigorous evaluation of the proposed met",
    "path": "papers/24/06/2406.12038.json",
    "total_tokens": 347,
    "tldr": "该文章提出了Soft Prompting for Unlearning（SPUL）框架，该框架通过在查询中附加特定的提示 tokens 来无监督地实现语言模型的特定训练例子的遗忘，从而能够在不更新大型语言模型参数的前提下完美遵守数据保护法规。"
}