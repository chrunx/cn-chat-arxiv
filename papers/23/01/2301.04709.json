{
    "title": "Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability",
    "abstract": "arXiv:2301.04709v3 Announce Type: replace  Abstract: Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of modular features, polysemantic neurons, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methodologies in the common language of causal abstraction, namely activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment se",
    "link": "https://arxiv.org/abs/2301.04709",
    "context": "Title: Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability\nAbstract: arXiv:2301.04709v3 Announce Type: replace  Abstract: Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of modular features, polysemantic neurons, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methodologies in the common language of causal abstraction, namely activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment se",
    "path": "papers/23/01/2301.04709.json",
    "total_tokens": 322,
    "tldr": "该文章提出了一种名为“因果抽象”的理论框架，用于解释模型内部的机制，并提供了一种精确灵活的描述方法，统一了多种解释性方法。"
}