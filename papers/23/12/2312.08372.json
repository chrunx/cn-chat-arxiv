{
    "title": "SAM-guided Graph Cut for 3D Instance Segmentation",
    "abstract": "arXiv:2312.08372v3 Announce Type: replace  Abstract: This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information. Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation. However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data. Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework. The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation. Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem. The superpoint graph is constructed based on 2D segmentation models, where node",
    "link": "https://arxiv.org/abs/2312.08372",
    "context": "Title: SAM-guided Graph Cut for 3D Instance Segmentation\nAbstract: arXiv:2312.08372v3 Announce Type: replace  Abstract: This paper addresses the challenge of 3D instance segmentation by simultaneously leveraging 3D geometric and multi-view image information. Many previous works have applied deep learning techniques to 3D point clouds for instance segmentation. However, these methods often failed to generalize to various types of scenes due to the scarcity and low-diversity of labeled 3D point cloud data. Some recent works have attempted to lift 2D instance segmentations to 3D within a bottom-up framework. The inconsistency in 2D instance segmentations among views can substantially degrade the performance of 3D segmentation. In this work, we introduce a novel 3D-to-2D query framework to effectively exploit 2D segmentation models for 3D instance segmentation. Specifically, we pre-segment the scene into several superpoints in 3D, formulating the task into a graph cut problem. The superpoint graph is constructed based on 2D segmentation models, where node",
    "path": "papers/23/12/2312.08372.json",
    "total_tokens": 718,
    "translated_title": "SAM-指导的图切割方法用于3D实例分割",
    "translated_abstract": "本论文解决3D实例分割挑战，通过同时利用3D几何信息和多视图图像信息。许多先前的工作已经应用深度学习技术到3D点云中进行实例分割。然而，这些方法往往因为标注的3D点云数据的稀缺性和多样性低而无法在不同类型的场景中进行泛化。一些最近的工作试图在基于底部的框架中将2D实例分割提升到3D。在不同视角中2D实例分割的不一致性可以显著降低3D分割的效果。在本工作中，我们介绍了一种新的3D-to-2D查询框架，以有效利用2D分割模型进行3D实例分割。具体地，我们将场景预先分割成3D中的多个超点，将任务转化为图切割问题。超级点图是基于2D分割模型构建的，其中节点的分割质量通过两个角度进行评估：单个视图的局部优势和图像间的信息流。实验结果表明，我们的方法在3D实例分割方面表现出了优越的性能，能够泛化到不同的场景中，并且提高了分割的鲁棒性和准确性。",
    "tldr": "本文提出了一种新的3D实例分割方法，该方法结合了3D几何信息与多视图图像信息，并通过2D实例分割提升到3D的方式提高了分割的性能和鲁棒性。"
}