{
    "title": "Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy",
    "abstract": "arXiv:2312.09436v2 Announce Type: replace  Abstract: The recent development of connected and automated vehicle (CAV) technologies has spurred investigations to optimize dense urban traffic to maximize vehicle speed and throughput. This paper explores advisory autonomy, in which real-time driving advisories are issued to the human drivers, thus achieving near-term performance of automated vehicles. Due to the complexity of traffic systems, recent studies of coordinating CAVs have resorted to leveraging deep reinforcement learning (RL). Coarse-grained advisory is formalized as zero-order holds, and we consider a range of hold duration from 0.1 to 40 seconds. However, despite the similarity of the higher frequency tasks on CAVs, a direct application of deep RL fails to be generalized to advisory autonomy tasks. To overcome this, we utilize zero-shot transfer, training policies on a set of source tasks--specific traffic scenarios with designated hold durations--and then evaluating the effi",
    "link": "https://arxiv.org/abs/2312.09436",
    "context": "Title: Temporal Transfer Learning for Traffic Optimization with Coarse-grained Advisory Autonomy\nAbstract: arXiv:2312.09436v2 Announce Type: replace  Abstract: The recent development of connected and automated vehicle (CAV) technologies has spurred investigations to optimize dense urban traffic to maximize vehicle speed and throughput. This paper explores advisory autonomy, in which real-time driving advisories are issued to the human drivers, thus achieving near-term performance of automated vehicles. Due to the complexity of traffic systems, recent studies of coordinating CAVs have resorted to leveraging deep reinforcement learning (RL). Coarse-grained advisory is formalized as zero-order holds, and we consider a range of hold duration from 0.1 to 40 seconds. However, despite the similarity of the higher frequency tasks on CAVs, a direct application of deep RL fails to be generalized to advisory autonomy tasks. To overcome this, we utilize zero-shot transfer, training policies on a set of source tasks--specific traffic scenarios with designated hold durations--and then evaluating the effi",
    "path": "papers/23/12/2312.09436.json",
    "total_tokens": 767,
    "translated_title": "时间转移学习在粗粒度咨询自治下的交通优化",
    "translated_abstract": "arXiv:2312.09436v2 公告类型：替换",
    "tldr": "本文提出了一种时间转移学习方法，用来提高咨询自治下的交通效率。这种方法通过在特定的车流量和速度条件下训练策略，然后将其应用于实际交通场景，即使在缺乏完全自动驾驶车辆的情况下，也能有效提高交通流量的通过率并减少事故发生率。",
    "en_tdlr": "This paper presents a temporal transfer learning approach to enhance traffic efficiency under advisory autonomy. By training policies under specific traffic scenarios and speeds, and then applying them to actual traffic situations, the method effectively improves traffic throughput and reduces accident rates even in the absence of fully autonomous vehicles."
}