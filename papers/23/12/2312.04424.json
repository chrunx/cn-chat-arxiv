{
    "title": "Cascade-Zero123: One Image to Highly Consistent 3D with Self-Prompted Nearby Views",
    "abstract": "arXiv:2312.04424v2 Announce Type: replace  Abstract: Synthesizing multi-view 3D from one single image is a significant but challenging task. Zero-1-to-3 methods have achieved great success by lifting a 2D latent diffusion model to the 3D scope. The target view image is generated with a single-view source image and the camera pose as condition information. However, due to the high sparsity of the single input image, Zero-1-to-3 tends to produce geometry and appearance inconsistency across views, especially for complex objects. To tackle this issue, we propose to supply more condition information for the generation model but in a self-prompt way. A cascade framework is constructed with two Zero-1-to-3 models, named Cascade-Zero123, which progressively extract 3D information from the source image. Specifically, several nearby views are first generated by the first model and then fed into the second-stage model along with the source image as generation conditions. With amplified self-promp",
    "link": "https://arxiv.org/abs/2312.04424",
    "context": "Title: Cascade-Zero123: One Image to Highly Consistent 3D with Self-Prompted Nearby Views\nAbstract: arXiv:2312.04424v2 Announce Type: replace  Abstract: Synthesizing multi-view 3D from one single image is a significant but challenging task. Zero-1-to-3 methods have achieved great success by lifting a 2D latent diffusion model to the 3D scope. The target view image is generated with a single-view source image and the camera pose as condition information. However, due to the high sparsity of the single input image, Zero-1-to-3 tends to produce geometry and appearance inconsistency across views, especially for complex objects. To tackle this issue, we propose to supply more condition information for the generation model but in a self-prompt way. A cascade framework is constructed with two Zero-1-to-3 models, named Cascade-Zero123, which progressively extract 3D information from the source image. Specifically, several nearby views are first generated by the first model and then fed into the second-stage model along with the source image as generation conditions. With amplified self-promp",
    "path": "papers/23/12/2312.04424.json",
    "total_tokens": 416,
    "tldr": "该文章提出一种名为Cascade-Zero123的框架，能够从单一图像中生成高度一致的多视角3D模型。通过两阶段的Zero-1-to-3模型，该框架首先生成一系列邻近视图，然后利用这些视图和源图像作为条件信息，对图像进行更深入的3D信息提取。这种自促进的方法显著增强了模型的视图一致性，尤其是在处理复杂对象时。"
}