{
    "title": "Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding",
    "abstract": "arXiv:2312.16477v3 Announce Type: replace  Abstract: In recent years, the results of view-based 3D shape recognition methods have saturated, and models with excellent performance cannot be deployed on memory-limited devices due to their huge size of parameters. To address this problem, we introduce a compression method based on knowledge distillation for this field, which largely reduces the number of parameters while preserving model performance as much as possible. Specifically, to enhance the capabilities of smaller models, we design a high-performing large model called Group Multi-view Vision Transformer (GMViT). In GMViT, the view-level ViT first establishes relationships between view-level features. Additionally, to capture deeper features, we employ the grouping module to enhance view-level features into group-level features. Finally, the group-level ViT aggregates group-level features into complete, well-formed 3D shape descriptors. Notably, in both ViTs, we introduce spatial e",
    "link": "https://arxiv.org/abs/2312.16477",
    "context": "Title: Group Multi-View Transformer for 3D Shape Analysis with Spatial Encoding\nAbstract: arXiv:2312.16477v3 Announce Type: replace  Abstract: In recent years, the results of view-based 3D shape recognition methods have saturated, and models with excellent performance cannot be deployed on memory-limited devices due to their huge size of parameters. To address this problem, we introduce a compression method based on knowledge distillation for this field, which largely reduces the number of parameters while preserving model performance as much as possible. Specifically, to enhance the capabilities of smaller models, we design a high-performing large model called Group Multi-view Vision Transformer (GMViT). In GMViT, the view-level ViT first establishes relationships between view-level features. Additionally, to capture deeper features, we employ the grouping module to enhance view-level features into group-level features. Finally, the group-level ViT aggregates group-level features into complete, well-formed 3D shape descriptors. Notably, in both ViTs, we introduce spatial e",
    "path": "papers/23/12/2312.16477.json",
    "total_tokens": 340,
    "tldr": "该文章提出了一种基于知识蒸馏的压缩方法，用以优化用于三维形状分析的组多视图 transformer 模型，从而在大幅减少模型参数数量的同时，保持了较优的性能。"
}