{
    "title": "Unsupervised Region-Growing Network for Object Segmentation in Atmospheric Turbulence",
    "abstract": "arXiv:2311.03572v2 Announce Type: replace  Abstract: Moving object segmentation in the presence of atmospheric turbulence is highly challenging due to turbulence-induced irregular and time-varying distortions. In this paper, we present an unsupervised approach for segmenting moving objects in videos downgraded by atmospheric turbulence. Our key approach is a detect-then-grow scheme: we first identify a small set of moving object pixels with high confidence, then gradually grow a foreground mask from those seeds to segment all moving objects. This method leverages rigid geometric consistency among video frames to disentangle different types of motions, and then uses the Sampson distance to initialize the seedling pixels. After growing per-frame foreground masks, we use spatial grouping loss and temporal consistency loss to further refine the masks in order to ensure their spatio-temporal consistency. Our method is unsupervised and does not require training on labeled data. For validatio",
    "link": "https://arxiv.org/abs/2311.03572",
    "context": "Title: Unsupervised Region-Growing Network for Object Segmentation in Atmospheric Turbulence\nAbstract: arXiv:2311.03572v2 Announce Type: replace  Abstract: Moving object segmentation in the presence of atmospheric turbulence is highly challenging due to turbulence-induced irregular and time-varying distortions. In this paper, we present an unsupervised approach for segmenting moving objects in videos downgraded by atmospheric turbulence. Our key approach is a detect-then-grow scheme: we first identify a small set of moving object pixels with high confidence, then gradually grow a foreground mask from those seeds to segment all moving objects. This method leverages rigid geometric consistency among video frames to disentangle different types of motions, and then uses the Sampson distance to initialize the seedling pixels. After growing per-frame foreground masks, we use spatial grouping loss and temporal consistency loss to further refine the masks in order to ensure their spatio-temporal consistency. Our method is unsupervised and does not require training on labeled data. For validatio",
    "path": "papers/23/11/2311.03572.json",
    "total_tokens": 409,
    "tldr": "该文章提出了一种无监督的区域生长网络，用于大气湍流条件下对象的分割，通过检测并生长的方案，首先识别出具有高置信度的少量移动对象像素，然后逐步从这些种子像素生长前景掩模以分割所有移动对象。该方法利用视频帧之间的一致几何关系来 disentangle 不同的运动类型，并使用 Sampson 距离来初始化种子像素。通过进一步使用空间分组损失和时序一致性损失来细化每帧前景掩模，以确保其空间和时间的一致性。该方法无需标注数据进行训练，是一个无需训练的无监督方法。"
}