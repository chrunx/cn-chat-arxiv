{
    "title": "Point-Based Value Iteration for POMDPs with Neural Perception Mechanisms",
    "abstract": "arXiv:2306.17639v2 Announce Type: replace-cross  Abstract: The increasing trend to integrate neural networks and conventional software components in safety-critical settings calls for methodologies for their formal modelling, verification and correct-by-construction policy synthesis. We introduce neuro-symbolic partially observable Markov decision processes (NS-POMDPs), a variant of continuous-state POMDPs with discrete observations and actions, in which the agent perceives a continuous-state environment using a neural {\\revise perception mechanism} and makes decisions symbolically. The perception mechanism classifies inputs such as images and sensor values into symbolic percepts, which are used in decision making.   We study the problem of optimising discounted cumulative rewards for NS-POMDPs. Working directly with the continuous state space, we exploit the underlying structure of the model and the neural perception mechanism to propose a novel piecewise linear and convex representat",
    "link": "https://arxiv.org/abs/2306.17639",
    "context": "Title: Point-Based Value Iteration for POMDPs with Neural Perception Mechanisms\nAbstract: arXiv:2306.17639v2 Announce Type: replace-cross  Abstract: The increasing trend to integrate neural networks and conventional software components in safety-critical settings calls for methodologies for their formal modelling, verification and correct-by-construction policy synthesis. We introduce neuro-symbolic partially observable Markov decision processes (NS-POMDPs), a variant of continuous-state POMDPs with discrete observations and actions, in which the agent perceives a continuous-state environment using a neural {\\revise perception mechanism} and makes decisions symbolically. The perception mechanism classifies inputs such as images and sensor values into symbolic percepts, which are used in decision making.   We study the problem of optimising discounted cumulative rewards for NS-POMDPs. Working directly with the continuous state space, we exploit the underlying structure of the model and the neural perception mechanism to propose a novel piecewise linear and convex representat",
    "path": "papers/23/06/2306.17639.json",
    "total_tokens": 345,
    "tldr": "该文章提出了一种基于点的值迭代算法，用于具有神经感知机制的部分 observable Markov 决策过程（POMDPs），解决了在连续状态空间中直接优化累积折扣奖励的问题。通过利用模型的内在结构和神经感知机制的特性，该算法能够有效地进行决策优化。"
}