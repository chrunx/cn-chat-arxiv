{
    "title": "Should We Attend More or Less? Modulating Attention for Fairness",
    "abstract": "arXiv:2305.13088v2 Announce Type: replace-cross  Abstract: The advances in natural language processing (NLP) pose both opportunities and challenges. While recent progress enables the development of high-performing models for a variety of tasks, it also poses the risk of models learning harmful biases from the data, such as gender stereotypes. In this work, we investigate the role of attention, a widely-used technique in current state-of-the-art NLP models, in the propagation of social biases. Specifically, we study the relationship between the entropy of the attention distribution and the model's performance and fairness. We then propose a novel method for modulating attention weights to improve model fairness after training. Since our method is only applied post-training and pre-inference, it is an intra-processing method and is, therefore, less computationally expensive than existing in-processing and pre-processing approaches. Our results show an increase in fairness and minimal per",
    "link": "https://arxiv.org/abs/2305.13088",
    "context": "Title: Should We Attend More or Less? Modulating Attention for Fairness\nAbstract: arXiv:2305.13088v2 Announce Type: replace-cross  Abstract: The advances in natural language processing (NLP) pose both opportunities and challenges. While recent progress enables the development of high-performing models for a variety of tasks, it also poses the risk of models learning harmful biases from the data, such as gender stereotypes. In this work, we investigate the role of attention, a widely-used technique in current state-of-the-art NLP models, in the propagation of social biases. Specifically, we study the relationship between the entropy of the attention distribution and the model's performance and fairness. We then propose a novel method for modulating attention weights to improve model fairness after training. Since our method is only applied post-training and pre-inference, it is an intra-processing method and is, therefore, less computationally expensive than existing in-processing and pre-processing approaches. Our results show an increase in fairness and minimal per",
    "path": "papers/23/05/2305.13088.json",
    "total_tokens": 371,
    "tldr": "该文章创新性地研究了注意力机制在自然语言处理模型中的作用，发现模型性能和公平性与其注意力分布的熵有关。作者提出了一种调整注意力权重的策略，以在模型训练完成后改善其公平性。这种事后调节方法相对于其他前处理和在处理方法而言，计算成本较低。实验结果表明，该方法在不显著影响性能的情况下，提升了模型的公平性。"
}