{
    "title": "Should We Attend More or Less? Modulating Attention for Fairness",
    "abstract": "arXiv:2305.13088v2 Announce Type: replace-cross  Abstract: The advances in natural language processing (NLP) pose both opportunities and challenges. While recent progress enables the development of high-performing models for a variety of tasks, it also poses the risk of models learning harmful biases from the data, such as gender stereotypes. In this work, we investigate the role of attention, a widely-used technique in current state-of-the-art NLP models, in the propagation of social biases. Specifically, we study the relationship between the entropy of the attention distribution and the model's performance and fairness. We then propose a novel method for modulating attention weights to improve model fairness after training. Since our method is only applied post-training and pre-inference, it is an intra-processing method and is, therefore, less computationally expensive than existing in-processing and pre-processing approaches. Our results show an increase in fairness and minimal per",
    "link": "https://arxiv.org/abs/2305.13088",
    "context": "Title: Should We Attend More or Less? Modulating Attention for Fairness\nAbstract: arXiv:2305.13088v2 Announce Type: replace-cross  Abstract: The advances in natural language processing (NLP) pose both opportunities and challenges. While recent progress enables the development of high-performing models for a variety of tasks, it also poses the risk of models learning harmful biases from the data, such as gender stereotypes. In this work, we investigate the role of attention, a widely-used technique in current state-of-the-art NLP models, in the propagation of social biases. Specifically, we study the relationship between the entropy of the attention distribution and the model's performance and fairness. We then propose a novel method for modulating attention weights to improve model fairness after training. Since our method is only applied post-training and pre-inference, it is an intra-processing method and is, therefore, less computationally expensive than existing in-processing and pre-processing approaches. Our results show an increase in fairness and minimal per",
    "path": "papers/23/05/2305.13088.json",
    "total_tokens": 634,
    "translated_title": "我们应该参加会议更多还是更少？公平性下的注意力调制",
    "translated_abstract": "arXiv:2305.13088v2 公告类型：替换交叉网络 摘要：自然语言处理（NLP）的进步既带来了机遇也带来了挑战。尽管近期的发展使得在高性能模型上进行多项任务的发展成为可能，但它同时也带来了从数据中学习有害偏见的风险，如性别偏见。在这项工作中，我们研究了当前先进NLP模型中广泛使用的注意力机制在社会偏见传播中的作用。具体来说，我们研究了注意力分布的熵与模型性能和公平性的关系。然后，我们提出了一个新颖的方法来调制注意力权重，以在训练后改善模型的公平性。由于我们的方法仅在训练后和推断前应用，它是一种中间处理方法，因此其计算成本比现有的处理方法和预处理方法要低。我们的结果表明，公平性有所提高，且几乎没有影响模型的性能。",
    "tldr": "这项研究提出了一种通过调整注意力权重来提高自然语言处理模型公平性的方法，该方法在模型训练后实施，对模型性能影响很小。"
}