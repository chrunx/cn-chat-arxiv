{
    "title": "Markov Decision Processes under External Temporal Processes",
    "abstract": "arXiv:2305.16056v2 Announce Type: replace-cross  Abstract: Most reinforcement learning algorithms treat the context under which they operate as a stationary, isolated, and undisturbed environment. However, in real world applications, environments constantly change due to a variety of external events. To address this problem, we study Markov Decision Processes (MDP) under the influence of an external temporal process. We formalize this notion and discuss conditions under which the problem becomes tractable with suitable solutions. We propose a policy iteration algorithm to solve this problem and theoretically analyze its performance. We derive results on the sample complexity of the algorithm and study its dependency on the extent of non-stationarity of the environment. We then conduct experiments to illustrate our results in a classic control environment.",
    "link": "https://arxiv.org/abs/2305.16056",
    "context": "Title: Markov Decision Processes under External Temporal Processes\nAbstract: arXiv:2305.16056v2 Announce Type: replace-cross  Abstract: Most reinforcement learning algorithms treat the context under which they operate as a stationary, isolated, and undisturbed environment. However, in real world applications, environments constantly change due to a variety of external events. To address this problem, we study Markov Decision Processes (MDP) under the influence of an external temporal process. We formalize this notion and discuss conditions under which the problem becomes tractable with suitable solutions. We propose a policy iteration algorithm to solve this problem and theoretically analyze its performance. We derive results on the sample complexity of the algorithm and study its dependency on the extent of non-stationarity of the environment. We then conduct experiments to illustrate our results in a classic control environment.",
    "path": "papers/23/05/2305.16056.json",
    "total_tokens": 305,
    "tldr": "该文章研究了在环境不断变化的情况下，强化学习算法如何通过定义外部事件对其行为的影响来解决马尔可夫决策过程问题，并提出了一种迭代算法来处理这些变化，同时分析了该算法的性能和样本复杂性，并通过实验验证了其有效性。"
}