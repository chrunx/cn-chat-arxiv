{
    "title": "SafeDreamer: Safe Reinforcement Learning with World Models",
    "abstract": "arXiv:2307.07176v3 Announce Type: replace-cross  Abstract: The deployment of Reinforcement Learning (RL) in real-world applications is constrained by its failure to satisfy safety criteria. Existing Safe Reinforcement Learning (SafeRL) methods, which rely on cost functions to enforce safety, often fail to achieve zero-cost performance in complex scenarios, especially vision-only tasks. These limitations are primarily due to model inaccuracies and inadequate sample efficiency. The integration of the world model has proven effective in mitigating these shortcomings. In this work, we introduce SafeDreamer, a novel algorithm incorporating Lagrangian-based methods into world model planning processes within the superior Dreamer framework. Our method achieves nearly zero-cost performance on various tasks, spanning low-dimensional and vision-only input, within the Safety-Gymnasium benchmark, showcasing its efficacy in balancing performance and safety in RL tasks. Further details can be found i",
    "link": "https://arxiv.org/abs/2307.07176",
    "context": "Title: SafeDreamer: Safe Reinforcement Learning with World Models\nAbstract: arXiv:2307.07176v3 Announce Type: replace-cross  Abstract: The deployment of Reinforcement Learning (RL) in real-world applications is constrained by its failure to satisfy safety criteria. Existing Safe Reinforcement Learning (SafeRL) methods, which rely on cost functions to enforce safety, often fail to achieve zero-cost performance in complex scenarios, especially vision-only tasks. These limitations are primarily due to model inaccuracies and inadequate sample efficiency. The integration of the world model has proven effective in mitigating these shortcomings. In this work, we introduce SafeDreamer, a novel algorithm incorporating Lagrangian-based methods into world model planning processes within the superior Dreamer framework. Our method achieves nearly zero-cost performance on various tasks, spanning low-dimensional and vision-only input, within the Safety-Gymnasium benchmark, showcasing its efficacy in balancing performance and safety in RL tasks. Further details can be found i",
    "path": "papers/23/07/2307.07176.json",
    "total_tokens": 354,
    "tldr": "该文章提出了一种名为SafeDreamer的算法，它利用Lagrangian方法结合世界模型规划，在Dreamer框架中实现了在复杂任务中的近零成本性能，尤其是对于低维度和纯视觉输入的任务，其在Safety-Gymnasium基准测试中展现了其在进行强化学习时既能保证性能又能确保安全的能力。"
}