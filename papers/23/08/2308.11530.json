{
    "title": "Leveraging Language Model Capabilities for Sound Event Detection",
    "abstract": "arXiv:2308.11530v2 Announce Type: replace-cross  Abstract: Large language models reveal deep comprehension and fluent generation in the field of multi-modality. Although significant advancements have been achieved in audio multi-modality, existing methods are rarely leverage language model for sound event detection (SED). In this work, we propose an end-to-end framework for understanding audio features while simultaneously generating sound event and their temporal location. Specifically, we employ pretrained acoustic models to capture discriminative features across different categories and language models for autoregressive text generation. Conventional methods generally struggle to obtain features in pure audio domain for classification. In contrast, our framework utilizes the language model to flexibly understand abundant semantic context aligned with the acoustic representation. The experimental results showcase the effectiveness of proposed method in enhancing timestamps precision ",
    "link": "https://arxiv.org/abs/2308.11530",
    "context": "Title: Leveraging Language Model Capabilities for Sound Event Detection\nAbstract: arXiv:2308.11530v2 Announce Type: replace-cross  Abstract: Large language models reveal deep comprehension and fluent generation in the field of multi-modality. Although significant advancements have been achieved in audio multi-modality, existing methods are rarely leverage language model for sound event detection (SED). In this work, we propose an end-to-end framework for understanding audio features while simultaneously generating sound event and their temporal location. Specifically, we employ pretrained acoustic models to capture discriminative features across different categories and language models for autoregressive text generation. Conventional methods generally struggle to obtain features in pure audio domain for classification. In contrast, our framework utilizes the language model to flexibly understand abundant semantic context aligned with the acoustic representation. The experimental results showcase the effectiveness of proposed method in enhancing timestamps precision ",
    "path": "papers/23/08/2308.11530.json",
    "total_tokens": 602,
    "translated_title": "利用语言模型能力进行声事件检测",
    "translated_abstract": "arXiv:2308.11530v2 公告类型: 替换交叉链",
    "tldr": "本文提出了一种采用预训练的声学和语言模型，结合使用多模态表示学习，以构建一个更有效地进行声事件检测的框架。"
}