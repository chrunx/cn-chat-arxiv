{
    "title": "Leveraging Language Model Capabilities for Sound Event Detection",
    "abstract": "arXiv:2308.11530v2 Announce Type: replace-cross  Abstract: Large language models reveal deep comprehension and fluent generation in the field of multi-modality. Although significant advancements have been achieved in audio multi-modality, existing methods are rarely leverage language model for sound event detection (SED). In this work, we propose an end-to-end framework for understanding audio features while simultaneously generating sound event and their temporal location. Specifically, we employ pretrained acoustic models to capture discriminative features across different categories and language models for autoregressive text generation. Conventional methods generally struggle to obtain features in pure audio domain for classification. In contrast, our framework utilizes the language model to flexibly understand abundant semantic context aligned with the acoustic representation. The experimental results showcase the effectiveness of proposed method in enhancing timestamps precision ",
    "link": "https://arxiv.org/abs/2308.11530",
    "context": "Title: Leveraging Language Model Capabilities for Sound Event Detection\nAbstract: arXiv:2308.11530v2 Announce Type: replace-cross  Abstract: Large language models reveal deep comprehension and fluent generation in the field of multi-modality. Although significant advancements have been achieved in audio multi-modality, existing methods are rarely leverage language model for sound event detection (SED). In this work, we propose an end-to-end framework for understanding audio features while simultaneously generating sound event and their temporal location. Specifically, we employ pretrained acoustic models to capture discriminative features across different categories and language models for autoregressive text generation. Conventional methods generally struggle to obtain features in pure audio domain for classification. In contrast, our framework utilizes the language model to flexibly understand abundant semantic context aligned with the acoustic representation. The experimental results showcase the effectiveness of proposed method in enhancing timestamps precision ",
    "path": "papers/23/08/2308.11530.json",
    "total_tokens": 302,
    "tldr": "该文章提出一种利用语言模型能力的声事件检测框架，该框架能够在多模态声音数据中同时捕捉和生成声音事件及其在音频中的时间位置，显著提高了时间标注的精确度。"
}