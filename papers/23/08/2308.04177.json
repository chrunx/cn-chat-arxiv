{
    "title": "How Generalizable are Deepfake Image Detectors? An Empirical Study",
    "abstract": "arXiv:2308.04177v2 Announce Type: replace  Abstract: Deepfakes are becoming increasingly credible, posing a significant threat given their potential to facilitate fraud or bypass access control systems. This has motivated the development of deepfake detection methods, in which deep learning models are trained to distinguish between real and synthesized footage. Unfortunately, existing detectors struggle to generalize to deepfakes from datasets they were not trained on, but little work has been done to examine why or how this limitation can be addressed. Especially, those single-modality deepfake images reveal little available forgery evidence, posing greater challenges than detecting deepfake videos. In this work, we present the first empirical study on the generalizability of deepfake detectors, an essential goal for detectors to stay one step ahead of attackers. Our study utilizes six deepfake datasets, five deepfake image detection methods, and two model augmentation approaches, con",
    "link": "https://arxiv.org/abs/2308.04177",
    "context": "Title: How Generalizable are Deepfake Image Detectors? An Empirical Study\nAbstract: arXiv:2308.04177v2 Announce Type: replace  Abstract: Deepfakes are becoming increasingly credible, posing a significant threat given their potential to facilitate fraud or bypass access control systems. This has motivated the development of deepfake detection methods, in which deep learning models are trained to distinguish between real and synthesized footage. Unfortunately, existing detectors struggle to generalize to deepfakes from datasets they were not trained on, but little work has been done to examine why or how this limitation can be addressed. Especially, those single-modality deepfake images reveal little available forgery evidence, posing greater challenges than detecting deepfake videos. In this work, we present the first empirical study on the generalizability of deepfake detectors, an essential goal for detectors to stay one step ahead of attackers. Our study utilizes six deepfake datasets, five deepfake image detection methods, and two model augmentation approaches, con",
    "path": "papers/23/08/2308.04177.json",
    "total_tokens": 652,
    "translated_title": "深度伪造图像检测器的泛化能力有多强？一项实证研究",
    "translated_abstract": "arXiv:2308.04177v2 宣布类型：替换摘要：随着深度伪造变得越来越逼真，其潜在的欺诈行为或绕过访问控制系统的风险日益增大。因此，人们开发了深度伪造检测方法，这些方法利用深度学习模型来区分真实与合成视频。不幸的是，现有的检测器在检测与训练数据不同的深度伪造方面遇到了困难，但尚未有人对这种局限性进行研究或探讨如何解决。尤其是，单模态深度伪造图像揭示的伪造证据很少，这相对于检测深度伪造视频来说是一个更大的挑战。在本研究中，我们首次对深度伪造检测器的泛化能力进行了研究，这是检测器必须实现的目标，以确保始终领先于攻击者一步。我们的研究利用了六个深度伪造数据集、五种深度伪造图像检测方法以及两种模型增强方法，旨在评估不同数据集、评估标准和模型自身属性对检测器泛化能力的影响。我们还发现在模型训练过程中采取模型增强可以显著提高检测器的泛化能力。",
    "tldr": "这项研究表明，目前深度伪造图像检测器缺乏跨数据集的泛化能力，但通过模型增强训练可以提高这一能力。",
    "en_tdlr": "This study reveals that contemporary deepfake image detectors lack the ability to generalize across different datasets, but adopting model augmentation during training can significantly enhance this capability."
}