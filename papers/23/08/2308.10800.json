{
    "title": "Fact-checking information from large language models can decrease headline discernment",
    "abstract": "arXiv:2308.10800v4 Announce Type: replace-cross  Abstract: Fact checking can be an effective strategy against misinformation, but its implementation at scale is impeded by the overwhelming volume of information online. Recent artificial intelligence (AI) language models have shown impressive ability in fact-checking tasks, but how humans interact with fact-checking information provided by these models is unclear. Here, we investigate the impact of fact-checking information generated by a popular large language model (LLM) on belief in, and sharing intent of, political news headlines in a preregistered randomized control experiment. Although the LLM accurately identifies most false headlines (90%), we find that this information does not significantly improve participants' ability to discern headline accuracy or share accurate news. In contrast, viewing human-generated fact checks enhances discernment in both cases. Subsequent analysis reveals that the AI fact-checker is harmful in speci",
    "link": "https://arxiv.org/abs/2308.10800",
    "context": "Title: Fact-checking information from large language models can decrease headline discernment\nAbstract: arXiv:2308.10800v4 Announce Type: replace-cross  Abstract: Fact checking can be an effective strategy against misinformation, but its implementation at scale is impeded by the overwhelming volume of information online. Recent artificial intelligence (AI) language models have shown impressive ability in fact-checking tasks, but how humans interact with fact-checking information provided by these models is unclear. Here, we investigate the impact of fact-checking information generated by a popular large language model (LLM) on belief in, and sharing intent of, political news headlines in a preregistered randomized control experiment. Although the LLM accurately identifies most false headlines (90%), we find that this information does not significantly improve participants' ability to discern headline accuracy or share accurate news. In contrast, viewing human-generated fact checks enhances discernment in both cases. Subsequent analysis reveals that the AI fact-checker is harmful in speci",
    "path": "papers/23/08/2308.10800.json",
    "total_tokens": 354,
    "tldr": "该文章揭示了使用大型语言模型进行的政治新闻标题事实核查虽然准确度高，但并未显著提高参与者的辨别能力或分享事实性新闻的意愿。相反，人类编写的核查报告在提高辨别能力和分享意愿方面显示出更好的效果。随后进行的分析表明，AI事实核查对政治新闻标题而言是有害的。"
}