{
    "title": "PCNN: Probable-Class Nearest-Neighbor Explanations Improve Fine-Grained Image Classification Accuracy for AIs and Humans",
    "abstract": "arXiv:2308.13651v4 Announce Type: replace  Abstract: Nearest neighbors (NN) are traditionally used to compute final decisions, e.g., in Support Vector Machines or k-NN classifiers, and to provide users with explanations for the model's decision. In this paper, we show a novel utility of nearest neighbors: To improve predictions of a frozen, pretrained classifier C. We leverage an image comparator S that (1) compares the input image with NN images from the top-K most probable classes; and (2) uses S' output scores to weight the confidence scores of C. Our method consistently improves fine-grained image classification accuracy on CUB-200, Cars-196, and Dogs-120. Also, a human study finds that showing lay users our probable-class nearest neighbors (PCNN) reduces over-reliance on AI, thus improving their decision accuracy over prior work which only shows only the top-1 class examples.",
    "link": "https://arxiv.org/abs/2308.13651",
    "context": "Title: PCNN: Probable-Class Nearest-Neighbor Explanations Improve Fine-Grained Image Classification Accuracy for AIs and Humans\nAbstract: arXiv:2308.13651v4 Announce Type: replace  Abstract: Nearest neighbors (NN) are traditionally used to compute final decisions, e.g., in Support Vector Machines or k-NN classifiers, and to provide users with explanations for the model's decision. In this paper, we show a novel utility of nearest neighbors: To improve predictions of a frozen, pretrained classifier C. We leverage an image comparator S that (1) compares the input image with NN images from the top-K most probable classes; and (2) uses S' output scores to weight the confidence scores of C. Our method consistently improves fine-grained image classification accuracy on CUB-200, Cars-196, and Dogs-120. Also, a human study finds that showing lay users our probable-class nearest neighbors (PCNN) reduces over-reliance on AI, thus improving their decision accuracy over prior work which only shows only the top-1 class examples.",
    "path": "papers/23/08/2308.13651.json",
    "total_tokens": 733,
    "translated_title": "PCNN: 概率分类最近邻解释提高人工智能和人类的细粒度图像分类准确性",
    "translated_abstract": "arXiv:2308.13651v4 宣布类型：替换 抽象： 传统上，最近邻（NN）用于计算最终决定，例如在支持向量机或k-NN分类器中，以及为用户提供模型决策的解释。在本文中，我们展示了最近邻的一种新颖用途：改进冻结的预训练分类器C的预测。我们利用一个图像比较器S，其（1）将输入图像与最可能的K类最近的邻图像进行比较；并（2）使用S的输出分数对C的置信分数进行加权。我们的方法在CUB-200、Cars-196和Dogs-120上一致地提高了细粒度图像分类的准确性。此外，针对人类的研究发现，向我们显示概率分类最近邻（PCNN）降低了人们对人工智能的过度依赖，从而提高了他们对工作的决策准确性，而这项工作此前的工作只展示了最可能的1类例子。",
    "tldr": "本文提出了一种新颖的方法，即利用图像比较器对输入图像与最可能的K类最近的邻图像进行比较，并根据比较结果对预训练分类器的置信度进行加权，从而显著提升了细粒度图像分类任务中人工智能和人类的预测准确性。"
}