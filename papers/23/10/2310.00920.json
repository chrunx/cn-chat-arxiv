{
    "title": "Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training",
    "abstract": "arXiv:2310.00920v3 Announce Type: replace  Abstract: Monocular 3D object detection plays a crucial role in autonomous driving. However, existing monocular 3D detection algorithms depend on 3D labels derived from LiDAR measurements, which are costly to acquire for new datasets and challenging to deploy in novel environments. Specifically, this study investigates the pipeline for training a monocular 3D object detection model on a diverse collection of 3D and 2D datasets. The proposed framework comprises three components: (1) a robust monocular 3D model capable of functioning across various camera settings, (2) a selective-training strategy to accommodate datasets with differing class annotations, and (3) a pseudo 3D training approach using 2D labels to enhance detection performance in scenes containing only 2D labels. With this framework, we could train models on a joint set of various open 3D/2D datasets to obtain models with significantly stronger generalization capability and enhance",
    "link": "https://arxiv.org/abs/2310.00920",
    "context": "Title: Every Dataset Counts: Scaling up Monocular 3D Object Detection with Joint Datasets Training\nAbstract: arXiv:2310.00920v3 Announce Type: replace  Abstract: Monocular 3D object detection plays a crucial role in autonomous driving. However, existing monocular 3D detection algorithms depend on 3D labels derived from LiDAR measurements, which are costly to acquire for new datasets and challenging to deploy in novel environments. Specifically, this study investigates the pipeline for training a monocular 3D object detection model on a diverse collection of 3D and 2D datasets. The proposed framework comprises three components: (1) a robust monocular 3D model capable of functioning across various camera settings, (2) a selective-training strategy to accommodate datasets with differing class annotations, and (3) a pseudo 3D training approach using 2D labels to enhance detection performance in scenes containing only 2D labels. With this framework, we could train models on a joint set of various open 3D/2D datasets to obtain models with significantly stronger generalization capability and enhance",
    "path": "papers/23/10/2310.00920.json",
    "total_tokens": 353,
    "tldr": "该文章提出了一种新的训练框架，能够训练出在多样化的3D和2D数据集上具有极佳泛化能力的单目3D物体检测模型，极大地提升了在仅有2D标注的未知场景中的检测性能。"
}