{
    "title": "Enhanced Local Explainability and Trust Scores with Random Forest Proximities",
    "abstract": "arXiv:2310.12428v3 Announce Type: replace-cross  Abstract: We initiate a novel approach to explain the predictions and out of sample performance of random forest (RF) regression and classification models by exploiting the fact that any RF can be mathematically formulated as an adaptive weighted K nearest-neighbors model. Specifically, we employ a recent result that, for both regression and classification tasks, any RF prediction can be rewritten exactly as a weighted sum of the training targets, where the weights are RF proximities between the corresponding pairs of data points. We show that this linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established feature-based methods like SHAP, which generate attributions for a model prediction across input features. We show how this proximity-based approach to explainability can be used in conjunction",
    "link": "https://arxiv.org/abs/2310.12428",
    "context": "Title: Enhanced Local Explainability and Trust Scores with Random Forest Proximities\nAbstract: arXiv:2310.12428v3 Announce Type: replace-cross  Abstract: We initiate a novel approach to explain the predictions and out of sample performance of random forest (RF) regression and classification models by exploiting the fact that any RF can be mathematically formulated as an adaptive weighted K nearest-neighbors model. Specifically, we employ a recent result that, for both regression and classification tasks, any RF prediction can be rewritten exactly as a weighted sum of the training targets, where the weights are RF proximities between the corresponding pairs of data points. We show that this linearity facilitates a local notion of explainability of RF predictions that generates attributions for any model prediction across observations in the training set, and thereby complements established feature-based methods like SHAP, which generate attributions for a model prediction across input features. We show how this proximity-based approach to explainability can be used in conjunction",
    "path": "papers/23/10/2310.12428.json",
    "total_tokens": 354,
    "tldr": "该文章提出了一个利用随机森林(RF)预测的数学表达式为其训练目标加权和的新方法，揭示了RF模型预测的线性关系，从而提供了一种针对RF预测的本地化解释方法，该方法能够为模型预测提供数据点之间的权重和训练集中的任何预测的局部解释，改进了现有特征解释方法，如SHAP。"
}