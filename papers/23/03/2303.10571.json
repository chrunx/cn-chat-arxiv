{
    "title": "Reinforcement Learning Friendly Vision-Language Model for Minecraft",
    "abstract": "arXiv:2303.10571v2 Announce Type: replace-cross  Abstract: One of the essential missions in the AI research community is to build an autonomous embodied agent that can achieve high-level performance across a wide spectrum of tasks. However, acquiring or manually designing rewards for all open-ended tasks is unrealistic. In this paper, we propose a novel cross-modal contrastive learning framework architecture, CLIP4MC, aiming to learn a reinforcement learning (RL) friendly vision-language model (VLM) that serves as an intrinsic reward function for open-ended tasks. Simply utilizing the similarity between the video snippet and the language prompt is not RL-friendly since standard VLMs may only capture the similarity at a coarse level. To achieve RL-friendliness, we incorporate the task completion degree into the VLM training objective, as this information can assist agents in distinguishing the importance between different states. Moreover, we provide neat YouTube datasets based on the l",
    "link": "https://arxiv.org/abs/2303.10571",
    "context": "Title: Reinforcement Learning Friendly Vision-Language Model for Minecraft\nAbstract: arXiv:2303.10571v2 Announce Type: replace-cross  Abstract: One of the essential missions in the AI research community is to build an autonomous embodied agent that can achieve high-level performance across a wide spectrum of tasks. However, acquiring or manually designing rewards for all open-ended tasks is unrealistic. In this paper, we propose a novel cross-modal contrastive learning framework architecture, CLIP4MC, aiming to learn a reinforcement learning (RL) friendly vision-language model (VLM) that serves as an intrinsic reward function for open-ended tasks. Simply utilizing the similarity between the video snippet and the language prompt is not RL-friendly since standard VLMs may only capture the similarity at a coarse level. To achieve RL-friendliness, we incorporate the task completion degree into the VLM training objective, as this information can assist agents in distinguishing the importance between different states. Moreover, we provide neat YouTube datasets based on the l",
    "path": "papers/23/03/2303.10571.json",
    "total_tokens": 709,
    "translated_title": "面向强化学习友好型视觉-语言模型的《我的世界》模型",
    "translated_abstract": "arXiv:2303.10571v2 公告类型：替换交叉  摘要：在人工智能研究社区中，建立一个能够在高水平任务上实现广泛任务自主嵌入式代理是至关重要的。然而，为所有开放式任务获取或手动设计奖励是不现实的。在这篇文章中，我们提出了一个新型的跨模态对比学习框架架构，CLIP4MC，旨在学习一种基于强化学习的视频-语言模型（VLM），它作为开放式任务的内在奖励函数。由于标准VLMs可能只在大范围内捕获相似性，因此仅利用视频快照和语言提示之间的相似性并不是RL友好的。为了实现RL友好性，我们将在VLM训练目标中融入任务完成程度的信息，因为这种信息可以帮助代理区分不同状态的重要性。此外，我们还提供了一个干净的YouTube数据集，基于《我的世界》的任务，用于训练VLM，以提升模型在开放式任务中的RL性能。我们还通过在Minecraft环境中的实验，对CLIP4MC进行验证，结果表明，我们的方法能够有效地区分最重要的奖励，并促进了任务执行的策略。",
    "tldr": "本文提出了一种新型强化学习友好的视觉-语言模型CLIP4MC，它在Minecraft环境中通过结合任务完成度和语言描述的相似性，实现了对开放式任务的有效指导。",
    "en_tdlr": "This paper presents a novel reinforcement learning-friendly Vision-Language Model CLIP4MC, which improves the performance of open-ended tasks in Minecraft by integrating task completion with semantic similarity, thus effectively guiding objectives and strategies within the environment."
}