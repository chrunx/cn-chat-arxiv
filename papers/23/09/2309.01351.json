{
    "title": "Adv3D: Generating 3D Adversarial Examples for 3D Object Detection in Driving Scenarios with NeRF",
    "abstract": "arXiv:2309.01351v2 Announce Type: replace  Abstract: Deep neural networks (DNNs) have been proven extremely susceptible to adversarial examples, which raises special safety-critical concerns for DNN-based autonomous driving stacks (i.e., 3D object detection). Although there are extensive works on image-level attacks, most are restricted to 2D pixel spaces, and such attacks are not always physically realistic in our 3D world. Here we present Adv3D, the first exploration of modeling adversarial examples as Neural Radiance Fields (NeRFs). Advances in NeRF provide photorealistic appearances and 3D accurate generation, yielding a more realistic and realizable adversarial example. We train our adversarial NeRF by minimizing the surrounding objects' confidence predicted by 3D detectors on the training set. Then we evaluate Adv3D on the unseen validation set and show that it can cause a large performance reduction when rendering NeRF in any sampled pose. To generate physically realizable adver",
    "link": "https://arxiv.org/abs/2309.01351",
    "context": "Title: Adv3D: Generating 3D Adversarial Examples for 3D Object Detection in Driving Scenarios with NeRF\nAbstract: arXiv:2309.01351v2 Announce Type: replace  Abstract: Deep neural networks (DNNs) have been proven extremely susceptible to adversarial examples, which raises special safety-critical concerns for DNN-based autonomous driving stacks (i.e., 3D object detection). Although there are extensive works on image-level attacks, most are restricted to 2D pixel spaces, and such attacks are not always physically realistic in our 3D world. Here we present Adv3D, the first exploration of modeling adversarial examples as Neural Radiance Fields (NeRFs). Advances in NeRF provide photorealistic appearances and 3D accurate generation, yielding a more realistic and realizable adversarial example. We train our adversarial NeRF by minimizing the surrounding objects' confidence predicted by 3D detectors on the training set. Then we evaluate Adv3D on the unseen validation set and show that it can cause a large performance reduction when rendering NeRF in any sampled pose. To generate physically realizable adver",
    "path": "papers/23/09/2309.01351.json",
    "total_tokens": 410,
    "tldr": "该文章创新地提出了Adv3D，一种使用Neural Radiance Fields（NeRF）生成3D对抗性样本的方法，专门针对3D物体检测在驾驶场景中的应用。通过最小化相邻对象在训练集中预测的信心，Adv3D利用NeRF的3D准确度和逼真外观特性，创造出一种新的物理上可实现的对抗性威胁，展示了在渲染NeRF时对3D检测器的显著性能影响。"
}