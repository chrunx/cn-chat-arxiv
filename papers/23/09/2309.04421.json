{
    "title": "SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios",
    "abstract": "arXiv:2309.04421v2 Announce Type: replace  Abstract: Creating a diverse and comprehensive dataset of hand gestures for dynamic human-machine interfaces in the automotive domain can be challenging and time-consuming. To overcome this challenge, we propose using synthetic gesture datasets generated by virtual 3D models. Our framework utilizes Unreal Engine to synthesize realistic hand gestures, offering customization options and reducing the risk of overfitting. Multiple variants, including gesture speed, performance, and hand shape, are generated to improve generalizability. In addition, we simulate different camera locations and types, such as RGB, infrared, and depth cameras, without incurring additional time and cost to obtain these cameras. Experimental results demonstrate that our proposed framework, SynthoGestures (https://github.com/amrgomaaelhady/SynthoGestures), improves gesture recognition accuracy and can replace or augment real-hand datasets. By saving time and effort in the",
    "link": "https://arxiv.org/abs/2309.04421",
    "context": "Title: SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios\nAbstract: arXiv:2309.04421v2 Announce Type: replace  Abstract: Creating a diverse and comprehensive dataset of hand gestures for dynamic human-machine interfaces in the automotive domain can be challenging and time-consuming. To overcome this challenge, we propose using synthetic gesture datasets generated by virtual 3D models. Our framework utilizes Unreal Engine to synthesize realistic hand gestures, offering customization options and reducing the risk of overfitting. Multiple variants, including gesture speed, performance, and hand shape, are generated to improve generalizability. In addition, we simulate different camera locations and types, such as RGB, infrared, and depth cameras, without incurring additional time and cost to obtain these cameras. Experimental results demonstrate that our proposed framework, SynthoGestures (https://github.com/amrgomaaelhady/SynthoGestures), improves gesture recognition accuracy and can replace or augment real-hand datasets. By saving time and effort in the",
    "path": "papers/23/09/2309.04421.json",
    "total_tokens": 692,
    "translated_title": "这里是一个针对动态手势生成的全新框架，用于驾驶情景",
    "translated_abstract": "arXiv:2309.04421v2 公告类型：替换 摘要：在汽车领域创建一个多样化的手势动作数据库可能会很艰难且耗时。为了解决这一挑战，我们提出了使用由虚拟3D模型生成的合成手势数据的构想。我们的框架使用虚幻引擎生成现实的手势动作，提供自定义选项并降低过度拟合的危险。我们还生成了多种变体，包括手势速度、表现力和手形，以提高泛化能力。此外，我们还模拟了不同位置的摄像头和类型的摄像头，如RGB、红外和深度摄像头，而不会增加获取这些摄像头的额外时间和成本。实验结果表明，我们提出的框架“SynthoGestures（https://github.com/amrgomaaelhady/SynthoGestures）”提高了手势识别精度，并可以代替或补充真实手势的数据集。通过节省时间，我们为驾驶情景中的动态手势生成提供了更高效的方法。",
    "tldr": "我们提出了一个使用虚拟3D模型的全新框架，该框架使用Unreal Engine生成现实的手势动作，通过节省时间和努力，为驾驶情景中的动态手势生成提供了更高效的方法。"
}