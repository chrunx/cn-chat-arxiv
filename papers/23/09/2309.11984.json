{
    "title": "State Representations as Incentives for Reinforcement Learning Agents: A Sim2Real Analysis on Robotic Grasping",
    "abstract": "arXiv:2309.11984v3 Announce Type: replace  Abstract: Choosing an appropriate representation of the environment for the underlying decision-making process of the reinforcement learning agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and disentangled enough to simplify policy training and the corresponding sim2real transfer. Given this outlook, this work examines the effect of various representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representations is defined, starting from hand-crafted numerical states to encoded image-based representations, with decreasing levels of induced task-specific knowledge. The effects of each representation on the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot are examined and compared against a model-based a",
    "link": "https://arxiv.org/abs/2309.11984",
    "context": "Title: State Representations as Incentives for Reinforcement Learning Agents: A Sim2Real Analysis on Robotic Grasping\nAbstract: arXiv:2309.11984v3 Announce Type: replace  Abstract: Choosing an appropriate representation of the environment for the underlying decision-making process of the reinforcement learning agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and disentangled enough to simplify policy training and the corresponding sim2real transfer. Given this outlook, this work examines the effect of various representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representations is defined, starting from hand-crafted numerical states to encoded image-based representations, with decreasing levels of induced task-specific knowledge. The effects of each representation on the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot are examined and compared against a model-based a",
    "path": "papers/23/09/2309.11984.json",
    "total_tokens": 395,
    "tldr": "该文章研究了在强化学习场景中，环境状态表示对激励学习代理解决特定任务的有效性，特别是在机器人抓取任务中的抗平面和平面物体抓取。通过定义一个从数值状态手工制作的到基于图像状态的编码的连续状态表示范围，研究了不同状态表示对学习代理在模拟环境中解决问题的能力和所学策略在真实机器人上转移的能力的影响。通过与基于模型的方法进行比较，该研究强调了状态表示在强化学习中的战略重要性，以及在真实世界中实现有效模拟到现实world转移的关键因素。"
}