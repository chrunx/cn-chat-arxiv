{
    "title": "Large AI Model Empowered Multimodal Semantic Communications",
    "abstract": "arXiv:2309.01249v2 Announce Type: replace  Abstract: Multimodal signals, including text, audio, image, and video, can be integrated into Semantic Communication (SC) systems to provide an immersive experience with low latency and high quality at the semantic level. However, the multimodal SC has several challenges, including data heterogeneity, semantic ambiguity, and signal distortion during transmission. Recent advancements in large AI models, particularly in the Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential solutions for addressing these issues. To this end, we propose a Large AI Model-based Multimodal SC (LAM-MSC) framework, where we first present the MLM-based Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation between multimodal and unimodal data while preserving semantic consistency. Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows users to perform personalized semantic extraction or recovery",
    "link": "https://arxiv.org/abs/2309.01249",
    "context": "Title: Large AI Model Empowered Multimodal Semantic Communications\nAbstract: arXiv:2309.01249v2 Announce Type: replace  Abstract: Multimodal signals, including text, audio, image, and video, can be integrated into Semantic Communication (SC) systems to provide an immersive experience with low latency and high quality at the semantic level. However, the multimodal SC has several challenges, including data heterogeneity, semantic ambiguity, and signal distortion during transmission. Recent advancements in large AI models, particularly in the Multimodal Language Model (MLM) and Large Language Model (LLM), offer potential solutions for addressing these issues. To this end, we propose a Large AI Model-based Multimodal SC (LAM-MSC) framework, where we first present the MLM-based Multimodal Alignment (MMA) that utilizes the MLM to enable the transformation between multimodal and unimodal data while preserving semantic consistency. Then, a personalized LLM-based Knowledge Base (LKB) is proposed, which allows users to perform personalized semantic extraction or recovery",
    "path": "papers/23/09/2309.01249.json",
    "total_tokens": 357,
    "tldr": "该文章提出了一种利用大型AI模型赋能的多模态语义通信框架，通过多模态语言模型实现数据转换和语义一致性，并通过个性化的大语言模型知识库进行用户特定的语义提取或恢复，解决了多模态语义通信中存在的挑战。"
}