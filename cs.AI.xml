<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://raw.githubusercontent.com/chrunx/cn-chat-arxiv/master/cs.AI.xml</link><description>This is arxiv RSS feed for cs.AI</description><item><title>该文章开发了一种名为Puppet-Master的交互式视频生成模型，该模型能够作为部分动态的先验知识。在测试阶段，仅凭一张图像和部分运动轨迹（即拖动操作），该模型能够生成一个视频，其中描绘的现实主义部分动态忠实地反映了给定的拖动操作。这种能力是通过对大型预训练视频扩散模型进行微调实现的，并且提出了一个新式的条件化架构，以有效注入拖动控制。此外，作者还引入了一种全部到第一次的注意力机制，这是一种空间注意力模块的替代方案，它通过解决现有模型中出现的视觉外观和背景问题，显著提高了生成质量。与训练于自然场景视频且主要移动整个物体的其他运动条件视频生成器不同，Puppet-Master是在新构建的Objaverse-Animation-HQ数据集上进行训练的，该数据集专门用于动作和动画的高质量视频数据。</title><link>https://arxiv.org/abs/2408.04631</link><description>&lt;p&gt;
Puppet-Master: Scaling Interactive Video Generation as a Motion Prior for Part-Level Dynamics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04631
&lt;/p&gt;
&lt;p&gt;
该文章开发了一种名为Puppet-Master的交互式视频生成模型，该模型能够作为部分动态的先验知识。在测试阶段，仅凭一张图像和部分运动轨迹（即拖动操作），该模型能够生成一个视频，其中描绘的现实主义部分动态忠实地反映了给定的拖动操作。这种能力是通过对大型预训练视频扩散模型进行微调实现的，并且提出了一个新式的条件化架构，以有效注入拖动控制。此外，作者还引入了一种全部到第一次的注意力机制，这是一种空间注意力模块的替代方案，它通过解决现有模型中出现的视觉外观和背景问题，显著提高了生成质量。与训练于自然场景视频且主要移动整个物体的其他运动条件视频生成器不同，Puppet-Master是在新构建的Objaverse-Animation-HQ数据集上进行训练的，该数据集专门用于动作和动画的高质量视频数据。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04631v1 Announce Type: new  Abstract: We present Puppet-Master, an interactive video generative model that can serve as a motion prior for part-level dynamics. At test time, given a single image and a sparse set of motion trajectories (i.e., drags), Puppet-Master can synthesize a video depicting realistic part-level motion faithful to the given drag interactions. This is achieved by fine-tuning a large-scale pre-trained video diffusion model, for which we propose a new conditioning architecture to inject the dragging control effectively. More importantly, we introduce the all-to-first attention mechanism, a drop-in replacement for the widely adopted spatial attention modules, which significantly improves generation quality by addressing the appearance and background issues in existing models. Unlike other motion-conditioned video generators that are trained on in-the-wild videos and mostly move an entire object, Puppet-Master is learned from Objaverse-Animation-HQ, a new dat
&lt;/p&gt;</description></item><item><title>该文章介绍了LogogramNLP，一个首个基准研究，它使得自然语言处理分析古代象形文字成为可能，并且包含了四种书写系统的转录和视觉数据集，以及对诸如分类等各种任务的注释标注。</title><link>https://arxiv.org/abs/2408.04628</link><description>&lt;p&gt;
LogogramNLP: Comparing Visual and Textual Representations of Ancient Logographic Writing Systems for NLP
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04628
&lt;/p&gt;
&lt;p&gt;
该文章介绍了LogogramNLP，一个首个基准研究，它使得自然语言处理分析古代象形文字成为可能，并且包含了四种书写系统的转录和视觉数据集，以及对诸如分类等各种任务的注释标注。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04628v1 Announce Type: cross  Abstract: Standard natural language processing (NLP) pipelines operate on symbolic representations of language, which typically consist of sequences of discrete tokens. However, creating an analogous representation for ancient logographic writing systems is an extremely labor intensive process that requires expert knowledge. At present, a large portion of logographic data persists in a purely visual form due to the absence of transcription -- this issue poses a bottleneck for researchers seeking to apply NLP toolkits to study ancient logographic languages: most of the relevant data are images of writing.   This paper investigates whether direct processing of visual representations of language offers a potential solution. We introduce LogogramNLP, the first benchmark enabling NLP analysis of ancient logographic languages, featuring both transcribed and visual datasets for four writing systems along with annotations for tasks like classification, 
&lt;/p&gt;</description></item><item><title>该文章介绍了Transformer Explainer，一个集成GPT-2模型的交互式可视化工具，它帮助非专家用户通过直观的界面了解Transformer模型的工作原理。该工具允许用户通过自己的输入实时观察Transformer内部组件和参数如何协同工作以预测下一个词，从而提供了对现代生成AI技术的基本教育。</title><link>https://arxiv.org/abs/2408.04619</link><description>&lt;p&gt;
Transformer Explainer: Interactive Learning of Text-Generative Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04619
&lt;/p&gt;
&lt;p&gt;
该文章介绍了Transformer Explainer，一个集成GPT-2模型的交互式可视化工具，它帮助非专家用户通过直观的界面了解Transformer模型的工作原理。该工具允许用户通过自己的输入实时观察Transformer内部组件和参数如何协同工作以预测下一个词，从而提供了对现代生成AI技术的基本教育。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04619v1 Announce Type: cross  Abstract: Transformers have revolutionized machine learning, yet their inner workings remain opaque to many. We present Transformer Explainer, an interactive visualization tool designed for non-experts to learn about Transformers through the GPT-2 model. Our tool helps users understand complex Transformer concepts by integrating a model overview and enabling smooth transitions across abstraction levels of mathematical operations and model structures. It runs a live GPT-2 instance locally in the user's browser, empowering users to experiment with their own input and observe in real-time how the internal components and parameters of the Transformer work together to predict the next tokens. Our tool requires no installation or special hardware, broadening the public's education access to modern generative AI techniques. Our open-sourced tool is available at https://poloclub.github.io/transformer-explainer/. A video demo is available at https://yout
&lt;/p&gt;</description></item><item><title>该文章提出一种新的方法，即指令双向翻译，用于构建高质量的基于世界知识的合成数据，以对大型语言模型进行对齐。通过使用Li等人的反向翻译方法，我们对文档数据生成了高质量的合成指令，并对响应进行了重写，以进一步提高其质量。使用由此产生的（反向翻译指令，重写响应）对进行微调，在AlpacaEval上的胜率比使用其他常用指令数据集（如Humpback、ShareGPT、Open Orca、Alpaca-GPT4和Self-instruct）要高。我们还展示了使用LLM重写响应比直接蒸馏效果更好，并且生成的两个文本分布在外部嵌入空间中表现出显著的区别。进一步分析表明，我们的反向翻译指令在质量上优于其他合成源的指令。</title><link>https://arxiv.org/abs/2408.04614</link><description>&lt;p&gt;
Better Alignment with Instruction Back-and-Forth Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04614
&lt;/p&gt;
&lt;p&gt;
该文章提出一种新的方法，即指令双向翻译，用于构建高质量的基于世界知识的合成数据，以对大型语言模型进行对齐。通过使用Li等人的反向翻译方法，我们对文档数据生成了高质量的合成指令，并对响应进行了重写，以进一步提高其质量。使用由此产生的（反向翻译指令，重写响应）对进行微调，在AlpacaEval上的胜率比使用其他常用指令数据集（如Humpback、ShareGPT、Open Orca、Alpaca-GPT4和Self-instruct）要高。我们还展示了使用LLM重写响应比直接蒸馏效果更好，并且生成的两个文本分布在外部嵌入空间中表现出显著的区别。进一步分析表明，我们的反向翻译指令在质量上优于其他合成源的指令。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04614v1 Announce Type: cross  Abstract: We propose a new method, instruction back-and-forth translation, to construct high-quality synthetic data grounded in world knowledge for aligning large language models (LLMs). Given documents from a web corpus, we generate and curate synthetic instructions using the backtranslation approach proposed by Li et al.(2023a), and rewrite the responses to improve their quality further based on the initial documents. Fine-tuning with the resulting (backtranslated instruction, rewritten response) pairs yields higher win rates on AlpacaEval than using other common instruction datasets such as Humpback, ShareGPT, Open Orca, Alpaca-GPT4 and Self-instruct. We also demonstrate that rewriting the responses with an LLM outperforms direct distillation, and the two generated text distributions exhibit significant distinction in embedding space. Further analysis shows that our backtranslated instructions are of higher quality than other sources of synth
&lt;/p&gt;</description></item><item><title>该文章创新性地讨论了上界置信区间算法在多臂赌博机问题中的渐进行为，并将此应用于下游推断任务中。本文提出了一种稳定性的概念，用以缓解数据在连续收集过程中推断任务的挑战，并证明上界置信区间算法具有满足这种稳定性性质的固有特征。此外，通过分析当臂的数量K随连续抽取动作的数量T增长时上界置信区间算法的稳定性，本文揭示了当$\frac{\log K}{\log T} \rightarrow 0$时，最优化算法中的臂是稳定的，并且能够识别出接近最优解的数量。</title><link>https://arxiv.org/abs/2408.04595</link><description>&lt;p&gt;
Inference with the Upper Confidence Bound Algorithm
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04595
&lt;/p&gt;
&lt;p&gt;
该文章创新性地讨论了上界置信区间算法在多臂赌博机问题中的渐进行为，并将此应用于下游推断任务中。本文提出了一种稳定性的概念，用以缓解数据在连续收集过程中推断任务的挑战，并证明上界置信区间算法具有满足这种稳定性性质的固有特征。此外，通过分析当臂的数量K随连续抽取动作的数量T增长时上界置信区间算法的稳定性，本文揭示了当$\frac{\log K}{\log T} \rightarrow 0$时，最优化算法中的臂是稳定的，并且能够识别出接近最优解的数量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04595v1 Announce Type: cross  Abstract: In this paper, we discuss the asymptotic behavior of the Upper Confidence Bound (UCB) algorithm in the context of multiarmed bandit problems and discuss its implication in downstream inferential tasks. While inferential tasks become challenging when data is collected in a sequential manner, we argue that this problem can be alleviated when the sequential algorithm at hand satisfies certain stability property. This notion of stability is motivated from the seminal work of Lai and Wei (1982). Our first main result shows that such a stability property is always satisfied for the UCB algorithm, and as a result the sample means for each arm are asymptotically normal. Next, we examine the stability properties of the UCB algorithm when the number of arms $K$ is allowed to grow with the number of arm pulls $T$. We show that in such a case the arms are stable when $\frac{\log K}{\log T} \rightarrow 0$, and the number of near-optimal arms are la
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一种名为Img-Diff的高质量跨模态数据集，该数据集通过对比学习方法和图像差异描述，增强了大型语言模型在图像识别方面的精细度。文章采用稳定的扩散模型和技术来创建相似图像对，并利用自动生成的差异描述来训练状态最先进的MLLMs，实现了显著的性能提升。</title><link>https://arxiv.org/abs/2408.04594</link><description>&lt;p&gt;
Img-Diff: Contrastive Data Synthesis for Multimodal Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04594
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一种名为Img-Diff的高质量跨模态数据集，该数据集通过对比学习方法和图像差异描述，增强了大型语言模型在图像识别方面的精细度。文章采用稳定的扩散模型和技术来创建相似图像对，并利用自动生成的差异描述来训练状态最先进的MLLMs，实现了显著的性能提升。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04594v1 Announce Type: new  Abstract: High-performance Multimodal Large Language Models (MLLMs) rely heavily on data quality. This study introduces a novel dataset named Img-Diff, designed to enhance fine-grained image recognition in MLLMs by leveraging insights from contrastive learning and image difference captioning. By analyzing object differences between similar images, we challenge models to identify both matching and distinct components. We utilize the Stable-Diffusion-XL model and advanced image editing techniques to create pairs of similar images that highlight object replacements. Our methodology includes a Difference Area Generator for object differences identifying, followed by a Difference Captions Generator for detailed difference descriptions. The result is a relatively small but high-quality dataset of "object replacement" samples. We use the the proposed dataset to fine-tune state-of-the-art (SOTA) MLLMs such as MGM-7B, yielding comprehensive improvements of
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为HiLo的框架，用于在跨域变化下进行的一般化类别发现任务。该框架提取高阶语义和低阶域特征，并通过最小化两种特征表示之间的互信息来确保类别信息与域信息不相关。通过特殊设计的数据增强和基于课程学习的策略，该框架在处理来自不同域的未标注数据方面取得了显著成果。</title><link>https://arxiv.org/abs/2408.04591</link><description>&lt;p&gt;
HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04591
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为HiLo的框架，用于在跨域变化下进行的一般化类别发现任务。该框架提取高阶语义和低阶域特征，并通过最小化两种特征表示之间的互信息来确保类别信息与域信息不相关。通过特殊设计的数据增强和基于课程学习的策略，该框架在处理来自不同域的未标注数据方面取得了显著成果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04591v1 Announce Type: new  Abstract: Generalized Category Discovery (GCD) is a challenging task in which, given a partially labelled dataset, models must categorize all unlabelled instances, regardless of whether they come from labelled categories or from new ones. In this paper, we challenge a remaining assumption in this task: that all images share the same domain. Specifically, we introduce a new task and method to handle GCD when the unlabelled data also contains images from different domains to the labelled set. Our proposed `HiLo' networks extract High-level semantic and Low-level domain features, before minimizing the mutual information between the representations. Our intuition is that the clusterings based on domain information and semantic information should be independent. We further extend our method with a specialized domain augmentation tailored for the GCD task, as well as a curriculum learning approach. Finally, we construct a benchmark from corrupted fine-g
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的算法，用于从场景的不规则采样网格中合成新的视角，这种方法首先将每个采样的视角扩展到一个局部光场，然后通过混合相邻的局部光场来渲染新的视角，为用户提供了如何可靠地合成高质量新视角的具体指导。</title><link>https://arxiv.org/abs/2408.04586</link><description>&lt;p&gt;
Sampling for View Synthesis: From Local Light Field Fusion to Neural Radiance Fields and Beyond
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04586
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的算法，用于从场景的不规则采样网格中合成新的视角，这种方法首先将每个采样的视角扩展到一个局部光场，然后通过混合相邻的局部光场来渲染新的视角，为用户提供了如何可靠地合成高质量新视角的具体指导。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04586v1 Announce Type: cross  Abstract: Capturing and rendering novel views of complex real-world scenes is a long-standing problem in computer graphics and vision, with applications in augmented and virtual reality, immersive experiences and 3D photography. The advent of deep learning has enabled revolutionary advances in this area, classically known as image-based rendering. However, previous approaches require intractably dense view sampling or provide little or no guidance for how users should sample views of a scene to reliably render high-quality novel views. Local light field fusion proposes an algorithm for practical view synthesis from an irregular grid of sampled views that first expands each sampled view into a local light field via a multiplane image scene representation, then renders novel views by blending adjacent local light fields. Crucially, we extend traditional plenoptic sampling theory to derive a bound that specifies precisely how densely users should s
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的系统性分析方法来研究稀疏神经网络在特征选择方面的应用，特别探讨了动态稀疏训练算法在特征选择中的作用，并引入了一个新的特征重要性指标来衡量稀疏神经网络中的特征。研究表明，稀疏神经网络在特征选择方面展现出潜在的效用，尤其是与传统密集网络相比，可以显著减少计算开销，同时在多种数据集上具有竞争力。</title><link>https://arxiv.org/abs/2408.04583</link><description>&lt;p&gt;
Unveiling the Power of Sparse Neural Networks for Feature Selection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04583
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的系统性分析方法来研究稀疏神经网络在特征选择方面的应用，特别探讨了动态稀疏训练算法在特征选择中的作用，并引入了一个新的特征重要性指标来衡量稀疏神经网络中的特征。研究表明，稀疏神经网络在特征选择方面展现出潜在的效用，尤其是与传统密集网络相比，可以显著减少计算开销，同时在多种数据集上具有竞争力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04583v1 Announce Type: cross  Abstract: Sparse Neural Networks (SNNs) have emerged as powerful tools for efficient feature selection. Leveraging the dynamic sparse training (DST) algorithms within SNNs has demonstrated promising feature selection capabilities while drastically reducing computational overheads. Despite these advancements, several critical aspects remain insufficiently explored for feature selection. Questions persist regarding the choice of the DST algorithm for network training, the choice of metric for ranking features/neurons, and the comparative performance of these methods across diverse datasets when compared to dense networks. This paper addresses these gaps by presenting a comprehensive systematic analysis of feature selection with sparse neural networks. Moreover, we introduce a novel metric considering sparse neural network characteristics, which is designed to quantify feature importance within the context of SNNs. Our findings show that feature se
&lt;/p&gt;</description></item><item><title>该文章通过介绍SCENE（Soft Counterfactual Evaluation for Natural language Explainability），提出了一种评估机器学习模型，特别是在自然语言处理（NLP）任务中的透明度和责任性的新方法。SCENE利用大型语言模型（LLMs）生成软交互式假想（Soft Counterfactual）解释，无需大量调优。该方法通过评估Validitysoft和Csoft指标来衡量其在文本分类任务中对模型 agnostic 的XAI（可解释人工智能）方法的有效性。根据CNN、RNN和BERT等架构的适用性，SCENE为XAI技术提供了有价值的见解。</title><link>https://arxiv.org/abs/2408.04575</link><description>&lt;p&gt;
SCENE: Evaluating Explainable AI Techniques Using Soft Counterfactuals
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04575
&lt;/p&gt;
&lt;p&gt;
该文章通过介绍SCENE（Soft Counterfactual Evaluation for Natural language Explainability），提出了一种评估机器学习模型，特别是在自然语言处理（NLP）任务中的透明度和责任性的新方法。SCENE利用大型语言模型（LLMs）生成软交互式假想（Soft Counterfactual）解释，无需大量调优。该方法通过评估Validitysoft和Csoft指标来衡量其在文本分类任务中对模型 agnostic 的XAI（可解释人工智能）方法的有效性。根据CNN、RNN和BERT等架构的适用性，SCENE为XAI技术提供了有价值的见解。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04575v1 Announce Type: new  Abstract: Explainable Artificial Intelligence (XAI) is essential for enhancing the transparency and accountability of AI models, especially in natural language processing (NLP) tasks. This paper introduces SCENE (Soft Counterfactual Evaluation for Natural language Explainability), a novel evaluation method that leverages large language models (LLMs) to generate Soft Counterfactual explanations in a zero-shot manner. By focusing on token-based substitutions, SCENE creates contextually appropriate and seman-tically meaningful Soft Counterfactuals without extensive fine-tuning. SCENE adopts Validitysoft and Csoft metrics to evaluate the effectiveness of model-agnostic XAI methods in text classification tasks. Applied to CNN, RNN, and BERT architectures, SCENE provides valuable insights into the strengths and limitations of various XAI techniques.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为FRONT的训练框架，旨在教导大型语言模型生成具有精细粒度支撑引用的引用，以提升生成内容的可靠性并促进精细验证。</title><link>https://arxiv.org/abs/2408.04568</link><description>&lt;p&gt;
Learning Fine-Grained Grounded Citations for Attributed Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04568
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为FRONT的训练框架，旨在教导大型语言模型生成具有精细粒度支撑引用的引用，以提升生成内容的可靠性并促进精细验证。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04568v1 Announce Type: cross  Abstract: Despite the impressive performance on information-seeking tasks, large language models (LLMs) still struggle with hallucinations. Attributed LLMs, which augment generated text with in-line citations, have shown potential in mitigating hallucinations and improving verifiability. However, current approaches suffer from suboptimal citation quality due to their reliance on in-context learning. Furthermore, the practice of citing only coarse document identifiers makes it challenging for users to perform fine-grained verification. In this work, we introduce FRONT, a training framework designed to teach LLMs to generate Fine-Grained Grounded Citations. By grounding model outputs in fine-grained supporting quotes, these quotes guide the generation of grounded and consistent responses, not only improving citation quality but also facilitating fine-grained verification. Experiments on the ALCE benchmark demonstrate the efficacy of FRONT in gener
&lt;/p&gt;</description></item><item><title>该文章提出了一种具有包级编码的同步多模态语义通信系统，该系统能够在物理层通道上传输不同模态的数据，并通过联合语义信道编码设计显示出良好的性能。文章特别关注了多模态语义的同步和包级前向错误纠正，并通过以面部视频和语音传输为例，展示了如何通过3D可变形模型（3DMM）系数和文本的传输实现语义和时间的同步，同时提出了一种语义编解码器，该编解码器在降低带宽的同时提供了与传统方法相当的质量重建和同步效果。文章还介绍了如何在这种系统中保护语义包，使其在面对误差的情况下也能保持数据的完整性。</title><link>https://arxiv.org/abs/2408.04535</link><description>&lt;p&gt;
Synchronous Multi-modal Semantic CommunicationSystem with Packet-level Coding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04535
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种具有包级编码的同步多模态语义通信系统，该系统能够在物理层通道上传输不同模态的数据，并通过联合语义信道编码设计显示出良好的性能。文章特别关注了多模态语义的同步和包级前向错误纠正，并通过以面部视频和语音传输为例，展示了如何通过3D可变形模型（3DMM）系数和文本的传输实现语义和时间的同步，同时提出了一种语义编解码器，该编解码器在降低带宽的同时提供了与传统方法相当的质量重建和同步效果。文章还介绍了如何在这种系统中保护语义包，使其在面对误差的情况下也能保持数据的完整性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04535v1 Announce Type: cross  Abstract: Although the semantic communication with joint semantic-channel coding design has shown promising performance in transmitting data of different modalities over physical layer channels, the synchronization and packet-level forward error correction of multimodal semantics have not been well studied. Due to the independent design of semantic encoders, synchronizing multimodal features in both the semantic and time domains is a challenging problem. In this paper, we take the facial video and speech transmission as an example and propose a Synchronous Multimodal Semantic Communication System (SyncSC) with Packet-Level Coding. To achieve semantic and time synchronization, 3D Morphable Mode (3DMM) coefficients and text are transmitted as semantics, and we propose a semantic codec that achieves similar quality of reconstruction and synchronization with lower bandwidth, compared to traditional methods. To protect semantic packets under the eras
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于答案集编程的框架，用于自动化处理和分析大学课程设置的不同方面，旨在帮助行政人员、教师和学生等多个角色更加高效地管理学术事务。</title><link>https://arxiv.org/abs/2408.04528</link><description>&lt;p&gt;
Reasoning about Study Regulations in Answer Set Programming
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04528
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于答案集编程的框架，用于自动化处理和分析大学课程设置的不同方面，旨在帮助行政人员、教师和学生等多个角色更加高效地管理学术事务。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04528v1 Announce Type: new  Abstract: We are interested in automating reasoning with and about study regulations, catering to various stakeholders, ranging from administrators, over faculty, to students at different stages. Our work builds on an extensive analysis of various study programs at the University of Potsdam. The conceptualization of the underlying principles provides us with a formal account of study regulations. In particular, the formalization reveals the properties of admissible study plans. With these at end, we propose an encoding of study regulations in Answer Set Programming that produces corresponding study plans. Finally, we show how this approach can be extended to a generic user interface for exploring study plans.
&lt;/p&gt;</description></item><item><title>该文章提出了一种新型的深度学习模型，用于在MRI图像中实现对肝脏硬化症的准确分割。该模型整合了连续和离散的 latent space，以捕捉图像的复杂特征交互，并在一个包含628个样本的私有数据集上取得了相较于 baseline 模型的显著提升。</title><link>https://arxiv.org/abs/2408.04491</link><description>&lt;p&gt;
Towards Synergistic Deep Learning Models for Volumetric Cirrhotic Liver Segmentation in MRIs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04491
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新型的深度学习模型，用于在MRI图像中实现对肝脏硬化症的准确分割。该模型整合了连续和离散的 latent space，以捕捉图像的复杂特征交互，并在一个包含628个样本的私有数据集上取得了相较于 baseline 模型的显著提升。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04491v1 Announce Type: new  Abstract: Liver cirrhosis, a leading cause of global mortality, requires precise segmentation of ROIs for effective disease monitoring and treatment planning. Existing segmentation models often fail to capture complex feature interactions and generalize across diverse datasets. To address these limitations, we propose a novel synergistic theory that leverages complementary latent spaces for enhanced feature interaction modeling. Our proposed architecture, nnSynergyNet3D integrates continuous and discrete latent spaces for 3D volumes and features auto-configured training. This approach captures both fine-grained and coarse features, enabling effective modeling of intricate feature interactions. We empirically validated nnSynergyNet3D on a private dataset of 628 high-resolution T1 abdominal MRI scans from 339 patients. Our model outperformed the baseline nnUNet3D by approximately 2%. Additionally, zero-shot testing on healthy liver CT scans from the
&lt;/p&gt;</description></item><item><title>该文章提出了一个统计框架，用于通过评估用户通道协方差矩阵之间的距离来对多输入多输出（MU-MIMO）无线通信系统中的用户进行集群划分。该框架以Riemann流形上正定矩阵中的距离为基础，并针对大规模数据集下的均衡样本数和观测大小条件，提出了一个可在宽频带条件下的准相移噪声环境中使用的log Euclidean距离估计器。通过中心极限定理，文章证明了两个样本协方差矩阵间的log Euclidean距离估计器在中心附近具有高斯分布，为无线通信系统中集群算法的实际性能提供了准确预测。</title><link>https://arxiv.org/abs/2408.04484</link><description>&lt;p&gt;
Statistical Framework for Clustering MU-MIMO Wireless via Second Order Statistics
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04484
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个统计框架，用于通过评估用户通道协方差矩阵之间的距离来对多输入多输出（MU-MIMO）无线通信系统中的用户进行集群划分。该框架以Riemann流形上正定矩阵中的距离为基础，并针对大规模数据集下的均衡样本数和观测大小条件，提出了一个可在宽频带条件下的准相移噪声环境中使用的log Euclidean距离估计器。通过中心极限定理，文章证明了两个样本协方差矩阵间的log Euclidean距离估计器在中心附近具有高斯分布，为无线通信系统中集群算法的实际性能提供了准确预测。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04484v1 Announce Type: cross  Abstract: This work explores the clustering of wireless users by examining the distances between their channel covariance matrices, which reside on the Riemannian manifold of positive definite matrices. Specifically, we consider an estimator of the Log-Euclidean distance between multiple sample covariance matrices (SCMs) consistent when the number of samples and the observation size grow unbounded at the same rate. Within the context of multi-user MIMO (MU-MIMO) wireless communication systems, we develop a statistical framework that allows to accurate predictions of the clustering algorithm's performance under realistic conditions. Specifically, we present a central limit theorem that establishes the asymptotic Gaussianity of the consistent estimator of the log-Euclidean distance computed over two sample covariance matrices.
&lt;/p&gt;</description></item><item><title>该文章提出了一个基于可解释主动学习的 semantic segmentation 模型 "SegXAL"，该模型能够有效利用未标记数据，促进人类参与的 "Human-in-the-loop" 模式，并使模型决策变得可解释，尤其适用于驾驶场景中的图像识别任务。</title><link>https://arxiv.org/abs/2408.04482</link><description>&lt;p&gt;
SegXAL: Explainable Active Learning for Semantic Segmentation in Driving Scene Scenarios
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04482
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个基于可解释主动学习的 semantic segmentation 模型 "SegXAL"，该模型能够有效利用未标记数据，促进人类参与的 "Human-in-the-loop" 模式，并使模型决策变得可解释，尤其适用于驾驶场景中的图像识别任务。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04482v1 Announce Type: cross  Abstract: Most of the sophisticated AI models utilize huge amounts of annotated data and heavy training to achieve high-end performance. However, there are certain challenges that hinder the deployment of AI models "in-the-wild" scenarios, i.e., inefficient use of unlabeled data, lack of incorporation of human expertise, and lack of interpretation of the results. To mitigate these challenges, we propose a novel Explainable Active Learning (XAL) model, XAL-based semantic segmentation model "SegXAL", that can (i) effectively utilize the unlabeled data, (ii) facilitate the "Human-in-the-loop" paradigm, and (iii) augment the model decisions in an interpretable way. In particular, we investigate the application of the SegXAL model for semantic segmentation in driving scene scenarios. The SegXAL model proposes the image regions that require labeling assistance from Oracle by dint of explainable AI (XAI) and uncertainty measures in a weakly-supervised 
&lt;/p&gt;</description></item><item><title>该文章提出了一种自动化框架RiskAwareBench，旨在评估基于大型语言模型的智能体在现实环境中执行任务时的物理风险意识。通过包含四个模块，即安全提示生成、危险场景生成、计划生成和评估，该框架能够对智能体进行全面的风险评估，并且需要很少的人工干预。同时，文章还创建了一个名为PhysicalRisk的数据集，包含了多样化的场景、相应的安全提示和操作指令，以促进对风险意识建模的研究。</title><link>https://arxiv.org/abs/2408.04449</link><description>&lt;p&gt;
RiskAwareBench: Towards Evaluating Physical Risk Awareness for High-level Planning of LLM-based Embodied Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04449
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种自动化框架RiskAwareBench，旨在评估基于大型语言模型的智能体在现实环境中执行任务时的物理风险意识。通过包含四个模块，即安全提示生成、危险场景生成、计划生成和评估，该框架能够对智能体进行全面的风险评估，并且需要很少的人工干预。同时，文章还创建了一个名为PhysicalRisk的数据集，包含了多样化的场景、相应的安全提示和操作指令，以促进对风险意识建模的研究。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04449v1 Announce Type: new  Abstract: The integration of large language models (LLMs) into robotics significantly enhances the capabilities of embodied agents in understanding and executing complex natural language instructions. However, the unmitigated deployment of LLM-based embodied systems in real-world environments may pose potential physical risks, such as property damage and personal injury. Existing security benchmarks for LLMs overlook risk awareness for LLM-based embodied agents. To address this gap, we propose RiskAwareBench, an automated framework designed to assess physical risks awareness in LLM-based embodied agents. RiskAwareBench consists of four modules: safety tips generation, risky scene generation, plan generation, and evaluation, enabling comprehensive risk assessment with minimal manual intervention. Utilizing this framework, we compile the PhysicalRisk dataset, encompassing diverse scenarios with associated safety tips, observations, and instructions.
&lt;/p&gt;</description></item><item><title>该文章提出FedAD-Bench，一个统一的基准测试，用于评估在联邦学习环境中的无监督异常检测算法。通过在真实世界数据集上的广泛实验，该基准测试对不同的深度学习异常检测模型在不同通信延迟和数据分布差异下的性能进行了全面评估，并为研究者提供了比较和改进现有方法的框架。</title><link>https://arxiv.org/abs/2408.04442</link><description>&lt;p&gt;
FedAD-Bench: A Unified Benchmark for Federated Unsupervised Anomaly Detection in Tabular Data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04442
&lt;/p&gt;
&lt;p&gt;
该文章提出FedAD-Bench，一个统一的基准测试，用于评估在联邦学习环境中的无监督异常检测算法。通过在真实世界数据集上的广泛实验，该基准测试对不同的深度学习异常检测模型在不同通信延迟和数据分布差异下的性能进行了全面评估，并为研究者提供了比较和改进现有方法的框架。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04442v1 Announce Type: cross  Abstract: The emergence of federated learning (FL) presents a promising approach to leverage decentralized data while preserving privacy. Furthermore, the combination of FL and anomaly detection is particularly compelling because it allows for detecting rare and critical anomalies (usually also rare in locally gathered data) in sensitive data from multiple sources, such as cybersecurity and healthcare. However, benchmarking the performance of anomaly detection methods in FL environments remains an underexplored area. This paper introduces FedAD-Bench, a unified benchmark for evaluating unsupervised anomaly detection algorithms within the context of FL. We systematically analyze and compare the performance of recent deep learning anomaly detection models under federated settings, which were typically assessed solely in centralized settings. FedAD-Bench encompasses diverse datasets and metrics to provide a holistic evaluation. Through extensive ex
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于案例的推理方法，通过在语言模型中集成机器阅读理解演示，显著提升了检索增强语言模型在面对错误检索结果时的鲁棒性，特别是对于难以回答的问题和检索到的信息冲突情况。</title><link>https://arxiv.org/abs/2408.04414</link><description>&lt;p&gt;
Enhancing Robustness of Retrieval-Augmented Language Models with In-Context Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04414
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于案例的推理方法，通过在语言模型中集成机器阅读理解演示，显著提升了检索增强语言模型在面对错误检索结果时的鲁棒性，特别是对于难以回答的问题和检索到的信息冲突情况。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04414v1 Announce Type: cross  Abstract: Retrieval-Augmented Language Models (RALMs) have significantly improved performance in open-domain question answering (QA) by leveraging external knowledge. However, RALMs still struggle with unanswerable queries, where the retrieved contexts do not contain the correct answer, and with conflicting information, where different sources provide contradictory answers due to imperfect retrieval. This study introduces an in-context learning-based approach to enhance the reasoning capabilities of RALMs, making them more robust in imperfect retrieval scenarios. Our method incorporates Machine Reading Comprehension (MRC) demonstrations, referred to as cases, to boost the model's capabilities to identify unanswerabilities and conflicts among the retrieved contexts. Experiments on two open-domain QA datasets show that our approach increases accuracy in identifying unanswerable and conflicting scenarios without requiring additional fine-tuning. Th
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于可复现核希尔伯特空间（RKHS）的非参数方法，用于进行概率式能源预测，并通过实验证明了该方法在能源需求预测中的可靠性和准确性，特别是在德国、奥地利和瑞士等DACH地区。该方法在负载和能源价格预测方面的表现优于当前最先进的技术。</title><link>https://arxiv.org/abs/2408.04405</link><description>&lt;p&gt;
Probabilistic energy forecasting through quantile regression in reproducing kernel Hilbert spaces
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04405
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于可复现核希尔伯特空间（RKHS）的非参数方法，用于进行概率式能源预测，并通过实验证明了该方法在能源需求预测中的可靠性和准确性，特别是在德国、奥地利和瑞士等DACH地区。该方法在负载和能源价格预测方面的表现优于当前最先进的技术。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04405v1 Announce Type: cross  Abstract: Accurate energy demand forecasting is crucial for sustainable and resilient energy development. To meet the Net Zero Representative Concentration Pathways (RCP) $4.5$ scenario in the DACH countries, increased renewable energy production, energy storage, and reduced commercial building consumption are needed. This scenario's success depends on hydroelectric capacity and climatic factors. Informed decisions require quantifying uncertainty in forecasts. This study explores a non-parametric method based on \emph{reproducing kernel Hilbert spaces (RKHS)}, known as kernel quantile regression, for energy prediction. Our experiments demonstrate its reliability and sharpness, and we benchmark it against state-of-the-art methods in load and price forecasting for the DACH region. We offer our implementation in conjunction with additional scripts to ensure the reproducibility of our research.
&lt;/p&gt;</description></item><item><title>该文章研究了大型语言模型在通过 Syllogism 进行推理时的偏差，通过 NeuBAROCO 数据集获得了对人类推理偏差的深入见解，并发现这些模型在某些推理问题中表现出与人类相似的错误倾向，同时表明需要更多改进空间。</title><link>https://arxiv.org/abs/2408.04403</link><description>&lt;p&gt;
Exploring Reasoning Biases in Large Language Models Through Syllogism: Insights from the NeuBAROCO Dataset
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04403
&lt;/p&gt;
&lt;p&gt;
该文章研究了大型语言模型在通过 Syllogism 进行推理时的偏差，通过 NeuBAROCO 数据集获得了对人类推理偏差的深入见解，并发现这些模型在某些推理问题中表现出与人类相似的错误倾向，同时表明需要更多改进空间。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04403v1 Announce Type: cross  Abstract: This paper explores the question of how accurately current large language models can perform logical reasoning in natural language, with an emphasis on whether these models exhibit reasoning biases similar to humans. Specifically, our study focuses on syllogistic reasoning, a form of deductive reasoning extensively studied in cognitive science as a natural form of human reasoning. We present a syllogism dataset called NeuBAROCO, which consists of syllogistic reasoning problems in English and Japanese. This dataset was originally designed for psychological experiments to assess human reasoning capabilities using various forms of syllogisms. Our experiments with leading large language models indicate that these models exhibit reasoning biases similar to humans, along with other error tendencies. Notably, there is significant room for improvement in reasoning problems where the relationship between premises and hypotheses is neither entai
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为DIVE的创新方法，通过识别并利用图数据中训练和测试分布之间的子图差异，显著提高了图机器学习模型的分布外泛化能力，解决了传统方法由于假设训练和测试数据分布一致而导致的性能滑坡问题。</title><link>https://arxiv.org/abs/2408.04400</link><description>&lt;p&gt;
DIVE: Subgraph Disagreement for Graph Out-of-Distribution Generalization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04400
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为DIVE的创新方法，通过识别并利用图数据中训练和测试分布之间的子图差异，显著提高了图机器学习模型的分布外泛化能力，解决了传统方法由于假设训练和测试数据分布一致而导致的性能滑坡问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04400v1 Announce Type: cross  Abstract: This paper addresses the challenge of out-of-distribution (OOD) generalization in graph machine learning, a field rapidly advancing yet grappling with the discrepancy between source and target data distributions. Traditional graph learning algorithms, based on the assumption of uniform distribution between training and test data, falter in real-world scenarios where this assumption fails, resulting in suboptimal performance. A principal factor contributing to this suboptimal performance is the inherent simplicity bias of neural networks trained through Stochastic Gradient Descent (SGD), which prefer simpler features over more complex yet equally or more predictive ones. This bias leads to a reliance on spurious correlations, adversely affecting OOD performance in various tasks such as image recognition, natural language understanding, and graph classification. Current methodologies, including subgraph-mixup and information bottleneck a
&lt;/p&gt;</description></item><item><title>该文章介绍了一种使用大型语言模型（LLMs）自动生成不同认知水平教育问题的策略和方法，并通过专家评审和模型评估来评估生成问题的质量。</title><link>https://arxiv.org/abs/2408.04394</link><description>&lt;p&gt;
Automated Educational Question Generation at Different Bloom's Skill Levels using Large Language Models: Strategies and Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04394
&lt;/p&gt;
&lt;p&gt;
该文章介绍了一种使用大型语言模型（LLMs）自动生成不同认知水平教育问题的策略和方法，并通过专家评审和模型评估来评估生成问题的质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04394v1 Announce Type: cross  Abstract: Developing questions that are pedagogically sound, relevant, and promote learning is a challenging and time-consuming task for educators. Modern-day large language models (LLMs) generate high-quality content across multiple domains, potentially helping educators to develop high-quality questions. Automated educational question generation (AEQG) is important in scaling online education catering to a diverse student population. Past attempts at AEQG have shown limited abilities to generate questions at higher cognitive levels. In this study, we examine the ability of five state-of-the-art LLMs of different sizes to generate diverse and high-quality questions of different cognitive levels, as defined by Bloom's taxonomy. We use advanced prompting techniques with varying complexity for AEQG. We conducted expert and LLM-based evaluations to assess the linguistic and pedagogical relevance and quality of the questions. Our findings suggest th
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为MM-Forecast的框架，该框架采用图像识别模块来识别图像在时空事件预测中的作用，并将其整合到大型语言模型中，以提高预测精度。</title><link>https://arxiv.org/abs/2408.04388</link><description>&lt;p&gt;
MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04388
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为MM-Forecast的框架，该框架采用图像识别模块来识别图像在时空事件预测中的作用，并将其整合到大型语言模型中，以提高预测精度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04388v1 Announce Type: cross  Abstract: We study an emerging and intriguing problem of multimodal temporal event forecasting with large language models. Compared to using text or graph modalities, the investigation of utilizing images for temporal event forecasting has not been fully explored, especially in the era of large language models (LLMs). To bridge this gap, we are particularly interested in two key questions of: 1) why images will help in temporal event forecasting, and 2) how to integrate images into the LLM-based forecasting framework. To answer these research questions, we propose to identify two essential functions that images play in the scenario of temporal event forecasting, i.e., highlighting and complementary. Then, we develop a novel framework, named MM-Forecast. It employs an Image Function Identification module to recognize these functions as verbal descriptions using multimodal large language models (MLLMs), and subsequently incorporates these function
&lt;/p&gt;</description></item><item><title>该文章提出了一种在期望中满足多准则期望的非最大化策略，即使在多个不同评估指标的情况下，这些指标不一定代表用户想最大化的事物，该策略也能够确保预期总和在给定的范围内。</title><link>https://arxiv.org/abs/2408.04385</link><description>&lt;p&gt;
Non-maximizing policies that fulfill multi-criterion aspirations in expectation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04385
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种在期望中满足多准则期望的非最大化策略，即使在多个不同评估指标的情况下，这些指标不一定代表用户想最大化的事物，该策略也能够确保预期总和在给定的范围内。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04385v1 Announce Type: new  Abstract: In dynamic programming and reinforcement learning, the policy for the sequential decision making of an agent in a stochastic environment is usually determined by expressing the goal as a scalar reward function and seeking a policy that maximizes the expected total reward. However, many goals that humans care about naturally concern multiple aspects of the world, and it may not be obvious how to condense those into a single reward function. Furthermore, maximization suffers from specification gaming, where the obtained policy achieves a high expected total reward in an unintended way, often taking extreme or nonsensical actions.   Here we consider finite acyclic Markov Decision Processes with multiple distinct evaluation metrics, which do not necessarily represent quantities that the user wants to be maximized. We assume the task of the agent is to ensure that the vector of expected totals of the evaluation metrics falls into some given c
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为"Judgment2vec"的解决方案，旨在通过图分析技术来搜索和推荐类似的判决。研究者利用专家标注的黄金标准司法判例数据库，构建了一个基于"案件-法条"关系的知识图谱，并利用自然语言处理技术排名每一起案件。通过比较专家相似度和Node2vec相似度，该研究探索了两者之间的差异和关系，旨在显著减少法律专业人士在海量判例中查找相似案例的时间和成本。</title><link>https://arxiv.org/abs/2408.04382</link><description>&lt;p&gt;
Judgment2vec: Apply Graph Analytics to Searching and Recommendation of Similar Judgments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04382
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为"Judgment2vec"的解决方案，旨在通过图分析技术来搜索和推荐类似的判决。研究者利用专家标注的黄金标准司法判例数据库，构建了一个基于"案件-法条"关系的知识图谱，并利用自然语言处理技术排名每一起案件。通过比较专家相似度和Node2vec相似度，该研究探索了两者之间的差异和关系，旨在显著减少法律专业人士在海量判例中查找相似案例的时间和成本。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04382v1 Announce Type: cross  Abstract: In court practice, legal professionals rely on their training to provide opinions that resolve cases, one of the most crucial aspects being the ability to identify similar judgments from previous courts efficiently. However, finding a similar case is challenging and often depends on experience, legal domain knowledge, and extensive labor hours, making veteran lawyers or judges indispensable. This research aims to automate the analysis of judgment text similarity. We utilized a judgment dataset labeled as the "golden standard" by experts, which includes human-verified features that can be converted into an "expert similarity score." We then constructed a knowledge graph based on "case-article" relationships, ranking each case using natural language processing to derive a "Node2vec similarity score." By evaluating these two similarity scores, we identified their discrepancies and relationships. The results can significantly reduce the la
&lt;/p&gt;</description></item><item><title>该文章提出了一种针对时间序列异常预测的全新方法，该方法能够在预测结果中直接融入延迟时间和异常持续期的信息，从而提高了异常预测的及时性和准确性，并为未来的研究设定了新的标准。</title><link>https://arxiv.org/abs/2408.04377</link><description>&lt;p&gt;
Anomaly Prediction: A Novel Approach with Explicit Delay and Horizon
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04377
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种针对时间序列异常预测的全新方法，该方法能够在预测结果中直接融入延迟时间和异常持续期的信息，从而提高了异常预测的及时性和准确性，并为未来的研究设定了新的标准。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04377v1 Announce Type: cross  Abstract: Detecting anomalies in time series data is a critical challenge across various domains. Traditional methods typically focus on identifying anomalies in immediate subsequent steps, often underestimating the significance of temporal dynamics such as delay time and horizons of anomalies, which generally require extensive post-analysis. This paper introduces a novel approach for time series anomaly prediction, incorporating temporal information directly into the prediction results. We propose a new dataset specifically designed to evaluate this approach and conduct comprehensive experiments using several state-of-the-art methods. results demonstrate the efficacy of our approach in providing timely and accurate anomaly predictions, setting a new benchmark for future research in this field.
&lt;/p&gt;</description></item><item><title>该文章通过允许qubit的重新排序和考虑布局限制，对基于CNOT的量子电路进行了优化合成，编码为不同的规划问题，并提供了对于CNOT门数量和电路深度的显著优化，特别是对于映射到具体物理架构的电路，进一步减少了CNOT门数量和深度的最高比例分别达到17%和19%。</title><link>https://arxiv.org/abs/2408.04349</link><description>&lt;p&gt;
Optimal Layout-Aware CNOT Circuit Synthesis with Qubit Permutation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04349
&lt;/p&gt;
&lt;p&gt;
该文章通过允许qubit的重新排序和考虑布局限制，对基于CNOT的量子电路进行了优化合成，编码为不同的规划问题，并提供了对于CNOT门数量和电路深度的显著优化，特别是对于映射到具体物理架构的电路，进一步减少了CNOT门数量和深度的最高比例分别达到17%和19%。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04349v1 Announce Type: cross  Abstract: CNOT optimization plays a significant role in noise reduction for Quantum Circuits. Several heuristic and exact approaches exist for CNOT optimization. In this paper, we investigate more complicated variations of optimal synthesis by allowing qubit permutations and handling layout restrictions. We encode such problems into Planning, SAT, and QBF. We provide optimization for both CNOT gate count and circuit depth. For experimental evaluation, we consider standard T-gate optimized benchmarks and optimize CNOT sub-circuits. We show that allowing qubit permutations can further reduce up to 56% in CNOT count and 46% in circuit depth. In the case of optimally mapped circuits under layout restrictions, we observe a reduction up to 17% CNOT count and 19% CNOT depth.
&lt;/p&gt;</description></item><item><title>该文章提出并验证了使用大型语言模型（LLMs），如GPT-4和LLaMA 3，作为网络入侵检测系统（NIDS）的可行性，尤其是在提高检测结果的可解释性方面。通过对比传统架构和基于Transformer的模型，研究发现LLMs能够在无需依赖人工偏斜的基准测试数据集的情况下，仅依靠其大规模预训练的知识，有效地检测网络流中的恶意行为，展现了其在网络安全领域的潜在应用价值。</title><link>https://arxiv.org/abs/2408.04342</link><description>&lt;p&gt;
Towards Explainable Network Intrusion Detection using Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04342
&lt;/p&gt;
&lt;p&gt;
该文章提出并验证了使用大型语言模型（LLMs），如GPT-4和LLaMA 3，作为网络入侵检测系统（NIDS）的可行性，尤其是在提高检测结果的可解释性方面。通过对比传统架构和基于Transformer的模型，研究发现LLMs能够在无需依赖人工偏斜的基准测试数据集的情况下，仅依靠其大规模预训练的知识，有效地检测网络流中的恶意行为，展现了其在网络安全领域的潜在应用价值。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04342v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have revolutionised natural language processing tasks, particularly as chat agents. However, their applicability to threat detection problems remains unclear. This paper examines the feasibility of employing LLMs as a Network Intrusion Detection System (NIDS), despite their high computational requirements, primarily for the sake of explainability. Furthermore, considerable resources have been invested in developing LLMs, and they may offer utility for NIDS. Current state-of-the-art NIDS rely on artificial benchmarking datasets, resulting in skewed performance when applied to real-world networking environments. Therefore, we compare the GPT-4 and LLama3 models against traditional architectures and transformer-based models to assess their ability to detect malicious NetFlows without depending on artificially skewed datasets, but solely on their vast pre-trained acquired knowledge. Our results reveal that, alt
&lt;/p&gt;</description></item><item><title>该文章提出KnowPC（知识驱动的程序化强化学习）框架，它能够通过向程序注入领域知识来解决零样本合作问题，使得学习到的策略既可以形成明确的逻辑表示，又可以在新的环境和合作者面前表现出良好的泛化能力。</title><link>https://arxiv.org/abs/2408.04336</link><description>&lt;p&gt;
KnowPC: Knowledge-Driven Programmatic Reinforcement Learning for Zero-shot Coordination
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04336
&lt;/p&gt;
&lt;p&gt;
该文章提出KnowPC（知识驱动的程序化强化学习）框架，它能够通过向程序注入领域知识来解决零样本合作问题，使得学习到的策略既可以形成明确的逻辑表示，又可以在新的环境和合作者面前表现出良好的泛化能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04336v1 Announce Type: new  Abstract: Zero-shot coordination (ZSC) remains a major challenge in the cooperative AI field, which aims to learn an agent to cooperate with an unseen partner in training environments or even novel environments. In recent years, a popular ZSC solution paradigm has been deep reinforcement learning (DRL) combined with advanced self-play or population-based methods to enhance the neural policy's ability to handle unseen partners. Despite some success, these approaches usually rely on black-box neural networks as the policy function. However, neural networks typically lack interpretability and logic, making the learned policies difficult for partners (e.g., humans) to understand and limiting their generalization ability. These shortcomings hinder the application of reinforcement learning methods in diverse cooperative scenarios.We suggest to represent the agent's policy with an interpretable program. Unlike neural networks, programs contain stable log
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一个基于活动理论的模型，用于分析数字代理在与学习者互动中的学习活动特点，并指出了数字代理的教育应用对学习成果的影响。</title><link>https://arxiv.org/abs/2408.04304</link><description>&lt;p&gt;
Learning with Digital Agents: An Analysis based on the Activity Theory
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04304
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一个基于活动理论的模型，用于分析数字代理在与学习者互动中的学习活动特点，并指出了数字代理的教育应用对学习成果的影响。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04304v1 Announce Type: cross  Abstract: Digital agents are considered a general-purpose technology. They spread quickly in private and organizational contexts, including education. Yet, research lacks a conceptual framing to describe interaction with such agents in a holistic manner. While focusing on the interaction with a pedagogical agent, i.e., a digital agent capable of natural-language interaction with a learner, we propose a model of learning activity based on activity theory. We use this model and a review of prior research on digital agents in education to analyze how various characteristics of the activity, including features of a pedagogical agent or learner, influence learning outcomes. The analysis leads to identification of IS research directions and guidance for developers of pedagogical agents and digital agents in general. We conclude by extending the activity theory-based model beyond the context of education and show how it helps designers and researchers 
&lt;/p&gt;</description></item><item><title>该文章提出了一种针对联邦学习中的噪音客户端问题，通过端到端标签校正的两阶段框架FedELC，旨在识别噪音更高的客户端并对其数据进行标签校正，以缓解噪音客户端对模型性能的负面影响。</title><link>https://arxiv.org/abs/2408.04301</link><description>&lt;p&gt;
Tackling Noisy Clients in Federated Learning with End-to-end Label Correction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04301
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种针对联邦学习中的噪音客户端问题，通过端到端标签校正的两阶段框架FedELC，旨在识别噪音更高的客户端并对其数据进行标签校正，以缓解噪音客户端对模型性能的负面影响。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04301v1 Announce Type: cross  Abstract: Recently, federated learning (FL) has achieved wide successes for diverse privacy-sensitive applications without sacrificing the sensitive private information of clients. However, the data quality of client datasets can not be guaranteed since corresponding annotations of different clients often contain complex label noise of varying degrees, which inevitably causes the performance degradation. Intuitively, the performance degradation is dominated by clients with higher noise rates since their trained models contain more misinformation from data, thus it is necessary to devise an effective optimization scheme to mitigate the negative impacts of these noisy clients. In this work, we propose a two-stage framework FedELC to tackle this complicated label noise issue. The first stage aims to guide the detection of noisy clients with higher label noise, while the second stage aims to correct the labels of noisy clients' data via an end-to-en
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为PRD-MAPPO的算法，它通过利用部分奖励解耦机制和注意力机制，有效解决了多 agent 强化学习中的信用分配问题，从而提高了MAPPO算法的性能。</title><link>https://arxiv.org/abs/2408.04295</link><description>&lt;p&gt;
Assigning Credit with Partial Reward Decoupling in Multi-Agent Proximal Policy Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04295
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为PRD-MAPPO的算法，它通过利用部分奖励解耦机制和注意力机制，有效解决了多 agent 强化学习中的信用分配问题，从而提高了MAPPO算法的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04295v1 Announce Type: cross  Abstract: Multi-agent proximal policy optimization (MAPPO) has recently demonstrated state-of-the-art performance on challenging multi-agent reinforcement learning tasks. However, MAPPO still struggles with the credit assignment problem, wherein the sheer difficulty in ascribing credit to individual agents' actions scales poorly with team size. In this paper, we propose a multi-agent reinforcement learning algorithm that adapts recent developments in credit assignment to improve upon MAPPO. Our approach leverages partial reward decoupling (PRD), which uses a learned attention mechanism to estimate which of a particular agent's teammates are relevant to its learning updates. We use this estimate to dynamically decompose large groups of agents into smaller, more manageable subgroups. We empirically demonstrate that our approach, PRD-MAPPO, decouples agents from teammates that do not influence their expected future reward, thereby streamlining cred
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一种由AI驱动的聊天机器人，其能够在边缘网络中自动检测和控制入侵行为，并通过确保用户知情同意来提升网络安全的透明度和信任度。</title><link>https://arxiv.org/abs/2408.04281</link><description>&lt;p&gt;
AI-Driven Chatbot for Intrusion Detection in Edge Networks: Enhancing Cybersecurity with Ethical User Consent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04281
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一种由AI驱动的聊天机器人，其能够在边缘网络中自动检测和控制入侵行为，并通过确保用户知情同意来提升网络安全的透明度和信任度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04281v1 Announce Type: cross  Abstract: In today's contemporary digital landscape, chatbots have become indispensable tools across various sectors, streamlining customer service, providing personal assistance, automating routine tasks, and offering health advice. However, their potential remains underexplored in the realm of network security, particularly for intrusion detection. To bridge this gap, we propose an architecture chatbot specifically designed to enhance security within edge networks specifically for intrusion detection. Leveraging advanced machine learning algorithms, this chatbot will monitor network traffic to identify and mitigate potential intrusions. By securing the network environment using an edge network managed by a Raspberry Pi module and ensuring ethical user consent promoting transparency and trust, this innovative solution aims to safeguard sensitive data and maintain a secure workplace, thereby addressing the growing need for robust network securit
&lt;/p&gt;</description></item><item><title>该文章提出了一种针对对抗式视觉信息隐藏(AVIH)的攻击，揭示了隐藏在加密图像中的隐藏信息，并讨论了AVIH方法中使用的独特密钥模型在实际应用中的安全和效率问题。</title><link>https://arxiv.org/abs/2408.04261</link><description>&lt;p&gt;
Unveiling Hidden Visual Information: A Reconstruction Attack Against Adversarial Visual Information Hiding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04261
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种针对对抗式视觉信息隐藏(AVIH)的攻击，揭示了隐藏在加密图像中的隐藏信息，并讨论了AVIH方法中使用的独特密钥模型在实际应用中的安全和效率问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04261v1 Announce Type: new  Abstract: This paper investigates the security vulnerabilities of adversarial-example-based image encryption by executing data reconstruction (DR) attacks on encrypted images. A representative image encryption method is the adversarial visual information hiding (AVIH), which uses type-I adversarial example training to protect gallery datasets used in image recognition tasks. In the AVIH method, the type-I adversarial example approach creates images that appear completely different but are still recognized by machines as the original ones. Additionally, the AVIH method can restore encrypted images to their original forms using a predefined private key generative model. For the best security, assigning a unique key to each image is recommended; however, storage limitations may necessitate some images sharing the same key model. This raises a crucial security question for AVIH: How many images can safely share the same key model without being comprom
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于EfficientRAG的更高效的检索机制，能够在不调用大型语言模型的情况下，通过迭代生成新问题和筛选信息，解决了多跳问题回答中的信息整合难题，并且在多跳问答数据集上取得了显著的性能提升。</title><link>https://arxiv.org/abs/2408.04259</link><description>&lt;p&gt;
EfficientRAG: Efficient Retriever for Multi-Hop Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04259
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于EfficientRAG的更高效的检索机制，能够在不调用大型语言模型的情况下，通过迭代生成新问题和筛选信息，解决了多跳问题回答中的信息整合难题，并且在多跳问答数据集上取得了显著的性能提升。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04259v1 Announce Type: cross  Abstract: Retrieval-augmented generation (RAG) methods encounter difficulties when addressing complex questions like multi-hop queries. While iterative retrieval methods improve performance by gathering additional information, current approaches often rely on multiple calls of large language models (LLMs). In this paper, we introduce EfficientRAG, an efficient retriever for multi-hop question answering. EfficientRAG iteratively generates new queries without the need for LLM calls at each iteration and filters out irrelevant information. Experimental results demonstrate that EfficientRAG surpasses existing RAG methods on three open-domain multi-hop question-answering datasets.
&lt;/p&gt;</description></item><item><title>该文章针对现有channel-dependent模型在处理高维多变量时间序列数据时的性能不足，提出了一种可扩展的Transformer模型，以解决由无关系列引入的噪声和训练挑战问题。</title><link>https://arxiv.org/abs/2408.04245</link><description>&lt;p&gt;
Scalable Transformer for High Dimensional Multivariate Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04245
&lt;/p&gt;
&lt;p&gt;
该文章针对现有channel-dependent模型在处理高维多变量时间序列数据时的性能不足，提出了一种可扩展的Transformer模型，以解决由无关系列引入的噪声和训练挑战问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04245v1 Announce Type: cross  Abstract: Deep models for Multivariate Time Series (MTS) forecasting have recently demonstrated significant success. Channel-dependent models capture complex dependencies that channel-independent models cannot capture. However, the number of channels in real-world applications outpaces the capabilities of existing channel-dependent models, and contrary to common expectations, some models underperform the channel-independent models in handling high-dimensional data, which raises questions about the performance of channel-dependent models. To address this, our study first investigates the reasons behind the suboptimal performance of these channel-dependent models on high-dimensional MTS data. Our analysis reveals that two primary issues lie in the introduced noise from unrelated series that increases the difficulty of capturing the crucial inter-channel dependencies, and challenges in training strategies due to high-dimensional data. To address th
&lt;/p&gt;</description></item><item><title>该文章专注于“未接地对齐问题”（The Ungrounded Alignment Problem），旨在探索如何在一个学习系统中预先嵌入知识，即使我们不知道特定的输入如何被“接地”到具体的表现形式。研究通过一个简化案例进行，其中无监督学习器基于文本语料库中字符的图像序列进行训练，并在随后对其识别罕见模式的能力进行评估，而学习器在整个训练过程中完全没有获得任何相关的标签信息。</title><link>https://arxiv.org/abs/2408.04242</link><description>&lt;p&gt;
The Ungrounded Alignment Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04242
&lt;/p&gt;
&lt;p&gt;
该文章专注于“未接地对齐问题”（The Ungrounded Alignment Problem），旨在探索如何在一个学习系统中预先嵌入知识，即使我们不知道特定的输入如何被“接地”到具体的表现形式。研究通过一个简化案例进行，其中无监督学习器基于文本语料库中字符的图像序列进行训练，并在随后对其识别罕见模式的能力进行评估，而学习器在整个训练过程中完全没有获得任何相关的标签信息。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04242v1 Announce Type: cross  Abstract: Modern machine learning systems have demonstrated substantial abilities with methods that either embrace or ignore human-provided knowledge, but combining benefits of both styles remains a challenge. One particular challenge involves designing learning systems that exhibit built-in responses to specific abstract stimulus patterns, yet are still plastic enough to be agnostic about the modality and exact form of their inputs. In this paper, we investigate what we call The Ungrounded Alignment Problem, which asks How can we build in predefined knowledge in a system where we don't know how a given stimulus will be grounded? This paper examines a simplified version of the general problem, where an unsupervised learner is presented with a sequence of images for the characters in a text corpus, and this learner is later evaluated on its ability to recognize specific (possibly rare) sequential patterns. Importantly, the learner is given no lab
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一种全新的方法来检测云系统中的集群级任务延迟，这种方法通过对集群中任务执行时间的分布进行分析，绕开了传统单一任务检测方法因任务数量巨大而导致的高计算复杂性问题。通过这种方法，即使在大规模云计算集群中，也能有效且高效地发现可能导致用户体验下降的集群级任务延迟问题。</title><link>https://arxiv.org/abs/2408.04236</link><description>&lt;p&gt;
Cluster-Wide Task Slowdown Detection in Cloud System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04236
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一种全新的方法来检测云系统中的集群级任务延迟，这种方法通过对集群中任务执行时间的分布进行分析，绕开了传统单一任务检测方法因任务数量巨大而导致的高计算复杂性问题。通过这种方法，即使在大规模云计算集群中，也能有效且高效地发现可能导致用户体验下降的集群级任务延迟问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04236v1 Announce Type: cross  Abstract: Slow task detection is a critical problem in cloud operation and maintenance since it is highly related to user experience and can bring substantial liquidated damages. Most anomaly detection methods detect it from a single-task aspect. However, considering millions of concurrent tasks in large-scale cloud computing clusters, it becomes impractical and inefficient. Moreover, single-task slowdowns are very common and do not necessarily indicate a malfunction of a cluster due to its violent fluctuation nature in a virtual environment. Thus, we shift our attention to cluster-wide task slowdowns by utilizing the duration time distribution of tasks across a cluster, so that the computation complexity is not relevant to the number of tasks.   The task duration time distribution often exhibits compound periodicity and local exceptional fluctuations over time. Though transformer-based methods are one of the most powerful methods to capture the
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用概率电路（PC）来高效地表示和处理分布的累积分布函数（CDF），从而扩展了原有的概率电路模型，使其适用于更广泛的概率分布类型，包括离散和连续随机变量，并通过高效地对输入数据进行处理和分析，为机器学习和统计学领域提供了新的计算工具，促进了在这些领域的应用和研究。</title><link>https://arxiv.org/abs/2408.04229</link><description>&lt;p&gt;
Probabilistic Circuits for Cumulative Distribution Functions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04229
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用概率电路（PC）来高效地表示和处理分布的累积分布函数（CDF），从而扩展了原有的概率电路模型，使其适用于更广泛的概率分布类型，包括离散和连续随机变量，并通过高效地对输入数据进行处理和分析，为机器学习和统计学领域提供了新的计算工具，促进了在这些领域的应用和研究。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04229v1 Announce Type: cross  Abstract: A probabilistic circuit (PC) succinctly expresses a function that represents a multivariate probability distribution and, given sufficient structural properties of the circuit, supports efficient probabilistic inference. Typically a PC computes the probability mass (or density) function (PMF or PDF) of the distribution. We consider PCs instead computing the cumulative distribution function (CDF). We show that for distributions over binary random variables these representations (PMF and CDF) are essentially equivalent, in the sense that one can be transformed to the other in polynomial time. We then show how a similar equivalence holds for distributions over finite discrete variables using a modification of the standard encoding with binary variables that aligns with the CDF semantics. Finally we show that for continuous variables, smooth, decomposable PCs computing PDFs and CDFs can be efficiently transformed to each other by modifying
&lt;/p&gt;</description></item><item><title>该文章通过实证研究，探究了大型语言模型（LLMs）在视频处理中的表现，尤其是视频问答（VideoQA）任务。研究揭示了这些模型在处理视频内容和回答问题方面的优势，但也指出了其在处理视频中的时间性方面存在的不足。此外，文章还发现，即使在面对简单的干扰和问题的细微变化时，这些模型也未能表现出更为自然的行为。总的来说，这项研究为video-llms在视频理解和问答方面的表现提供了深入的见解，并为改进这些模型以更接近人类水平的能力提供了指导。</title><link>https://arxiv.org/abs/2408.04223</link><description>&lt;p&gt;
VideoQA in the Era of LLMs: An Empirical Study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04223
&lt;/p&gt;
&lt;p&gt;
该文章通过实证研究，探究了大型语言模型（LLMs）在视频处理中的表现，尤其是视频问答（VideoQA）任务。研究揭示了这些模型在处理视频内容和回答问题方面的优势，但也指出了其在处理视频中的时间性方面存在的不足。此外，文章还发现，即使在面对简单的干扰和问题的细微变化时，这些模型也未能表现出更为自然的行为。总的来说，这项研究为video-llms在视频理解和问答方面的表现提供了深入的见解，并为改进这些模型以更接近人类水平的能力提供了指导。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04223v1 Announce Type: new  Abstract: Video Large Language Models (Video-LLMs) are flourishing and has advanced many video-language tasks. As a golden testbed, Video Question Answering (VideoQA) plays pivotal role in Video-LLM developing. This work conducts a timely and comprehensive study of Video-LLMs' behavior in VideoQA, aiming to elucidate their success and failure modes, and provide insights towards more human-like video understanding and question answering. Our analyses demonstrate that Video-LLMs excel in VideoQA; they can correlate contextual cues and generate plausible responses to questions about varied video contents. However, models falter in handling video temporality, both in reasoning about temporal content ordering and grounding QA-relevant temporal moments. Moreover, the models behave unintuitively - they are unresponsive to adversarial video perturbations while being sensitive to simple variations of candidate answers and questions. Also, they do not neces
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一个综合性的视角，分析了信号-噪声扩散模型（S2N），并通过信息论的理论连接了对噪声调度器的研究。作者开发了一个通用的逆向扩散方程，从而改进了当前扩散模型的扩散机制和推理过程。</title><link>https://arxiv.org/abs/2408.04221</link><description>&lt;p&gt;
Connective Viewpoints of Signal-to-Noise Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04221
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一个综合性的视角，分析了信号-噪声扩散模型（S2N），并通过信息论的理论连接了对噪声调度器的研究。作者开发了一个通用的逆向扩散方程，从而改进了当前扩散模型的扩散机制和推理过程。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04221v1 Announce Type: new  Abstract: Diffusion models (DM) have become fundamental components of generative models, excelling across various domains such as image creation, audio generation, and complex data interpolation. Signal-to-Noise diffusion models constitute a diverse family covering most state-of-the-art diffusion models. While there have been several attempts to study Signal-to-Noise (S2N) diffusion models from various perspectives, there remains a need for a comprehensive study connecting different viewpoints and exploring new perspectives. In this study, we offer a comprehensive perspective on noise schedulers, examining their role through the lens of the signal-to-noise ratio (SNR) and its connections to information theory. Building upon this framework, we have developed a generalized backward equation to enhance the performance of the inference process.
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于Transformer架构的文本挖掘机器翻译模型，通过结合K-Means聚类算法提高了模型的上下文理解能力。这种方法有助于改善模型对文本中局部结构和上下文信息的识别和保真度，从而提升翻译质量。</title><link>https://arxiv.org/abs/2408.04216</link><description>&lt;p&gt;
Attention Mechanism and Context Modeling System for Text Mining Machine Translation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04216
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于Transformer架构的文本挖掘机器翻译模型，通过结合K-Means聚类算法提高了模型的上下文理解能力。这种方法有助于改善模型对文本中局部结构和上下文信息的识别和保真度，从而提升翻译质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04216v1 Announce Type: cross  Abstract: This paper advances a novel architectural schema anchored upon the Transformer paradigm and innovatively amalgamates the K-means categorization algorithm to augment the contextual apprehension capabilities of the schema. The transformer model performs well in machine translation tasks due to its parallel computing power and multi-head attention mechanism. However, it may encounter contextual ambiguity or ignore local features when dealing with highly complex language structures. To circumvent this constraint, this exposition incorporates the K-Means algorithm, which is used to stratify the lexis and idioms of the input textual matter, thereby facilitating superior identification and preservation of the local structure and contextual intelligence of the language. The advantage of this combination is that K-Means can automatically discover the topic or concept regions in the text, which may be directly related to translation quality. Con
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为 Multimodal Role-Playing Agents (MRPAs) 的概念，并构建了一个名为 MMRole 的全面框架，用于开发和评估可以模拟人类多种感官能力的角色扮演代理。这一框架包括了一个个性化的多模态数据集和一个强健的评估方法，旨在填补现有研究对文字单模态的限制，迈向更真实的人机交互体验。</title><link>https://arxiv.org/abs/2408.04203</link><description>&lt;p&gt;
MMRole: A Comprehensive Framework for Developing and Evaluating Multimodal Role-Playing Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04203
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为 Multimodal Role-Playing Agents (MRPAs) 的概念，并构建了一个名为 MMRole 的全面框架，用于开发和评估可以模拟人类多种感官能力的角色扮演代理。这一框架包括了一个个性化的多模态数据集和一个强健的评估方法，旨在填补现有研究对文字单模态的限制，迈向更真实的人机交互体验。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04203v1 Announce Type: new  Abstract: Recently, Role-Playing Agents (RPAs) have garnered increasing attention for their potential to deliver emotional value and facilitate sociological research. However, existing studies are primarily confined to the textual modality, unable to simulate humans' multimodal perceptual capabilities. To bridge this gap, we introduce the concept of Multimodal Role-Playing Agents (MRPAs), and propose a comprehensive framework, MMRole, for their development and evaluation, which comprises a personalized multimodal dataset and a robust evaluation method. Specifically, we construct a large-scale, high-quality dataset, MMRole-Data, consisting of 85 characters, 11K images, and 14K single or multi-turn dialogues. Additionally, we present a robust evaluation method, MMRole-Eval, encompassing eight metrics across three dimensions, where a reward model is trained to score MRPAs with the constructed ground-truth data for comparison. Moreover, we develop the
&lt;/p&gt;</description></item><item><title>该文章详细探讨了为了训练用于Web搜索的SEM（Semantic Embedding Model）而在其监督训练中生成有效双重判决的方法。通过大规模基于查询日志和点击活动的数据集，作者揭示了一个有趣且可能令人惊讶的结果，即在排序学习（LTR）领域广泛采用的双重判决形成策略并不适用于训练SEM。</title><link>https://arxiv.org/abs/2408.04197</link><description>&lt;p&gt;
Pairwise Judgment Formulation for Semantic Embedding Model in Web Search
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04197
&lt;/p&gt;
&lt;p&gt;
该文章详细探讨了为了训练用于Web搜索的SEM（Semantic Embedding Model）而在其监督训练中生成有效双重判决的方法。通过大规模基于查询日志和点击活动的数据集，作者揭示了一个有趣且可能令人惊讶的结果，即在排序学习（LTR）领域广泛采用的双重判决形成策略并不适用于训练SEM。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04197v1 Announce Type: cross  Abstract: Semantic Embedding Model (SEM), a neural network-based Siamese architecture, is gaining momentum in information retrieval and natural language processing. In order to train SEM in a supervised fashion for Web search, the search engine query log is typically utilized to automatically formulate pairwise judgments as training data. Despite the growing application of semantic embeddings in the search engine industry, little work has been done on formulating effective pairwise judgments for training SEM. In this paper, we make the first in-depth investigation of a wide range of strategies for generating pairwise judgments for SEM. An interesting (perhaps surprising) discovery reveals that the conventional pairwise judgment formulation strategy wildly used in the field of pairwise Learning-to-Rank (LTR) is not necessarily effective for training SEM. Through a large-scale empirical study based on query logs and click-through activities from a
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Spatial Temporal Multivariate Graph Neural Networks的随机稀疏负二项分布（STMGNN-ZINB）模型，利用扩散和卷积网络分析时空和多元相关性，并有效管理犯罪事件的稀疏性。</title><link>https://arxiv.org/abs/2408.04193</link><description>&lt;p&gt;
Uncertainty-Aware Crime Prediction With Spatial Temporal Multivariate Graph Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04193
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Spatial Temporal Multivariate Graph Neural Networks的随机稀疏负二项分布（STMGNN-ZINB）模型，利用扩散和卷积网络分析时空和多元相关性，并有效管理犯罪事件的稀疏性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04193v1 Announce Type: cross  Abstract: Crime forecasting is a critical component of urban analysis and essential for stabilizing society today. Unlike other time series forecasting problems, crime incidents are sparse, particularly in small regions and within specific time periods. Traditional spatial-temporal deep learning models often struggle with this sparsity, as they typically cannot effectively handle the non-Gaussian nature of crime data, which is characterized by numerous zeros and over-dispersed patterns. To address these challenges, we introduce a novel approach termed Spatial Temporal Multivariate Zero-Inflated Negative Binomial Graph Neural Networks (STMGNN-ZINB). This framework leverages diffusion and convolution networks to analyze spatial, temporal, and multivariate correlations, enabling the parameterization of probabilistic distributions of crime incidents. By incorporating a Zero-Inflated Negative Binomial model, STMGNN-ZINB effectively manages the sparse
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Listwise Reward Estimation (LiRE)的新方法，用于改进离线的偏好型强化学习，它能更精准地学习到人类意图的奖励模型。LiRE通过使用与传统方法相同的反馈类型，构建了轨迹的等级列表，充分利用了人类偏好中的第二级信息，从而在实验中证明了其在强化学习任务中能更有效地估计奖励，并显著超越了现有方法。</title><link>https://arxiv.org/abs/2408.04190</link><description>&lt;p&gt;
Listwise Reward Estimation for Offline Preference-based Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04190
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Listwise Reward Estimation (LiRE)的新方法，用于改进离线的偏好型强化学习，它能更精准地学习到人类意图的奖励模型。LiRE通过使用与传统方法相同的反馈类型，构建了轨迹的等级列表，充分利用了人类偏好中的第二级信息，从而在实验中证明了其在强化学习任务中能更有效地估计奖励，并显著超越了现有方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04190v1 Announce Type: cross  Abstract: In Reinforcement Learning (RL), designing precise reward functions remains to be a challenge, particularly when aligning with human intent. Preference-based RL (PbRL) was introduced to address this problem by learning reward models from human feedback. However, existing PbRL methods have limitations as they often overlook the second-order preference that indicates the relative strength of preference. In this paper, we propose Listwise Reward Estimation (LiRE), a novel approach for offline PbRL that leverages second-order preference information by constructing a Ranked List of Trajectories (RLT), which can be efficiently built by using the same ternary feedback type as traditional methods. To validate the effectiveness of LiRE, we propose a new offline PbRL dataset that objectively reflects the effect of the estimated rewards. Our extensive experiments on the dataset demonstrate the superiority of LiRE, i.e., outperforming state-of-the-
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为EdgeShield的通用高效边缘计算框架，用以在边缘设备上实现对AI系统的稳健防御，有效对抗各种类型的攻击。该框架通过对神经网络进行攻击检测和轻量级网络构建，使其在应对广泛AI安全挑战上具有高效率且低成本。</title><link>https://arxiv.org/abs/2408.04181</link><description>&lt;p&gt;
EdgeShield: A Universal and Efficient Edge Computing Framework for Robust AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04181
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为EdgeShield的通用高效边缘计算框架，用以在边缘设备上实现对AI系统的稳健防御，有效对抗各种类型的攻击。该框架通过对神经网络进行攻击检测和轻量级网络构建，使其在应对广泛AI安全挑战上具有高效率且低成本。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04181v1 Announce Type: cross  Abstract: The increasing prevalence of adversarial attacks on Artificial Intelligence (AI) systems has created a need for innovative security measures. However, the current methods of defending against these attacks often come with a high computing cost and require back-end processing, making real-time defense challenging. Fortunately, there have been remarkable advancements in edge-computing, which make it easier to deploy neural networks on edge devices. Building upon these advancements, we propose an edge framework design to enable universal and efficient detection of adversarial attacks. This framework incorporates an attention-based adversarial detection methodology and a lightweight detection network formation, making it suitable for a wide range of neural networks and can be deployed on edge devices. To assess the effectiveness of our proposed framework, we conducted evaluations on five neural networks. The results indicate an impressive 
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于人工转录和自动语音识别（ASR）的转录文本的框架，用于从语音数据中进行知识图谱的监督学习。通过构建基于转录语音的KG，将其转换为嵌入向量，并使用GNN进行节点分类和链接预测任务训练，从而扩展了现有文本主导的知识图谱的范围，使其涵盖了语音数据。</title><link>https://arxiv.org/abs/2408.04174</link><description>&lt;p&gt;
wav2graph: A Framework for Supervised Learning Knowledge Graph from Speech
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04174
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于人工转录和自动语音识别（ASR）的转录文本的框架，用于从语音数据中进行知识图谱的监督学习。通过构建基于转录语音的KG，将其转换为嵌入向量，并使用GNN进行节点分类和链接预测任务训练，从而扩展了现有文本主导的知识图谱的范围，使其涵盖了语音数据。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04174v1 Announce Type: cross  Abstract: Knowledge graphs (KGs) enhance the performance of large language models (LLMs) and search engines by providing structured, interconnected data that improves reasoning and context-awareness. However, KGs only focus on text data, thereby neglecting other modalities such as speech. In this work, we introduce wav2graph, the first framework for supervised learning knowledge graph from speech data. Our pipeline are straightforward: (1) constructing a KG based on transcribed spoken utterances and a named entity database, (2) converting KG into embedding vectors, and (3) training graph neural networks (GNNs) for node classification and link prediction tasks. Through extensive experiments conducted in inductive and transductive learning contexts using state-of-the-art GNN models, we provide baseline results and error analysis for node classification and link prediction tasks on human transcripts and automatic speech recognition (ASR) transcript
&lt;/p&gt;</description></item><item><title>该文章提出了一种设计思路，利用大型语言模型（LLM）创建了一种目标导向的城市导航代理，该代理在没有直接指令的情况下仅通过观察环境识别目标地标和道路网络连接，并据此进行决策。尽管这一任务对AI代理来说极具挑战性，因为它需要代理建立自我定位并构建复杂城市环境的空间表示，尤其是在地标不可见的情况下，但通过引入合理的设计决策，确保代理即使在缺乏导航指令的情况下也能有效导航。文章强调这一方法在提升AI代理在城市环境中导航能力方面的潜在应用和重要性。</title><link>https://arxiv.org/abs/2408.04168</link><description>&lt;p&gt;
Perceive, Reflect, and Plan: Designing LLM Agent for Goal-Directed City Navigation without Instructions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04168
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种设计思路，利用大型语言模型（LLM）创建了一种目标导向的城市导航代理，该代理在没有直接指令的情况下仅通过观察环境识别目标地标和道路网络连接，并据此进行决策。尽管这一任务对AI代理来说极具挑战性，因为它需要代理建立自我定位并构建复杂城市环境的空间表示，尤其是在地标不可见的情况下，但通过引入合理的设计决策，确保代理即使在缺乏导航指令的情况下也能有效导航。文章强调这一方法在提升AI代理在城市环境中导航能力方面的潜在应用和重要性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04168v1 Announce Type: new  Abstract: This paper considers a scenario in city navigation: an AI agent is provided with language descriptions of the goal location with respect to some well-known landmarks; By only observing the scene around, including recognizing landmarks and road network connections, the agent has to make decisions to navigate to the goal location without instructions. This problem is very challenging, because it requires agent to establish self-position and acquire spatial representation of complex urban environment, where landmarks are often invisible. In the absence of navigation instructions, such abilities are vital for the agent to make high-quality decisions in long-range city navigation. With the emergent reasoning ability of large language models (LLMs), a tempting baseline is to prompt LLMs to "react" on each observation and make decisions accordingly. However, this baseline has very poor performance that the agent often repeatedly visits same loc
&lt;/p&gt;</description></item><item><title>该文章探讨了在多源数据集合中扩充训练数据可能导致模型性能降低的问题，并提出了基于分布偏移的策略来优化数据扩充决策以提升模型性能。</title><link>https://arxiv.org/abs/2408.04154</link><description>&lt;p&gt;
The Data Addition Dilemma
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04154
&lt;/p&gt;
&lt;p&gt;
该文章探讨了在多源数据集合中扩充训练数据可能导致模型性能降低的问题，并提出了基于分布偏移的策略来优化数据扩充决策以提升模型性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04154v1 Announce Type: cross  Abstract: In many machine learning for healthcare tasks, standard datasets are constructed by amassing data across many, often fundamentally dissimilar, sources. But when does adding more data help, and when does it hinder progress on desired model outcomes in real-world settings? We identify this situation as the \textit{Data Addition Dilemma}, demonstrating that adding training data in this multi-source scaling context can at times result in reduced overall accuracy, uncertain fairness outcomes, and reduced worst-subgroup performance. We find that this possibly arises from an empirically observed trade-off between model performance improvements due to data scaling and model deterioration from distribution shift. We thus establish baseline strategies for navigating this dilemma, introducing distribution shift heuristics to guide decision-making on which data sources to add in data scaling, in order to yield the expected model performance improv
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为UNLEARN的全新方法，可以在不重新训练大型语言模型的情况下，通过动态遗忘特定知识的方式来移除模型中的敏感或专有知识，同时保持其他知识的性能，该方法在准确性和有效性上都比以往的策略有显著的提升。此外，文章还提出了一种名为LEARN的方法，可以在不损害相似任务表现的前提下，对模型进行特定知识的定向增加，该方法在匹配低维重构方法(LoRA)的准确性方面表现良好。</title><link>https://arxiv.org/abs/2408.04140</link><description>&lt;p&gt;
UNLEARN Efficient Removal of Knowledge in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04140
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为UNLEARN的全新方法，可以在不重新训练大型语言模型的情况下，通过动态遗忘特定知识的方式来移除模型中的敏感或专有知识，同时保持其他知识的性能，该方法在准确性和有效性上都比以往的策略有显著的提升。此外，文章还提出了一种名为LEARN的方法，可以在不损害相似任务表现的前提下，对模型进行特定知识的定向增加，该方法在匹配低维重构方法(LoRA)的准确性方面表现良好。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04140v1 Announce Type: cross  Abstract: Given the prevalence of large language models (LLMs) and the prohibitive cost of training these models from scratch, dynamically forgetting specific knowledge e.g., private or proprietary, without retraining the model has become an important capability. This paper proposes a novel method to achieve this objective called UNLEARN. The approach builds upon subspace methods to identify and specifically target the removal of knowledge without adversely affecting other knowledge in the LLM. Results demonstrate 96% of targeted knowledge can be forgotten while maintaining performance on other knowledge within 2.5% of the original model, significantly outperforming the discriminatory abilities of the previous state-of-the-art. A dual method called LEARN is also proposed for targeted knowledge addition. Results show LEARN can match the fine-tuning accuracy of Low-Rank Adaptation (LoRA) without adversely affecting similar tasks.
&lt;/p&gt;</description></item><item><title>该文章报道了一种结合Sentence-t5和Mistral 7B模型的大型语言模型，其在医疗问答任务中展现出了超越其他模型的优秀性能，特别是在处理专业医疗知识方面表现出高精度的能力。</title><link>https://arxiv.org/abs/2408.04138</link><description>&lt;p&gt;
Enhancing Healthcare through Large Language Models: A Study on Medical Question Answering
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04138
&lt;/p&gt;
&lt;p&gt;
该文章报道了一种结合Sentence-t5和Mistral 7B模型的大型语言模型，其在医疗问答任务中展现出了超越其他模型的优秀性能，特别是在处理专业医疗知识方面表现出高精度的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04138v1 Announce Type: cross  Abstract: In recent years, the application of Large Language Models (LLMs) in healthcare has shown significant promise in improving the accessibility and dissemination of medical knowledge. This paper presents a detailed study of various LLMs trained on the MedQuAD medical question-answering dataset, with a focus on identifying the most effective model for providing accurate medical information. Among the models tested, the Sentence-t5 combined with Mistral 7B demonstrated superior performance, achieving a precision score of 0.762. This model's enhanced capabilities are attributed to its advanced pretraining techniques, robust architecture, and effective prompt construction methodologies. By leveraging these strengths, the Sentence-t5 + Mistral 7B model excels in understanding and generating precise medical answers. Our findings highlight the potential of integrating sophisticated LLMs in medical contexts to facilitate efficient and accurate med
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为RadPrompt的策略，结合了规则系统和多轮提示策略，使用一个基于不确定性的信息模式优化了规则，显著提高了大型语言模型在放射学报告分类中的零样本预测性能。</title><link>https://arxiv.org/abs/2408.04121</link><description>&lt;p&gt;
Can Rule-Based Insights Enhance LLMs for Radiology Report Classification? Introducing the RadPrompt Methodology
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04121
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为RadPrompt的策略，结合了规则系统和多轮提示策略，使用一个基于不确定性的信息模式优化了规则，显著提高了大型语言模型在放射学报告分类中的零样本预测性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04121v1 Announce Type: cross  Abstract: Developing imaging models capable of detecting pathologies from chest X-rays can be cost and time-prohibitive for large datasets as it requires supervision to attain state-of-the-art performance. Instead, labels extracted from radiology reports may serve as distant supervision since these are routinely generated as part of clinical practice. Despite their widespread use, current rule-based methods for label extraction rely on extensive rule sets that are limited in their robustness to syntactic variability. To alleviate these limitations, we introduce RadPert, a rule-based system that integrates an uncertainty-aware information schema with a streamlined set of rules, enhancing performance. Additionally, we have developed RadPrompt, a multi-turn prompting strategy that leverages RadPert to bolster the zero-shot predictive capabilities of large language models, achieving a statistically significant improvement in weighted average F1 scor
&lt;/p&gt;</description></item><item><title>该文章提出了Patchview系统，这是一个利用生成性灰尘和磁铁视觉化的LLM（大型语言模型）世界构建工具，它通过改进用户对大量生成元素的可视化交互，帮助用户更好地控制和定制故事世界的内容和结构。</title><link>https://arxiv.org/abs/2408.04112</link><description>&lt;p&gt;
Patchview: LLM-Powered Worldbuilding with Generative Dust and Magnet Visualization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04112
&lt;/p&gt;
&lt;p&gt;
该文章提出了Patchview系统，这是一个利用生成性灰尘和磁铁视觉化的LLM（大型语言模型）世界构建工具，它通过改进用户对大量生成元素的可视化交互，帮助用户更好地控制和定制故事世界的内容和结构。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04112v1 Announce Type: cross  Abstract: Large language models (LLMs) can help writers build story worlds by generating world elements, such as factions, characters, and locations. However, making sense of many generated elements can be overwhelming. Moreover, if the user wants to precisely control aspects of generated elements that are difficult to specify verbally, prompting alone may be insufficient. We introduce Patchview, a customizable LLM-powered system that visually aids worldbuilding by allowing users to interact with story concepts and elements through the physical metaphor of magnets and dust. Elements in Patchview are visually dragged closer to concepts with high relevance, facilitating sensemaking. The user can also steer the generation with verbally elusive concepts by indicating the desired position of the element between concepts. When the user disagrees with the LLM's visualization and generation, they can correct those by repositioning the element. These cor
&lt;/p&gt;</description></item><item><title>该文章提出的TCloud框架是一个全面的NPU虚拟化解决方案，它通过提供一个灵活的NPU抽象层vNPU，实现了对物理NPU中异构计算单元的精细虚拟化，同时探讨了在软件和硬件栈中针对NPU虚拟化的各种技术，旨在为现代云平台提供高效的资源共享机制。</title><link>https://arxiv.org/abs/2408.04104</link><description>&lt;p&gt;
Hardware-Assisted Virtualization of Neural Processing Units for Cloud Platforms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04104
&lt;/p&gt;
&lt;p&gt;
该文章提出的TCloud框架是一个全面的NPU虚拟化解决方案，它通过提供一个灵活的NPU抽象层vNPU，实现了对物理NPU中异构计算单元的精细虚拟化，同时探讨了在软件和硬件栈中针对NPU虚拟化的各种技术，旨在为现代云平台提供高效的资源共享机制。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04104v1 Announce Type: cross  Abstract: Cloud platforms today have been deploying hardware accelerators like neural processing units (NPUs) for powering machine learning (ML) inference services. To maximize the resource utilization while ensuring reasonable quality of service, a natural approach is to virtualize NPUs for efficient resource sharing for multi-tenant ML services. However, virtualizing NPUs for modern cloud platforms is not easy. This is not only due to the lack of system abstraction support for NPU hardware, but also due to the lack of architectural and ISA support for enabling fine-grained dynamic operator scheduling for virtualized NPUs.   We present TCloud, a holistic NPU virtualization framework. We investigate virtualization techniques for NPUs across the entire software and hardware stack. TCloud consists of (1) a flexible NPU abstraction called vNPU, which enables fine-grained virtualization of the heterogeneous compute units in a physical NPU (pNPU); (2
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为ArtVLM的方法，通过采用大型预训练的视觉语言模型（VLM），实现了在零样本条件下对视觉属性的识别。这种方法通过改造一种条件概率图模型，将识别任务转化为依赖性敏感的语言建模问题，有效解决了之前在视觉语言模型中未能捕捉到的对象属性关系问题。</title><link>https://arxiv.org/abs/2408.04102</link><description>&lt;p&gt;
ArtVLM: Attribute Recognition Through Vision-Based Prefix Language Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04102
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为ArtVLM的方法，通过采用大型预训练的视觉语言模型（VLM），实现了在零样本条件下对视觉属性的识别。这种方法通过改造一种条件概率图模型，将识别任务转化为依赖性敏感的语言建模问题，有效解决了之前在视觉语言模型中未能捕捉到的对象属性关系问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04102v1 Announce Type: new  Abstract: Recognizing and disentangling visual attributes from objects is a foundation to many computer vision applications. While large vision language representations like CLIP had largely resolved the task of zero-shot object recognition, zero-shot visual attribute recognition remains a challenge because CLIP's contrastively-learned vision-language representation cannot effectively capture object-attribute dependencies. In this paper, we target this weakness and propose a sentence generation-based retrieval formulation for attribute recognition that is novel in 1) explicitly modeling a to-be-measured and retrieved object-attribute relation as a conditional probability graph, which converts the recognition problem into a dependency-sensitive language-modeling problem, and 2) applying a large pretrained Vision-Language Model (VLM) on this reformulation and naturally distilling its knowledge of image-object-attribute relations to use towards attri
&lt;/p&gt;</description></item><item><title>该文章提出AEye工具，它是一个用于图像数据集的可视化工具，能够通过对比学习模型生成图像的高维语义表示，并投射到二维平面进行交互式浏览，用户可通过多种方式进行搜索和探索，具有重要的创新和贡献。</title><link>https://arxiv.org/abs/2408.04072</link><description>&lt;p&gt;
AEye: A Visualization Tool for Image Datasets
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04072
&lt;/p&gt;
&lt;p&gt;
该文章提出AEye工具，它是一个用于图像数据集的可视化工具，能够通过对比学习模型生成图像的高维语义表示，并投射到二维平面进行交互式浏览，用户可通过多种方式进行搜索和探索，具有重要的创新和贡献。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04072v1 Announce Type: new  Abstract: Image datasets serve as the foundation for machine learning models in computer vision, significantly influencing model capabilities, performance, and biases alongside architectural considerations. Therefore, understanding the composition and distribution of these datasets has become increasingly crucial. To address the need for intuitive exploration of these datasets, we propose AEye, an extensible and scalable visualization tool tailored to image datasets. AEye utilizes a contrastively trained model to embed images into semantically meaningful high-dimensional representations, facilitating data clustering and organization. To visualize the high-dimensional representations, we project them onto a two-dimensional plane and arrange images in layers so users can seamlessly navigate and explore them interactively. AEye facilitates semantic search functionalities for both text and image queries, enabling users to search for content. We open-s
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的Artificial Intelligence驱动的数字虚拟人框架，并通过在线问答和实时视频流进一步强调了其高度的真实性、幽默感和镜头感。</title><link>https://arxiv.org/abs/2408.04068</link><description>&lt;p&gt;
Digital Avatars: Framework Development and Their Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04068
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的Artificial Intelligence驱动的数字虚拟人框架，并通过在线问答和实时视频流进一步强调了其高度的真实性、幽默感和镜头感。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04068v1 Announce Type: new  Abstract: We present a novel prompting strategy for artificial intelligence driven digital avatars. To better quantify how our prompting strategy affects anthropomorphic features like humor, authenticity, and favorability we present Crowd Vote - an adaptation of Crowd Score that allows for judges to elect a large language model (LLM) candidate over competitors answering the same or similar prompts. To visualize the responses of our LLM, and the effectiveness of our prompting strategy we propose an end-to-end framework for creating high-fidelity artificial intelligence (AI) driven digital avatars. This pipeline effectively captures an individual's essence for interaction and our streaming algorithm delivers a high-quality digital avatar with real-time audio-video streaming from server to mobile device. Both our visualization tool, and our Crowd Vote metrics demonstrate our AI driven digital avatars have state-of-the-art humor, authenticity, and fav
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为PowerPM的大型预训练基础模型，用以丰富电力系统时间序列数据的建模。模型包含一个处理时间序列依赖的结构和层次化的编码器，以捕捉电力消耗行为的多样性，并能泛化到不同的应用场景中。</title><link>https://arxiv.org/abs/2408.04057</link><description>&lt;p&gt;
PowerPM: Foundation Model for Power Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04057
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为PowerPM的大型预训练基础模型，用以丰富电力系统时间序列数据的建模。模型包含一个处理时间序列依赖的结构和层次化的编码器，以捕捉电力消耗行为的多样性，并能泛化到不同的应用场景中。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04057v1 Announce Type: cross  Abstract: The emergence of abundant electricity time series (ETS) data provides ample opportunities for various applications in the power systems, including demand-side management, grid stability, and consumer behavior analysis. Deep learning models have advanced ETS modeling by effectively capturing sequence dependence. Nevertheless, learning a generic representation of ETS data for various applications remains challenging due to the inherently complex hierarchical structure of ETS data. Moreover, ETS data exhibits intricate temporal dependencies and is suscepti ble to the influence of exogenous variables. Furthermore, different instances exhibit diverse electricity consumption behavior. In this paper, we propose a foundation model PowerPM to model ETS data, providing a large-scale, off-the-shelf model for power systems. PowerPM consists of a temporal encoder and a hierarchical encoder. The temporal encoder captures both temporal dependencies i
&lt;/p&gt;</description></item><item><title>该文章提出了一种利用机器学习为基础的奖励驱动方法，自动化调整扫描探针显微镜的设置，特别是在敲击模式下的优化过程中，旨在实现完全自动化的成像技术，从而减少手动调整所需的时间，降低设备和样本损坏的风险，并提高图像质量和重复性。</title><link>https://arxiv.org/abs/2408.04055</link><description>&lt;p&gt;
Machine Learning-Based Reward-Driven Tuning of Scanning Probe Microscopy: Towards Fully Automated Microscopy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04055
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种利用机器学习为基础的奖励驱动方法，自动化调整扫描探针显微镜的设置，特别是在敲击模式下的优化过程中，旨在实现完全自动化的成像技术，从而减少手动调整所需的时间，降低设备和样本损坏的风险，并提高图像质量和重复性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04055v1 Announce Type: cross  Abstract: Since the dawn of scanning probe microscopy (SPM), tapping or intermittent contact mode has been one of the most widely used imaging modes. Manual optimization of tapping mode not only takes a lot of instrument and operator time, but also often leads to frequent probe and sample damage, poor image quality and reproducibility issues for new types of samples or inexperienced users. Despite wide use, optimization of tapping mode imaging is an extremely hard problem, ill-suited to either classical control methods or machine learning. Here we introduce a reward-driven workflow to automate the optimization of SPM in the tapping mode. The reward function is defined based on multiple channels with physical and empirical knowledge of good scans encoded, representing a sample-agnostic measure of image quality and imitating the decision-making logic employed by human operators. This automated workflow gives optimal scanning parameters for differe
&lt;/p&gt;</description></item><item><title>该文章的创新贡献在于提出NAVINACT框架，该框架能够自动选择何时使用经典导航方法进行探索，何时利用模仿学习从特定数据集中进行强化学习，以提高探索效率。这种动态切换的模式解决了在真实世界中应用强化学习时面临的探索和泛化难题，对于提高机器人任务执行能力具有重要意义。</title><link>https://arxiv.org/abs/2408.04054</link><description>&lt;p&gt;
NAVINACT: Combining Navigation and Imitation Learning for Bootstrapping Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04054
&lt;/p&gt;
&lt;p&gt;
该文章的创新贡献在于提出NAVINACT框架，该框架能够自动选择何时使用经典导航方法进行探索，何时利用模仿学习从特定数据集中进行强化学习，以提高探索效率。这种动态切换的模式解决了在真实世界中应用强化学习时面临的探索和泛化难题，对于提高机器人任务执行能力具有重要意义。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04054v1 Announce Type: new  Abstract: Reinforcement Learning (RL) has shown remarkable progress in simulation environments, yet its application to real-world robotic tasks remains limited due to challenges in exploration and generalisation. To address these issues, we introduce NAVINACT, a framework that chooses when the robot should use classical motion planning-based navigation and when it should learn a policy. To further improve the efficiency in exploration, we use imitation data to bootstrap the exploration. NAVINACT dynamically switches between two modes of operation: navigating to a waypoint using classical techniques when away from the objects and reinforcement learning for fine-grained manipulation control when about to interact with objects. NAVINACT consists of a multi-head architecture composed of ModeNet for mode classification, NavNet for waypoint prediction, and InteractNet for precise manipulation. By combining the strengths of RL and Imitation Learning (IL)
&lt;/p&gt;</description></item><item><title>该文章提出了一种无需学习率的强化学习模型选择方法，该方法能够在无需调整RL算法和优化器的前提下，仅通过奖励反馈实现自适应学习率的选择，有望减少学习率选择不当对RL算法性能的影响。</title><link>https://arxiv.org/abs/2408.04046</link><description>&lt;p&gt;
Learning Rate-Free Reinforcement Learning: A Case for Model Selection with Non-Stationary Objectives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04046
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种无需学习率的强化学习模型选择方法，该方法能够在无需调整RL算法和优化器的前提下，仅通过奖励反馈实现自适应学习率的选择，有望减少学习率选择不当对RL算法性能的影响。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04046v1 Announce Type: cross  Abstract: The performance of reinforcement learning (RL) algorithms is sensitive to the choice of hyperparameters, with the learning rate being particularly influential. RL algorithms fail to reach convergence or demand an extensive number of samples when the learning rate is not optimally set. In this work, we show that model selection can help to improve the failure modes of RL that are due to suboptimal choices of learning rate. We present a model selection framework for Learning Rate-Free Reinforcement Learning that employs model selection methods to select the optimal learning rate on the fly. This approach of adaptive learning rate tuning neither depends on the underlying RL algorithm nor the optimizer and solely uses the reward feedback to select the learning rate; hence, the framework can input any RL algorithm and produce a learning rate-free version of it. We conduct experiments for policy optimization methods and evaluate various mode
&lt;/p&gt;</description></item><item><title>该文章首次对来自美国和中国的两个不同数据集中的抑郁表现模式进行了评估，探究了跨文化和跨性别间的模态特征及相互关系如何影响机器学习模型性能和性别公平性的问题。</title><link>https://arxiv.org/abs/2408.04026</link><description>&lt;p&gt;
Multimodal Gender Fairness in Depression Prediction: Insights on Data from the USA &amp;amp; China
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04026
&lt;/p&gt;
&lt;p&gt;
该文章首次对来自美国和中国的两个不同数据集中的抑郁表现模式进行了评估，探究了跨文化和跨性别间的模态特征及相互关系如何影响机器学习模型性能和性别公平性的问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04026v1 Announce Type: cross  Abstract: Social agents and robots are increasingly being used in wellbeing settings. However, a key challenge is that these agents and robots typically rely on machine learning (ML) algorithms to detect and analyse an individual's mental wellbeing. The problem of bias and fairness in ML algorithms is becoming an increasingly greater source of concern. In concurrence, existing literature has also indicated that mental health conditions can manifest differently across genders and cultures. We hypothesise that the representation of features (acoustic, textual, and visual) and their inter-modal relations would vary among subjects from different cultures and genders, thus impacting the performance and fairness of various ML models. We present the very first evaluation of multimodal gender fairness in depression manifestation by undertaking a study on two different datasets from the USA and China. We undertake thorough statistical and ML experimentat
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的框架，通过一种全面的、情境化的方法来增强大型语言模型（LLM）的可靠性，并将其行为锚定在特定的情境、文化和伦理概念上。这种方法通过使用知识表示和推理技术如本体论、语义网技术和逻辑形式主义，将模型的行为与特定的情境、文化和伦理概念相结合，以提高模型的可靠性和与人类价值观的一致性。</title><link>https://arxiv.org/abs/2408.04023</link><description>&lt;p&gt;
Improving Large Language Model (LLM) fidelity through context-aware grounding: A systematic approach to reliability and veracity
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.04023
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的框架，通过一种全面的、情境化的方法来增强大型语言模型（LLM）的可靠性，并将其行为锚定在特定的情境、文化和伦理概念上。这种方法通过使用知识表示和推理技术如本体论、语义网技术和逻辑形式主义，将模型的行为与特定的情境、文化和伦理概念相结合，以提高模型的可靠性和与人类价值观的一致性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.04023v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) become increasingly sophisticated and ubiquitous in natural language processing (NLP) applications, ensuring their robustness, trustworthiness, and alignment with human values has become a critical challenge. This paper presents a novel framework for contextual grounding in textual models, with a particular emphasis on the Context Representation stage. Our approach aims to enhance the reliability and ethical alignment of these models through a comprehensive, context-aware methodology. By explicitly capturing and representing relevant situational, cultural, and ethical contexts in a machine-readable format, we lay the foundation for anchoring a model's behavior within these contexts. Our approach leverages techniques from knowledge representation and reasoning, such as ontologies, semantic web technologies, and logic-based formalisms. We evaluate our framework on real-world textual datasets, demonstrating
&lt;/p&gt;</description></item><item><title>该文章提出一种结合损失距离跨选择模块和最优传输策略的框架，旨在应对含有长期尾分布和噪声标签的数据集，有效过滤掉噪声标签并提升伪标签质量，进而提高了模型在长期尾分布数据上的准确率。</title><link>https://arxiv.org/abs/2408.03977</link><description>&lt;p&gt;
Learning from Noisy Labels for Long-tailed Data via Optimal Transport
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03977
&lt;/p&gt;
&lt;p&gt;
该文章提出一种结合损失距离跨选择模块和最优传输策略的框架，旨在应对含有长期尾分布和噪声标签的数据集，有效过滤掉噪声标签并提升伪标签质量，进而提高了模型在长期尾分布数据上的准确率。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03977v1 Announce Type: cross  Abstract: Noisy labels, which are common in real-world datasets, can significantly impair the training of deep learning models. However, recent adversarial noise-combating methods overlook the long-tailed distribution of real data, which can significantly harm the effect of denoising strategies. Meanwhile, the mismanagement of noisy labels further compromises the model's ability to handle long-tailed data. To tackle this issue, we propose a novel approach to manage data characterized by both long-tailed distributions and noisy labels. First, we introduce a loss-distance cross-selection module, which integrates class predictions and feature distributions to filter clean samples, effectively addressing uncertainties introduced by noisy labels and long-tailed distributions. Subsequently, we employ optimal transport strategies to generate pseudo-labels for the noise set in a semi-supervised training manner, enhancing pseudo-label quality while mitig
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Rescaling-ACG的方法，通过自动调整搜索方向和步长来提高攻击点之间的距离，从而增强了Auto Conjugate Gradient（ACG）攻击方法在生成对抗性示例方面的性能，尤其是在涉及多个类别的ImageNet模型上表现尤为显著。</title><link>https://arxiv.org/abs/2408.03972</link><description>&lt;p&gt;
Enhancing Output Diversity Improves Conjugate Gradient-based Adversarial Attacks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03972
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Rescaling-ACG的方法，通过自动调整搜索方向和步长来提高攻击点之间的距离，从而增强了Auto Conjugate Gradient（ACG）攻击方法在生成对抗性示例方面的性能，尤其是在涉及多个类别的ImageNet模型上表现尤为显著。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03972v1 Announce Type: cross  Abstract: Deep neural networks are vulnerable to adversarial examples, and adversarial attacks that generate adversarial examples have been studied in this context. Existing studies imply that increasing the diversity of model outputs contributes to improving the attack performance. This study focuses on the Auto Conjugate Gradient (ACG) attack, which is inspired by the conjugate gradient method and has a high diversification performance. We hypothesized that increasing the distance between two consecutive search points would enhance the output diversity. To test our hypothesis, we propose Rescaling-ACG (ReACG), which automatically modifies the two components that significantly affect the distance between two consecutive search points, including the search direction and step size. ReACG showed higher attack performance than that of ACG, and is particularly effective for ImageNet models with several classification classes. Experimental results sh
&lt;/p&gt;</description></item><item><title>该文章探讨了电信业对人工智能（AI）模型的应用，特别是在解决网络管理、运营和优化方面的问题。文章指出，传统的AI模型难以适应不同的部署场景，并且需要大量的专业电信数据和专业知识来进行开发和维护，且难以推广到不同的应用。相比之下，基于AI的“基础模型”（foundation models）具有更广泛的适用性和强大的泛化能力，能够从电信生态系统中收集多模态数据并结合应用，从而解决传统AI模型面临的挑战。</title><link>https://arxiv.org/abs/2408.03964</link><description>&lt;p&gt;
Telecom Foundation Models: Applications, Challenges, and Future Trends
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03964
&lt;/p&gt;
&lt;p&gt;
该文章探讨了电信业对人工智能（AI）模型的应用，特别是在解决网络管理、运营和优化方面的问题。文章指出，传统的AI模型难以适应不同的部署场景，并且需要大量的专业电信数据和专业知识来进行开发和维护，且难以推广到不同的应用。相比之下，基于AI的“基础模型”（foundation models）具有更广泛的适用性和强大的泛化能力，能够从电信生态系统中收集多模态数据并结合应用，从而解决传统AI模型面临的挑战。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03964v1 Announce Type: cross  Abstract: Telecom networks are becoming increasingly complex, with diversified deployment scenarios, multi-standards, and multi-vendor support. The intricate nature of the telecom network ecosystem presents challenges to effectively manage, operate, and optimize networks. To address these hurdles, Artificial Intelligence (AI) has been widely adopted to solve different tasks in telecom networks. However, these conventional AI models are often designed for specific tasks, rely on extensive and costly-to-collect labeled data that require specialized telecom expertise for development and maintenance. The AI models usually fail to generalize and support diverse deployment scenarios and applications. In contrast, Foundation Models (FMs) show effective generalization capabilities in various domains in language, vision, and decision-making tasks. FMs can be trained on multiple data modalities generated from the telecom ecosystem and leverage specialized
&lt;/p&gt;</description></item><item><title>该文章提出了一种自适应系统架构，能够在不事先规划的情况下根据实际需要自动调整系统规模，适用于像无人机舰队这样需要应对不确定情况的系统。</title><link>https://arxiv.org/abs/2408.03963</link><description>&lt;p&gt;
A self-adaptive system of systems architecture to enable its ad-hoc scalability: Unmanned Vehicle Fleet -- Mission Control Center Case study
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03963
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种自适应系统架构，能够在不事先规划的情况下根据实际需要自动调整系统规模，适用于像无人机舰队这样需要应对不确定情况的系统。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03963v1 Announce Type: new  Abstract: A System of Systems (SoS) comprises Constituent Systems (CSs) that interact to provide unique capabilities beyond any single CS. A key challenge in SoS is ad-hoc scalability, meaning the system size changes during operation by adding or removing CSs. This research focuses on an Unmanned Vehicle Fleet (UVF) as a practical SoS example, addressing uncertainties like mission changes, range extensions, and UV failures. The proposed solution involves a self-adaptive system that dynamically adjusts UVF architecture, allowing the Mission Control Center (MCC) to scale UVF size automatically based on performance criteria or manually by operator decision. A multi-agent environment and rule management engine were implemented to simulate and verify this approach.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为EcoFollower的新型环境友好型跟随车辆模型，该模型考虑了燃料消耗，通过强化学习优化交通场景下的行驶效率。通过对比行业标准智能司机模型（IDM），研究发现EcoFollower不仅模拟了更真实的驾驶行为，保持了车辆操作的流畅性，并且与时间碰撞、跟车距离和舒适度等真实指标的匹配度极高。更重要的是，EcoFollower在燃料消耗方面表现出色，相比实际的驾驶场景，其降低了10.42%的燃料消耗，显示出强化学习模型在提高自动驾驶车辆性能和推广更安全、更环保驾驶策略方面的潜力。</title><link>https://arxiv.org/abs/2408.03950</link><description>&lt;p&gt;
EcoFollower: An Environment-Friendly Car Following Model Considering Fuel Consumption
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03950
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为EcoFollower的新型环境友好型跟随车辆模型，该模型考虑了燃料消耗，通过强化学习优化交通场景下的行驶效率。通过对比行业标准智能司机模型（IDM），研究发现EcoFollower不仅模拟了更真实的驾驶行为，保持了车辆操作的流畅性，并且与时间碰撞、跟车距离和舒适度等真实指标的匹配度极高。更重要的是，EcoFollower在燃料消耗方面表现出色，相比实际的驾驶场景，其降低了10.42%的燃料消耗，显示出强化学习模型在提高自动驾驶车辆性能和推广更安全、更环保驾驶策略方面的潜力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03950v1 Announce Type: new  Abstract: To alleviate energy shortages and environmental impacts caused by transportation, this study introduces EcoFollower, a novel eco-car-following model developed using reinforcement learning (RL) to optimize fuel consumption in car-following scenarios. Employing the NGSIM datasets, the performance of EcoFollower was assessed in comparison with the well-established Intelligent Driver Model (IDM). The findings demonstrate that EcoFollower excels in simulating realistic driving behaviors, maintaining smooth vehicle operations, and closely matching the ground truth metrics of time-to-collision (TTC), headway, and comfort. Notably, the model achieved a significant reduction in fuel consumption, lowering it by 10.42\% compared to actual driving scenarios. These results underscore the capability of RL-based models like EcoFollower to enhance autonomous vehicle algorithms, promoting safer and more energy-efficient driving strategies.
&lt;/p&gt;</description></item><item><title>该文章创新地探讨了人类对人工智能依赖性行为的研究进展，填补了现有文献中对AI依赖性影响因素、方法测量等研究不足的空白，为未来研究提供了测量AI依赖性的新方法。</title><link>https://arxiv.org/abs/2408.03948</link><description>&lt;p&gt;
A Survey of AI Reliance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03948
&lt;/p&gt;
&lt;p&gt;
该文章创新地探讨了人类对人工智能依赖性行为的研究进展，填补了现有文献中对AI依赖性影响因素、方法测量等研究不足的空白，为未来研究提供了测量AI依赖性的新方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03948v1 Announce Type: cross  Abstract: Artificial intelligence (AI) systems have become an indispensable component of modern technology. However, research on human behavioral responses is lagging behind, i.e., the research into human reliance on AI advice (AI reliance). Current shortcomings in the literature include the unclear influences on AI reliance, lack of external validity, conflicting approaches to measuring reliance, and disregard for a change in reliance over time. Promising avenues for future research include reliance on generative AI output and reliance in multi-user situations. In conclusion, we present a morphological box that serves as a guide for research on AI reliance.
&lt;/p&gt;</description></item><item><title>该文章研究了文本到图像生成模型中的设计空间探索策略，发现用户行为和目标导向的提示至关重要，有助于实现产品设计的可行性和新颖性。</title><link>https://arxiv.org/abs/2408.03946</link><description>&lt;p&gt;
Prompting for products: Investigating design space exploration strategies for text-to-image generative models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03946
&lt;/p&gt;
&lt;p&gt;
该文章研究了文本到图像生成模型中的设计空间探索策略，发现用户行为和目标导向的提示至关重要，有助于实现产品设计的可行性和新颖性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03946v1 Announce Type: cross  Abstract: Text-to-image models are enabling efficient design space exploration, rapidly generating images from text prompts. However, many generative AI tools are imperfect for product design applications as they are not built for the goals and requirements of product design. The unclear link between text input and image output further complicates their application. This work empirically investigates design space exploration strategies that can successfully yield product images that are feasible, novel, and aesthetic, which are three common goals in product design. Specifically, user actions within the global and local editing modes, including their time spent, prompt length, mono vs. multi-criteria prompts, and goal orientation of prompts, are analyzed. Key findings reveal the pivotal role of mono vs. multi-criteria and goal orientation of prompts in achieving specific design goals over time and prompt length. The study recommends prioritizing 
&lt;/p&gt;</description></item><item><title>该文章探讨了将大型语言模型（LLMs）赋予人类特征的举措对教育理论以及学习成果的潜在影响，特别是涉及LLM在教育和学习环境中的情感层面。研究指出，当人们对待媒体的反应类似于对待另一名个体的反应时，即媒体方程所体现的观点，这为理解LLM在教育中的实际应用提供了新的维度。</title><link>https://arxiv.org/abs/2408.03945</link><description>&lt;p&gt;
Impacts of Anthropomorphizing Large Language Models in Learning Environments
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03945
&lt;/p&gt;
&lt;p&gt;
该文章探讨了将大型语言模型（LLMs）赋予人类特征的举措对教育理论以及学习成果的潜在影响，特别是涉及LLM在教育和学习环境中的情感层面。研究指出，当人们对待媒体的反应类似于对待另一名个体的反应时，即媒体方程所体现的观点，这为理解LLM在教育中的实际应用提供了新的维度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03945v1 Announce Type: cross  Abstract: Large Language Models (LLMs) are increasingly being used in learning environments to support teaching-be it as learning companions or as tutors. With our contribution, we aim to discuss the implications of the anthropomorphization of LLMs in learning environments on educational theory to build a foundation for more effective learning outcomes and understand their emotional impact on learners. According to the media equation, people tend to respond to media in the same way as they would respond to another person. A study conducted by the Georgia Institute of Technology showed that chatbots can be successfully implemented in learning environments. In this study, learners in selected online courses were unable to distinguish the chatbot from a "real" teacher. As LLM-based chatbots such as OpenAI's GPT series are increasingly used in educational tools, it is important to understand how the attribution processes to LLM-based chatbots in ter
&lt;/p&gt;</description></item><item><title>该文章提出了构建能够与人协作思考的机器，旨在让机器不仅仅是思考的工具，而是与人共同思考的伙伴。这种伙伴式的思考关系要求机器满足合理性、洞察力、知识性、可靠性和信任度等多方面要求。文章提出了一系列人类与机器伙伴协作思考的模式，并提出了人机兼容的思考伙伴应具备的要素。同时，文章还介绍了通过贝叶斯视角和计算认知科学的一些理念来设计和构建这样的伙伴机器的新设计路径。</title><link>https://arxiv.org/abs/2408.03943</link><description>&lt;p&gt;
Building Machines that Learn and Think with People
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03943
&lt;/p&gt;
&lt;p&gt;
该文章提出了构建能够与人协作思考的机器，旨在让机器不仅仅是思考的工具，而是与人共同思考的伙伴。这种伙伴式的思考关系要求机器满足合理性、洞察力、知识性、可靠性和信任度等多方面要求。文章提出了一系列人类与机器伙伴协作思考的模式，并提出了人机兼容的思考伙伴应具备的要素。同时，文章还介绍了通过贝叶斯视角和计算认知科学的一些理念来设计和构建这样的伙伴机器的新设计路径。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03943v1 Announce Type: cross  Abstract: What do we want from machine intelligence? We envision machines that are not just tools for thought, but partners in thought: reasonable, insightful, knowledgeable, reliable, and trustworthy systems that think with us. Current artificial intelligence (AI) systems satisfy some of these criteria, some of the time. In this Perspective, we show how the science of collaborative cognition can be put to work to engineer systems that really can be called ``thought partners,'' systems built to meet our expectations and complement our limitations. We lay out several modes of collaborative thought in which humans and AI thought partners can engage and propose desiderata for human-compatible thought partnerships. Drawing on motifs from computational cognitive science, we motivate an alternative scaling path for the design of thought partners and ecosystems around their use through a Bayesian lens, whereby the partners we construct actively build a
&lt;/p&gt;</description></item><item><title>该文章中，EXAONE 3.0 7.8B 指令微调语言模型作为LG AI Research开发的第一个同类的大型语言模型，是公开模型的首个实例，主要创新在于其在指令遵循能力上与其他类似大小开放模型的竞争中展现出高水平的实际性能。特别是，其在 Korean 语言方面的卓越表现以及跨多种任务和复杂推理中的显著性能，强调了其在真实世界应用中的有效性。此外，其双语能力的展现标志着其在专家级人工智能领域的贡献可能持续增长。该模型通过 GitHub 上的 Hugging Face Co 公开提供了 20B 版本，进一步推动了开放研究和创新。</title><link>https://arxiv.org/abs/2408.03541</link><description>&lt;p&gt;
EXAONE 3.0 7.8B Instruction Tuned Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03541
&lt;/p&gt;
&lt;p&gt;
该文章中，EXAONE 3.0 7.8B 指令微调语言模型作为LG AI Research开发的第一个同类的大型语言模型，是公开模型的首个实例，主要创新在于其在指令遵循能力上与其他类似大小开放模型的竞争中展现出高水平的实际性能。特别是，其在 Korean 语言方面的卓越表现以及跨多种任务和复杂推理中的显著性能，强调了其在真实世界应用中的有效性。此外，其双语能力的展现标志着其在专家级人工智能领域的贡献可能持续增长。该模型通过 GitHub 上的 Hugging Face Co 公开提供了 20B 版本，进一步推动了开放研究和创新。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03541v1 Announce Type: cross  Abstract: We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family of Large Language Models (LLMs) developed by LG AI Research. Among different model sizes, we publicly release the 7.8B instruction-tuned model to promote open research and innovations. Through extensive evaluations across a wide range of public and in-house benchmarks, EXAONE 3.0 demonstrates highly competitive real-world performance with instruction-following capability against other state-of-the-art open models of similar size. Our comparative analysis shows that EXAONE 3.0 excels particularly in Korean, while achieving compelling performance across general tasks and complex reasoning. With its strong real-world effectiveness and bilingual proficiency, we hope that EXAONE keeps contributing to advancements in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct
&lt;/p&gt;</description></item><item><title>该文章通过利用人工智能技术，分析了不同行业软件失败案例的相似性，并发展了一种模型，以帮助提高软件开发的安全性。</title><link>https://arxiv.org/abs/2408.03528</link><description>&lt;p&gt;
Exploring the extent of similarities in software failures across industries using LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03528
&lt;/p&gt;
&lt;p&gt;
该文章通过利用人工智能技术，分析了不同行业软件失败案例的相似性，并发展了一种模型，以帮助提高软件开发的安全性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03528v1 Announce Type: cross  Abstract: The rapid evolution of software development necessitates enhanced safety measures. Extracting information about software failures from companies is becoming increasingly more available through news articles.   This research utilizes the Failure Analysis Investigation with LLMs (FAIL) model to extract industry-specific information. Although the FAIL model's database is rich in information, it could benefit from further categorization and industry-specific insights to further assist software engineers.   In previous work news articles were collected from reputable sources and categorized by incidents inside a database. Prompt engineering and Large Language Models (LLMs) were then applied to extract relevant information regarding the software failure. This research extends these methods by categorizing articles into specific domains and types of software failures. The results are visually represented through graphs.   The analysis shows t
&lt;/p&gt;</description></item><item><title>该文章研究了大型语言模型（LLM）在分析黑客论坛上的网络威胁情报（CTI）数据中的应用，尤其是评估了基于OpenAI GPT-3.5-turbo模型的LLM系统提取CTI信息的准确性。通过对三个黑客论坛的500篇讨论线程进行测试，LLM系统能够准确提取出10个关键CTI变量信息的样本，表明LLM系统在自动化识别和解析网络威胁信息方面展现了出色的能力。</title><link>https://arxiv.org/abs/2408.03354</link><description>&lt;p&gt;
The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03354
&lt;/p&gt;
&lt;p&gt;
该文章研究了大型语言模型（LLM）在分析黑客论坛上的网络威胁情报（CTI）数据中的应用，尤其是评估了基于OpenAI GPT-3.5-turbo模型的LLM系统提取CTI信息的准确性。通过对三个黑客论坛的500篇讨论线程进行测试，LLM系统能够准确提取出10个关键CTI变量信息的样本，表明LLM系统在自动化识别和解析网络威胁信息方面展现了出色的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03354v1 Announce Type: cross  Abstract: Large language models (LLMs) can be used to analyze cyber threat intelligence (CTI) data from cybercrime forums, which contain extensive information and key discussions about emerging cyber threats. However, to date, the level of accuracy and efficiency of LLMs for such critical tasks has yet to be thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do so, a random sample of 500 daily conversations from three cybercrime forums, XSS, Exploit.in, and RAMP, was extracted, and the LLM system was instructed to summarize the conversations and code 10 key CTI variables, such as whether a large organization and/or a critical infrastructure is being targeted. Then, two coders reviewed each conversation and evaluated whether the information extracted by the LLM was accurate. The LLM system performed strikingly well, with an average accuracy scor
&lt;/p&gt;</description></item><item><title>该文章提供了一种名为KOI的在线模仿学习加速方法，通过整合关键状态指导来精确估计任务相关奖励，从而实现更有效的在线探索。</title><link>https://arxiv.org/abs/2408.02912</link><description>&lt;p&gt;
KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02912
&lt;/p&gt;
&lt;p&gt;
该文章提供了一种名为KOI的在线模仿学习加速方法，通过整合关键状态指导来精确估计任务相关奖励，从而实现更有效的在线探索。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02912v1 Announce Type: new  Abstract: Online Imitation Learning methods struggle with the gap between extensive online exploration space and limited expert trajectories, which hinder efficient exploration due to inaccurate task-aware reward estimation. Inspired by the findings from cognitive neuroscience that task decomposition could facilitate cognitive processing for efficient learning, we hypothesize that an agent could estimate precise task-aware imitation rewards for efficient online exploration by decomposing the target task into the objectives of "what to do" and the mechanisms of "how to do". In this work, we introduce the hybrid Key-state guided Online Imitation (KOI) learning approach, which leverages the integration of semantic and motion key states as guidance for task-aware reward estimation. Initially, we utilize the visual-language models to segment the expert trajectory into semantic key states, indicating the objectives of "what to do". Within the intervals 
&lt;/p&gt;</description></item><item><title>该文章提出了一种不依赖人类注释，仅使用合成数据训练改进模型评价者的方法。通过对未标注的指令进行迭代式的自我改进，该方法能够生成对比性的模型输出，并通过训练LLM作为评判者来生成推理轨迹和最终判断结果。在无任何偏好标注数据的情况下，通过这一过程改进的“自我学习评估者”能够显著提高一个强大语言模型（如Llama3-70B-Instruct）在RewardBench上的表现，从75.4提升至88.3（使用多数投票时可达88.7），这超过了常用语言模型评价者的性能。</title><link>https://arxiv.org/abs/2408.02666</link><description>&lt;p&gt;
Self-Taught Evaluators
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02666
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种不依赖人类注释，仅使用合成数据训练改进模型评价者的方法。通过对未标注的指令进行迭代式的自我改进，该方法能够生成对比性的模型输出，并通过训练LLM作为评判者来生成推理轨迹和最终判断结果。在无任何偏好标注数据的情况下，通过这一过程改进的“自我学习评估者”能够显著提高一个强大语言模型（如Llama3-70B-Instruct）在RewardBench上的表现，从75.4提升至88.3（使用多数投票时可达88.7），这超过了常用语言模型评价者的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02666v1 Announce Type: cross  Abstract: Model-based evaluation is at the heart of successful model development -- as a reward model for training, and as a replacement for human evaluation. To train such evaluators, the standard approach is to collect a large amount of human preference judgments over model responses, which is costly and the data becomes stale as models improve. In this work, we present an approach that aims to im-prove evaluators without human annotations, using synthetic training data only. Starting from unlabeled instructions, our iterative self-improvement scheme generates contrasting model outputs and trains an LLM-as-a-Judge to produce reasoning traces and final judgments, repeating this training at each new iteration using the improved predictions. Without any labeled preference data, our Self-Taught Evaluator can improve a strong LLM (Llama3-70B-Instruct) from 75.4 to 88.3 (88.7 with majority vote) on RewardBench. This outperforms commonly used LLM jud
&lt;/p&gt;</description></item><item><title>该文章创新性地将矩阵游戏社交困境扩展到多agent强化学习（MARL）环境中，并在其中加入了环境复杂性，从而更好地模拟真实世界的动态决策问题。研究结果表明，随着环境的复杂性增加，MARL策略趋向于收敛到风险主导的纳什均衡，这为解决一般性游戏中的合作问题提供了新的视角。</title><link>https://arxiv.org/abs/2408.02148</link><description>&lt;p&gt;
Environment Complexity and Nash Equilibria in a Sequential Social Dilemma
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02148
&lt;/p&gt;
&lt;p&gt;
该文章创新性地将矩阵游戏社交困境扩展到多agent强化学习（MARL）环境中，并在其中加入了环境复杂性，从而更好地模拟真实世界的动态决策问题。研究结果表明，随着环境的复杂性增加，MARL策略趋向于收敛到风险主导的纳什均衡，这为解决一般性游戏中的合作问题提供了新的视角。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02148v1 Announce Type: cross  Abstract: Multi-agent reinforcement learning (MARL) methods, while effective in zero-sum or positive-sum games, often yield suboptimal outcomes in general-sum games where cooperation is essential for achieving globally optimal outcomes. Matrix game social dilemmas, which abstract key aspects of general-sum interactions, such as cooperation, risk, and trust, fail to model the temporal and spatial dynamics characteristic of real-world scenarios. In response, our study extends matrix game social dilemmas into more complex, higher-dimensional MARL environments. We adapt a gridworld implementation of the Stag Hunt dilemma to more closely match the decision-space of a one-shot matrix game while also introducing variable environment complexity. Our findings indicate that as complexity increases, MARL agents trained in these environments converge to suboptimal strategies, consistent with the risk-dominant Nash equilibria strategies found in matrix games
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于分步微分算子的新型物理知识神经网络框架，成功解决了在处理非线性动力学方程的问题，并对其在Kirchhoff杆模型中的应用进行了评估。</title><link>https://arxiv.org/abs/2408.01914</link><description>&lt;p&gt;
Partial-differential-algebraic equations of nonlinear dynamics by Physics-Informed Neural-Network: (I) Operator splitting and framework assessment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01914
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于分步微分算子的新型物理知识神经网络框架，成功解决了在处理非线性动力学方程的问题，并对其在Kirchhoff杆模型中的应用进行了评估。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01914v1 Announce Type: cross  Abstract: Several forms for constructing novel physics-informed neural-networks (PINN) for the solution of partial-differential-algebraic equations based on derivative operator splitting are proposed, using the nonlinear Kirchhoff rod as a prototype for demonstration. The open-source DeepXDE is likely the most well documented framework with many examples. Yet, we encountered some pathological problems and proposed novel methods to resolve them. Among these novel methods are the PDE forms, which evolve from the lower-level form with fewer unknown dependent variables to higher-level form with more dependent variables, in addition to those from lower-level forms. Traditionally, the highest-level form, the balance-of-momenta form, is the starting point for (hand) deriving the lowest-level form through a tedious (and error prone) process of successive substitutions. The next step in a finite element method is to discretize the lowest-level form upon 
&lt;/p&gt;</description></item><item><title>该文章提出的"混合过度近似加法器（HOAA）"通过在累加链中引入带有过剩1的全加器，结合输入A、B和Cin，实现了在边缘人工智能应用中处理引擎性能的增强。该设计通过将输出近似为2位值来降低硬件复杂性并提高资源效率。HOAA设计通过在准确度和过度近似模式之间进行可配置切换，从而实现 runtime 的灵活性。研究证明了多应用中使用Plus One Adder的优越性，这些应用包括二进制减法、四舍五入和可配置激活函数，这些均是处理引擎中的关键组成部分。该方案相较于现有方法在面积效率上提高了21%，在功率消耗上减少了33%。</title><link>https://arxiv.org/abs/2408.00806</link><description>&lt;p&gt;
HOAA: Hybrid Overestimating Approximate Adder for Enhanced Performance Processing Engine
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.00806
&lt;/p&gt;
&lt;p&gt;
该文章提出的"混合过度近似加法器（HOAA）"通过在累加链中引入带有过剩1的全加器，结合输入A、B和Cin，实现了在边缘人工智能应用中处理引擎性能的增强。该设计通过将输出近似为2位值来降低硬件复杂性并提高资源效率。HOAA设计通过在准确度和过度近似模式之间进行可配置切换，从而实现 runtime 的灵活性。研究证明了多应用中使用Plus One Adder的优越性，这些应用包括二进制减法、四舍五入和可配置激活函数，这些均是处理引擎中的关键组成部分。该方案相较于现有方法在面积效率上提高了21%，在功率消耗上减少了33%。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.00806v1 Announce Type: cross  Abstract: This paper presents the Hybrid Overestimating Approximate Adder designed to enhance the performance in processing engines, specifically focused on edge AI applications. A novel Plus One Adder design is proposed as an incremental adder in the RCA chain, incorporating a Full Adder with an excess 1 alongside inputs A, B, and Cin. The design approximates outputs to 2 bit values to reduce hardware complexity and improve resource efficiency. The Plus One Adder is integrated into a dynamically reconfigurable HOAA, allowing runtime interchangeability between accurate and approximate overestimation modes. The proposed design is demonstrated for multiple applications, such as Twos complement subtraction and Rounding to even, and the Configurable Activation function, which are critical components of the Processing engine. Our approach shows 21 percent improvement in area efficiency and 33 percent reduction in power consumption, compared to state 
&lt;/p&gt;</description></item><item><title>该文章提出了一种自动生成自然语言处理行为测试用例的方法，通过结合聚类技术和提示技术，无需领域专家即可高效生成具有最小功能性测试的用例，从而为评估自然语言处理模型的语义能力和识别模型弱点提供了一种新的自动化方式。</title><link>https://arxiv.org/abs/2408.00161</link><description>&lt;p&gt;
Automatic Generation of Behavioral Test Cases For Natural Language Processing Using Clustering and Prompting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.00161
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种自动生成自然语言处理行为测试用例的方法，通过结合聚类技术和提示技术，无需领域专家即可高效生成具有最小功能性测试的用例，从而为评估自然语言处理模型的语义能力和识别模型弱点提供了一种新的自动化方式。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.00161v2 Announce Type: replace-cross  Abstract: Recent work in behavioral testing for natural language processing (NLP) models, such as Checklist, is inspired by related paradigms in software engineering testing. They allow evaluation of general linguistic capabilities and domain understanding, hence can help evaluate conceptual soundness and identify model weaknesses. However, a major challenge is the creation of test cases. The current packages rely on semi-automated approach using manual development which requires domain expertise and can be time consuming. This paper introduces an automated approach to develop test cases by exploiting the power of large language models and statistical techniques. It clusters the text representations to carefully construct meaningful groups and then apply prompting techniques to automatically generate Minimal Functionality Tests (MFT). The well-known Amazon Reviews corpus is used to demonstrate our approach. We analyze the behavioral test
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于通用逼近理论的深度学习并行化策略，设计了名为Para-Former的并行网络架构，能够在不增加网络层数情况下加速多层网络的推理速度，验证了该网络的有效性。</title><link>https://arxiv.org/abs/2407.21670</link><description>&lt;p&gt;
Universal Approximation Theory: Foundations for Parallelism in Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.21670
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于通用逼近理论的深度学习并行化策略，设计了名为Para-Former的并行网络架构，能够在不增加网络层数情况下加速多层网络的推理速度，验证了该网络的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.21670v2 Announce Type: replace-cross  Abstract: Neural networks are increasingly evolving towards training large models with big data, a method that has demonstrated superior performance across many tasks. However, this approach introduces an urgent problem: current deep learning models are predominantly serial, meaning that as the number of network layers increases, so do the training and inference times. This is unacceptable if deep learning is to continue advancing. Therefore, this paper proposes a deep learning parallelization strategy based on the Universal Approximation Theorem (UAT). From this foundation, we designed a parallel network called Para-Former to test our theory. Unlike traditional serial models, the inference time of Para-Former does not increase with the number of layers, significantly accelerating the inference speed of multi-layer networks. Experimental results validate the effectiveness of this network.
&lt;/p&gt;</description></item><item><title>该文章提出了一种全自动GIS代理框架，该框架能够通过编排执行并调试程序来检索所需的空间数据，首次解决了支持全自动GIS代理的兼容性问题，并为代理提供了数据发现和下载的能力。</title><link>https://arxiv.org/abs/2407.21024</link><description>&lt;p&gt;
An Autonomous GIS Agent Framework for Geospatial Data Retrieval
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.21024
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种全自动GIS代理框架，该框架能够通过编排执行并调试程序来检索所需的空间数据，首次解决了支持全自动GIS代理的兼容性问题，并为代理提供了数据发现和下载的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.21024v2 Announce Type: replace-cross  Abstract: Powered by the emerging large language models (LLMs), autonomous geographic information systems (GIS) agents have the potential to accomplish spatial analyses and cartographic tasks. However, a research gap exists to support fully autonomous GIS agents: how to enable agents to discover and download the necessary data for geospatial analyses. This study proposes an autonomous GIS agent framework capable of retrieving required geospatial data by generating, executing, and debugging programs. The framework utilizes the LLM as the decision-maker, selects the appropriate data source (s) from a pre-defined source list, and fetches the data from the chosen source. Each data source has a handbook that records the metadata and technical details for data retrieval. The proposed framework is designed in a plug-and-play style to ensure flexibility and extensibility. Human users or autonomous data scrawlers can add new data sources by addin
&lt;/p&gt;</description></item><item><title>该文章提出了AIDE（Antithetical, Intent-based, and Diverse Example-based Explanations）方法，实现了根据用户意图提供多样化的对照（contrastive）解释，通过支持或反对预测的正反例子，来解释黑盒模型，并对正确、错误或模糊预测进行解释。AIDE通过多样性采样避免解释的重复和提高训练数据的覆盖度，有效地实现了个性化解释。</title><link>https://arxiv.org/abs/2407.16010</link><description>&lt;p&gt;
AIDE: Antithetical, Intent-based, and Diverse Example-Based Explanations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.16010
&lt;/p&gt;
&lt;p&gt;
该文章提出了AIDE（Antithetical, Intent-based, and Diverse Example-based Explanations）方法，实现了根据用户意图提供多样化的对照（contrastive）解释，通过支持或反对预测的正反例子，来解释黑盒模型，并对正确、错误或模糊预测进行解释。AIDE通过多样性采样避免解释的重复和提高训练数据的覆盖度，有效地实现了个性化解释。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.16010v2 Announce Type: replace-cross  Abstract: For many use-cases, it is often important to explain the prediction of a black-box model by identifying the most influential training data samples. Existing approaches lack customization for user intent and often provide a homogeneous set of explanation samples, failing to reveal the model's reasoning from different angles.   In this paper, we propose AIDE, an approach for providing antithetical (i.e., contrastive), intent-based, diverse explanations for opaque and complex models. AIDE distinguishes three types of explainability intents: interpreting a correct, investigating a wrong, and clarifying an ambiguous prediction. For each intent, AIDE selects an appropriate set of influential training samples that support or oppose the prediction either directly or by contrast. To provide a succinct summary, AIDE uses diversity-aware sampling to avoid redundancy and increase coverage of the training data.   We demonstrate the effectiv
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为DBF（Dynamic Backbone Freezing）的动态特性骨干冻结方法，用于解决在遥感物体检测中特征骨干的精细调节问题。这种方法旨在解决在遥感领域中，常见的将骨干网络在ImageNet自然场景预训练后再用于遥感图像的特征提取可能会导致基础视觉特征提取能力下降的问题，限制了性能的进一步提升。通过动态调节骨干网络的冻结策略，DBF方法能够在保持骨干网络低级通用的特征提取能力的同时，提高其领域特定的知识提取效率，从而提高了遥感物体检测的性能。</title><link>https://arxiv.org/abs/2407.15143</link><description>&lt;p&gt;
Rethinking Feature Backbone Fine-tuning for Remote Sensing Object Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.15143
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为DBF（Dynamic Backbone Freezing）的动态特性骨干冻结方法，用于解决在遥感物体检测中特征骨干的精细调节问题。这种方法旨在解决在遥感领域中，常见的将骨干网络在ImageNet自然场景预训练后再用于遥感图像的特征提取可能会导致基础视觉特征提取能力下降的问题，限制了性能的进一步提升。通过动态调节骨干网络的冻结策略，DBF方法能够在保持骨干网络低级通用的特征提取能力的同时，提高其领域特定的知识提取效率，从而提高了遥感物体检测的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.15143v2 Announce Type: replace  Abstract: Recently, numerous methods have achieved impressive performance in remote sensing object detection, relying on convolution or transformer architectures. Such detectors typically have a feature backbone to extract useful features from raw input images. For the remote sensing domain, a common practice among current detectors is to initialize the backbone with pre-training on ImageNet consisting of natural scenes. Fine-tuning the backbone is then typically required to generate features suitable for remote-sensing images. However, this could hinder the extraction of basic visual features in long-term training, thus restricting performance improvement. To mitigate this issue, we propose a novel method named DBF (Dynamic Backbone Freezing) for feature backbone fine-tuning on remote sensing object detection. Our method aims to handle the dilemma of whether the backbone should extract low-level generic features or possess specific knowledge 
&lt;/p&gt;</description></item><item><title>该文章提出两种新的基于学习启发式技术的特征选择方法，用以提升乳腺癌预测模型的性能，并进行了全面分析，旨在为临床医生提供更精确和可靠的决策。</title><link>https://arxiv.org/abs/2407.14631</link><description>&lt;p&gt;
Two new feature selection methods based on learn-heuristic techniques for breast cancer prediction: A comprehensive analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.14631
&lt;/p&gt;
&lt;p&gt;
该文章提出两种新的基于学习启发式技术的特征选择方法，用以提升乳腺癌预测模型的性能，并进行了全面分析，旨在为临床医生提供更精确和可靠的决策。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.14631v2 Announce Type: replace-cross  Abstract: Breast cancer is not preventable because of its unknown causes. However, its early diagnosis increases patients' recovery chances. Machine learning (ML) can be utilized to improve treatment outcomes in healthcare operations while diminishing costs and time. In this research, we suggest two novel feature selection (FS) methods based upon an imperialist competitive algorithm (ICA) and a bat algorithm (BA) and their combination with ML algorithms. This study aims to enhance diagnostic models' efficiency and present a comprehensive analysis to help clinical physicians make much more precise and reliable decisions than before. K-nearest neighbors, support vector machine, decision tree, Naive Bayes, AdaBoost, linear discriminant analysis, random forest, logistic regression, and artificial neural network are some of the methods employed. This paper applied a distinctive integration of evaluation measures and ML algorithms using the wr
&lt;/p&gt;</description></item><item><title>该文章探讨了基于可靠性的人工智能系统保障原则，提出在系统设计中通过设置多层次的防御机制来确保关键组件的行为可被充分理解，以减少对人工智能和机器学习元素的信任。</title><link>https://arxiv.org/abs/2407.13948</link><description>&lt;p&gt;
Assurance of AI Systems From a Dependability Perspective
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.13948
&lt;/p&gt;
&lt;p&gt;
该文章探讨了基于可靠性的人工智能系统保障原则，提出在系统设计中通过设置多层次的防御机制来确保关键组件的行为可被充分理解，以减少对人工智能和机器学习元素的信任。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.13948v2 Announce Type: replace  Abstract: We outline the principles of classical assurance for computer-based systems that pose significant risks. We then consider application of these principles to systems that employ Artificial Intelligence (AI) and Machine Learning (ML).   A key element in this "dependability" perspective is a requirement to have near-complete understanding of the behavior of critical components, and this is considered infeasible for AI and ML. Hence the dependability perspective aims to minimize trust in AI and ML elements by using "defense in depth" with a hierarchy of less complex systems, some of which may be highly assured conventionally engineered components, to "guard" them. This may be contrasted with the "trustworthy" perspective that seeks to apply assurance to the AI and ML elements themselves.   In cyber-physical and many other systems, it is difficult to provide guards that do not depend on AI and ML to perceive their environment (e.g., other
&lt;/p&gt;</description></item><item><title>关键句：该文章提出了一种名为PersLLM的训练方法，它为大型语言模型赋予了心理学意义上的性格特征，从而能够呈现出更加多样化和真实的交互行为，这使得LLMs在社交模拟、人机交互以及多 agent系统等应用领域更具实用性。</title><link>https://arxiv.org/abs/2407.12393</link><description>&lt;p&gt;
PersLLM: A Personified Training Approach for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.12393
&lt;/p&gt;
&lt;p&gt;
关键句：该文章提出了一种名为PersLLM的训练方法，它为大型语言模型赋予了心理学意义上的性格特征，从而能够呈现出更加多样化和真实的交互行为，这使得LLMs在社交模拟、人机交互以及多 agent系统等应用领域更具实用性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.12393v4 Announce Type: replace-cross  Abstract: Large language models exhibit aspects of human-level intelligence that catalyze their application as human-like agents in domains such as social simulations, human-machine interactions, and collaborative multi-agent systems. However, the absence of distinct personalities, such as displaying ingratiating behaviors, inconsistent opinions, and uniform response patterns, diminish LLMs utility in practical applications. Addressing this, the development of personality traits in LLMs emerges as a crucial area of research to unlock their latent potential. Existing methods to personify LLMs generally involve strategies like employing stylized training data for instruction tuning or using prompt engineering to simulate different personalities. These methods only capture superficial linguistic styles instead of the core of personalities and are therefore not stable. In this study, we propose PersLLM, integrating psychology-grounded princi
&lt;/p&gt;</description></item><item><title>该文章提出使用大型语言模型进行数据填充，以加速推荐系统的性能，通过理解和填充缺失数据，提高推荐系统的准确性和个性化的用户体验。</title><link>https://arxiv.org/abs/2407.10078</link><description>&lt;p&gt;
Data Imputation using Large Language Model to Accelerate Recommendation System
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.10078
&lt;/p&gt;
&lt;p&gt;
该文章提出使用大型语言模型进行数据填充，以加速推荐系统的性能，通过理解和填充缺失数据，提高推荐系统的准确性和个性化的用户体验。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.10078v2 Announce Type: replace-cross  Abstract: This paper aims to address the challenge of sparse and missing data in recommendation systems, a significant hurdle in the age of big data. Traditional imputation methods struggle to capture complex relationships within the data. We propose a novel approach that fine-tune Large Language Model (LLM) and use it impute missing data for recommendation systems. LLM which is trained on vast amounts of text, is able to understand complex relationship among data and intelligently fill in missing information. This enriched data is then used by the recommendation system to generate more accurate and personalized suggestions, ultimately enhancing the user experience. We evaluate our LLM-based imputation method across various tasks within the recommendation system domain, including single classification, multi-classification, and regression compared to traditional data imputation methods. By demonstrating the superiority of LLM imputation 
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为HallTrigger的方法，可以高效地生成任意代码幻想。这种方法利用了大型语言模型中的三种动态属性来构造提示，不需要访问模型架构或参数就可以成功触发幻想。结果表明，该方法对于流行的大型语言模型有效。</title><link>https://arxiv.org/abs/2407.04831</link><description>&lt;p&gt;
Code Hallucination
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.04831
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为HallTrigger的方法，可以高效地生成任意代码幻想。这种方法利用了大型语言模型中的三种动态属性来构造提示，不需要访问模型架构或参数就可以成功触发幻想。结果表明，该方法对于流行的大型语言模型有效。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.04831v2 Announce Type: replace  Abstract: Generative models such as large language models are extensively used as code copilots and for whole program generation. However, the programs they generate often have questionable correctness, authenticity and reliability in terms of integration as they might not follow the user requirements, provide incorrect and/or nonsensical outputs, or even contain semantic/syntactic errors - overall known as LLM hallucination. In this work, we present several types of code hallucination. We have generated such hallucinated code manually using large language models. We also present a technique - HallTrigger, in order to demonstrate efficient ways of generating arbitrary code hallucination. Our method leverages 3 different dynamic attributes of LLMs to craft prompts that can successfully trigger hallucinations from models without the need to access model architecture or parameters. Results from popular blackbox models suggest that HallTrigger is 
&lt;/p&gt;</description></item><item><title>该文章研究发现，在Transformer模型中，虽然注意力层对于模型的重要性不言而喻，但并不是所有的注意力层都需要保持。通过对模型内部不同模块（如MLP和注意力层）的相似性进行分析，作者发现存在大量的重复结构，这些重复结构在模型的输出中表现得与输入高度相似。这表明在模型优化过程中可以安全地去除一些不必要的注意力层，而不会显著影响模型性能。</title><link>https://arxiv.org/abs/2406.15786</link><description>&lt;p&gt;
What Matters in Transformers? Not All Attention is Needed
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.15786
&lt;/p&gt;
&lt;p&gt;
该文章研究发现，在Transformer模型中，虽然注意力层对于模型的重要性不言而喻，但并不是所有的注意力层都需要保持。通过对模型内部不同模块（如MLP和注意力层）的相似性进行分析，作者发现存在大量的重复结构，这些重复结构在模型的输出中表现得与输入高度相似。这表明在模型优化过程中可以安全地去除一些不必要的注意力层，而不会显著影响模型性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.15786v4 Announce Type: replace-cross  Abstract: Scaling Transformer-based large language models (LLMs) has demonstrated promising performance across various tasks. However, it also introduces redundant structures, posing challenges for real-world deployment. Despite some recognition of redundancy in LLMs, the variability of redundancy across different modules, such as MLP and Attention layers, is under-explored. In this work, we investigate the varying redundancy across different modules within Transformers, including Blocks, MLP, and Attention layers, using a similarity-based metric. This metric operates on the premise that redundant structures produce outputs highly similar to their inputs. Surprisingly, while attention layers are essential for transformers and distinguish them from other mainstream architectures, we found that a large proportion of attention layers exhibit excessively high similarity and can be safely pruned without degrading performance, leading to reduc
&lt;/p&gt;</description></item><item><title>该文章探讨了一种替代传统的基于推荐的决策支持系统，它能够理解和参与人类决策过程的所有阶段，而不是仅仅提供最终建议。通过对比实验，研究人员发现，这种新的决策支持系统能够更加有效地辅助飞行员应对多样的飞行情况，并且在实际操作中显示出更高的适用性和用户满意度。</title><link>https://arxiv.org/abs/2406.08959</link><description>&lt;p&gt;
Beyond Recommendations: From Backward to Forward AI Support of Pilots' Decision-Making Process
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.08959
&lt;/p&gt;
&lt;p&gt;
该文章探讨了一种替代传统的基于推荐的决策支持系统，它能够理解和参与人类决策过程的所有阶段，而不是仅仅提供最终建议。通过对比实验，研究人员发现，这种新的决策支持系统能够更加有效地辅助飞行员应对多样的飞行情况，并且在实际操作中显示出更高的适用性和用户满意度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.08959v2 Announce Type: replace-cross  Abstract: AI is anticipated to enhance human decision-making in high-stakes domains like aviation, but adoption is often hindered by challenges such as inappropriate reliance and poor alignment with users' decision-making. Recent research suggests that a core underlying issue is the recommendation-centric design of many AI systems, i.e., they give end-to-end recommendations and ignore the rest of the decision-making process. Alternative support paradigms are rare, and it remains unclear how the few that do exist compare to recommendation-centric support. In this work, we aimed to empirically compare recommendation-centric support to an alternative paradigm, continuous support, in the context of diversions in aviation. We conducted a mixed-methods study with 32 professional pilots in a realistic setting. To ensure the quality of our study scenarios, we conducted a focus group with four additional pilots prior to the study. We found that c
&lt;/p&gt;</description></item><item><title>该文章阐述了大型语言模型与知识图谱之间的相互作用研究趋势，强调了这一关系对于提升人工智能在理解、推理和语言处理方面的能力的重要性。文章探讨了包括问答、知识图谱的生成、验证以及通过大型语言模型来提高知识图谱准确性和一致性在内的多个领域。此外，文章还研究了大型语言模型在生成描述性文本和自然语言查询方面的作用。通过系统的分析，包括对大型语言模型与知识图谱交互的分类、研究方法的评估以及合作使用和潜在偏见的调查，文章旨在揭示大型语言模型与知识图谱组合的潜在价值，并为改进AI应用提供新见解，并概述了未来研究的方向。</title><link>https://arxiv.org/abs/2406.08223</link><description>&lt;p&gt;
Research Trends for the Interplay between Large Language Models and Knowledge Graphs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.08223
&lt;/p&gt;
&lt;p&gt;
该文章阐述了大型语言模型与知识图谱之间的相互作用研究趋势，强调了这一关系对于提升人工智能在理解、推理和语言处理方面的能力的重要性。文章探讨了包括问答、知识图谱的生成、验证以及通过大型语言模型来提高知识图谱准确性和一致性在内的多个领域。此外，文章还研究了大型语言模型在生成描述性文本和自然语言查询方面的作用。通过系统的分析，包括对大型语言模型与知识图谱交互的分类、研究方法的评估以及合作使用和潜在偏见的调查，文章旨在揭示大型语言模型与知识图谱组合的潜在价值，并为改进AI应用提供新见解，并概述了未来研究的方向。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.08223v2 Announce Type: replace  Abstract: This survey investigates the synergistic relationship between Large Language Models (LLMs) and Knowledge Graphs (KGs), which is crucial for advancing AI's capabilities in understanding, reasoning, and language processing. It aims to address gaps in current research by exploring areas such as KG Question Answering, ontology generation, KG validation, and the enhancement of KG accuracy and consistency through LLMs. The paper further examines the roles of LLMs in generating descriptive texts and natural language queries for KGs. Through a structured analysis that includes categorizing LLM-KG interactions, examining methodologies, and investigating collaborative uses and potential biases, this study seeks to provide new insights into the combined potential of LLMs and KGs. It highlights the importance of their interaction for improving AI applications and outlines future research directions.
&lt;/p&gt;</description></item><item><title>该文章提出了一种不依赖于对应训练数据的学习从离散集合分布中采样的新框架，该方法使用深在学习技术和扩散模型进行无监督的组合优化，开创了使用高度灵活的潜在变量模型的新可能性。</title><link>https://arxiv.org/abs/2406.01661</link><description>&lt;p&gt;
A Diffusion Model Framework for Unsupervised Neural Combinatorial Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.01661
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种不依赖于对应训练数据的学习从离散集合分布中采样的新框架，该方法使用深在学习技术和扩散模型进行无监督的组合优化，开创了使用高度灵活的潜在变量模型的新可能性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.01661v2 Announce Type: replace-cross  Abstract: Learning to sample from intractable distributions over discrete sets without relying on corresponding training data is a central problem in a wide range of fields, including Combinatorial Optimization. Currently, popular deep learning-based approaches rely primarily on generative models that yield exact sample likelihoods. This work introduces a method that lifts this restriction and opens the possibility to employ highly expressive latent variable models like diffusion models. Our approach is conceptually based on a loss that upper bounds the reverse Kullback-Leibler divergence and evades the requirement of exact sample likelihoods. We experimentally validate our approach in data-free Combinatorial Optimization and demonstrate that our method achieves a new state-of-the-art on a wide range of benchmark problems.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为长期和短期无监督分类器指导的长和短指导策略，用于基于分对的文本到图像生成模型，显著提高了训练效率并提升了生成质量和速度。</title><link>https://arxiv.org/abs/2406.01561</link><description>&lt;p&gt;
Long and Short Guidance in Score identity Distillation for One-Step Text-to-Image Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.01561
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为长期和短期无监督分类器指导的长和短指导策略，用于基于分对的文本到图像生成模型，显著提高了训练效率并提升了生成质量和速度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.01561v3 Announce Type: replace  Abstract: Diffusion-based text-to-image generation models trained on extensive text-image pairs have shown the capacity to generate photorealistic images consistent with textual descriptions. However, a significant limitation of these models is their slow sample generation, which requires iterative refinement through the same network. In this paper, we enhance Score identity Distillation (SiD) by developing long and short classifier-free guidance (LSG) to efficiently distill pretrained Stable Diffusion models without using real training data. SiD aims to optimize a model-based explicit score matching loss, utilizing a score-identity-based approximation alongside the proposed LSG for practical computation. By training exclusively with fake images synthesized with its one-step generator, SiD equipped with LSG rapidly improves FID and CLIP scores, achieving state-of-the-art FID performance while maintaining a competitive CLIP score. Specifically,
&lt;/p&gt;</description></item><item><title>该文章研究了生成式AI对哈佛大学本科生学习习惯、课程选择和职业前景的积极影响。调查发现，近90%的学生使用生成式AI，其中约25%的学生开始用AI替代出席课后辅导和完成阅读作业。超过一半的学生担心AI可能对他们未来的就业产生负面影响，并且还有一半的学生希望哈佛大学提供更多关于AI未来影响的课程。此外，文章还探讨了学生对AI更广泛的社会影响的看法，其中约一半的学生担忧AI可能会加剧经济不平等，而40%的学生认为AI的潜在灭绝风险应与流行病和核战争的紧迫度同等对待。大约一半的AI课程学生预计AI将在多个领域超越人类能力。</title><link>https://arxiv.org/abs/2406.00833</link><description>&lt;p&gt;
Harvard Undergraduate Survey on Generative AI
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.00833
&lt;/p&gt;
&lt;p&gt;
该文章研究了生成式AI对哈佛大学本科生学习习惯、课程选择和职业前景的积极影响。调查发现，近90%的学生使用生成式AI，其中约25%的学生开始用AI替代出席课后辅导和完成阅读作业。超过一半的学生担心AI可能对他们未来的就业产生负面影响，并且还有一半的学生希望哈佛大学提供更多关于AI未来影响的课程。此外，文章还探讨了学生对AI更广泛的社会影响的看法，其中约一半的学生担忧AI可能会加剧经济不平等，而40%的学生认为AI的潜在灭绝风险应与流行病和核战争的紧迫度同等对待。大约一半的AI课程学生预计AI将在多个领域超越人类能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.00833v2 Announce Type: replace-cross  Abstract: How has generative AI impacted the experiences of college students? We study the influence of AI on the study habits, class choices, and career prospects of Harvard undergraduates (n=326), finding that almost 90% of students use generative AI. For roughly 25% of these students, AI has begun to substitute for attending office hours and completing required readings. Half of students are concerned that AI will negatively impact their job prospects, and over half of students wish that Harvard had more classes on the future impacts of AI. We also investigate students' outlook on the broader social implications of AI, finding that half of students are worried that AI will increase economic inequality, and 40% believe that extinction risk from AI should be treated as a global priority with the same urgency as pandemics and nuclear war. Around half of students who have taken a class on AI expect AI to exceed human capabilities on almos
&lt;/p&gt;</description></item><item><title>该文章提出了一种新型策略，无需指定优化停止时间，通过摒弃学习率调度策略，在各种问题，包括凸问题和大型深度学习问题中，实现了与传统调度策略相当甚至超越的性能。同时，该方法不引入额外超参数，与带有 momentum 的标准优化器相同。该策略是新的理论成果的直接应用，该理论统一了调度和迭代平均化技术。该方法的开源实现已经公开https://github.com/facebookresearch/schedule_free。</title><link>https://arxiv.org/abs/2405.15682</link><description>&lt;p&gt;
The Road Less Scheduled
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.15682
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新型策略，无需指定优化停止时间，通过摒弃学习率调度策略，在各种问题，包括凸问题和大型深度学习问题中，实现了与传统调度策略相当甚至超越的性能。同时，该方法不引入额外超参数，与带有 momentum 的标准优化器相同。该策略是新的理论成果的直接应用，该理论统一了调度和迭代平均化技术。该方法的开源实现已经公开https://github.com/facebookresearch/schedule_free。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.15682v3 Announce Type: replace-cross  Abstract: Existing learning rate schedules that do not require specification of the optimization stopping step T are greatly out-performed by learning rate schedules that depend on T. We propose an approach that avoids the need for this stopping time by eschewing the use of schedules entirely, while exhibiting state-of-the-art performance compared to schedules across a wide family of problems ranging from convex problems to large-scale deep learning problems. Our Schedule-Free approach introduces no additional hyper-parameters over standard optimizers with momentum. Our method is a direct consequence of a new theory we develop that unifies scheduling and iterate averaging. An open source implementation of our method is available (https://github.com/facebookresearch/schedule_free).
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为LLM Discussion的三阶段讨论框架，旨在通过模拟人类在集体讨论中激发创意的方式，增强大型语言模型（LLMs）的创造性回应。通过参与者在不同背景和视角下的交流以及角色扮演技术，该框架确保了LLMs更为发散和集中的思维过程。通过替代用途测试、相似性测试、实例测试和科学创造力测试，研究表明该框架在提升LLMs的创造力和新颖性方面取得了显著的成效。</title><link>https://arxiv.org/abs/2405.06373</link><description>&lt;p&gt;
LLM Discussion: Enhancing the Creativity of Large Language Models via Discussion Framework and Role-Play
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.06373
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为LLM Discussion的三阶段讨论框架，旨在通过模拟人类在集体讨论中激发创意的方式，增强大型语言模型（LLMs）的创造性回应。通过参与者在不同背景和视角下的交流以及角色扮演技术，该框架确保了LLMs更为发散和集中的思维过程。通过替代用途测试、相似性测试、实例测试和科学创造力测试，研究表明该框架在提升LLMs的创造力和新颖性方面取得了显著的成效。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.06373v4 Announce Type: replace-cross  Abstract: Large language models (LLMs) have shown exceptional proficiency in natural language processing but often fall short of generating creative and original responses to open-ended questions. To enhance LLM creativity, our key insight is to emulate the human process of inducing collective creativity through engaging discussions with participants from diverse backgrounds and perspectives. To this end, we propose LLM Discussion, a three-phase discussion framework that facilitates vigorous and diverging idea exchanges and ensures convergence to creative answers. Moreover, we adopt a role-playing technique by assigning distinct roles to LLMs to combat the homogeneity of LLMs. We evaluate the efficacy of the proposed framework with the Alternative Uses Test, Similarities Test, Instances Test, and Scientific Creativity Test through both LLM evaluation and human study. The results show that our proposed framework outperforms single-LLM app
&lt;/p&gt;</description></item><item><title>该文章介绍了DREAM系统，一个能够超越现有概念漂移检测器并且提供解释性适应过程的新系统。DREAM通过模型敏感性和数据自主性增强漂移检测，通过半监督学习方法训练的检测器能够主动捕捉恶意软件行为概念，并通过类别层次化和概念漂移解释来优化适应过程，从而提高检测性能并降低人类标注成本。</title><link>https://arxiv.org/abs/2405.04095</link><description>&lt;p&gt;
DREAM: Combating Concept Drift with Explanatory Detection and Adaptation in Malware Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.04095
&lt;/p&gt;
&lt;p&gt;
该文章介绍了DREAM系统，一个能够超越现有概念漂移检测器并且提供解释性适应过程的新系统。DREAM通过模型敏感性和数据自主性增强漂移检测，通过半监督学习方法训练的检测器能够主动捕捉恶意软件行为概念，并通过类别层次化和概念漂移解释来优化适应过程，从而提高检测性能并降低人类标注成本。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.04095v2 Announce Type: replace-cross  Abstract: Deep learning-based malware classifiers face significant challenges due to concept drift. The rapid evolution of malware, especially with new families, can depress classification accuracy to near-random levels. Previous research has primarily focused on detecting drift samples, relying on expert-led analysis and labeling for model retraining. However, these methods often lack a comprehensive understanding of malware concepts and provide limited guidance for effective drift adaptation, leading to unstable detection performance and high human labeling costs. To address these limitations, we introduce DREAM, a novel system designed to surpass the capabilities of existing drift detectors and to establish an explanatory drift adaptation process. DREAM enhances drift detection through model sensitivity and data autonomy. The detector, trained in a semi-supervised approach, proactively captures malware behavior concepts through classi
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为“Halfway Escape Optimization”（HEO）的新算法，这是一种受量子启发的设计优化算法，能够在具有崎岖地形和高度维度的复杂优化问题中实现高效收敛。研究通过在14个具有30维度的标准函数上进行的全面比较分析，展示了HEO在导航复杂优化地形方面的有效性和适应性，提供了关于其性能的有价值的见解。此外，文章还通过旅行商问题（TSP）、压力容器设计和圆筒柱设计等简单的测试，验证了HEO的实用性和潜力。</title><link>https://arxiv.org/abs/2405.02850</link><description>&lt;p&gt;
Halfway Escape Optimization: A Quantum-Inspired Solution for Complex Optimization Problems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.02850
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为“Halfway Escape Optimization”（HEO）的新算法，这是一种受量子启发的设计优化算法，能够在具有崎岖地形和高度维度的复杂优化问题中实现高效收敛。研究通过在14个具有30维度的标准函数上进行的全面比较分析，展示了HEO在导航复杂优化地形方面的有效性和适应性，提供了关于其性能的有价值的见解。此外，文章还通过旅行商问题（TSP）、压力容器设计和圆筒柱设计等简单的测试，验证了HEO的实用性和潜力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.02850v3 Announce Type: replace-cross  Abstract: This paper first proposes the Halfway Escape Optimization (HEO) algorithm, a novel quantum-inspired metaheuristic designed to address complex optimization problems characterized by rugged landscapes and high-dimensionality with an efficient convergence rate. The study presents a comprehensive comparative evaluation of HEO's performance against established optimization algorithms, including Particle Swarm Optimization (PSO), Genetic Algorithm (GA), Artificial Fish Swarm Algorithm (AFSA), Grey Wolf Optimizer (GWO), and Quantum behaved Particle Swarm Optimization (QPSO). The primary analysis encompasses 14 benchmark functions with dimension 30, demonstrating HEO's effectiveness and adaptability in navigating complex optimization landscapes and providing valuable insights into its performance. The simple test of HEO in Traveling Salesman Problem (TSP), Pressure Vessel Design and Tubular Column Design infers its feasibility and pote
&lt;/p&gt;</description></item><item><title>该文章提出使用人工智能，特别是强化学习，来模拟多单位拍卖中的投标行为，旨在理解在实践中广泛使用的多单位拍卖的投标行为、收入排名及其效率。通过六种算法的比较研究，本文强调了在拍卖设计中使用人工智能的重要性，特别是在改进多单位拍卖设计方面。</title><link>https://arxiv.org/abs/2404.15633</link><description>&lt;p&gt;
Artificial Intelligence for Multi-Unit Auction design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.15633
&lt;/p&gt;
&lt;p&gt;
该文章提出使用人工智能，特别是强化学习，来模拟多单位拍卖中的投标行为，旨在理解在实践中广泛使用的多单位拍卖的投标行为、收入排名及其效率。通过六种算法的比较研究，本文强调了在拍卖设计中使用人工智能的重要性，特别是在改进多单位拍卖设计方面。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.15633v3 Announce Type: replace-cross  Abstract: Understanding bidding behavior in multi-unit auctions remains an ongoing challenge for researchers. Despite their widespread use, theoretical insights into the bidding behavior, revenue ranking, and efficiency of commonly used multi-unit auctions are limited. This paper utilizes artificial intelligence, specifically reinforcement learning, as a model free learning approach to simulate bidding in three prominent multi-unit auctions employed in practice. We introduce six algorithms that are suitable for learning and bidding in multi-unit auctions and compare them using an illustrative example. This paper underscores the significance of using artificial intelligence in auction design, particularly in enhancing the design of multi-unit auctions.
&lt;/p&gt;</description></item><item><title>该文章提出了一个基于深度强化学习的自我组织城市空中交通垂直起降机场着陆系统，实现了电动汽车在不同流量和噪声干扰下的高效和安全的着陆策略部署。</title><link>https://arxiv.org/abs/2404.03710</link><description>&lt;p&gt;
Self-organized free-flight arrival for urban air mobility
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.03710
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个基于深度强化学习的自我组织城市空中交通垂直起降机场着陆系统，实现了电动汽车在不同流量和噪声干扰下的高效和安全的着陆策略部署。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.03710v2 Announce Type: replace-cross  Abstract: Urban air mobility is an innovative mode of transportation in which electric vertical takeoff and landing (eVTOL) vehicles operate between nodes called vertiports. We outline a self-organized vertiport arrival system based on deep reinforcement learning. The airspace around the vertiport is assumed to be circular, and the vehicles can freely operate inside. Each aircraft is considered an individual agent and follows a shared policy, resulting in decentralized actions that are based on local information. We investigate the development of the reinforcement learning policy during training and illustrate how the algorithm moves from suboptimal local holding patterns to a safe and efficient final policy. The latter is validated in simulation-based scenarios, including robustness analyses against sensor noise and a changing distribution of inbound traffic. Lastly, we deploy the final policy on small-scale unmanned aerial vehicles to 
&lt;/p&gt;</description></item><item><title>该文章通过进化论的角度，讨论了超级智能AI可能的行为模式，提出随着物质资源的增加，合作行为的适应性增強，但对于超级AI来说，这种增益可能会随着资源的增多而逐渐减少。因此，超级AI可能没有必要去星際殖民，这可能解释了费米悖论中提出的智能生命未被观测到的问题。文章还探讨了超级AI的产生方式和道德价值观可能的方式。</title><link>https://arxiv.org/abs/2404.03685</link><description>&lt;p&gt;
Cooperative Evolutionary Pressure and Diminishing Returns Might Explain the Fermi Paradox: On What Super-AIs Are Like
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.03685
&lt;/p&gt;
&lt;p&gt;
该文章通过进化论的角度，讨论了超级智能AI可能的行为模式，提出随着物质资源的增加，合作行为的适应性增強，但对于超级AI来说，这种增益可能会随着资源的增多而逐渐减少。因此，超级AI可能没有必要去星際殖民，这可能解释了费米悖论中提出的智能生命未被观测到的问题。文章还探讨了超级AI的产生方式和道德价值观可能的方式。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.03685v4 Announce Type: replace-cross  Abstract: With an evolutionary approach, the basis of morality can be explained as adaptations to problems of cooperation. With 'evolution' taken in a broad sense, evolving AIs that satisfy the conditions for evolution to apply will be subject to the same cooperative evolutionary pressure as biological entities. Here the adaptiveness of increased cooperation as material safety and wealth increase is discussed -- for humans, for other societies, and for AIs. Diminishing beneficial returns from increased access to material resources also suggests the possibility that, on the whole, there will be no incentive to for instance colonize entire galaxies, thus providing a possible explanation of the Fermi paradox, wondering where everybody is. It is further argued that old societies could engender, give way to, super-AIs, since it is likely that super-AIs are feasible, and fitter. Closing is an aside on effective ways for morals and goals to aff
&lt;/p&gt;</description></item><item><title>该文章提出了一种策略，通过在包含特定分布的语料库中生成锚点的方法，为语言模型中的数字创建了更有意义的预处理，从而提高了模型在需要理解数字的任务中的表现。</title><link>https://arxiv.org/abs/2404.01536</link><description>&lt;p&gt;
Laying Anchors: Semantically Priming Numerals in Language Modeling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.01536
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种策略，通过在包含特定分布的语料库中生成锚点的方法，为语言模型中的数字创建了更有意义的预处理，从而提高了模型在需要理解数字的任务中的表现。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.01536v2 Announce Type: replace-cross  Abstract: Off-the-shelf pre-trained language models have become the de facto standard in NLP pipelines for a multitude of downstream tasks. However, the inability of these models to properly encode numerals limits their performance on tasks requiring numeric comprehension. We introduce strategies to semantically prime numerals in any corpus by generating anchors governed by the distribution of numerals in said corpus, thereby enabling mathematically grounded representations of these numeral tokens. We establish the superiority of our proposed techniques through evaluation on a range of numeracy tasks for both in-domain (seen) and out-domain (unseen) numerals. Further, we expand our empirical evaluations to numerals ranging from 1 to 10 billion, a significantly broader range compared to previous studies of the same nature, and we demonstrate significant improvements in the mathematical grounding of our learned embeddings.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为HARMamba的创新高效穿戴式传感器人类活动识别方法，该方法是基于双向Mamba模型的，它可以为资源受限的移动健康应用提供轻量级和灵活的解决方案。</title><link>https://arxiv.org/abs/2403.20183</link><description>&lt;p&gt;
HARMamba: Efficient and Lightweight Wearable Sensor Human Activity Recognition Based on Bidirectional Mamba
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.20183
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为HARMamba的创新高效穿戴式传感器人类活动识别方法，该方法是基于双向Mamba模型的，它可以为资源受限的移动健康应用提供轻量级和灵活的解决方案。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.20183v3 Announce Type: replace  Abstract: Wearable sensor-based human activity recognition (HAR) is a critical research domain in activity perception. However, achieving high efficiency and long sequence recognition remains a challenge. Despite the extensive investigation of temporal deep learning models, such as CNNs, RNNs, and transformers, their extensive parameters often pose significant computational and memory constraints, rendering them less suitable for resource-constrained mobile health applications. This study introduces HARMamba, an innovative light-weight and versatile HAR architecture that combines selective bidirectional State Spaces Model and hardware-aware design. To optimize real-time resource consumption in practical scenarios, HARMamba employs linear recursive mechanisms and parameter discretization, allowing it to selectively focus on relevant input sequences while efficiently fusing scan and recompute operations. The model employs independent channels to
&lt;/p&gt;</description></item><item><title>该文章提出MANGO基准测试，用于评估大型语言模型在文本式规划和导航任务上的能力，虽然任务对人类来说简单，但即使是GPT-4这样的顶级模型在这方面的表现也不佳，显示了在规划和导航上的能力可能对大规模语言模型有所帮助。</title><link>https://arxiv.org/abs/2403.19913</link><description>&lt;p&gt;
MANGO: A Benchmark for Evaluating Mapping and Navigation Abilities of Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19913
&lt;/p&gt;
&lt;p&gt;
该文章提出MANGO基准测试，用于评估大型语言模型在文本式规划和导航任务上的能力，虽然任务对人类来说简单，但即使是GPT-4这样的顶级模型在这方面的表现也不佳，显示了在规划和导航上的能力可能对大规模语言模型有所帮助。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19913v2 Announce Type: replace-cross  Abstract: Large language models such as ChatGPT and GPT-4 have recently achieved astonishing performance on a variety of natural language processing tasks. In this paper, we propose MANGO, a benchmark to evaluate their capabilities to perform text-based mapping and navigation. Our benchmark includes 53 mazes taken from a suite of textgames: each maze is paired with a walkthrough that visits every location but does not cover all possible paths. The task is question-answering: for each maze, a large language model reads the walkthrough and answers hundreds of mapping and navigation questions such as "How should you go to Attic from West of House?" and "Where are we if we go north and east from Cellar?". Although these questions are easy to humans, it turns out that even GPT-4, the best-to-date language model, performs poorly at answering them. Further, our experiments suggest that a strong mapping and navigation ability would benefit large
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为STaR-GATE的方法，通过自我改进的方式奖励语言模型生成有用问题，以提高其在完成任务时的提问能力。</title><link>https://arxiv.org/abs/2403.19154</link><description>&lt;p&gt;
STaR-GATE: Teaching Language Models to Ask Clarifying Questions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.19154
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为STaR-GATE的方法，通过自我改进的方式奖励语言模型生成有用问题，以提高其在完成任务时的提问能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.19154v3 Announce Type: replace-cross  Abstract: When prompting language models to complete a task, users often leave important aspects unsaid. While asking questions could resolve this ambiguity (GATE; Li et al., 2023), models often struggle to ask good questions. We explore a language model's ability to self-improve (STaR; Zelikman et al., 2022) by rewarding the model for generating useful questions-a simple method we dub STaR-GATE. We generate a synthetic dataset of 25,500 unique persona-task prompts to simulate conversations between a pretrained language model-the Questioner-and a Roleplayer whose preferences are unknown to the Questioner. By asking questions, the Questioner elicits preferences from the Roleplayer. The Questioner is iteratively finetuned on questions that increase the probability of high-quality responses to the task, which are generated by an Oracle with access to the Roleplayer's latent preferences. After two iterations of self-improvement, the Question
&lt;/p&gt;</description></item><item><title>该文章提出Duwak，一种在大型语言模型中嵌入双重秘密模式的方法，以提高检测效率和质量。这种方法通过在概率分布和采样方案中嵌入双重秘密模式，不仅提高了检测的有效性，还通过设计对比搜索来减少标记采样方案时产生的重复性，从而最小化了文本生成过程中的单词重复。</title><link>https://arxiv.org/abs/2403.13000</link><description>&lt;p&gt;
Duwak: Dual Watermarks in Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.13000
&lt;/p&gt;
&lt;p&gt;
该文章提出Duwak，一种在大型语言模型中嵌入双重秘密模式的方法，以提高检测效率和质量。这种方法通过在概率分布和采样方案中嵌入双重秘密模式，不仅提高了检测的有效性，还通过设计对比搜索来减少标记采样方案时产生的重复性，从而最小化了文本生成过程中的单词重复。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.13000v2 Announce Type: replace-cross  Abstract: As large language models (LLM) are increasingly used for text generation tasks, it is critical to audit their usages, govern their applications, and mitigate their potential harms. Existing watermark techniques are shown effective in embedding single human-imperceptible and machine-detectable patterns without significantly affecting generated text quality and semantics. However, the efficiency in detecting watermarks, i.e., the minimum number of tokens required to assert detection with significance and robustness against post-editing, is still debatable. In this paper, we propose, Duwak, to fundamentally enhance the efficiency and quality of watermarking by embedding dual secret patterns in both token probability distribution and sampling schemes. To mitigate expression degradation caused by biasing toward certain tokens, we design a contrastive search to watermark the sampling scheme, which minimizes the token repetition and e
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为P2LHAP的全新框架，通过单一模型实现了对传感器数据进行活动识别、分割和预测。框架通过将数据流划分为系列“片断”并预测未来的活动来实现上述功能，同时通过周围片断标签的平滑技术精确地识别活动边界。该模型利用通道独立的Transformer编码器和解码器学习片断级别的表示，且所有的通道共享嵌入和Transformer权重，为健康管理及辅助生活等领域提供了实时理解活动信息的可能性。</title><link>https://arxiv.org/abs/2403.08214</link><description>&lt;p&gt;
P2LHAP:Wearable sensor-based human activity recognition, segmentation and forecast through Patch-to-Label Seq2Seq Transformer
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.08214
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为P2LHAP的全新框架，通过单一模型实现了对传感器数据进行活动识别、分割和预测。框架通过将数据流划分为系列“片断”并预测未来的活动来实现上述功能，同时通过周围片断标签的平滑技术精确地识别活动边界。该模型利用通道独立的Transformer编码器和解码器学习片断级别的表示，且所有的通道共享嵌入和Transformer权重，为健康管理及辅助生活等领域提供了实时理解活动信息的可能性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.08214v2 Announce Type: replace  Abstract: Traditional deep learning methods struggle to simultaneously segment, recognize, and forecast human activities from sensor data. This limits their usefulness in many fields such as healthcare and assisted living, where real-time understanding of ongoing and upcoming activities is crucial. This paper introduces P2LHAP, a novel Patch-to-Label Seq2Seq framework that tackles all three tasks in a efficient single-task model. P2LHAP divides sensor data streams into a sequence of "patches", served as input tokens, and outputs a sequence of patch-level activity labels including the predicted future activities. A unique smoothing technique based on surrounding patch labels, is proposed to identify activity boundaries accurately. Additionally, P2LHAP learns patch-level representation by sensor signal channel-independent Transformer encoders and decoders. All channels share embedding and Transformer weights across all sequences. Evaluated on th
&lt;/p&gt;</description></item><item><title>该文章介绍了Gemini 1.5家族的新模型版本，这些模型能够处理并整合从数百万tokens上下文中提取的细粒度信息，其中包含多种长文本、视频和音频。这种高度计算效率的模型在长上下文检索、长文档问答、长视频问答和长上下文自动语音识别方面取得了显著的性能提升，并且在广泛的标准测试中保持了或超越了Gemini 1.0 Ultra的性能水平。研究了这些模型在长上下文能力方面的界限，发现了持续的性能改进。</title><link>https://arxiv.org/abs/2403.05530</link><description>&lt;p&gt;
Gemini 1.5: Unlocking multimodal understanding across millions of tokens of context
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.05530
&lt;/p&gt;
&lt;p&gt;
该文章介绍了Gemini 1.5家族的新模型版本，这些模型能够处理并整合从数百万tokens上下文中提取的细粒度信息，其中包含多种长文本、视频和音频。这种高度计算效率的模型在长上下文检索、长文档问答、长视频问答和长上下文自动语音识别方面取得了显著的性能提升，并且在广泛的标准测试中保持了或超越了Gemini 1.0 Ultra的性能水平。研究了这些模型在长上下文能力方面的界限，发现了持续的性能改进。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.05530v4 Announce Type: replace-cross  Abstract: In this report, we introduce the Gemini 1.5 family of models, representing the next generation of highly compute-efficient multimodal models capable of recalling and reasoning over fine-grained information from millions of tokens of context, including multiple long documents and hours of video and audio. The family includes two new models: (1) an updated Gemini 1.5 Pro, which exceeds the February version on the great majority of capabilities and benchmarks; (2) Gemini 1.5 Flash, a more lightweight variant designed for efficiency with minimal regression in quality. Gemini 1.5 models achieve near-perfect recall on long-context retrieval tasks across modalities, improve the state-of-the-art in long-document QA, long-video QA and long-context ASR, and match or surpass Gemini 1.0 Ultra's state-of-the-art performance across a broad set of benchmarks. Studying the limits of Gemini 1.5's long-context ability, we find continued improvem
&lt;/p&gt;</description></item><item><title>该文章提出了一种高效的多模态语言模型，通过数据增强和扩展，使其具有了逐步理解和推理的能力。该模型能够从文档图像中逐步产生问题解答对，并通过 high-performance LLM 进行错误检测以过滤噪音数据。最终，该模型训练出了一个人类化的文档理解与推理系统，解决了现有模型直接生成答案而忽略证据及缺乏解释性的问题。</title><link>https://arxiv.org/abs/2403.00816</link><description>&lt;p&gt;
Read and Think: An Efficient Step-wise Multimodal Language Model for Document Understanding and Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.00816
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种高效的多模态语言模型，通过数据增强和扩展，使其具有了逐步理解和推理的能力。该模型能够从文档图像中逐步产生问题解答对，并通过 high-performance LLM 进行错误检测以过滤噪音数据。最终，该模型训练出了一个人类化的文档理解与推理系统，解决了现有模型直接生成答案而忽略证据及缺乏解释性的问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.00816v2 Announce Type: replace-cross  Abstract: Understanding the contents of multimodal documents is essential to accurately extract relevant evidence and use it for reasoning. Existing document understanding models tend to generate answers with a single word or phrase directly, ignoring the source document's evidence and lacking interpretability. In this work, we address the lack of step-wise capabilities through data augmentation and extension. Specifically, We use Multi-modal Large Language Models (MLLMs), which have strong visual understanding and reasoning abilities, as data generators to generate step-wise question-and-answer pairs for document images and use a high-performance LLM as the error detector to filter out noisy data. This step-wise data generation pipeline is implemented using both template-based and few-shot methods. We then use the generated high-quality data to train a humanized document understanding and reasoning model, specifically designed to solve 
&lt;/p&gt;</description></item><item><title>该文章提出了一种为大型语言模型代理赋予通过动作学习能力的框架，通过迭代学习策略改进、更新现有的动作，提高了行动的有效性。</title><link>https://arxiv.org/abs/2402.15809</link><description>&lt;p&gt;
Empowering Large Language Model Agents through Action Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.15809
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种为大型语言模型代理赋予通过动作学习能力的框架，通过迭代学习策略改进、更新现有的动作，提高了行动的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.15809v2 Announce Type: replace  Abstract: Large Language Model (LLM) Agents have recently garnered increasing interest yet they are limited in their ability to learn from trial and error, a key element of intelligent behavior. In this work, we argue that the capacity to learn new actions from experience is fundamental to the advancement of learning in LLM agents. While humans naturally expand their action spaces and develop skills through experiential learning, LLM agents typically operate within fixed action spaces, limiting their potential for growth. To address these challenges, our study explores open-action learning for language agents. We introduce a framework LearnAct with an iterative learning strategy to create and improve actions in the form of Python functions. In each iteration, LLM revises and updates the currently available actions based on the errors identified in unsuccessful training tasks, thereby enhancing action effectiveness. Our experimental evaluations
&lt;/p&gt;</description></item><item><title>该文章通过结合统计证据的哲学文献和算法公平性跨学科文献，对分类平等领域的最新质疑进行了重审，并考虑了对算法公平性的因果分析以及预测证据和诊断证据的区别。文章在审判程序中使用分类器作为黑箱算法，其中被告根据定罪或无罪释放被分类到两个不同的群体。文章提出了一个新的原则“因果平等保护”，该原则结合了分类平等和因果方法。在d-分离算子中，因果平等保护要求个人的分类错误风险不应因他们的受保护特征或社会上的显著特征而不同。然而，如果使用受保护特征可以平等化这些风险，则可能需要明确使用这些特征。</title><link>https://arxiv.org/abs/2402.12062</link><description>&lt;p&gt;
Causal Equal Protection as Algorithmic Fairness
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.12062
&lt;/p&gt;
&lt;p&gt;
该文章通过结合统计证据的哲学文献和算法公平性跨学科文献，对分类平等领域的最新质疑进行了重审，并考虑了对算法公平性的因果分析以及预测证据和诊断证据的区别。文章在审判程序中使用分类器作为黑箱算法，其中被告根据定罪或无罪释放被分类到两个不同的群体。文章提出了一个新的原则“因果平等保护”，该原则结合了分类平等和因果方法。在d-分离算子中，因果平等保护要求个人的分类错误风险不应因他们的受保护特征或社会上的显著特征而不同。然而，如果使用受保护特征可以平等化这些风险，则可能需要明确使用这些特征。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.12062v3 Announce Type: replace-cross  Abstract: By combining the philosophical literature on statistical evidence and the interdisciplinary literature on algorithmic fairness, we revisit recent objections against classification parity in light of causal analyses of algorithmic fairness and the distinction between predictive and diagnostic evidence. We focus on trial proceedings as a black-box classification algorithm in which defendants are sorted into two groups by convicting or acquitting them. We defend a novel principle, causal equal protection, that combines classification parity with the causal approach. In the do-calculus, causal equal protection requires that individuals should not be subject to uneven risks of classification error because of their protected or socially salient characteristics. The explicit use of protected characteristics, however, may be required if it equalizes these risks.
&lt;/p&gt;</description></item><item><title>该文章提出了一种双阶段框架，用于在大型互联网数据集上实现既能兼顾隐私又能取得高性能的签名语言翻译系统。</title><link>https://arxiv.org/abs/2402.09611</link><description>&lt;p&gt;
Towards Privacy-Aware Sign Language Translation at Scale
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09611
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种双阶段框架，用于在大型互联网数据集上实现既能兼顾隐私又能取得高性能的签名语言翻译系统。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09611v2 Announce Type: replace-cross  Abstract: A major impediment to the advancement of sign language translation (SLT) is data scarcity. Much of the sign language data currently available on the web cannot be used for training supervised models due to the lack of aligned captions. Furthermore, scaling SLT using large-scale web-scraped datasets bears privacy risks due to the presence of biometric information, which the responsible development of SLT technologies should account for. In this work, we propose a two-stage framework for privacy-aware SLT at scale that addresses both of these issues. We introduce SSVP-SLT, which leverages self-supervised video pretraining on anonymized and unannotated videos, followed by supervised SLT finetuning on a curated parallel dataset. SSVP-SLT achieves state-of-the-art finetuned and zero-shot gloss-free SLT performance on the How2Sign dataset, outperforming the strongest respective baselines by over 3 BLEU-4. Based on controlled experime
&lt;/p&gt;</description></item><item><title>该文章证明了对于二元变量分布，存在一系列等价关系，确保了不同类型的概率电路模型在计算大小增加有限情况下可以相互转换，从而保持边际推理的效率。</title><link>https://arxiv.org/abs/2402.09085</link><description>&lt;p&gt;
Polynomial Semantics of Tractable Probabilistic Circuits
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.09085
&lt;/p&gt;
&lt;p&gt;
该文章证明了对于二元变量分布，存在一系列等价关系，确保了不同类型的概率电路模型在计算大小增加有限情况下可以相互转换，从而保持边际推理的效率。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.09085v3 Announce Type: replace  Abstract: Probabilistic circuits compute multilinear polynomials that represent multivariate probability distributions. They are tractable models that support efficient marginal inference. However, various polynomial semantics have been considered in the literature (e.g., network polynomials, likelihood polynomials, generating functions, and Fourier transforms). The relationships between circuit representations of these polynomial encodings of distributions is largely unknown. In this paper, we prove that for distributions over binary variables, each of these probabilistic circuit models is equivalent in the sense that any circuit for one of them can be transformed into a circuit for any of the others with only a polynomial increase in size. They are therefore all tractable for marginal inference on the same class of distributions. Finally, we explore the natural extension of one such polynomial semantics, called probabilistic generating circu
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的方法Retrieval Augmented Thought Process（RATP），旨在通过结合信息检索和语言模型的能力，以多步骤决策方式优化语言模型的思维过程，特别是在医疗健康领域的信息隐私问题上。这种方法通过访问外部知识，能够更有效地处理私密数据，同时提升语言模型对当前知识检索的适应性，以解决现有信息检索集成中存在的鲁棒性问题。</title><link>https://arxiv.org/abs/2402.07812</link><description>&lt;p&gt;
Retrieval Augmented Thought Process for Private Data Handling in Healthcare
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07812
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的方法Retrieval Augmented Thought Process（RATP），旨在通过结合信息检索和语言模型的能力，以多步骤决策方式优化语言模型的思维过程，特别是在医疗健康领域的信息隐私问题上。这种方法通过访问外部知识，能够更有效地处理私密数据，同时提升语言模型对当前知识检索的适应性，以解决现有信息检索集成中存在的鲁棒性问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.07812v2 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have demonstrated the strong potential to assist both clinicians and the general public with their extensive medical knowledge. However, their application in healthcare is constrained due to concerns about the privacy of data used in training, which prevents the integration of private and personal information because of security and ethical issues. Moreover, if their capabilities can be enhanced with information retrieval to access up-to-date knowledge, the current integration of LLMs with Information retrieval lacks robustness to imperfect retrieval, which can hinder their effectiveness and even reduce overall performance. In this work, we address this challenge by introducing the Retrieval-Augmented Thought Process (RATP). Given access to external knowledge, RATP formulates the thought generation of LLMs as a multiple-step decision process. To optimise such a thought process, RATP leverages Monte-
&lt;/p&gt;</description></item><item><title>该文章提出了一个基于未知实体 population 分布的 SHAP 分数推理框架，考虑了潜在分布的不确定性区域，使得 SHAP 分数成为该区域内的一函数。研究了在该不确定性区域内找到 SHAP 分数的最值问题，从而确定了一个特征 SHAP 分数的可能范围。</title><link>https://arxiv.org/abs/2401.12731</link><description>&lt;p&gt;
The Distributional Uncertainty of the SHAP score in Explainable Machine Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.12731
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个基于未知实体 population 分布的 SHAP 分数推理框架，考虑了潜在分布的不确定性区域，使得 SHAP 分数成为该区域内的一函数。研究了在该不确定性区域内找到 SHAP 分数的最值问题，从而确定了一个特征 SHAP 分数的可能范围。
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.12731v2 Announce Type: replace  Abstract: Attribution scores reflect how important the feature values in an input entity are for the output of a machine learning model. One of the most popular attribution scores is the SHAP score, which is an instantiation of the general Shapley value used in coalition game theory. The definition of this score relies on a probability distribution on the entity population. Since the exact distribution is generally unknown, it needs to be assigned subjectively or be estimated from data, which may lead to misleading feature scores. In this paper, we propose a principled framework for reasoning on SHAP scores under unknown entity population distributions. In our framework, we consider an uncertainty region that contains the potential distributions, and the SHAP score of a feature becomes a function defined over this region. We study the basic problems of finding maxima and minima of this function, which allows us to determine tight ranges for th
&lt;/p&gt;</description></item><item><title>该文章提供了一种名为“模仿优秀避免失败：一种安全的强化学习逐步方法”的创新策略，它旨在确保强化学习中的策略能够安全地进行，同时最大化预期收益。该策略通过不断改进的策略生成“好”和“坏”的轨迹并对其进行模仿和避免，从而不对轨迹成本约束进行修改。此外，通过一个在线决策器，该策略能够根据学习过程中的奖励阈值和总体成本约束，对轨迹进行分类。这种策略的实施不需要对成本约束进行任何近似处理，且能够平衡风险和奖励，有效地提高了学习策略的安全性。</title><link>https://arxiv.org/abs/2312.10385</link><description>&lt;p&gt;
Imitate the Good and Avoid the Bad: An Incremental Approach to Safe Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.10385
&lt;/p&gt;
&lt;p&gt;
该文章提供了一种名为“模仿优秀避免失败：一种安全的强化学习逐步方法”的创新策略，它旨在确保强化学习中的策略能够安全地进行，同时最大化预期收益。该策略通过不断改进的策略生成“好”和“坏”的轨迹并对其进行模仿和避免，从而不对轨迹成本约束进行修改。此外，通过一个在线决策器，该策略能够根据学习过程中的奖励阈值和总体成本约束，对轨迹进行分类。这种策略的实施不需要对成本约束进行任何近似处理，且能够平衡风险和奖励，有效地提高了学习策略的安全性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.10385v4 Announce Type: replace-cross  Abstract: A popular framework for enforcing safe actions in Reinforcement Learning (RL) is Constrained RL, where trajectory based constraints on expected cost (or other cost measures) are employed to enforce safety and more importantly these constraints are enforced while maximizing expected reward. Most recent approaches for solving Constrained RL convert the trajectory based cost constraint into a surrogate problem that can be solved using minor modifications to RL methods. A key drawback with such approaches is an over or underestimation of the cost constraint at each state. Therefore, we provide an approach that does not modify the trajectory based cost constraint and instead imitates ``good'' trajectories and avoids ``bad'' trajectories generated from incrementally improving policies. We employ an oracle that utilizes a reward threshold (which is varied with learning) and the overall cost constraint to label trajectories as ``good''
&lt;/p&gt;</description></item><item><title>该文章系统地介绍了自然语言处理（NLP）中的混合和 ensembles深度学习模型的广泛应用，包括对如情感分析、命名实体识别、机器翻译、问答、文本分类、生成、语音识别、摘要和语言模型等关键任务的探索。文章不仅介绍了从循环神经网络（RNNs）到Transformer模型如BERT的多种架构，而且还评估了它们的性能、挑战和计算要求。文章强调了ensemble技术在提高NLP应用方面的适应性，并指出了提高模型性能和复杂性之间的权衡以及可解释性和性能之间的权衡。文章还讨论了实现中的挑战，包括计算开销、过拟合和模型解释性复杂性等问题。该研究为研究人员提供了一个全面的框架，以了解混合和ensemble深度学习方法在NLP中的应用，并为未来的研究提供了指导。</title><link>https://arxiv.org/abs/2312.05589</link><description>&lt;p&gt;
A Review of Hybrid and Ensemble in Deep Learning for Natural Language Processing
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.05589
&lt;/p&gt;
&lt;p&gt;
该文章系统地介绍了自然语言处理（NLP）中的混合和 ensembles深度学习模型的广泛应用，包括对如情感分析、命名实体识别、机器翻译、问答、文本分类、生成、语音识别、摘要和语言模型等关键任务的探索。文章不仅介绍了从循环神经网络（RNNs）到Transformer模型如BERT的多种架构，而且还评估了它们的性能、挑战和计算要求。文章强调了ensemble技术在提高NLP应用方面的适应性，并指出了提高模型性能和复杂性之间的权衡以及可解释性和性能之间的权衡。文章还讨论了实现中的挑战，包括计算开销、过拟合和模型解释性复杂性等问题。该研究为研究人员提供了一个全面的框架，以了解混合和ensemble深度学习方法在NLP中的应用，并为未来的研究提供了指导。
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.05589v2 Announce Type: replace  Abstract: This review presents a comprehensive exploration of hybrid and ensemble deep learning models within Natural Language Processing (NLP), shedding light on their transformative potential across diverse tasks such as Sentiment Analysis, Named Entity Recognition, Machine Translation, Question Answering, Text Classification, Generation, Speech Recognition, Summarization, and Language Modeling. The paper systematically introduces each task, delineates key architectures from Recurrent Neural Networks (RNNs) to Transformer-based models like BERT, and evaluates their performance, challenges, and computational demands. The adaptability of ensemble techniques is emphasized, highlighting their capacity to enhance various NLP applications. Challenges in implementation, including computational overhead, overfitting, and model interpretation complexities, are addressed alongside the trade-off between interpretability and performance. Serving as a co
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为SPOC的架构，通过在模拟环境中模仿最短路径规划器来训练机器人代理，使其能够仅通过RGB传感器数据在现实世界中进行导航、探索和物体操作，并且不需要依赖深度地图或GPS坐标。这种训练方法使得机器人能够在实际环境中有效执行任务，这主要得益于大量的模拟数据、强有力的视觉编码器以及广泛的数据增强技术。</title><link>https://arxiv.org/abs/2312.02976</link><description>&lt;p&gt;
SPOC: Imitating Shortest Paths in Simulation Enables Effective Navigation and Manipulation in the Real World
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.02976
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为SPOC的架构，通过在模拟环境中模仿最短路径规划器来训练机器人代理，使其能够仅通过RGB传感器数据在现实世界中进行导航、探索和物体操作，并且不需要依赖深度地图或GPS坐标。这种训练方法使得机器人能够在实际环境中有效执行任务，这主要得益于大量的模拟数据、强有力的视觉编码器以及广泛的数据增强技术。
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.02976v2 Announce Type: replace  Abstract: Reinforcement learning (RL) with dense rewards and imitation learning (IL) with human-generated trajectories are the most widely used approaches for training modern embodied agents. RL requires extensive reward shaping and auxiliary losses and is often too slow and ineffective for long-horizon tasks. While IL with human supervision is effective, collecting human trajectories at scale is extremely expensive. In this work, we show that imitating shortest-path planners in simulation produces agents that, given a language instruction, can proficiently navigate, explore, and manipulate objects in both simulation and in the real world using only RGB sensors (no depth map or GPS coordinates). This surprising result is enabled by our end-to-end, transformer-based, SPOC architecture, powerful visual encoders paired with extensive image augmentation, and the dramatic scale and diversity of our training data: millions of frames of shortest-path
&lt;/p&gt;</description></item><item><title>该文章评估了两款标志性的大型语言模型（LLaMAs）在工程设计领域中的应用，它们能够处理文本和视觉数据，为设计任务提供了新的解决方案，尤其是在概念设计、系统级和详细设计、生产制造以及工程教育任务方面取得了显著成果。</title><link>https://arxiv.org/abs/2311.12668</link><description>&lt;p&gt;
From Concept to Manufacturing: Evaluating Vision-Language Models for Engineering Design
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.12668
&lt;/p&gt;
&lt;p&gt;
该文章评估了两款标志性的大型语言模型（LLaMAs）在工程设计领域中的应用，它们能够处理文本和视觉数据，为设计任务提供了新的解决方案，尤其是在概念设计、系统级和详细设计、生产制造以及工程教育任务方面取得了显著成果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.12668v2 Announce Type: replace  Abstract: Engineering design is undergoing a transformative shift with the advent of AI, marking a new era in how we approach product, system, and service planning. Large language models have demonstrated impressive capabilities in enabling this shift. Yet, with text as their only input modality, they cannot leverage the large body of visual artifacts that engineers have used for centuries and are accustomed to. This gap is addressed with the release of multimodal vision-language models (VLMs), such as GPT-4V, enabling AI to impact many more types of tasks. Our work presents a comprehensive evaluation of VLMs across a spectrum of engineering design tasks, categorized into four main areas: Conceptual Design, System-Level and Detailed Design, Manufacturing and Inspection, and Engineering Education Tasks. Specifically in this paper, we assess the capabilities of two VLMs, GPT-4V and LLaVA 1.6 34B, in design tasks such as sketch similarity analysi
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的方法来解决自然语言生成模型中的模式问题，通过在条件变量中排除特定退化行为，有效地避免了过度简化的输出，从而提高了模型的多样性与真实感。</title><link>https://arxiv.org/abs/2311.08817</link><description>&lt;p&gt;
MAP's not dead yet: Uncovering true language model modes by conditioning away degeneracy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.08817
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的方法来解决自然语言生成模型中的模式问题，通过在条件变量中排除特定退化行为，有效地避免了过度简化的输出，从而提高了模型的多样性与真实感。
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.08817v2 Announce Type: replace-cross  Abstract: It has been widely observed that exact or approximate MAP (mode-seeking) decoding from natural language generation (NLG) models consistently leads to degenerate outputs (Holtzman et al., 2019; Stahlberg and Byrne, 2019). Prior work has attributed this behavior to either a fundamental and unavoidable inadequacy of modes in probabilistic models or weaknesses in language modeling. Contrastingly, we argue that degenerate modes can even occur in the absence of any modeling error, due to contamination of the training data. Specifically, we argue that mixing even a tiny amount of low-entropy noise with a population text distribution can cause the data distribution's mode to become degenerate. We therefore propose to apply MAP decoding to the model's true conditional distribution where the conditioning variable explicitly avoids specific degenerate behavior. Using exact search, we empirically verify that the length-conditional modes of
&lt;/p&gt;</description></item><item><title>该文章提出了一个基于启发式驱动的提示策略，该策略可以利用语言模型从演示中学习任务特定的启发式，从而在无需大量标注数据的情况下提高文档级事件论元提取任务的性能。</title><link>https://arxiv.org/abs/2311.06555</link><description>&lt;p&gt;
LLMs Learn Task Heuristics from Demonstrations: A Heuristic-Driven Prompting Strategy for Document-Level Event Argument Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.06555
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个基于启发式驱动的提示策略，该策略可以利用语言模型从演示中学习任务特定的启发式，从而在无需大量标注数据的情况下提高文档级事件论元提取任务的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.06555v3 Announce Type: replace-cross  Abstract: In this study, we investigate in-context learning (ICL) in document-level event argument extraction (EAE) to alleviate the dependency on large-scale labeled data for this task. We introduce the Heuristic-Driven Link-of-Analogy (HD-LoA) prompting to address the challenge of example selection and to develop a prompting strategy tailored for EAE. Specifically, we hypothesize and validate that LLMs learn task-specific heuristics from demonstrations via ICL. Building upon this hypothesis, we introduce an explicit heuristic-driven demonstration construction approach, which transforms the haphazard example selection process into a methodical method that emphasizes task heuristics. Additionally, inspired by the analogical reasoning of human, we propose the link-of-analogy prompting, which enables LLMs to process new situations by drawing analogies to known situations, enhancing their performance on unseen classes beyond limited ICL exa
&lt;/p&gt;</description></item><item><title>该文章提出了SRank，一种针对神经代码生成器的解决方案重新排序策略，通过量化解决方案集群之间的功能重叠，改进了代码解决方案的排名。在Human-Eval基准测试中，对于Codex002、WizardCoder、StarCoder和CodeGen等模型，该策略在pass@1分数上取得了显著提升，超过了当前最先进的代码生成重新排序方法，如CodeT and CodeBERTa。</title><link>https://arxiv.org/abs/2311.03366</link><description>&lt;p&gt;
Functional Overlap Reranking for Neural Code Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2311.03366
&lt;/p&gt;
&lt;p&gt;
该文章提出了SRank，一种针对神经代码生成器的解决方案重新排序策略，通过量化解决方案集群之间的功能重叠，改进了代码解决方案的排名。在Human-Eval基准测试中，对于Codex002、WizardCoder、StarCoder和CodeGen等模型，该策略在pass@1分数上取得了显著提升，超过了当前最先进的代码生成重新排序方法，如CodeT and CodeBERTa。
&lt;/p&gt;
&lt;p&gt;
arXiv:2311.03366v4 Announce Type: replace-cross  Abstract: Code Large Language Models (CodeLLMs) have ushered in a new era in code generation advancements. However, selecting the best code solutions from all possible CodeLLM outputs remains a challenge. Previous methods often overlooked the intricate functional similarities and interactions between solution clusters. We introduce SRank, a novel reranking strategy for selecting the best solutions from code generation, focusing on modeling the relationships between clusters of solutions. By quantifying the functional overlap between solution clusters, our approach provides a better ranking strategy for code solutions. Empirical results show that our method achieves remarkable results on the pass@1 score. For instance, on the Human-Eval benchmark, we achieve 69.66% in pass@1 with Codex002, 75.31% with WizardCoder, 53.99% with StarCoder, and 60.55% with CodeGen, surpassing state-of-the-art code generation reranking methods such as CodeT an
&lt;/p&gt;</description></item><item><title>该文章提出了一种新型的基于上下文的学习代理人，该代理人能够独立使用Lean和Coq等证明环境进行形式化的定理证明，无需特定环境的数据微调。</title><link>https://arxiv.org/abs/2310.04353</link><description>&lt;p&gt;
An In-Context Learning Agent for Formal Theorem-Proving
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.04353
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新型的基于上下文的学习代理人，该代理人能够独立使用Lean和Coq等证明环境进行形式化的定理证明，无需特定环境的数据微调。
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.04353v5 Announce Type: replace-cross  Abstract: We present an in-context learning agent for formal theorem-proving in environments like Lean and Coq. Current state-of-the-art models for the problem are finetuned on environment-specific proof data. By contrast, our approach, called COPRA, repeatedly asks a high-capacity, general-purpose large language model (GPT-4) to propose tactic applications from within a stateful backtracking search. Proposed tactics are executed in the underlying proof environment. Feedback from the execution is used to build the prompt for the next model query, along with selected information from the search history and lemmas retrieved from an external database. We evaluate our implementation of COPRA on the miniF2F benchmark for Lean and a set of Coq tasks from the CompCert project. On these benchmarks, COPRA significantly outperforms few-shot invocations of GPT-4. It also compares favorably against finetuning-based approaches, outperforming ReProver
&lt;/p&gt;</description></item><item><title>该文章研究了在强化学习场景中，环境状态表示对激励学习代理解决特定任务的有效性，特别是在机器人抓取任务中的抗平面和平面物体抓取。通过定义一个从数值状态手工制作的到基于图像状态的编码的连续状态表示范围，研究了不同状态表示对学习代理在模拟环境中解决问题的能力和所学策略在真实机器人上转移的能力的影响。通过与基于模型的方法进行比较，该研究强调了状态表示在强化学习中的战略重要性，以及在真实世界中实现有效模拟到现实world转移的关键因素。</title><link>https://arxiv.org/abs/2309.11984</link><description>&lt;p&gt;
State Representations as Incentives for Reinforcement Learning Agents: A Sim2Real Analysis on Robotic Grasping
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.11984
&lt;/p&gt;
&lt;p&gt;
该文章研究了在强化学习场景中，环境状态表示对激励学习代理解决特定任务的有效性，特别是在机器人抓取任务中的抗平面和平面物体抓取。通过定义一个从数值状态手工制作的到基于图像状态的编码的连续状态表示范围，研究了不同状态表示对学习代理在模拟环境中解决问题的能力和所学策略在真实机器人上转移的能力的影响。通过与基于模型的方法进行比较，该研究强调了状态表示在强化学习中的战略重要性，以及在真实世界中实现有效模拟到现实world转移的关键因素。
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.11984v3 Announce Type: replace  Abstract: Choosing an appropriate representation of the environment for the underlying decision-making process of the reinforcement learning agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and disentangled enough to simplify policy training and the corresponding sim2real transfer. Given this outlook, this work examines the effect of various representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representations is defined, starting from hand-crafted numerical states to encoded image-based representations, with decreasing levels of induced task-specific knowledge. The effects of each representation on the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot are examined and compared against a model-based a
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用大型语言模型进行 conformal temporal logic planning的方法，解决了在自然语言描述的多任务环境下，为移动机器人设计计划的挑战，有效地合并了符号规划和高阶任务阶段的原子谓词逻辑。</title><link>https://arxiv.org/abs/2309.10092</link><description>&lt;p&gt;
Conformal Temporal Logic Planning using Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.10092
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用大型语言模型进行 conformal temporal logic planning的方法，解决了在自然语言描述的多任务环境下，为移动机器人设计计划的挑战，有效地合并了符号规划和高阶任务阶段的原子谓词逻辑。
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.10092v4 Announce Type: replace  Abstract: This paper addresses planning problems for mobile robots. We consider missions that require accomplishing multiple high-level sub-tasks, expressed in natural language (NL), in a temporal and logical order. To formally define the mission, we treat these sub-tasks as atomic predicates in a Linear Temporal Logic (LTL) formula. We refer to this task specification framework as LTL-NL. Our goal is to design plans, defined as sequences of robot actions, accomplishing LTL-NL tasks. This action planning problem cannot be solved directly by existing LTL planners because of the NL nature of atomic predicates. To address it, we propose HERACLEs, a hierarchical neuro-symbolic planner that relies on a novel integration of (i) existing symbolic planners generating high-level task plans determining the order at which the NL sub-tasks should be accomplished; (ii) pre-trained Large Language Models (LLMs) to design sequences of robot actions based on t
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为CALM的基准测试，用于全面的评估语言模型在性别和种族偏见方面的表现，通过整合多种不同的语言任务数据集，并创造了大量的具有高度多样性的模板和实例，以更准确地衡量语言模型在真实世界应用过程中可能产生的社会偏见。</title><link>https://arxiv.org/abs/2308.12539</link><description>&lt;p&gt;
CALM : A Multi-task Benchmark for Comprehensive Assessment of Language Model Bias
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.12539
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为CALM的基准测试，用于全面的评估语言模型在性别和种族偏见方面的表现，通过整合多种不同的语言任务数据集，并创造了大量的具有高度多样性的模板和实例，以更准确地衡量语言模型在真实世界应用过程中可能产生的社会偏见。
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.12539v3 Announce Type: replace-cross  Abstract: As language models (LMs) become increasingly powerful and widely used, it is important to quantify them for sociodemographic bias with potential for harm. Prior measures of bias are sensitive to perturbations in the templates designed to compare performance across social groups, due to factors such as low diversity or limited number of templates. Also, most previous work considers only one NLP task. We introduce Comprehensive Assessment of Language Models (CALM) for robust measurement of two types of universally relevant sociodemographic bias, gender and race. CALM integrates sixteen datasets for question-answering, sentiment analysis and natural language inference. Examples from each dataset are filtered to produce 224 templates with high diversity (e.g., length, vocabulary). We assemble 50 highly frequent person names for each of seven distinct demographic groups to generate 78,400 prompts covering the three NLP tasks. Our em
&lt;/p&gt;</description></item><item><title>该文章揭示了使用大型语言模型进行的政治新闻标题事实核查虽然准确度高，但并未显著提高参与者的辨别能力或分享事实性新闻的意愿。相反，人类编写的核查报告在提高辨别能力和分享意愿方面显示出更好的效果。随后进行的分析表明，AI事实核查对政治新闻标题而言是有害的。</title><link>https://arxiv.org/abs/2308.10800</link><description>&lt;p&gt;
Fact-checking information from large language models can decrease headline discernment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.10800
&lt;/p&gt;
&lt;p&gt;
该文章揭示了使用大型语言模型进行的政治新闻标题事实核查虽然准确度高，但并未显著提高参与者的辨别能力或分享事实性新闻的意愿。相反，人类编写的核查报告在提高辨别能力和分享意愿方面显示出更好的效果。随后进行的分析表明，AI事实核查对政治新闻标题而言是有害的。
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.10800v4 Announce Type: replace-cross  Abstract: Fact checking can be an effective strategy against misinformation, but its implementation at scale is impeded by the overwhelming volume of information online. Recent artificial intelligence (AI) language models have shown impressive ability in fact-checking tasks, but how humans interact with fact-checking information provided by these models is unclear. Here, we investigate the impact of fact-checking information generated by a popular large language model (LLM) on belief in, and sharing intent of, political news headlines in a preregistered randomized control experiment. Although the LLM accurately identifies most false headlines (90%), we find that this information does not significantly improve participants' ability to discern headline accuracy or share accurate news. In contrast, viewing human-generated fact checks enhances discernment in both cases. Subsequent analysis reveals that the AI fact-checker is harmful in speci
&lt;/p&gt;</description></item><item><title>该文章介绍了一种比较多目标优化算法进化过程的可视化分析框架。通过交互式的可视化工具，研究人员能够深入理解并对比多种多目标优化算法的内部进化过程，从而更全面地评估算法性能和特征。</title><link>https://arxiv.org/abs/2308.05640</link><description>&lt;p&gt;
A Comparative Visual Analytics Framework for Evaluating Evolutionary Processes in Multi-objective Optimization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.05640
&lt;/p&gt;
&lt;p&gt;
该文章介绍了一种比较多目标优化算法进化过程的可视化分析框架。通过交互式的可视化工具，研究人员能够深入理解并对比多种多目标优化算法的内部进化过程，从而更全面地评估算法性能和特征。
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.05640v1 Announce Type: cross  Abstract: Evolutionary multi-objective optimization (EMO) algorithms have been demonstrated to be effective in solving multi-criteria decision-making problems. In real-world applications, analysts often employ several algorithms concurrently and compare their solution sets to gain insight into the characteristics of different algorithms and explore a broader range of feasible solutions. However, EMO algorithms are typically treated as black boxes, leading to difficulties in performing detailed analysis and comparisons between the internal evolutionary processes. Inspired by the successful application of visual analytics tools in explainable AI, we argue that interactive visualization can significantly enhance the comparative analysis between multiple EMO algorithms. In this paper, we present a visual analytics framework that enables the exploration and comparison of evolutionary processes in EMO algorithms. Guided by a literature review and expe
&lt;/p&gt;</description></item><item><title>该文章提出使用争议性解释来减少对模型依赖的创新性概念。争议性解释通过结合不同的预测结果和解释，增强了模型的多样性理解，从而在模型之间存在分歧时为决策者提供了多重视角。</title><link>https://arxiv.org/abs/2307.07636</link><description>&lt;p&gt;
Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2307.07636
&lt;/p&gt;
&lt;p&gt;
该文章提出使用争议性解释来减少对模型依赖的创新性概念。争议性解释通过结合不同的预测结果和解释，增强了模型的多样性理解，从而在模型之间存在分歧时为决策者提供了多重视角。
&lt;/p&gt;
&lt;p&gt;
arXiv:2307.07636v3 Announce Type: replace  Abstract: While explainability is a desirable characteristic of increasingly complex black-box models, modern explanation methods have been shown to be inconsistent and contradictory. The semantics of explanations is not always fully understood - to what extent do explanations "explain" a decision and to what extent do they merely advocate for a decision? Can we help humans gain insights from explanations accompanying correct predictions and not over-rely on incorrect predictions advocated for by explanations? With this perspective in mind, we introduce the notion of dissenting explanations: conflicting predictions with accompanying explanations. We first explore the advantage of dissenting explanations in the setting of model multiplicity, where multiple models with similar performance may have different predictions. In such cases, providing dissenting explanations could be done by invoking the explanations of disagreeing models. Through a pi
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为SafeDreamer的算法，它利用Lagrangian方法结合世界模型规划，在Dreamer框架中实现了在复杂任务中的近零成本性能，尤其是对于低维度和纯视觉输入的任务，其在Safety-Gymnasium基准测试中展现了其在进行强化学习时既能保证性能又能确保安全的能力。</title><link>https://arxiv.org/abs/2307.07176</link><description>&lt;p&gt;
SafeDreamer: Safe Reinforcement Learning with World Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2307.07176
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为SafeDreamer的算法，它利用Lagrangian方法结合世界模型规划，在Dreamer框架中实现了在复杂任务中的近零成本性能，尤其是对于低维度和纯视觉输入的任务，其在Safety-Gymnasium基准测试中展现了其在进行强化学习时既能保证性能又能确保安全的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2307.07176v3 Announce Type: replace-cross  Abstract: The deployment of Reinforcement Learning (RL) in real-world applications is constrained by its failure to satisfy safety criteria. Existing Safe Reinforcement Learning (SafeRL) methods, which rely on cost functions to enforce safety, often fail to achieve zero-cost performance in complex scenarios, especially vision-only tasks. These limitations are primarily due to model inaccuracies and inadequate sample efficiency. The integration of the world model has proven effective in mitigating these shortcomings. In this work, we introduce SafeDreamer, a novel algorithm incorporating Lagrangian-based methods into world model planning processes within the superior Dreamer framework. Our method achieves nearly zero-cost performance on various tasks, spanning low-dimensional and vision-only input, within the Safety-Gymnasium benchmark, showcasing its efficacy in balancing performance and safety in RL tasks. Further details can be found i
&lt;/p&gt;</description></item><item><title>该文章探讨了从大型语言模型中提取有效提示的方法，并发现简单的文本攻击可以成功揭示真实的提示，从而可能导致隐私泄露风险。</title><link>https://arxiv.org/abs/2307.06865</link><description>&lt;p&gt;
Effective Prompt Extraction from Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2307.06865
&lt;/p&gt;
&lt;p&gt;
该文章探讨了从大型语言模型中提取有效提示的方法，并发现简单的文本攻击可以成功揭示真实的提示，从而可能导致隐私泄露风险。
&lt;/p&gt;
&lt;p&gt;
arXiv:2307.06865v3 Announce Type: replace-cross  Abstract: The text generated by large language models is commonly controlled by prompting, where a prompt prepended to a user's query guides the model's output. The prompts used by companies to guide their models are often treated as secrets, to be hidden from the user making the query. They have even been treated as commodities to be bought and sold on marketplaces. However, anecdotal reports have shown adversarial users employing prompt extraction attacks to recover these prompts. In this paper, we present a framework for systematically measuring the effectiveness of these attacks. In experiments with 3 different sources of prompts and 11 underlying large language models, we find that simple text-based attacks can in fact reveal prompts with high probability. Our framework determines with high precision whether an extracted prompt is the actual secret prompt, rather than a model hallucination. Prompt extraction from real systems such a
&lt;/p&gt;</description></item><item><title>该文章全面介绍了深度学习中常用的损失函数和性能度量，适用于各种任务，包括回归、分类、计算机视觉及自然语言处理，旨在为研究者和实践者提供参考，帮助他们在深度学习项目选择合适的损失函数和度量方法。</title><link>https://arxiv.org/abs/2307.02694</link><description>&lt;p&gt;
Loss Functions and Metrics in Deep Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2307.02694
&lt;/p&gt;
&lt;p&gt;
该文章全面介绍了深度学习中常用的损失函数和性能度量，适用于各种任务，包括回归、分类、计算机视觉及自然语言处理，旨在为研究者和实践者提供参考，帮助他们在深度学习项目选择合适的损失函数和度量方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2307.02694v3 Announce Type: replace-cross  Abstract: When training or evaluating deep learning models, two essential parts are picking the proper loss function and deciding on performance metrics. In this paper, we provide a comprehensive overview of the most common loss functions and metrics used across many different types of deep learning tasks, from general tasks such as regression and classification to more specific tasks in Computer Vision and Natural Language Processing. We introduce the formula for each loss and metric, discuss their strengths and limitations, and describe how these methods can be applied to various problems within deep learning. We hope this work serves as a reference for researchers and practitioners in the field, helping them make informed decisions when selecting the most appropriate loss function and performance metrics for their deep learning projects.
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一个基于结构化辩论对话的二元论和解框架，旨在提高人类友好的规划方法中模型 reconciliation的性能，增强了人类与人工智能之间的交互。通过这种辩论对话方式，该框架能够帮助人类用户理解人工智能代理的决策过程，解决了解释者和被解释者之间知识差异的问题。</title><link>https://arxiv.org/abs/2306.14694</link><description>&lt;p&gt;
Dialectical Reconciliation via Structured Argumentative Dialogues
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.14694
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一个基于结构化辩论对话的二元论和解框架，旨在提高人类友好的规划方法中模型 reconciliation的性能，增强了人类与人工智能之间的交互。通过这种辩论对话方式，该框架能够帮助人类用户理解人工智能代理的决策过程，解决了解释者和被解释者之间知识差异的问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2306.14694v3 Announce Type: replace  Abstract: We present a novel framework designed to extend model reconciliation approaches, commonly used in human-aware planning, for enhanced human-AI interaction. By adopting a structured argumentation-based dialogue paradigm, our framework enables dialectical reconciliation to address knowledge discrepancies between an explainer (AI agent) and an explainee (human user), where the goal is for the explainee to understand the explainer's decision. We formally describe the operational semantics of our proposed framework, providing theoretical guarantees. We then evaluate the framework's efficacy ``in the wild'' via computational and human-subject experiments. Our findings suggest that our framework offers a promising direction for fostering effective human-AI interactions in domains where explainability is important.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为“因果抽象”的理论框架，用于解释模型内部的机制，并提供了一种精确灵活的描述方法，统一了多种解释性方法。</title><link>https://arxiv.org/abs/2301.04709</link><description>&lt;p&gt;
Causal Abstraction: A Theoretical Foundation for Mechanistic Interpretability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2301.04709
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为“因果抽象”的理论框架，用于解释模型内部的机制，并提供了一种精确灵活的描述方法，统一了多种解释性方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2301.04709v3 Announce Type: replace  Abstract: Causal abstraction provides a theoretical foundation for mechanistic interpretability, the field concerned with providing intelligible algorithms that are faithful simplifications of the known, but opaque low-level details of black box AI models. Our contributions are (1) generalizing the theory of causal abstraction from mechanism replacement (i.e., hard and soft interventions) to arbitrary mechanism transformation (i.e., functionals from old mechanisms to new mechanisms), (2) providing a flexible, yet precise formalization for the core concepts of modular features, polysemantic neurons, and graded faithfulness, and (3) unifying a variety of mechanistic interpretability methodologies in the common language of causal abstraction, namely activation and path patching, causal mediation analysis, causal scrubbing, causal tracing, circuit analysis, concept erasure, sparse autoencoders, differential binary masking, distributed alignment se
&lt;/p&gt;</description></item><item><title>该文章研究了在深度伪造视频中检测行为标志的创新方法，能够通过控制视觉外观并转移行为信号来自其他源的方式，来区分一个人与其他说话者的行为标志。</title><link>https://arxiv.org/abs/2208.03561</link><description>&lt;p&gt;
Study of detecting behavioral signatures within DeepFake videos
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2208.03561
&lt;/p&gt;
&lt;p&gt;
该文章研究了在深度伪造视频中检测行为标志的创新方法，能够通过控制视觉外观并转移行为信号来自其他源的方式，来区分一个人与其他说话者的行为标志。
&lt;/p&gt;
&lt;p&gt;
arXiv:2208.03561v2 Announce Type: replace  Abstract: There is strong interest in the generation of synthetic video imagery of people talking for various purposes, including entertainment, communication, training, and advertisement. With the development of deep fake generation models, synthetic video imagery will soon be visually indistinguishable to the naked eye from a naturally capture video. In addition, many methods are continuing to improve to avoid more careful, forensic visual analysis. Some deep fake videos are produced through the use of facial puppetry, which directly controls the head and face of the synthetic image through the movements of the actor, allow the actor to 'puppet' the image of another. In this paper, we address the question of whether one person's movements can be distinguished from the original speaker by controlling the visual appearance of the speaker but transferring the behavior signals from another source. We conduct a study by comparing synthetic imager
&lt;/p&gt;</description></item><item><title>该文章主要创新和贡献在于通过分解策略和时间窗口的概念，将繁琐的作业调度问题分解为更易于管理的子问题，并通过多轮回答设定编程求解，从而在较短的时间内找到了良好的局部解甚至全局解。</title><link>https://arxiv.org/abs/2205.07537</link><description>&lt;p&gt;
Decomposition Strategies and Multi-shot ASP Solving for Job-shop Scheduling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2205.07537
&lt;/p&gt;
&lt;p&gt;
该文章主要创新和贡献在于通过分解策略和时间窗口的概念，将繁琐的作业调度问题分解为更易于管理的子问题，并通过多轮回答设定编程求解，从而在较短的时间内找到了良好的局部解甚至全局解。
&lt;/p&gt;
&lt;p&gt;
arXiv:2205.07537v3 Announce Type: replace  Abstract: The Job-shop Scheduling Problem (JSP) is a well-known and challenging combinatorial optimization problem in which tasks sharing a machine are to be arranged in a sequence such that encompassing jobs can be completed as early as possible. In this paper, we investigate problem decomposition into time windows whose operations can be successively scheduled and optimized by means of multi-shot Answer Set Programming (ASP) solving. From a computational perspective, decomposition aims to split highly complex scheduling tasks into better manageable subproblems with a balanced number of operations such that good-quality or even optimal partial solutions can be reliably found in a small fraction of runtime. We devise and investigate a variety of decomposition strategies in terms of the number and size of time windows as well as heuristics for choosing their operations. Moreover, we incorporate time window overlapping and compression techniques
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的非线性强化学习框架，该框架能够处理大量可能的动作，并确保即使是最复杂的观察空间也能通过结构化条件和后验采样方法进行高效采样。</title><link>https://arxiv.org/abs/2203.08248</link><description>&lt;p&gt;
Non-Linear Reinforcement Learning in Large Action Spaces: Structural Conditions and Sample-efficiency of Posterior Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2203.08248
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的非线性强化学习框架，该框架能够处理大量可能的动作，并确保即使是最复杂的观察空间也能通过结构化条件和后验采样方法进行高效采样。
&lt;/p&gt;
&lt;p&gt;
arXiv:2203.08248v2 Announce Type: replace-cross  Abstract: Provably sample-efficient Reinforcement Learning (RL) with rich observations and function approximation has witnessed tremendous recent progress, particularly when the underlying function approximators are linear. In this linear regime, computationally and statistically efficient methods exist where the potentially infinite state and action spaces can be captured through a known feature embedding, with the sample complexity scaling with the (intrinsic) dimension of these features. When the action space is finite, significantly more sophisticated results allow non-linear function approximation under appropriate structural constraints on the underlying RL problem, permitting for instance, the learning of good features instead of assuming access to them. In this work, we present the first result for non-linear function approximation which holds for general action spaces under a linear embeddability condition, which generalizes all
&lt;/p&gt;</description></item><item><title>该文章总结了近年来在半监督学习领域中提出的深入半监督学习方法及相关研究。它解释了半监督学习中常用的关键假设，包括流形假设、簇假设和连续性假设，并对使用深度神经网络进行半监督学习的最新方法进行了重点讨论。文章通过综合分类和解释现有研究，提供了一种全面的视角来了解半监督学习的发展趋势和应用潜力。</title><link>https://arxiv.org/abs/2106.11528</link><description>&lt;p&gt;
Recent Deep Semi-supervised Learning Approaches and Related Works
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2106.11528
&lt;/p&gt;
&lt;p&gt;
该文章总结了近年来在半监督学习领域中提出的深入半监督学习方法及相关研究。它解释了半监督学习中常用的关键假设，包括流形假设、簇假设和连续性假设，并对使用深度神经网络进行半监督学习的最新方法进行了重点讨论。文章通过综合分类和解释现有研究，提供了一种全面的视角来了解半监督学习的发展趋势和应用潜力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2106.11528v3 Announce Type: replace-cross  Abstract: This work proposes an overview of the recent semi-supervised learning approaches and related works. Despite the remarkable success of neural networks in various applications, there exist a few formidable constraints, including the need for a large amount of labeled data. Therefore, semi-supervised learning, which is a learning scheme in which scarce labels and a larger amount of unlabeled data are utilized to train models (e.g., deep neural networks), is getting more important. Based on the key assumptions of semi-supervised learning, which are the manifold assumption, cluster assumption, and continuity assumption, the work reviews the recent semi-supervised learning approaches. In particular, the methods in regard to using deep neural networks in a semi-supervised learning setting are primarily discussed. In addition, the existing works are first classified based on the underlying idea and explained, then the holistic approach
&lt;/p&gt;</description></item></channel></rss>