<?xml version='1.0' encoding='utf-8'?>
<rss version="2.0"><channel><title>Chat Arxiv cs.AI</title><link>https://raw.githubusercontent.com/chrunx/cn-chat-arxiv/master/cs.AI.xml</link><description>This is arxiv RSS feed for cs.AI</description><item><title>该文章提出了一种名为SLIM-RAFT的基于检索的精调方法，以改善对巴西协调关税系统（HS）的NCM应用程序的处理能力。这项创新采用了简化的RAFT技术和任务特化的TeenyTineLLaMA小型葡萄牙语语言模型，通过利用短而专注的文档进行训练，显著提高了其性能。该方法为小型语言模型的精调提供了一种高效且成本效益高的替代方案。</title><link>https://arxiv.org/abs/2408.03936</link><description>&lt;p&gt;
SLIM-RAFT: A Novel Fine-Tuning Approach to Improve Cross-Linguistic Performance for Mercosur Common Nomenclature
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03936
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为SLIM-RAFT的基于检索的精调方法，以改善对巴西协调关税系统（HS）的NCM应用程序的处理能力。这项创新采用了简化的RAFT技术和任务特化的TeenyTineLLaMA小型葡萄牙语语言模型，通过利用短而专注的文档进行训练，显著提高了其性能。该方法为小型语言模型的精调提供了一种高效且成本效益高的替代方案。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03936v1 Announce Type: cross  Abstract: Natural language processing (NLP) has seen significant advancements with the advent of large language models (LLMs). However, substantial improvements are still needed for languages other than English, especially for specific domains like the applications of Mercosur Common Nomenclature (NCM), a Brazilian Harmonized System (HS). To address this gap, this study uses TeenyTineLLaMA, a foundational Portuguese LLM, as an LLM source to implement the NCM application processing. Additionally, a simplified Retrieval-Augmented Fine-Tuning (RAFT) technique, termed SLIM-RAFT, is proposed for task-specific fine-tuning of LLMs. This approach retains the chain-of-thought (CoT) methodology for prompt development in a more concise and streamlined manner, utilizing brief and focused documents for training. The proposed model demonstrates an efficient and cost-effective alternative for fine-tuning smaller LLMs, significantly outperforming TeenyTineLLaMA
&lt;/p&gt;</description></item><item><title>该文章提出了CodexGraph系统，它是一种利用代码图数据库将大型语言模型与代码库连接起来的方法。通过集成查询语言和图数据库的灵活性，CodexGraph增强了LLM在处理大型代码库方面的能力，使其能够在复杂的代码任务中精确地检索和操作代码结构，从而提高这些任务的整体性能和效率。</title><link>https://arxiv.org/abs/2408.03910</link><description>&lt;p&gt;
CodexGraph: Bridging Large Language Models and Code Repositories via Code Graph Databases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03910
&lt;/p&gt;
&lt;p&gt;
该文章提出了CodexGraph系统，它是一种利用代码图数据库将大型语言模型与代码库连接起来的方法。通过集成查询语言和图数据库的灵活性，CodexGraph增强了LLM在处理大型代码库方面的能力，使其能够在复杂的代码任务中精确地检索和操作代码结构，从而提高这些任务的整体性能和效率。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03910v1 Announce Type: cross  Abstract: Large Language Models (LLMs) excel in stand-alone code tasks like HumanEval and MBPP, but struggle with handling entire code repositories. This challenge has prompted research on enhancing LLM-codebase interaction at a repository scale. Current solutions rely on similarity-based retrieval or manual tools and APIs, each with notable drawbacks. Similarity-based retrieval often has low recall in complex tasks, while manual tools and APIs are typically task-specific and require expert knowledge, reducing their generalizability across diverse code tasks and real-world applications. To mitigate these limitations, we introduce \framework, a system that integrates LLM agents with graph database interfaces extracted from code repositories. By leveraging the structural properties of graph databases and the flexibility of the graph query language, \framework enables the LLM agent to construct and execute queries, allowing for precise, code struct
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为Latent Feature Attacks（LaFA）的全新攻击方法，旨在针对Non-negative Matrix Factorization（NMF）算法中的潜在特征进行操纵，以质疑该算法的安全性。</title><link>https://arxiv.org/abs/2408.03909</link><description>&lt;p&gt;
LaFA: Latent Feature Attacks on Non-negative Matrix Factorization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03909
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为Latent Feature Attacks（LaFA）的全新攻击方法，旨在针对Non-negative Matrix Factorization（NMF）算法中的潜在特征进行操纵，以质疑该算法的安全性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03909v1 Announce Type: cross  Abstract: As Machine Learning (ML) applications rapidly grow, concerns about adversarial attacks compromising their reliability have gained significant attention. One unsupervised ML method known for its resilience to such attacks is Non-negative Matrix Factorization (NMF), an algorithm that decomposes input data into lower-dimensional latent features. However, the introduction of powerful computational tools such as Pytorch enables the computation of gradients of the latent features with respect to the original data, raising concerns about NMF's reliability. Interestingly, naively deriving the adversarial loss for NMF as in the case of ML would result in the reconstruction loss, which can be shown theoretically to be an ineffective attacking objective. In this work, we introduce a novel class of attacks in NMF termed Latent Feature Attacks (LaFA), which aim to manipulate the latent features produced by the NMF process. Our method utilizes the F
&lt;/p&gt;</description></item><item><title>该文章提出了一种自动化方法，用于检测大型语言模型（LLMs）中的性别偏见，并通过利用机器学习（ML）模型和高级语言模型（LLM）来评估和识别模型中的潜在偏见。通过训练模型生成对抗性提示来诱导模型产生涉及性别偏见的反应，该文章研究了自动评价方法的有效性和提出了新的评估指标，分析了不同模型家族的性能特点，评估了现有自动评估方法的优势和局限性，并在此基础上提出了改进建议。</title><link>https://arxiv.org/abs/2408.03907</link><description>&lt;p&gt;
Decoding Biases: Automated Methods and LLM Judges for Gender Bias Detection in Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03907
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种自动化方法，用于检测大型语言模型（LLMs）中的性别偏见，并通过利用机器学习（ML）模型和高级语言模型（LLM）来评估和识别模型中的潜在偏见。通过训练模型生成对抗性提示来诱导模型产生涉及性别偏见的反应，该文章研究了自动评价方法的有效性和提出了新的评估指标，分析了不同模型家族的性能特点，评估了现有自动评估方法的优势和局限性，并在此基础上提出了改进建议。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03907v1 Announce Type: cross  Abstract: Large Language Models (LLMs) have excelled at language understanding and generating human-level text. However, even with supervised training and human alignment, these LLMs are susceptible to adversarial attacks where malicious users can prompt the model to generate undesirable text. LLMs also inherently encode potential biases that can cause various harmful effects during interactions. Bias evaluation metrics lack standards as well as consensus and existing methods often rely on human-generated templates and annotations which are expensive and labor intensive. In this work, we train models to automatically create adversarial prompts to elicit biased responses from target LLMs. We present LLM- based bias evaluation metrics and also analyze several existing automatic evaluation methods and metrics. We analyze the various nuances of model responses, identify the strengths and weaknesses of model families, and assess where evaluation meth
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用经典贝叶斯核的瘦视频去噪方法，通过小型辅助网络改进原始去噪器的性能，同时保持快速的去噪速度。这项研究采用了一种混合维纳滤波器，它使用小型辅助网络来改进维纳核估计、优化窗函数并估计未知噪声模式。通过这些方法，论文中提出的去噪器平均在0.2 dB左右优于流行的VRT变换器。这种方法比变换器方法快了超过10倍，同时还具有较低的参数数量和内存需求，提供了一种在速度和去噪效果之间取得平衡的有效视频去噪解决方案。</title><link>https://arxiv.org/abs/2408.03904</link><description>&lt;p&gt;
Lightweight Video Denoising Using a Classic Bayesian Backbone
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03904
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用经典贝叶斯核的瘦视频去噪方法，通过小型辅助网络改进原始去噪器的性能，同时保持快速的去噪速度。这项研究采用了一种混合维纳滤波器，它使用小型辅助网络来改进维纳核估计、优化窗函数并估计未知噪声模式。通过这些方法，论文中提出的去噪器平均在0.2 dB左右优于流行的VRT变换器。这种方法比变换器方法快了超过10倍，同时还具有较低的参数数量和内存需求，提供了一种在速度和去噪效果之间取得平衡的有效视频去噪解决方案。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03904v1 Announce Type: cross  Abstract: In recent years, state-of-the-art image and video denoising networks have become increasingly large, requiring millions of trainable parameters to achieve best-in-class performance. Improved denoising quality has come at the cost of denoising speed, where modern transformer networks are far slower to run than smaller denoising networks such as FastDVDnet and classic Bayesian denoisers such as the Wiener filter.   In this paper, we implement a hybrid Wiener filter which leverages small ancillary networks to increase the original denoiser performance, while retaining fast denoising speeds. These networks are used to refine the Wiener coring estimate, optimise windowing functions and estimate the unknown noise profile. Using these methods, we outperform several popular denoisers and remain within 0.2 dB, on average, of the popular VRT transformer. Our method was found to be over x10 faster than the transformer method, with a far lower par
&lt;/p&gt;</description></item><item><title>该文章提出了一个创新的方案，即使用语言模型来简化数字图书馆中的学术论文摘要，使其更易于被普通公众理解，从而提高了学术文献的访问性。</title><link>https://arxiv.org/abs/2408.03899</link><description>&lt;p&gt;
Simplifying Scholarly Abstracts for Accessible Digital Libraries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03899
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个创新的方案，即使用语言模型来简化数字图书馆中的学术论文摘要，使其更易于被普通公众理解，从而提高了学术文献的访问性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03899v1 Announce Type: cross  Abstract: Standing at the forefront of knowledge dissemination, digital libraries curate vast collections of scientific literature. However, these scholarly writings are often laden with jargon and tailored for domain experts rather than the general public. As librarians, we strive to offer services to a diverse audience, including those with lower reading levels. To extend our services beyond mere access, we propose fine-tuning a language model to rewrite scholarly abstracts into more comprehensible versions, thereby making scholarly literature more accessible when requested. We began by introducing a corpus specifically designed for training models to simplify scholarly abstracts. This corpus consists of over three thousand pairs of abstracts and significance statements from diverse disciplines. We then fine-tuned four language models using this corpus. The outputs from the models were subsequently examined both quantitatively for accessibilit
&lt;/p&gt;</description></item><item><title>该文章提出的MORTAR框架是一种基于模型的运行时动作修复方法，专门针对AI-CPS中的AI控制器。MORTAR能够在无需访问底层AI模型详细信息的情况下，通过模拟和优化技术有效地修复控制器的动作，从而增强AI-CPS的安全性和质量保证。</title><link>https://arxiv.org/abs/2408.03892</link><description>&lt;p&gt;
MORTAR: A Model-based Runtime Action Repair Framework for AI-enabled Cyber-Physical Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03892
&lt;/p&gt;
&lt;p&gt;
该文章提出的MORTAR框架是一种基于模型的运行时动作修复方法，专门针对AI-CPS中的AI控制器。MORTAR能够在无需访问底层AI模型详细信息的情况下，通过模拟和优化技术有效地修复控制器的动作，从而增强AI-CPS的安全性和质量保证。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03892v1 Announce Type: cross  Abstract: Cyber-Physical Systems (CPSs) are increasingly prevalent across various industrial and daily-life domains, with applications ranging from robotic operations to autonomous driving. With recent advancements in artificial intelligence (AI), learning-based components, especially AI controllers, have become essential in enhancing the functionality and efficiency of CPSs. However, the lack of interpretability in these AI controllers presents challenges to the safety and quality assurance of AI-enabled CPSs (AI-CPSs). Existing methods for improving the safety of AI controllers often involve neural network repair, which requires retraining with additional adversarial examples or access to detailed internal information of the neural network. Hence, these approaches have limited applicability for black-box policies, where only the inputs and outputs are accessible during operation. To overcome this, we propose MORTAR, a runtime action repair fra
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为GraphProbe的新的图探针框架，用于研究并解释图形学习方法是否在不同程度上在图形表示学习中编码了图的结构信息，并设计了三个探针来分别从节点级、路径级和结构级三个角度来系统地调查和解读图形表示学习的过程，并对九种不同的图形学习方法进行了全面评估。</title><link>https://arxiv.org/abs/2408.03877</link><description>&lt;p&gt;
Knowledge Probing for Graph Representation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03877
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为GraphProbe的新的图探针框架，用于研究并解释图形学习方法是否在不同程度上在图形表示学习中编码了图的结构信息，并设计了三个探针来分别从节点级、路径级和结构级三个角度来系统地调查和解读图形表示学习的过程，并对九种不同的图形学习方法进行了全面评估。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03877v1 Announce Type: cross  Abstract: Graph learning methods have been extensively applied in diverse application areas. However, what kind of inherent graph properties e.g. graph proximity, graph structural information has been encoded into graph representation learning for downstream tasks is still under-explored. In this paper, we propose a novel graph probing framework (GraphProbe) to investigate and interpret whether the family of graph learning methods has encoded different levels of knowledge in graph representation learning. Based on the intrinsic properties of graphs, we design three probes to systematically investigate the graph representation learning process from different perspectives, respectively the node-wise level, the path-wise level, and the structural level. We construct a thorough evaluation benchmark with nine representative graph learning methods from random walk based approaches, basic graph neural networks and self-supervised graph methods, and pro
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的Transformer模型，用于处理具有稀疏性和跨系列效应的供应链需求预测问题，通过对时间序列进行跨序列注意机制，有效提升了预测精度。</title><link>https://arxiv.org/abs/2408.03872</link><description>&lt;p&gt;
Inter-Series Transformer: Attending to Products in Time Series Forecasting
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03872
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的Transformer模型，用于处理具有稀疏性和跨系列效应的供应链需求预测问题，通过对时间序列进行跨序列注意机制，有效提升了预测精度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03872v1 Announce Type: cross  Abstract: Time series forecasting is an important task in many fields ranging from supply chain management to weather forecasting. Recently, Transformer neural network architectures have shown promising results in forecasting on common time series benchmark datasets. However, application to supply chain demand forecasting, which can have challenging characteristics such as sparsity and cross-series effects, has been limited.   In this work, we explore the application of Transformer-based models to supply chain demand forecasting. In particular, we develop a new Transformer-based forecasting approach using a shared, multi-task per-time series network with an initial component applying attention across time series, to capture interactions and help address sparsity. We provide a case study applying our approach to successfully improve demand prediction for a medical device manufacturing company. To further validate our approach, we also apply it to
&lt;/p&gt;</description></item><item><title>该文章描述了在TAC-2023的PLABA生物医学文本简化任务中，利用语言模型和可控属性来改进文本可读性的方法，并分析了由T5-like模型、BARTLarge模型及其与可控属性的结合，以及通过ChatGPT提出的方法生成的输出。在自动评价中，该系统提交的输出在SARI得分中排名第二，而且在人类评分的句子简化性和术语简化性方面也取得了较好的成绩。</title><link>https://arxiv.org/abs/2408.03871</link><description>&lt;p&gt;
BeeManc at the PLABA Track of TAC-2023: Investigating LLMs and Controllable Attributes for Improving Biomedical Text Readability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03871
&lt;/p&gt;
&lt;p&gt;
该文章描述了在TAC-2023的PLABA生物医学文本简化任务中，利用语言模型和可控属性来改进文本可读性的方法，并分析了由T5-like模型、BARTLarge模型及其与可控属性的结合，以及通过ChatGPT提出的方法生成的输出。在自动评价中，该系统提交的输出在SARI得分中排名第二，而且在人类评分的句子简化性和术语简化性方面也取得了较好的成绩。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03871v1 Announce Type: cross  Abstract: In this system report, we describe the models and methods we used for our participation in the PLABA2023 task on biomedical abstract simplification, part of the TAC 2023 tracks. The system outputs we submitted come from the following three categories: 1) domain fine-tuned T5-like models including Biomedical-T5 and Lay-SciFive; 2) fine-tuned BARTLarge model with controllable attributes (via tokens) BART-w-CTs; 3) ChatGPTprompting. We also present the work we carried out for this task on BioGPT finetuning. In the official automatic evaluation using SARI scores, BeeManc ranks 2nd among all teams and our model LaySciFive ranks 3rd among all 13 evaluated systems. In the official human evaluation, our model BART-w-CTs ranks 2nd on Sentence-Simplicity (score 92.84), 3rd on Term-Simplicity (score 82.33) among all 7 evaluated systems; It also produced a high score 91.57 on Fluency in comparison to the highest score 93.53. In the second round of
&lt;/p&gt;</description></item><item><title>该文章介绍了如何根据特定的映射标准和方法论，将W3C推荐的Provenance Ontology（PROV-O）与ISO/IEC标准Basic Formal Ontology（BFO）进行对齐，以提高它们及其扩展版本的数据互操作性。通过使用SPARQL查询对齐结果的逻辑一致性进行了评估，并检查了不符合映射标准的术语。此外，使用了多种 semantic web technologies 来支持FAIR原则。</title><link>https://arxiv.org/abs/2408.03866</link><description>&lt;p&gt;
Mapping the Provenance Ontology to Basic Formal Ontology
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03866
&lt;/p&gt;
&lt;p&gt;
该文章介绍了如何根据特定的映射标准和方法论，将W3C推荐的Provenance Ontology（PROV-O）与ISO/IEC标准Basic Formal Ontology（BFO）进行对齐，以提高它们及其扩展版本的数据互操作性。通过使用SPARQL查询对齐结果的逻辑一致性进行了评估，并检查了不符合映射标准的术语。此外，使用了多种 semantic web technologies 来支持FAIR原则。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03866v1 Announce Type: cross  Abstract: The Provenance Ontology (PROV-O) is a World Wide Web Consortium (W3C) recommended ontology used to structure data about provenance across a wide variety of domains. Basic Formal Ontology (BFO) is a top-level ontology ISO/IEC standard used to structure a wide variety of ontologies, such as the OBO Foundry ontologies and the Common Core Ontologies (CCO). To enhance interoperability between these two ontologies, their extensions, and data organized by them, an alignment is presented according to a specific mapping criteria and methodology which prioritizes structural and semantic considerations. The ontology alignment is evaluated by checking its logical consistency with canonical examples of PROV-O instances and querying terms that do not satisfy the mapping criteria as formalized in SPARQL. A variety of semantic web technologies are used in support of FAIR (Findable, Accessible, Interoperable, Reusable) principles.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为MaxMind的记忆循环网络模型，旨在利用大型语言模型提高软件开发效率，通过实时记忆和经验参考机制，以及知识精确度分段，优化了RAG机制，并设计了一个名为MaxMind4Sheet的电子表格处理软件，展示了如何将记忆模型应用于特定的软件工具开发中，从而提高了软件开发的效率和智能化水平。</title><link>https://arxiv.org/abs/2408.03841</link><description>&lt;p&gt;
MaxMind: A Memory Loop Network to Enhance Software Productivity based on Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03841
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为MaxMind的记忆循环网络模型，旨在利用大型语言模型提高软件开发效率，通过实时记忆和经验参考机制，以及知识精确度分段，优化了RAG机制，并设计了一个名为MaxMind4Sheet的电子表格处理软件，展示了如何将记忆模型应用于特定的软件工具开发中，从而提高了软件开发的效率和智能化水平。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03841v1 Announce Type: cross  Abstract: The application of large language models to facilitate automated software operations and tool generation (SOTG), thus augmenting software productivity, mirrors the early stages of human evolution when the ability to create and use tools accelerated the progress of civilization. These complex tasks require AI to continuously summarize and improve. Current research often overlooks the importance of converting real-time task experiences into system memory and differentiating the value of existing knowledge for future reference. This paper addresses these issues by evolving external memory models into Memory-Loop Networks for timely memorization and experience referencing. We also enhance a RAG mechanism with knowledge precision segmentation to utilize memory based on value differentiation, and design the MaxMind model for SOTG accordingly.To demonstrate our approach, we developed MaxMind4Sheet, an electronic spreadsheet processing system 
&lt;/p&gt;</description></item><item><title>该工具为研究者提供了一种开放性高、功能全面的评估大型语言模型安全性的方法，并且覆盖了多种不同类型的安全测试场景，促进了相关模型安全性的深入研究。</title><link>https://arxiv.org/abs/2408.03837</link><description>&lt;p&gt;
WalledEval: A Comprehensive Safety Evaluation Toolkit for Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03837
&lt;/p&gt;
&lt;p&gt;
该工具为研究者提供了一种开放性高、功能全面的评估大型语言模型安全性的方法，并且覆盖了多种不同类型的安全测试场景，促进了相关模型安全性的深入研究。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03837v1 Announce Type: cross  Abstract: WalledEval is a comprehensive AI safety testing toolkit designed to evaluate large language models (LLMs). It accommodates a diverse range of models, including both open-weight and API-based ones, and features over 35 safety benchmarks covering areas such as multilingual safety, exaggerated safety, and prompt injections. The framework supports both LLM and judge benchmarking, and incorporates custom mutators to test safety against various text-style mutations such as future tense and paraphrasing. Additionally, WalledEval introduces WalledGuard, a new, small and performant content moderation tool, and SGXSTest, a benchmark for assessing exaggerated safety in cultural contexts. We make WalledEval publicly available at https://github.com/walledai/walledevalA.
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了针对信息提取的视觉语言模型的目标提示方法，以期解决传统通用提示在特定场合下的不足，通过针对性地设计提示，提高了视觉语言模型在文档生成和问答系统中的准确性。</title><link>https://arxiv.org/abs/2408.03834</link><description>&lt;p&gt;
Target Prompting for Information Extraction with Vision Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03834
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了针对信息提取的视觉语言模型的目标提示方法，以期解决传统通用提示在特定场合下的不足，通过针对性地设计提示，提高了视觉语言模型在文档生成和问答系统中的准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03834v1 Announce Type: new  Abstract: The recent trend in the Large Vision and Language model has brought a new change in how information extraction systems are built. VLMs have set a new benchmark with their State-of-the-art techniques in understanding documents and building question-answering systems across various industries. They are significantly better at generating text from document images and providing accurate answers to questions. However, there are still some challenges in effectively utilizing these models to build a precise conversational system. General prompting techniques used with large language models are often not suitable for these specially designed vision language models. The output generated by such generic input prompts is ordinary and may contain information gaps when compared with the actual content of the document. To obtain more accurate and specific answers, a well-targeted prompt is required by the vision language model, along with the document
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为FixAlly的自动工具，该工具可结合多代理LLM（语言模型）架构，为移动应用中的访问性问题自动提出代码修复建议。该工具能够解决由访问性扫描器检测到的77%的问题，同时它对iOS开发者的调查结果显示，开发者愿意接受约69.4%的代码修复建议。</title><link>https://arxiv.org/abs/2408.03827</link><description>&lt;p&gt;
Automated Code Fix Suggestions for Accessibility Issues in Mobile Apps
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03827
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为FixAlly的自动工具，该工具可结合多代理LLM（语言模型）架构，为移动应用中的访问性问题自动提出代码修复建议。该工具能够解决由访问性扫描器检测到的77%的问题，同时它对iOS开发者的调查结果显示，开发者愿意接受约69.4%的代码修复建议。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03827v1 Announce Type: cross  Abstract: Accessibility is crucial for inclusive app usability, yet developers often struggle to identify and fix app accessibility issues due to a lack of awareness, expertise, and inadequate tools. Current accessibility testing tools can identify accessibility issues but may not always provide guidance on how to address them. We introduce FixAlly, an automated tool designed to suggest source code fixes for accessibility issues detected by automated accessibility scanners. FixAlly employs a multi-agent LLM architecture to generate fix strategies, localize issues within the source code, and propose code modification suggestions to fix the accessibility issue. Our empirical study demonstrates FixAlly's capability in suggesting fixes that resolve issues found by accessibility scanners -- with an effectiveness of 77% in generating plausible fix suggestions -- and our survey of 12 iOS developers finds they would be willing to accept 69.4% of evaluat
&lt;/p&gt;</description></item><item><title>该文章提出的模型结合了向量数据库和GLM技术，通过改进的检索过程和提示工程，在ASAS领域实现了显著的性能提升。</title><link>https://arxiv.org/abs/2408.03811</link><description>&lt;p&gt;
Generative Language Models with Retrieval Augmented Generation for Automated Short Answer Scoring
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03811
&lt;/p&gt;
&lt;p&gt;
该文章提出的模型结合了向量数据库和GLM技术，通过改进的检索过程和提示工程，在ASAS领域实现了显著的性能提升。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03811v1 Announce Type: cross  Abstract: Automated Short Answer Scoring (ASAS) is a critical component in educational assessment. While traditional ASAS systems relied on rule-based algorithms or complex deep learning methods, recent advancements in Generative Language Models (GLMs) offer new opportunities for improvement. This study explores the application of GLMs to ASAS, leveraging their off-the-shelf capabilities and performance in various domains. We propose a novel pipeline that combines vector databases, transformer-based encoders, and GLMs to enhance short answer scoring accuracy. Our approach stores training responses in a vector database, retrieves semantically similar responses during inference, and employs a GLM to analyze these responses and determine appropriate scores. We further optimize the system through fine-tuned retrieval processes and prompt engineering. Evaluation on the SemEval 2013 dataset demonstrates a significant improvement on the SCIENTSBANK 3-w
&lt;/p&gt;</description></item><item><title>该文章提出了一种结合目标条件生成模型和采样式模型预测控制的算法，实现了在拥挤环境中实时机器人的路径规划，通过预测周围人群的反应来减少碰撞风险并缩短路径长度，并在实际机器人平台上得到了验证。</title><link>https://arxiv.org/abs/2408.03807</link><description>&lt;p&gt;
Navigating the Human Maze: Real-Time Robot Pathfinding with Generative Imitation Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03807
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种结合目标条件生成模型和采样式模型预测控制的算法，实现了在拥挤环境中实时机器人的路径规划，通过预测周围人群的反应来减少碰撞风险并缩短路径长度，并在实际机器人平台上得到了验证。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03807v1 Announce Type: new  Abstract: This paper addresses navigation in crowded environments by integrating goal-conditioned generative models with Sampling-based Model Predictive Control (SMPC). We introduce goal-conditioned autoregressive models to generate crowd behaviors, capturing intricate interactions among individuals. The model processes potential robot trajectory samples and predicts the reactions of surrounding individuals, enabling proactive robotic navigation in complex scenarios. Extensive experiments show that this algorithm enables real-time navigation, significantly reducing collision rates and path lengths, and outperforming selected baseline methods. The practical effectiveness of this algorithm is validated on an actual robotic platform, demonstrating its capability in dynamic settings.
&lt;/p&gt;</description></item><item><title>该文章创新性地将布尔逻辑比例的概念与三角非模糊集的Frank家族结合，提出了基于三角恒等式的新方法，用于定义数值之间的类比比例。这一贡献对理解不同逻辑系统间的比例关系具有重要意义。</title><link>https://arxiv.org/abs/2408.03795</link><description>&lt;p&gt;
Frank's triangular norms in Piaget's logical proportions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03795
&lt;/p&gt;
&lt;p&gt;
该文章创新性地将布尔逻辑比例的概念与三角非模糊集的Frank家族结合，提出了基于三角恒等式的新方法，用于定义数值之间的类比比例。这一贡献对理解不同逻辑系统间的比例关系具有重要意义。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03795v1 Announce Type: new  Abstract: Starting from the Boolean notion of logical proportion in Piaget's sense, which turns out to be equivalent to analogical proportion, this note proposes a definition of analogical proportion between numerical values based on triangular norms (and dual co-norms). Frank's family of triangular norms is particularly interesting from this perspective. The article concludes with a comparative discussion with another very recent proposal for defining analogical proportions between numerical values based on the family of generalized means.
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的用户中心化的知识探索推荐框架，通过考虑用户的交互行为，提高了推荐系统的多样性和用户的知识获取量。</title><link>https://arxiv.org/abs/2408.03772</link><description>&lt;p&gt;
Relevance meets Diversity: A User-Centric Framework for Knowledge Exploration through Recommendations
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03772
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的用户中心化的知识探索推荐框架，通过考虑用户的交互行为，提高了推荐系统的多样性和用户的知识获取量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03772v1 Announce Type: cross  Abstract: Providing recommendations that are both relevant and diverse is a key consideration of modern recommender systems. Optimizing both of these measures presents a fundamental trade-off, as higher diversity typically comes at the cost of relevance, resulting in lower user engagement. Existing recommendation algorithms try to resolve this trade-off by combining the two measures, relevance and diversity, into one aim and then seeking recommendations that optimize the combined objective, for a given number of items to recommend. Traditional approaches, however, do not consider the user interaction with the recommended items.   In this paper, we put the user at the central stage, and build on the interplay between relevance, diversity, and user behavior. In contrast to applications where the goal is solely to maximize engagement, we focus on scenarios aiming at maximizing the total amount of knowledge encountered by the user. We use diversity 
&lt;/p&gt;</description></item><item><title>该文章详细介绍了在线模型为基础的多元时间序列异常检测的最新研究进展，提出了一个新颖的分类体系来理解和评估时间序列异常检测方法，并对当前最先进的方法进行了综述。</title><link>https://arxiv.org/abs/2408.03747</link><description>&lt;p&gt;
Online Model-based Anomaly Detection in Multivariate Time Series: Taxonomy, Survey, Research Challenges and Future Directions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03747
&lt;/p&gt;
&lt;p&gt;
该文章详细介绍了在线模型为基础的多元时间序列异常检测的最新研究进展，提出了一个新颖的分类体系来理解和评估时间序列异常检测方法，并对当前最先进的方法进行了综述。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03747v1 Announce Type: cross  Abstract: Time-series anomaly detection plays an important role in engineering processes, like development, manufacturing and other operations involving dynamic systems. These processes can greatly benefit from advances in the field, as state-of-the-art approaches may aid in cases involving, for example, highly dimensional data. To provide the reader with understanding of the terminology, this survey introduces a novel taxonomy where a distinction between online and offline, and training and inference is made. Additionally, it presents the most popular data sets and evaluation metrics used in the literature, as well as a detailed analysis. Furthermore, this survey provides an extensive overview of the state-of-the-art model-based online semi- and unsupervised anomaly detection approaches for multivariate time-series data, categorising them into different model families and other properties. The biggest research challenge revolves around benchmar
&lt;/p&gt;</description></item><item><title>该文章提供了一种新颖的方法，将扩散技术与隐式先验相结合，用于学习后验似然的变分法，以增强贝叶斯最后层模型（BLL）的表达能力，特别是在处理非正态分布、异常值丰富或高维数据集时。通过使用隐式分布来建模BLL的权重先验，并将扩散采样器用于近似真实的后验预测，本文提出的方法建立了一个全面的后验和先验估计策略。</title><link>https://arxiv.org/abs/2408.03746</link><description>&lt;p&gt;
Flexible Bayesian Last Layer Models Using Implicit Priors and Diffusion Posterior Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03746
&lt;/p&gt;
&lt;p&gt;
该文章提供了一种新颖的方法，将扩散技术与隐式先验相结合，用于学习后验似然的变分法，以增强贝叶斯最后层模型（BLL）的表达能力，特别是在处理非正态分布、异常值丰富或高维数据集时。通过使用隐式分布来建模BLL的权重先验，并将扩散采样器用于近似真实的后验预测，本文提出的方法建立了一个全面的后验和先验估计策略。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03746v1 Announce Type: cross  Abstract: Bayesian Last Layer (BLL) models focus solely on uncertainty in the output layer of neural networks, demonstrating comparable performance to more complex Bayesian models. However, the use of Gaussian priors for last layer weights in Bayesian Last Layer (BLL) models limits their expressive capacity when faced with non-Gaussian, outlier-rich, or high-dimensional datasets. To address this shortfall, we introduce a novel approach that combines diffusion techniques and implicit priors for variational learning of Bayesian last layer weights. This method leverages implicit distributions for modeling weight priors in BLL, coupled with diffusion samplers for approximating true posterior predictions, thereby establishing a comprehensive Bayesian prior and posterior estimation strategy. By delivering an explicit and computationally efficient variational lower bound, our method aims to augment the expressive abilities of BLL models, enhancing mode
&lt;/p&gt;</description></item><item><title>该文章提出了一个基于直觉模糊认知地图（iFCM）的图像分类框架，该框架能够为深度学习模型提供可解释性。这种方法使得用户能够理解模型决策背后的逻辑，从而在使用时更加放心。通过将直觉模糊认知地图应用于图像分类任务，该研究可能在模糊系统在图像处理领域的应用方面实现了重要创新，提升了机器学习模型在复杂决策场景中的实际应用价值。</title><link>https://arxiv.org/abs/2408.03745</link><description>&lt;p&gt;
Intuitionistic Fuzzy Cognitive Maps for Interpretable Image Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03745
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个基于直觉模糊认知地图（iFCM）的图像分类框架，该框架能够为深度学习模型提供可解释性。这种方法使得用户能够理解模型决策背后的逻辑，从而在使用时更加放心。通过将直觉模糊认知地图应用于图像分类任务，该研究可能在模糊系统在图像处理领域的应用方面实现了重要创新，提升了机器学习模型在复杂决策场景中的实际应用价值。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03745v1 Announce Type: new  Abstract: The interpretability of machine learning models is critical, as users may be reluctant to rely on their inferences. Intuitionistic FCMs (iFCMs) have been proposed as an extension of FCMs offering a natural mechanism to assess the quality of their output through the estimation of hesitancy, a concept resembling to human hesitation in decision making. To address the challenge of interpretable image classification, this paper introduces a novel framework, named Interpretable Intuitionistic FCM (I2FCM) which is domain-independent, simple to implement, and can be applied on Convolutional Neural Network (CNN) models, rendering them interpretable. To the best of our knowledge this is the first time iFCMs are applied for image classification. Further novel contributions include: a feature extraction process focusing on the most informative image regions; a learning algorithm for data-driven determination of the intuitionistic fuzzy interconnecti
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了基于组间尺度学习的方法，结合量化自适应和多模态优化，改进了多模态大型语言模型在视觉语言指导训练中的资源消耗。通过学习量化后的模型权重组间尺度因子，缓解了因激活异常值导致的量化错误，并有效提升了视觉语言指导训练的性能。此外，通过渐进式的多模态训练样本集成，该方法防止了模型对多模态数据的过拟合并保证了多模态大型语言模型在下游视觉语言任务中的稳定适应性。实验结果表明，采用该方法进行量化的模型性能有了显著提升。</title><link>https://arxiv.org/abs/2408.03735</link><description>&lt;p&gt;
Advancing Multimodal Large Language Models with Quantization-Aware Scale Learning for Efficient Adaptation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03735
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了基于组间尺度学习的方法，结合量化自适应和多模态优化，改进了多模态大型语言模型在视觉语言指导训练中的资源消耗。通过学习量化后的模型权重组间尺度因子，缓解了因激活异常值导致的量化错误，并有效提升了视觉语言指导训练的性能。此外，通过渐进式的多模态训练样本集成，该方法防止了模型对多模态数据的过拟合并保证了多模态大型语言模型在下游视觉语言任务中的稳定适应性。实验结果表明，采用该方法进行量化的模型性能有了显著提升。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03735v1 Announce Type: new  Abstract: This paper presents the first study to explore the potential of parameter quantization for multimodal large language models to alleviate the significant resource constraint encountered during vision-language instruction tuning. We introduce a Quantization-aware Scale LeArning method based on multimodal Warmup, termed QSLAW. This method is grounded in two key innovations: (1) The learning of group-wise scale factors for quantized LLM weights to mitigate the quantization error arising from activation outliers and achieve more effective vision-language instruction tuning; (2) The implementation of a multimodal warmup that progressively integrates linguistic and multimodal training samples, thereby preventing overfitting of the quantized model to multimodal data while ensuring stable adaptation of multimodal large language models to downstream vision-language tasks. Extensive experiments demonstrate that models quantized by QSLAW perform on 
&lt;/p&gt;</description></item><item><title>该文章创新性地提出了一种以应用到对话术语提取为例，为上下文语言模型的隐空间局部拓扑复杂度测量方法。</title><link>https://arxiv.org/abs/2408.03706</link><description>&lt;p&gt;
Local Topology Measures of Contextual Language Model Latent Spaces With Applications to Dialogue Term Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03706
&lt;/p&gt;
&lt;p&gt;
该文章创新性地提出了一种以应用到对话术语提取为例，为上下文语言模型的隐空间局部拓扑复杂度测量方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03706v1 Announce Type: cross  Abstract: A common approach for sequence tagging tasks based on contextual word representations is to train a machine learning classifier directly on these embedding vectors. This approach has two shortcomings. First, such methods consider single input sequences in isolation and are unable to put an individual embedding vector in relation to vectors outside the current local context of use. Second, the high performance of these models relies on fine-tuning the embedding model in conjunction with the classifier, which may not always be feasible due to the size or inaccessibility of the underlying feature-generation model. It is thus desirable, given a collection of embedding vectors of a corpus, i.e., a datastore, to find features of each vector that describe its relation to other, similar vectors in the datastore. With this in mind, we introduce complexity measures of the local topology of the latent space of a contextual language model with res
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于区块链的可靠联邦元学习方法，用于管理metaverse中的元学习者作为工人，通过双游戏理论框架来解决元学习者在元宇宙服务中的异质性问题。</title><link>https://arxiv.org/abs/2408.03694</link><description>&lt;p&gt;
A Blockchain-based Reliable Federated Meta-learning for Metaverse: A Dual Game Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03694
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于区块链的可靠联邦元学习方法，用于管理metaverse中的元学习者作为工人，通过双游戏理论框架来解决元学习者在元宇宙服务中的异质性问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03694v1 Announce Type: cross  Abstract: The metaverse, envisioned as the next digital frontier for avatar-based virtual interaction, involves high-performance models. In this dynamic environment, users' tasks frequently shift, requiring fast model personalization despite limited data. This evolution consumes extensive resources and requires vast data volumes. To address this, meta-learning emerges as an invaluable tool for metaverse users, with federated meta-learning (FML), offering even more tailored solutions owing to its adaptive capabilities. However, the metaverse is characterized by users heterogeneity with diverse data structures, varied tasks, and uneven sample sizes, potentially undermining global training outcomes due to statistical difference. Given this, an urgent need arises for smart coalition formation that accounts for these disparities. This paper introduces a dual game-theoretic framework for metaverse services involving meta-learners as workers to manage 
&lt;/p&gt;</description></item><item><title>该文章通过利用生成型人工智能，特别是VAE及其内部表示，成功地开发了一种创新方法来设计周期性轨道，尤其是在限制性三体问题中。这种方法通过训练深度学习模型来捕捉关键轨道特征，并应用于CR3BP的周期性轨道数据集，为未来的空间任务规划和天体动力学研究提供了新的视角和工具。</title><link>https://arxiv.org/abs/2408.03691</link><description>&lt;p&gt;
Generative Design of Periodic Orbits in the Restricted Three-Body Problem
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03691
&lt;/p&gt;
&lt;p&gt;
该文章通过利用生成型人工智能，特别是VAE及其内部表示，成功地开发了一种创新方法来设计周期性轨道，尤其是在限制性三体问题中。这种方法通过训练深度学习模型来捕捉关键轨道特征，并应用于CR3BP的周期性轨道数据集，为未来的空间任务规划和天体动力学研究提供了新的视角和工具。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03691v1 Announce Type: cross  Abstract: The Three-Body Problem has fascinated scientists for centuries and it has been crucial in the design of modern space missions. Recent developments in Generative Artificial Intelligence hold transformative promise for addressing this longstanding problem. This work investigates the use of Variational Autoencoder (VAE) and its internal representation to generate periodic orbits. We utilize a comprehensive dataset of periodic orbits in the Circular Restricted Three-Body Problem (CR3BP) to train deep-learning architectures that capture key orbital characteristics, and we set up physical evaluation metrics for the generated trajectories. Through this investigation, we seek to enhance the understanding of how Generative AI can improve space mission planning and astrodynamics research, leading to novel, data-driven approaches in the field.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为HiQuE的深度学习模型，该模型能够有效地利用临床访谈中的问题结构信息，通过考虑基础问题和跟进问题之间的层级关系来提高抑郁症的自动检测准确率。</title><link>https://arxiv.org/abs/2408.03648</link><description>&lt;p&gt;
HiQuE: Hierarchical Question Embedding Network for Multimodal Depression Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03648
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为HiQuE的深度学习模型，该模型能够有效地利用临床访谈中的问题结构信息，通过考虑基础问题和跟进问题之间的层级关系来提高抑郁症的自动检测准确率。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03648v1 Announce Type: new  Abstract: The utilization of automated depression detection significantly enhances early intervention for individuals experiencing depression. Despite numerous proposals on automated depression detection using recorded clinical interview videos, limited attention has been paid to considering the hierarchical structure of the interview questions. In clinical interviews for diagnosing depression, clinicians use a structured questionnaire that includes routine baseline questions and follow-up questions to assess the interviewee's condition. This paper introduces HiQuE (Hierarchical Question Embedding network), a novel depression detection framework that leverages the hierarchical relationship between primary and follow-up questions in clinical interviews. HiQuE can effectively capture the importance of each question in diagnosing depression by learning mutual information across multiple modalities. We conduct extensive experiments on the widely-used 
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为 Concept Conductor 的训练免费框架，能够确保在多概念定制下实现视觉真实感和正确布局，并通过自我注意为基础的空间指导纠正布局错误，通过特征融合和使用形状感知遮罩以指定每个概念的生成区域，从而在注意力层中注入个人化概念的结构和外观。</title><link>https://arxiv.org/abs/2408.03632</link><description>&lt;p&gt;
Concept Conductor: Orchestrating Multiple Personalized Concepts in Text-to-Image Synthesis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03632
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为 Concept Conductor 的训练免费框架，能够确保在多概念定制下实现视觉真实感和正确布局，并通过自我注意为基础的空间指导纠正布局错误，通过特征融合和使用形状感知遮罩以指定每个概念的生成区域，从而在注意力层中注入个人化概念的结构和外观。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03632v1 Announce Type: new  Abstract: The customization of text-to-image models has seen significant advancements, yet generating multiple personalized concepts remains a challenging task. Current methods struggle with attribute leakage and layout confusion when handling multiple concepts, leading to reduced concept fidelity and semantic consistency. In this work, we introduce a novel training-free framework, Concept Conductor, designed to ensure visual fidelity and correct layout in multi-concept customization. Concept Conductor isolates the sampling processes of multiple custom models to prevent attribute leakage between different concepts and corrects erroneous layouts through self-attention-based spatial guidance. Additionally, we present a concept injection technique that employs shape-aware masks to specify the generation area for each concept. This technique injects the structure and appearance of personalized concepts through feature fusion in the attention layers, e
&lt;/p&gt;</description></item><item><title>该文章开发了一种基于大型语言模型的基站选址优化框架，通过引人人的经验和知识，实现了更高效的用户与AI系统的自然语言通信，推进了AI服务在通信领域的应用。</title><link>https://arxiv.org/abs/2408.03631</link><description>&lt;p&gt;
Large Language Models for Base Station Siting: Intelligent Deployment based on Prompt or Agent
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03631
&lt;/p&gt;
&lt;p&gt;
该文章开发了一种基于大型语言模型的基站选址优化框架，通过引人人的经验和知识，实现了更高效的用户与AI系统的自然语言通信，推进了AI服务在通信领域的应用。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03631v1 Announce Type: new  Abstract: Traditional base station siting (BSS) methods rely heavily on drive testing and user feedback, which are laborious and require extensive expertise in communication, networking, and optimization. As large language models (LLMs) and their associated technologies advance, particularly in the realms of prompt engineering and agent engineering, network optimization will witness a revolutionary approach. This approach entails the strategic use of well-crafted prompts to infuse human experience and knowledge into these sophisticated LLMs, and the deployment of autonomous agents as a communication bridge to seamlessly connect the machine language based LLMs with human users using natural language. This integration represents the future paradigm of artificial intelligence (AI) as a service and AI for more ease. As a preliminary exploration, this research first develops a novel LLM-empowered BSS optimization framework, and heuristically proposes f
&lt;/p&gt;</description></item><item><title>该文章创新地开发了一种针对Persian临床文本的拼写校正系统，通过结合深度学习模型和专门的字符视觉相似性匹配算法，有效提高了电子健康记录中拼写准确性的同时，确保了临床研究和患者安全工作的效率与质量。</title><link>https://arxiv.org/abs/2408.03622</link><description>&lt;p&gt;
Improving the quality of Persian clinical text with a novel spelling correction system
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03622
&lt;/p&gt;
&lt;p&gt;
该文章创新地开发了一种针对Persian临床文本的拼写校正系统，通过结合深度学习模型和专门的字符视觉相似性匹配算法，有效提高了电子健康记录中拼写准确性的同时，确保了临床研究和患者安全工作的效率与质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03622v1 Announce Type: cross  Abstract: Background: The accuracy of spelling in Electronic Health Records (EHRs) is a critical factor for efficient clinical care, research, and ensuring patient safety. The Persian language, with its abundant vocabulary and complex characteristics, poses unique challenges for real-word error correction. This research aimed to develop an innovative approach for detecting and correcting spelling errors in Persian clinical text.   Methods: Our strategy employs a state-of-the-art pre-trained model that has been meticulously fine-tuned specifically for the task of spelling correction in the Persian clinical domain. This model is complemented by an innovative orthographic similarity matching algorithm, PERTO, which uses visual similarity of characters for ranking correction candidates.   Results: The evaluation of our approach demonstrated its robustness and precision in detecting and rectifying word errors in Persian clinical text. In terms of non
&lt;/p&gt;</description></item><item><title>该文章提出了一个基于逻辑谬误的Argument Generation框架，通过引入偏好优化方法和逻辑谬误的校正，显著提升了大型语言模型生成逻辑上连贯和正确论点的能力，并提高了由人类评价的生成论点的质量。</title><link>https://arxiv.org/abs/2408.03618</link><description>&lt;p&gt;
A Logical Fallacy-Informed Framework for Argument Generation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03618
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个基于逻辑谬误的Argument Generation框架，通过引入偏好优化方法和逻辑谬误的校正，显著提升了大型语言模型生成逻辑上连贯和正确论点的能力，并提高了由人类评价的生成论点的质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03618v1 Announce Type: cross  Abstract: Despite the remarkable performance of Large Language Models (LLMs), they still struggle with generating logically sound arguments, resulting in potential risks such as spreading misinformation. An important factor contributing to LLMs' suboptimal performance in generating coherent arguments is their oversight of logical fallacies. To address this issue, we introduce FIPO, a fallacy-informed framework that leverages preference optimization methods to steer LLMs toward logically sound arguments. FIPO includes a classification loss, to capture the fine-grained information on fallacy categories. Our results on argumentation datasets show that our method reduces the fallacy errors by up to 17.5%. Furthermore, our human evaluation results indicate that the quality of the generated arguments by our method significantly outperforms the fine-tuned baselines, as well as prior preference optimization methods, such as DPO. These findings highlight
&lt;/p&gt;</description></item><item><title>该文章提出并训练了一种基于儿童指令性口语的大语言模型，并对模型在语言理解和学习任务上的表现进行了评估。研究结果显示，儿童指令性口语的局部特性对模型性能有显著影响，但整体特性并未展现出预期的效果。这一发现揭示了儿童在语言学习中所接收到的数据类型对语言模型训练的价值，尤其是其局部语境和对话顺序特征可能在语言模型的发展中扮演了关键角色。</title><link>https://arxiv.org/abs/2408.03617</link><description>&lt;p&gt;
Is Child-Directed Speech Effective Training Data for Language Models?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03617
&lt;/p&gt;
&lt;p&gt;
该文章提出并训练了一种基于儿童指令性口语的大语言模型，并对模型在语言理解和学习任务上的表现进行了评估。研究结果显示，儿童指令性口语的局部特性对模型性能有显著影响，但整体特性并未展现出预期的效果。这一发现揭示了儿童在语言学习中所接收到的数据类型对语言模型训练的价值，尤其是其局部语境和对话顺序特征可能在语言模型的发展中扮演了关键角色。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03617v1 Announce Type: cross  Abstract: While high-performing language models are typically trained on hundreds of billions of words, human children become fluent language users with a much smaller amount of data. What are the features of the data they receive, and how do these features support language modeling objectives? To investigate this question, we train GPT-2 models on 29M words of English-language child-directed speech and a new matched, synthetic dataset (TinyDialogues), comparing to a heterogeneous blend of datasets from the BabyLM challenge. We evaluate both the syntactic and semantic knowledge of these models using developmentally-inspired evaluations. Through pretraining experiments, we test whether the global developmental ordering or the local discourse ordering of children's training data support high performance relative to other datasets. The local properties of the data affect model results, but somewhat surprisingly, global properties do not. Further, c
&lt;/p&gt;</description></item><item><title>该文章提出Optimus-1混合模态记忆赋能的代理在长期任务中表现出色，通过构建层级化知识图和抽象化多模态经验池，代理能够有效理解和决策。</title><link>https://arxiv.org/abs/2408.03615</link><description>&lt;p&gt;
Optimus-1: Hybrid Multimodal Memory Empowered Agents Excel in Long-Horizon Tasks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03615
&lt;/p&gt;
&lt;p&gt;
该文章提出Optimus-1混合模态记忆赋能的代理在长期任务中表现出色，通过构建层级化知识图和抽象化多模态经验池，代理能够有效理解和决策。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03615v1 Announce Type: new  Abstract: Building a general-purpose agent is a long-standing vision in the field of artificial intelligence. Existing agents have made remarkable progress in many domains, yet they still struggle to complete long-horizon tasks in an open world. We attribute this to the lack of necessary world knowledge and multimodal experience that can guide agents through a variety of long-horizon tasks. In this paper, we propose a Hybrid Multimodal Memory module to address the above challenges. It 1) transforms knowledge into Hierarchical Directed Knowledge Graph that allows agents to explicitly represent and learn world knowledge, and 2) summarises historical information into Abstracted Multimodal Experience Pool that provide agents with rich references for in-context learning. On top of the Hybrid Multimodal Memory module, a multimodal agent, Optimus-1, is constructed with dedicated Knowledge-guided Planner and Experience-Driven Reflector, contributing to a 
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为Ensemble Jailbreak的创新攻击方法，该方法结合了现有攻击中的故事/逻辑绕过和梯度精确攻击，旨在对大型语言模型实施更强大的混合攻击，从而绕过当前的安全机制。</title><link>https://arxiv.org/abs/2408.03603</link><description>&lt;p&gt;
EnJa: Ensemble Jailbreak on Large Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03603
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为Ensemble Jailbreak的创新攻击方法，该方法结合了现有攻击中的故事/逻辑绕过和梯度精确攻击，旨在对大型语言模型实施更强大的混合攻击，从而绕过当前的安全机制。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03603v1 Announce Type: cross  Abstract: As Large Language Models (LLMs) are increasingly being deployed in safety-critical applications, their vulnerability to potential jailbreaks -- malicious prompts that can disable the safety mechanism of LLMs -- has attracted growing research attention. While alignment methods have been proposed to protect LLMs from jailbreaks, many have found that aligned LLMs can still be jailbroken by carefully crafted malicious prompts, producing content that violates policy regulations. Existing jailbreak attacks on LLMs can be categorized into prompt-level methods which make up stories/logic to circumvent safety alignment and token-level attack methods which leverage gradient methods to find adversarial tokens. In this work, we introduce the concept of Ensemble Jailbreak and explore methods that can integrate prompt-level and token-level jailbreak into a more powerful hybrid jailbreak attack. Specifically, we propose a novel EnJa attack to hide ha
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的框架，用于通过操作激活函数来扩展神经网络，以此来提升神经网络的性能。这种拓展不仅对标准测试函数有显著的性能提升，并且在时间序列数据上的表现也得到了验证。此外，与传统的神经网络相比，这种拓展来的神经网络在空间和时间复杂性上几乎没有增加。</title><link>https://arxiv.org/abs/2408.03599</link><description>&lt;p&gt;
Activations Through Extensions: A Framework To Boost Performance Of Neural Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03599
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的框架，用于通过操作激活函数来扩展神经网络，以此来提升神经网络的性能。这种拓展不仅对标准测试函数有显著的性能提升，并且在时间序列数据上的表现也得到了验证。此外，与传统的神经网络相比，这种拓展来的神经网络在空间和时间复杂性上几乎没有增加。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03599v1 Announce Type: cross  Abstract: Activation functions are non-linearities in neural networks that allow them to learn complex mapping between inputs and outputs. Typical choices for activation functions are ReLU, Tanh, Sigmoid etc., where the choice generally depends on the application domain. In this work, we propose a framework/strategy that unifies several works on activation functions and theoretically explains the performance benefits of these works. We also propose novel techniques that originate from the framework and allow us to obtain ``extensions'' (i.e. special generalizations of a given neural network) of neural networks through operations on activation functions. We theoretically and empirically show that ``extensions'' of neural networks have performance benefits compared to vanilla neural networks with insignificant space and time complexity costs on standard test functions. We also show the benefits of neural network ``extensions'' in the time-series d
&lt;/p&gt;</description></item><item><title>该文章提出了一种无需用户特定校准的眼球追踪系统，通过深度学习模型分析眼球运动特征，实现了厘米级别的焦点距离估算精度，为提高个性化视觉技术和增强现实应用的集成水平做出了贡献。</title><link>https://arxiv.org/abs/2408.03591</link><description>&lt;p&gt;
Focal Depth Estimation: A Calibration-Free, Subject- and Daytime Invariant Approach
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03591
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种无需用户特定校准的眼球追踪系统，通过深度学习模型分析眼球运动特征，实现了厘米级别的焦点距离估算精度，为提高个性化视觉技术和增强现实应用的集成水平做出了贡献。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03591v1 Announce Type: new  Abstract: In an era where personalized technology is increasingly intertwined with daily life, traditional eye-tracking systems and autofocal glasses face a significant challenge: the need for frequent, user-specific calibration, which impedes their practicality. This study introduces a groundbreaking calibration-free method for estimating focal depth, leveraging machine learning techniques to analyze eye movement features within short sequences. Our approach, distinguished by its innovative use of LSTM networks and domain-specific feature engineering, achieves a mean absolute error (MAE) of less than 10 cm, setting a new focal depth estimation accuracy standard. This advancement promises to enhance the usability of autofocal glasses and pave the way for their seamless integration into extended reality environments, marking a significant leap forward in personalized visual technology.
&lt;/p&gt;</description></item><item><title>该文章提出了一种将唱歌声音分离纳入电影音频源分离的解决方案，改进了现有的音频源分离模型，能够更有效地处理电影中的唱歌声音，从而提高声音分离的准确性和实用性。</title><link>https://arxiv.org/abs/2408.03588</link><description>&lt;p&gt;
Facing the Music: Tackling Singing Voice Separation in Cinematic Audio Source Separation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03588
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种将唱歌声音分离纳入电影音频源分离的解决方案，改进了现有的音频源分离模型，能够更有效地处理电影中的唱歌声音，从而提高声音分离的准确性和实用性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03588v1 Announce Type: cross  Abstract: Cinematic audio source separation (CASS) is a fairly new subtask of audio source separation. A typical setup of CASS is a three-stem problem, with the aim of separating the mixture into the dialogue stem (DX), music stem (MX), and effects stem (FX). In practice, however, several edge cases exist as some sound sources do not fit neatly in either of these three stems, necessitating the use of additional auxiliary stems in production. One very common edge case is the singing voice in film audio, which may belong in either the DX or MX, depending heavily on the cinematic context. In this work, we demonstrate a very straightforward extension of the dedicated-decoder Bandit and query-based single-decoder Banquet models to a four-stem problem, treating non-musical dialogue, instrumental music, singing voice, and effects as separate stems. Interestingly, the query-based Banquet model outperformed the dedicated-decoder Bandit model. We hypothes
&lt;/p&gt;</description></item><item><title>该文章聚焦于旅游推销问题的神经构造解决方案，为了解决实际问题中出现的与随机问题实例不同的挑战，研究者们提出了一种层次化的神经构造求解器，它能够更好地处理现实世界的场景。该求解器不仅考虑了当前位置，而且对未访问的节点进行了有效的管理，同时通过引入基于自编码器和Hypernetworks的机制对下一步的选择进行优先排序，从而提出了一种更为有效的构造解决方案的方法。</title><link>https://arxiv.org/abs/2408.03585</link><description>&lt;p&gt;
Hierarchical Neural Constructive Solver for Real-world TSP Scenarios
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03585
&lt;/p&gt;
&lt;p&gt;
该文章聚焦于旅游推销问题的神经构造解决方案，为了解决实际问题中出现的与随机问题实例不同的挑战，研究者们提出了一种层次化的神经构造求解器，它能够更好地处理现实世界的场景。该求解器不仅考虑了当前位置，而且对未访问的节点进行了有效的管理，同时通过引入基于自编码器和Hypernetworks的机制对下一步的选择进行优先排序，从而提出了一种更为有效的构造解决方案的方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03585v1 Announce Type: cross  Abstract: Existing neural constructive solvers for routing problems have predominantly employed transformer architectures, conceptualizing the route construction as a set-to-sequence learning task. However, their efficacy has primarily been demonstrated on entirely random problem instances that inadequately capture real-world scenarios. In this paper, we introduce realistic Traveling Salesman Problem (TSP) scenarios relevant to industrial settings and derive the following insights: (1) The optimal next node (or city) to visit often lies within proximity to the current node, suggesting the potential benefits of biasing choices based on current locations. (2) Effectively solving the TSP requires robust tracking of unvisited nodes and warrants succinct grouping strategies. Building upon these insights, we propose integrating a learnable choice layer inspired by Hypernetworks to prioritize choices based on the current location, and a learnable appro
&lt;/p&gt;</description></item><item><title>该文章提出了一个通过多阶段采样技术进行大型语言模型主动测试的方法，该技术能够高效地评估模型的整体性能，同时减少了高质数据需求和测试成本，对LLM的性能评估具有重要的创新和贡献。</title><link>https://arxiv.org/abs/2408.03573</link><description>&lt;p&gt;
Active Testing of Large Language Model via Multi-Stage Sampling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03573
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个通过多阶段采样技术进行大型语言模型主动测试的方法，该技术能够高效地评估模型的整体性能，同时减少了高质数据需求和测试成本，对LLM的性能评估具有重要的创新和贡献。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03573v1 Announce Type: cross  Abstract: Performance evaluation plays a crucial role in the development life cycle of large language models (LLMs). It estimates the model's capability, elucidates behavior characteristics, and facilitates the identification of potential issues and limitations, thereby guiding further improvement. Given that LLMs' diverse task-handling abilities stem from large volumes of training data, a comprehensive evaluation also necessitates abundant, well-annotated, and representative test data to assess LLM performance across various downstream tasks. However, the demand for high-quality test data often entails substantial time, computational resources, and manual efforts, sometimes causing the evaluation to be inefficient or impractical. To address these challenges, researchers propose active testing, which estimates the overall performance by selecting a subset of test data. Nevertheless, the existing active testing methods tend to be inefficient, eve
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为2D-OOB的框架，用于对单个数据点的不同细胞进行联合估值，这对于量化单个数据点对机器学习模型训练的贡献至关重要。该方法能够识别出有助于或阻碍模型训练的数据点以及驱动这些数据点的具体细胞。经过广泛实验验证，2D-OOB在多种应用场景中都取得了优于现有方法的表现，并且运行效率更高。</title><link>https://arxiv.org/abs/2408.03572</link><description>&lt;p&gt;
2D-OOB: Attributing Data Contribution through Joint Valuation Framework
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03572
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为2D-OOB的框架，用于对单个数据点的不同细胞进行联合估值，这对于量化单个数据点对机器学习模型训练的贡献至关重要。该方法能够识别出有助于或阻碍模型训练的数据点以及驱动这些数据点的具体细胞。经过广泛实验验证，2D-OOB在多种应用场景中都取得了优于现有方法的表现，并且运行效率更高。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03572v1 Announce Type: cross  Abstract: Data valuation has emerged as a powerful framework to quantify the contribution of each datum to the training of a particular machine learning model. However, it is crucial to recognize that the quality of various cells within a single data point can vary greatly in practice. For example, even in the case of an abnormal data point, not all cells are necessarily noisy. The single scalar valuation assigned by existing methods blurs the distinction between noisy and clean cells of a data point, thereby compromising the interpretability of the valuation. In this paper, we propose 2D-OOB, an out-of-bag estimation framework for jointly determining helpful (or detrimental) samples, as well as the particular cells that drive them. Our comprehensive experiments demonstrate that 2D-OOB achieves state-of-the-art performance across multiple use cases, while being exponentially faster. 2D-OOB excels in detecting and rectifying fine-grained outliers
&lt;/p&gt;</description></item><item><title>该文章对比了LLM微调方法，包括量化低秩适配器(QLoRA)、检索增强训练(RAFT)和人类反馈强化学习(RLHF)，以及评估方法，如“黄金答案”端到端基准方法、传统NLP指标、RAG评估(Ragas)、OpenAI GPT-4评估指标和人类评估，使用了一个旅行聊天机器人用例。研究使用了从Reddit API获取的旅游相关子版块帖子组成的旅游数据集，用以提供旅游相关对话提示和个人旅游体验，然后对每种微调方法进行增强。研究使用了两种预训练的LLM，LLaMA 2 7B和Mistral 7B，对这两种模型应用了QLoRA和RAFT。模型推断结果被广泛地用于与上述评估方法进行比较。</title><link>https://arxiv.org/abs/2408.03562</link><description>&lt;p&gt;
A Comparison of LLM Finetuning Methods &amp;amp; Evaluation Metrics with Travel Chatbot Use Case
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03562
&lt;/p&gt;
&lt;p&gt;
该文章对比了LLM微调方法，包括量化低秩适配器(QLoRA)、检索增强训练(RAFT)和人类反馈强化学习(RLHF)，以及评估方法，如“黄金答案”端到端基准方法、传统NLP指标、RAG评估(Ragas)、OpenAI GPT-4评估指标和人类评估，使用了一个旅行聊天机器人用例。研究使用了从Reddit API获取的旅游相关子版块帖子组成的旅游数据集，用以提供旅游相关对话提示和个人旅游体验，然后对每种微调方法进行增强。研究使用了两种预训练的LLM，LLaMA 2 7B和Mistral 7B，对这两种模型应用了QLoRA和RAFT。模型推断结果被广泛地用于与上述评估方法进行比较。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03562v1 Announce Type: cross  Abstract: This research compares large language model (LLM) fine-tuning methods, including Quantized Low Rank Adapter (QLoRA), Retrieval Augmented fine-tuning (RAFT), and Reinforcement Learning from Human Feedback (RLHF), and additionally compared LLM evaluation methods including End to End (E2E) benchmark method of "Golden Answers", traditional natural language processing (NLP) metrics, RAG Assessment (Ragas), OpenAI GPT-4 evaluation metrics, and human evaluation, using the travel chatbot use case. The travel dataset was sourced from the the Reddit API by requesting posts from travel-related subreddits to get travel-related conversation prompts and personalized travel experiences, and augmented for each fine-tuning method. We used two pretrained LLMs utilized for fine-tuning research: LLaMa 2 7B, and Mistral 7B. QLoRA and RAFT are applied to the two pretrained models. The inferences from these models are extensively evaluated against the aforem
&lt;/p&gt;</description></item><item><title>"该文章提出了一种名为Marill的框架，通过在模型微调过程中引入结构性的变化，减少了在安全推理过程中使用安全多方计算（MPC）时所需的高成本操作。这不仅减少了MPC的计算负担，而且还扩大了MPC优化的应用范围。此外，该框架能够在不牺牲安全性的情况下，优化现有LLM模型的推理性能，对于希望保护用户隐私和模型知识产权的推理服务提供商来说，这是一个重要的贡献。"</title><link>https://arxiv.org/abs/2408.03561</link><description>&lt;p&gt;
MPC-Minimized Secure LLM Inference
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03561
&lt;/p&gt;
&lt;p&gt;
"该文章提出了一种名为Marill的框架，通过在模型微调过程中引入结构性的变化，减少了在安全推理过程中使用安全多方计算（MPC）时所需的高成本操作。这不仅减少了MPC的计算负担，而且还扩大了MPC优化的应用范围。此外，该框架能够在不牺牲安全性的情况下，优化现有LLM模型的推理性能，对于希望保护用户隐私和模型知识产权的推理服务提供商来说，这是一个重要的贡献。"
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03561v1 Announce Type: cross  Abstract: Many inference services based on large language models (LLMs) pose a privacy concern, either revealing user prompts to the service or the proprietary weights to the user. Secure inference offers a solution to this problem through secure multi-party computation (MPC), however, it is still impractical for modern LLM workload due to the large overhead imposed by MPC. To address this overhead, we propose Marill, a framework that adapts LLM fine-tuning to minimize MPC usage during secure inference. Marill introduces high-level architectural changes during fine-tuning that significantly reduce the number of expensive operations needed within MPC during inference, by removing some and relocating others outside MPC without compromising security. As a result, Marill-generated models are more efficient across all secure inference protocols and our approach complements MPC-friendly approximations for such operations. Compared to standard fine-tun
&lt;/p&gt;</description></item><item><title>该文章提出了一个称为D²Styler的框架，该框架使用VQ-GANs的离散表示能力和离散差分的优势，如稳定的训练和无模式塌陷，结合了自适应实例归一化（AdaIN），以在内容和风格图像之间平滑地转移特征，显著提高了风格转移图像的视觉质量。</title><link>https://arxiv.org/abs/2408.03558</link><description>&lt;p&gt;
D2Styler: Advancing Arbitrary Style Transfer with Discrete Diffusion Methods
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03558
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个称为D²Styler的框架，该框架使用VQ-GANs的离散表示能力和离散差分的优势，如稳定的训练和无模式塌陷，结合了自适应实例归一化（AdaIN），以在内容和风格图像之间平滑地转移特征，显著提高了风格转移图像的视觉质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03558v1 Announce Type: new  Abstract: In image processing, one of the most challenging tasks is to render an image's semantic meaning using a variety of artistic approaches. Existing techniques for arbitrary style transfer (AST) frequently experience mode-collapse, over-stylization, or under-stylization due to a disparity between the style and content images. We propose a novel framework called D$^2$Styler (Discrete Diffusion Styler) that leverages the discrete representational capability of VQ-GANs and the advantages of discrete diffusion, including stable training and avoidance of mode collapse. Our method uses Adaptive Instance Normalization (AdaIN) features as a context guide for the reverse diffusion process. This makes it easy to move features from the style image to the content image without bias. The proposed method substantially enhances the visual quality of style-transferred images, allowing the combination of content and style in a visually appealing manner. We t
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Native Language Prompting（NatLan）的策略，通过在机器学习模型中模拟人类多语言者使用母语知识的方式，使得模型即使在接收到的文本内容不在其主要熟语言范围内也可以有效提取相关知识，解决了传统机器学习模型在处理非主要熟语言内容时的困境。</title><link>https://arxiv.org/abs/2408.03544</link><description>&lt;p&gt;
Unlocking the Non-Native Language Context Limitation: Native Language Prompting Facilitates Knowledge Elicitation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03544
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Native Language Prompting（NatLan）的策略，通过在机器学习模型中模拟人类多语言者使用母语知识的方式，使得模型即使在接收到的文本内容不在其主要熟语言范围内也可以有效提取相关知识，解决了传统机器学习模型在处理非主要熟语言内容时的困境。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03544v1 Announce Type: cross  Abstract: Multilingual large language models (MLLMs) struggle to answer questions posed in non-dominant languages, even though they have already acquired the relevant knowledge from their dominant language corpus. In contrast, human multilinguals can overcome this issue by invoking the relatively rich knowledge acquired from native language texts through Positive Native Language Transfer (PNLT). Inspired by this, we analogize the dominant language of MLLMs to the native language of human multilinguals, and propose Native Language Prompting (NatLan) to simulate the PNLT observed in human multilinguals. It explicitly creates native language contexts for MLLMs to facilitate the elicitation of the rich native language knowledge during question-answering, unlocking the limitations imposed by non-native language contexts on the effective application of knowledge. By employing multi-MLLM collaboration, NatLan reduces the workload on each MLLM in simula
&lt;/p&gt;</description></item><item><title>该文章提出了通过自动估计覆盖面积（SAC）来最大化西班牙Extremadura地区橡树林下放养的伊比利亚猪的数量的方法。使用遥感技术，作者旨在通过自动检测技术来确定橡树的冠层覆盖面积，以及估算在特定土地上可以放养的伊比利亚猪的数量。</title><link>https://arxiv.org/abs/2408.03542</link><description>&lt;p&gt;
Automatic identification of the area covered by acorn trees in the dehesa (pastureland) Extremadura of Spain
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03542
&lt;/p&gt;
&lt;p&gt;
该文章提出了通过自动估计覆盖面积（SAC）来最大化西班牙Extremadura地区橡树林下放养的伊比利亚猪的数量的方法。使用遥感技术，作者旨在通过自动检测技术来确定橡树的冠层覆盖面积，以及估算在特定土地上可以放养的伊比利亚猪的数量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03542v1 Announce Type: new  Abstract: The acorn is the fruit of the oak and is an important crop in the Spanish dehesa extreme\~na, especially for the value it provides in the Iberian pig food to obtain the "acorn" certification. For this reason, we want to maximise the production of Iberian pigs with the appropriate weight. Hence the need to know the area covered by the crowns of the acorn trees, to determine the covered wooded area (CWA, from the Spanish Superficie Arbolada Cubierta SAC) and thereby estimate the number of Iberian pigs that can be released per hectare, as indicated by the royal decree 4/2014. In this work, we propose the automatic estimation of the CWA, through aerial digital images (orthophotos) of the pastureland of Extremadura, and with this, to offer the possibility of determining the number of Iberian pigs to be released in a specific plot of land. Among the main issues for automatic detection are, first, the correct identification of acorn trees, seco
&lt;/p&gt;</description></item><item><title>该文章中，EXAONE 3.0 7.8B 指令微调语言模型作为LG AI Research开发的第一个同类的大型语言模型，是公开模型的首个实例，主要创新在于其在指令遵循能力上与其他类似大小开放模型的竞争中展现出高水平的实际性能。特别是，其在 Korean 语言方面的卓越表现以及跨多种任务和复杂推理中的显著性能，强调了其在真实世界应用中的有效性。此外，其双语能力的展现标志着其在专家级人工智能领域的贡献可能持续增长。该模型通过 GitHub 上的 Hugging Face Co 公开提供了 20B 版本，进一步推动了开放研究和创新。</title><link>https://arxiv.org/abs/2408.03541</link><description>&lt;p&gt;
EXAONE 3.0 7.8B Instruction Tuned Language Model
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03541
&lt;/p&gt;
&lt;p&gt;
该文章中，EXAONE 3.0 7.8B 指令微调语言模型作为LG AI Research开发的第一个同类的大型语言模型，是公开模型的首个实例，主要创新在于其在指令遵循能力上与其他类似大小开放模型的竞争中展现出高水平的实际性能。特别是，其在 Korean 语言方面的卓越表现以及跨多种任务和复杂推理中的显著性能，强调了其在真实世界应用中的有效性。此外，其双语能力的展现标志着其在专家级人工智能领域的贡献可能持续增长。该模型通过 GitHub 上的 Hugging Face Co 公开提供了 20B 版本，进一步推动了开放研究和创新。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03541v1 Announce Type: cross  Abstract: We introduce EXAONE 3.0 instruction-tuned language model, the first open model in the family of Large Language Models (LLMs) developed by LG AI Research. Among different model sizes, we publicly release the 7.8B instruction-tuned model to promote open research and innovations. Through extensive evaluations across a wide range of public and in-house benchmarks, EXAONE 3.0 demonstrates highly competitive real-world performance with instruction-following capability against other state-of-the-art open models of similar size. Our comparative analysis shows that EXAONE 3.0 excels particularly in Korean, while achieving compelling performance across general tasks and complex reasoning. With its strong real-world effectiveness and bilingual proficiency, we hope that EXAONE keeps contributing to advancements in Expert AI. Our EXAONE 3.0 instruction-tuned model is available at https://huggingface.co/LGAI-EXAONE/EXAONE-3.0-7.8B-Instruct
&lt;/p&gt;</description></item><item><title>该文章提出了一种 lifelong personalized low-rank adaptation (LPALA) 方法，将大规模语言模型应用于推荐系统中，通过在低秩分解的参数上进行 lifetime adaptation，实现了个性化的提高，同时保持了推理效率，从而在推荐系统中实现了更高的个性化水平。</title><link>https://arxiv.org/abs/2408.03533</link><description>&lt;p&gt;
Lifelong Personalized Low-Rank Adaptation of Large Language Models for Recommendation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03533
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种 lifelong personalized low-rank adaptation (LPALA) 方法，将大规模语言模型应用于推荐系统中，通过在低秩分解的参数上进行 lifetime adaptation，实现了个性化的提高，同时保持了推理效率，从而在推荐系统中实现了更高的个性化水平。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03533v1 Announce Type: cross  Abstract: We primarily focus on the field of large language models (LLMs) for recommendation, which has been actively explored recently and poses a significant challenge in effectively enhancing recommender systems with logical reasoning abilities and open-world knowledge. Current mainstream efforts mainly center around injecting personalized information from recommendation models into LLMs by customizing input templates or aligning representations between semantic and recommendation spaces at the prediction layer. However, they face three significant limitations: (1) LoRA is mostly used as a core component in existing works, but personalization is not well established in LoRA parameters as the LoRA matrix shared by every user may not cater to different users' characteristics, leading to suboptimal performance. (2) Although lifelong personalized behavior sequences are ideal for personalization, their use raises effectiveness and efficiency issue
&lt;/p&gt;</description></item><item><title>该文章通过利用人工智能技术，分析了不同行业软件失败案例的相似性，并发展了一种模型，以帮助提高软件开发的安全性。</title><link>https://arxiv.org/abs/2408.03528</link><description>&lt;p&gt;
Exploring the extent of similarities in software failures across industries using LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03528
&lt;/p&gt;
&lt;p&gt;
该文章通过利用人工智能技术，分析了不同行业软件失败案例的相似性，并发展了一种模型，以帮助提高软件开发的安全性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03528v1 Announce Type: cross  Abstract: The rapid evolution of software development necessitates enhanced safety measures. Extracting information about software failures from companies is becoming increasingly more available through news articles.   This research utilizes the Failure Analysis Investigation with LLMs (FAIL) model to extract industry-specific information. Although the FAIL model's database is rich in information, it could benefit from further categorization and industry-specific insights to further assist software engineers.   In previous work news articles were collected from reputable sources and categorized by incidents inside a database. Prompt engineering and Large Language Models (LLMs) were then applied to extract relevant information regarding the software failure. This research extends these methods by categorizing articles into specific domains and types of software failures. The results are visually represented through graphs.   The analysis shows t
&lt;/p&gt;</description></item><item><title>该文章提出了一种模仿中枢神经系统分层结构与协作互动行为的学习控制框架，旨在提升机器人控制系统的灵活性与可靠性，并实现多样化的自主行为。通过在模拟和实际实验中验证对六足机器人的应用，该框架展现了其在复杂环境下的有效性。</title><link>https://arxiv.org/abs/2408.03525</link><description>&lt;p&gt;
Hierarchical learning control for autonomous robots inspired by central nervous system
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03525
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种模仿中枢神经系统分层结构与协作互动行为的学习控制框架，旨在提升机器人控制系统的灵活性与可靠性，并实现多样化的自主行为。通过在模拟和实际实验中验证对六足机器人的应用，该框架展现了其在复杂环境下的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03525v1 Announce Type: new  Abstract: Mammals can generate autonomous behaviors in various complex environments through the coordination and interaction of activities at different levels of their central nervous system. In this paper, we propose a novel hierarchical learning control framework by mimicking the hierarchical structure of the central nervous system along with their coordination and interaction behaviors. The framework combines the active and passive control systems to improve both the flexibility and reliability of the control system as well as to achieve more diverse autonomous behaviors of robots. Specifically, the framework has a backbone of independent neural network controllers at different levels and takes a three-level dual descending pathway structure, inspired from the functionality of the cerebral cortex, cerebellum, and spinal cord. We comprehensively validated the proposed approach through the simulation as well as the experiment of a hexapod robot i
&lt;/p&gt;</description></item><item><title>该文章提出RepoMasterEval，一个基于真实世界Python和TypeScript仓库的代码完成模型评估基准。每个数据点都是通过从源代码文件中加密一个代码段（真值），并用现有的测试套件来改善模型生成的代码测试的准确性。</title><link>https://arxiv.org/abs/2408.03519</link><description>&lt;p&gt;
RepoMasterEval: Evaluating Code Completion via Real-World Repositories
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03519
&lt;/p&gt;
&lt;p&gt;
该文章提出RepoMasterEval，一个基于真实世界Python和TypeScript仓库的代码完成模型评估基准。每个数据点都是通过从源代码文件中加密一个代码段（真值），并用现有的测试套件来改善模型生成的代码测试的准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03519v1 Announce Type: cross  Abstract: With the growing reliance on automated code completion tools in software development, the need for robust evaluation benchmarks has become critical. However, existing benchmarks focus more on code generation tasks in function and class level and provide rich text description to prompt the model. By contrast, such descriptive prompt is commonly unavailable in real development and code completion can occur in wider range of situations such as in the middle of a function or a code block. These limitations makes the evaluation poorly align with the practical scenarios of code completion tools. In this paper, we propose RepoMasterEval, a novel benchmark for evaluating code completion models constructed from real-world Python and TypeScript repositories. Each benchmark datum is generated by masking a code snippet (ground truth) from one source code file with existing test suites. To improve test accuracy of model generated code, we employ mu
&lt;/p&gt;</description></item><item><title>该文章揭示了当大型语言模型集成到移动机器人系统中时，多模态提示注入攻击可能导致的导航性能和安全风险，并探讨了如何通过制定更安全的提示策略来缓解这类威胁。</title><link>https://arxiv.org/abs/2408.03515</link><description>&lt;p&gt;
A Study on Prompt Injection Attack Against LLM-Integrated Mobile Robotic Systems
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03515
&lt;/p&gt;
&lt;p&gt;
该文章揭示了当大型语言模型集成到移动机器人系统中时，多模态提示注入攻击可能导致的导航性能和安全风险，并探讨了如何通过制定更安全的提示策略来缓解这类威胁。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03515v1 Announce Type: new  Abstract: The integration of Large Language Models (LLMs) like GPT-4o into robotic systems represents a significant advancement in embodied artificial intelligence. These models can process multi-modal prompts, enabling them to generate more context-aware responses. However, this integration is not without challenges. One of the primary concerns is the potential security risks associated with using LLMs in robotic navigation tasks. These tasks require precise and reliable responses to ensure safe and effective operation. Multi-modal prompts, while enhancing the robot's understanding, also introduce complexities that can be exploited maliciously. For instance, adversarial inputs designed to mislead the model can lead to incorrect or dangerous navigational decisions. This study investigates the impact of prompt injections on mobile robot performance in LLM-integrated systems and explores secure prompt strategies to mitigate these risks. Our findings
&lt;/p&gt;</description></item><item><title>该文章提出的Optimus系统通过优化GPU处理任务的方式，能在大型多模态语言模型训练中减少“GPU气泡”（GPU bubbles），从而加速训练过程。</title><link>https://arxiv.org/abs/2408.03505</link><description>&lt;p&gt;
Optimus: Accelerating Large-Scale Multi-Modal LLM Training by Bubble Exploitation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03505
&lt;/p&gt;
&lt;p&gt;
该文章提出的Optimus系统通过优化GPU处理任务的方式，能在大型多模态语言模型训练中减少“GPU气泡”（GPU bubbles），从而加速训练过程。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03505v1 Announce Type: cross  Abstract: Multimodal large language models (MLLMs) have extended the success of large language models (LLMs) to multiple data types, such as image, text and audio, achieving significant performance in various domains, including multimodal translation, visual question answering and content generation. Nonetheless, existing systems are inefficient to train MLLMs due to substantial GPU bubbles caused by the heterogeneous modality models and complex data dependencies in 3D parallelism. This paper proposes Optimus, a distributed MLLM training system that reduces end-to-end MLLM training time. Optimus is based on our principled analysis that scheduling the encoder computation within the LLM bubbles can reduce bubbles in MLLM training. To make scheduling encoder computation possible for all GPUs, Optimus searches the separate parallel plans for encoder and LLM, and adopts a bubble scheduling algorithm to enable exploiting LLM bubbles without breaking t
&lt;/p&gt;</description></item><item><title>该文章引入了一种高级用户信用风险预测模型，结合了LightGBM、XGBoost和Tabnet算法，并通过SMOTEENN技术增强了模型对不平衡数据集的适应性，显著提高了银行对于大量信用卡申请人的筛选效率和准确性，增强了银行信贷业务的盈利能力。</title><link>https://arxiv.org/abs/2408.03497</link><description>&lt;p&gt;
Advanced User Credit Risk Prediction Model using LightGBM, XGBoost and Tabnet with SMOTEENN
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03497
&lt;/p&gt;
&lt;p&gt;
该文章引入了一种高级用户信用风险预测模型，结合了LightGBM、XGBoost和Tabnet算法，并通过SMOTEENN技术增强了模型对不平衡数据集的适应性，显著提高了银行对于大量信用卡申请人的筛选效率和准确性，增强了银行信贷业务的盈利能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03497v1 Announce Type: cross  Abstract: Bank credit risk is a significant challenge in modern financial transactions, and the ability to identify qualified credit card holders among a large number of applicants is crucial for the profitability of a bank'sbank's credit card business. In the past, screening applicants'applicants' conditions often required a significant amount of manual labor, which was time-consuming and labor-intensive. Although the accuracy and reliability of previously used ML models have been continuously improving, the pursuit of more reliable and powerful AI intelligent models is undoubtedly the unremitting pursuit by major banks in the financial industry. In this study, we used a dataset of over 40,000 records provided by a commercial bank as the research object. We compared various dimensionality reduction techniques such as PCA and T-SNE for preprocessing high-dimensional datasets and performed in-depth adaptation and tuning of distributed models such
&lt;/p&gt;</description></item><item><title>该文章提出使用逻辑编程系统和自动定理证明器改进大型语言模型在逻辑推理任务中的准确度，特别是通过神经符号架构来提高性能。研究人员在评价大型语言模型在蒸汽引擎难题中的表现后，发现通过自动定理证明器来解决相关问题可以大幅提升准确度。文章还介绍了错误分类框架，并在实际应用中发现大型语言模型在翻译过程中的错误，进而优化了方法，提升了结果。</title><link>https://arxiv.org/abs/2408.03492</link><description>&lt;p&gt;
Automated Theorem Provers Help Improve Large Language Model Reasoning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03492
&lt;/p&gt;
&lt;p&gt;
该文章提出使用逻辑编程系统和自动定理证明器改进大型语言模型在逻辑推理任务中的准确度，特别是通过神经符号架构来提高性能。研究人员在评价大型语言模型在蒸汽引擎难题中的表现后，发现通过自动定理证明器来解决相关问题可以大幅提升准确度。文章还介绍了错误分类框架，并在实际应用中发现大型语言模型在翻译过程中的错误，进而优化了方法，提升了结果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03492v1 Announce Type: new  Abstract: In this paper we demonstrate how logic programming systems and Automated first-order logic Theorem Provers (ATPs) can improve the accuracy of Large Language Models (LLMs) for logical reasoning tasks where the baseline performance is given by direct LLM solutions. We first evaluate LLM reasoning on steamroller problems using the PRONTOQA benchmark. We show how accuracy can be improved with a neuro-symbolic architecture where the LLM acts solely as a front-end for translating a given problem into a formal logic language and an automated reasoning engine is called for solving it. However, this approach critically hinges on the correctness of the LLM translation. To assess this translation correctness, we secondly define a framework of syntactic and semantic error categories. We implemented the framework and used it to identify errors that LLMs make in the benchmark domain. Based on these findings, we thirdly extended our method with capabil
&lt;/p&gt;</description></item><item><title>该文章提出利用大型语言模型(LLM)分析源代码，以实现自动化漏洞检测，并通过转换源代码为LLVM中间表示来使得方法在多语言间适用。实验结果表明，该方法在高精度下有效识别了多种编程语言中的漏洞，提升了静态源代码分析的自动化和准确性。</title><link>https://arxiv.org/abs/2408.03489</link><description>&lt;p&gt;
Harnessing the Power of LLMs in Source Code Vulnerability Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03489
&lt;/p&gt;
&lt;p&gt;
该文章提出利用大型语言模型(LLM)分析源代码，以实现自动化漏洞检测，并通过转换源代码为LLVM中间表示来使得方法在多语言间适用。实验结果表明，该方法在高精度下有效识别了多种编程语言中的漏洞，提升了静态源代码分析的自动化和准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03489v1 Announce Type: cross  Abstract: Software vulnerabilities, caused by unintentional flaws in source code, are a primary root cause of cyberattacks. Static analysis of source code has been widely used to detect these unintentional defects introduced by software developers. Large Language Models (LLMs) have demonstrated human-like conversational abilities due to their capacity to capture complex patterns in sequential data, such as natural languages. In this paper, we harness LLMs' capabilities to analyze source code and detect known vulnerabilities. To ensure the proposed vulnerability detection method is universal across multiple programming languages, we convert source code to LLVM IR and train LLMs on these intermediate representations. We conduct extensive experiments on various LLM architectures and compare their accuracy. Our comprehensive experiments on real-world and synthetic codes from NVD and SARD demonstrate high accuracy in identifying source code vulnerabi
&lt;/p&gt;</description></item><item><title>该文章探讨了大型语言模型（LLMs），尤其是GPT-4和LLaMA3，在时间序列异常检测方面的潜力。研究表明，尽管LLMs不能直接用于时间序列异常检测，但通过特定的提示策略，如in-context learning和chain-of-thought prompting，GPT-4能够在检测时间序列异常方面与基准方法相媲美。此外，文章提出了一种自动生成时间序列异常和相关解释的合成数据集，并通过在数据集上进行指令微调，LLaMA3在某些指标上表现出了检测异常的能力。</title><link>https://arxiv.org/abs/2408.03475</link><description>&lt;p&gt;
Can LLMs Serve As Time Series Anomaly Detectors?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03475
&lt;/p&gt;
&lt;p&gt;
该文章探讨了大型语言模型（LLMs），尤其是GPT-4和LLaMA3，在时间序列异常检测方面的潜力。研究表明，尽管LLMs不能直接用于时间序列异常检测，但通过特定的提示策略，如in-context learning和chain-of-thought prompting，GPT-4能够在检测时间序列异常方面与基准方法相媲美。此外，文章提出了一种自动生成时间序列异常和相关解释的合成数据集，并通过在数据集上进行指令微调，LLaMA3在某些指标上表现出了检测异常的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03475v1 Announce Type: cross  Abstract: An emerging topic in large language models (LLMs) is their application to time series forecasting, characterizing mainstream and patternable characteristics of time series. A relevant but rarely explored and more challenging question is whether LLMs can detect and explain time series anomalies, a critical task across various real-world applications. In this paper, we investigate the capabilities of LLMs, specifically GPT-4 and LLaMA3, in detecting and explaining anomalies in time series. Our studies reveal that: 1) LLMs cannot be directly used for time series anomaly detection. 2) By designing prompt strategies such as in-context learning and chain-of-thought prompting, GPT-4 can detect time series anomalies with results competitive to baseline methods. 3) We propose a synthesized dataset to automatically generate time series anomalies with corresponding explanations. By applying instruction fine-tuning on this dataset, LLaMA3 demonstr
&lt;/p&gt;</description></item><item><title>该文章创新性地推出了MultiHateClip, 一个包含2000个视频的跨文化中文和英文多模态仇恨内容检测数据集。它不仅区分了视频是否具有仇恨性，还细化了视频中的中性内容和冒犯性内容，为理解不同文化背景下的性别歧视仇恨言论提供了一定帮助。</title><link>https://arxiv.org/abs/2408.03468</link><description>&lt;p&gt;
MultiHateClip: A Multilingual Benchmark Dataset for Hateful Video Detection on YouTube and Bilibili
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03468
&lt;/p&gt;
&lt;p&gt;
该文章创新性地推出了MultiHateClip, 一个包含2000个视频的跨文化中文和英文多模态仇恨内容检测数据集。它不仅区分了视频是否具有仇恨性，还细化了视频中的中性内容和冒犯性内容，为理解不同文化背景下的性别歧视仇恨言论提供了一定帮助。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03468v1 Announce Type: cross  Abstract: Hate speech is a pressing issue in modern society, with significant effects both online and offline. Recent research in hate speech detection has primarily centered on text-based media, largely overlooking multimodal content such as videos. Existing studies on hateful video datasets have predominantly focused on English content within a Western context and have been limited to binary labels (hateful or non-hateful), lacking detailed contextual information. This study presents MultiHateClip1 , an novel multilingual dataset created through hate lexicons and human annotation. It aims to enhance the detection of hateful videos on platforms such as YouTube and Bilibili, including content in both English and Chinese languages. Comprising 2,000 videos annotated for hatefulness, offensiveness, and normalcy, this dataset provides a cross-cultural perspective on gender-based hate speech. Through a detailed examination of human annotation results
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的、以结局为导向的方法，用于在观察性研究中识别治疗反应亚组。这种方法将每个患者分配到与两种时间-事件分布相关的亚组中：治疗和控制方案下的分布。这使得研究者能够分析不同患者群体在治疗和控制方案下的治疗效果，从而为实际临床实践中患者群体的治疗建议提供了强有力的证据。</title><link>https://arxiv.org/abs/2408.03463</link><description>&lt;p&gt;
Identifying treatment response subgroups in observational time-to-event data
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03463
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的、以结局为导向的方法，用于在观察性研究中识别治疗反应亚组。这种方法将每个患者分配到与两种时间-事件分布相关的亚组中：治疗和控制方案下的分布。这使得研究者能够分析不同患者群体在治疗和控制方案下的治疗效果，从而为实际临床实践中患者群体的治疗建议提供了强有力的证据。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03463v1 Announce Type: cross  Abstract: Identifying patient subgroups with different treatment responses is an important task to inform medical recommendations, guidelines, and the design of future clinical trials. Existing approaches for subgroup analysis primarily focus on Randomised Controlled Trials (RCTs), in which treatment assignment is randomised. Furthermore, the patient cohort of an RCT is often constrained by cost, and is not representative of the heterogeneity of patients likely to receive treatment in real-world clinical practice. Therefore, when applied to observational studies, such approaches suffer from significant statistical biases because of the non-randomisation of treatment. Our work introduces a novel, outcome-guided method for identifying treatment response subgroups in observational studies. Our approach assigns each patient to a subgroup associated with two time-to-event distributions: one under treatment and one under control regime. It hence posit
&lt;/p&gt;</description></item><item><title>该文章通过结合预训练的MobileViT和知识蒸馏技术，对EEG信号进行智能预测，大幅提升了预测的速度和准确性，同时模型的体积显著减小。</title><link>https://arxiv.org/abs/2408.03449</link><description>&lt;p&gt;
EEGMobile: Enhancing Speed and Accuracy in EEG-Based Gaze Prediction with Advanced Mobile Architectures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03449
&lt;/p&gt;
&lt;p&gt;
该文章通过结合预训练的MobileViT和知识蒸馏技术，对EEG信号进行智能预测，大幅提升了预测的速度和准确性，同时模型的体积显著减小。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03449v1 Announce Type: cross  Abstract: Electroencephalography (EEG) analysis is an important domain in the realm of Brain-Computer Interface (BCI) research. To ensure BCI devices are capable of providing practical applications in the real world, brain signal processing techniques must be fast, accurate, and resource-conscious to deliver low-latency neural analytics. This study presents a model that leverages a pre-trained MobileViT alongside Knowledge Distillation (KD) for EEG regression tasks. Our results showcase that this model is capable of performing at a level comparable (only 3% lower) to the previous State-Of-The-Art (SOTA) on the EEGEyeNet Absolute Position Task while being 33% faster and 60% smaller. Our research presents a cost-effective model applicable to resource-constrained devices and contributes to expanding future research on lightweight, mobile-friendly models for EEG regression.
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于深度确定性策略梯度（DDPG）算法的强化学习框架，用于解决在移动车辆中，时间敏感且计算密集型的任务从车辆迁移到附近的边缘服务器、V2I系统或通过V2V通信的其他协作车辆时，频繁的网络访问点（AP）手操作和任务迁移造成的服务效率问题。这种方法旨在通过协同优化通信和计算资源，来提高服务质量，并减少由于频繁切换和网络重连导致的延迟。通过这种方式，该框架有助于保持连续的网络连接，并提高了移动环境中任务执行的效率和稳定性。</title><link>https://arxiv.org/abs/2408.03435</link><description>&lt;p&gt;
Communication-Aware Consistent Edge Selection for Mobile Users and Autonomous Vehicles
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03435
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于深度确定性策略梯度（DDPG）算法的强化学习框架，用于解决在移动车辆中，时间敏感且计算密集型的任务从车辆迁移到附近的边缘服务器、V2I系统或通过V2V通信的其他协作车辆时，频繁的网络访问点（AP）手操作和任务迁移造成的服务效率问题。这种方法旨在通过协同优化通信和计算资源，来提高服务质量，并减少由于频繁切换和网络重连导致的延迟。通过这种方式，该框架有助于保持连续的网络连接，并提高了移动环境中任务执行的效率和稳定性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03435v1 Announce Type: cross  Abstract: Offloading time-sensitive, computationally intensive tasks-such as advanced learning algorithms for autonomous driving-from vehicles to nearby edge servers, vehicle-to-infrastructure (V2I) systems, or other collaborating vehicles via vehicle-to-vehicle (V2V) communication enhances service efficiency. However, whence traversing the path to the destination, the vehicle's mobility necessitates frequent handovers among the access points (APs) to maintain continuous and uninterrupted wireless connections to maintain the network's Quality of Service (QoS). These frequent handovers subsequently lead to task migrations among the edge servers associated with the respective APs. This paper addresses the joint problem of task migration and access-point handover by proposing a deep reinforcement learning framework based on the Deep Deterministic Policy Gradient (DDPG) algorithm. A joint allocation method of communication and computation of APs is 
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的STAC-Min-Width算法，用于解决在具有不同敏感性的多代理人多臂乐队问题中，如何综合来自不同代理人的信息并协调他们的行动。该算法通过精心设计的策略，能够从不同的概率分布中聚合奖励，并有效地协调代理人的任务分配，从而在提高整体性能的同时保持效率。</title><link>https://arxiv.org/abs/2408.03405</link><description>&lt;p&gt;
Combining Diverse Information for Coordinated Action: Stochastic Bandit Algorithms for Heterogeneous Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03405
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的STAC-Min-Width算法，用于解决在具有不同敏感性的多代理人多臂乐队问题中，如何综合来自不同代理人的信息并协调他们的行动。该算法通过精心设计的策略，能够从不同的概率分布中聚合奖励，并有效地协调代理人的任务分配，从而在提高整体性能的同时保持效率。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03405v1 Announce Type: cross  Abstract: Stochastic multi-agent multi-armed bandits typically assume that the rewards from each arm follow a fixed distribution, regardless of which agent pulls the arm. However, in many real-world settings, rewards can depend on the sensitivity of each agent to their environment. In medical screening, disease detection rates can vary by test type; in preference matching, rewards can depend on user preferences; and in environmental sensing, observation quality can vary across sensors. Since past work does not specify how to allocate agents of heterogeneous but known sensitivity of these types in a stochastic bandit setting, we introduce a UCB-style algorithm, Min-Width, which aggregates information from diverse agents. In doing so, we address the joint challenges of (i) aggregating the rewards, which follow different distributions for each agent-arm pair, and (ii) coordinating the assignments of agents to arms. Min-Width facilitates efficient c
&lt;/p&gt;</description></item><item><title>该文章介绍了生成扩散模型（DMs）在图像合成、文本到图像和其他生成任务中的最新进展，并强调了这种强大的技术也可能成为潜在的威胁。作者详细分析了多模态攻击，如对抗攻击、成员推断、后门注入和多重威胁，并给出了解决方案，强调了DM安全性的重要性，以防止这些攻击对社会造成伤害。</title><link>https://arxiv.org/abs/2408.03400</link><description>&lt;p&gt;
Attacks and Defenses for Generative Diffusion Models: A Comprehensive Survey
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03400
&lt;/p&gt;
&lt;p&gt;
该文章介绍了生成扩散模型（DMs）在图像合成、文本到图像和其他生成任务中的最新进展，并强调了这种强大的技术也可能成为潜在的威胁。作者详细分析了多模态攻击，如对抗攻击、成员推断、后门注入和多重威胁，并给出了解决方案，强调了DM安全性的重要性，以防止这些攻击对社会造成伤害。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03400v1 Announce Type: cross  Abstract: Diffusion models (DMs) have achieved state-of-the-art performance on various generative tasks such as image synthesis, text-to-image, and text-guided image-to-image generation. However, the more powerful the DMs, the more harmful they potentially are. Recent studies have shown that DMs are prone to a wide range of attacks, including adversarial attacks, membership inference, backdoor injection, and various multi-modal threats. Since numerous pre-trained DMs are published widely on the Internet, potential threats from these attacks are especially detrimental to the society, making DM-related security a worth investigating topic. Therefore, in this paper, we conduct a comprehensive survey on the security aspect of DMs, focusing on various attack and defense methods for DMs. First, we present crucial knowledge of DMs with five main types of DMs, including denoising diffusion probabilistic models, denoising diffusion implicit models, noise
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为RHiOTS的框架，用于评估具有层次结构的时间序列预测算法的稳健性，尤其是对于在诸如零售销售这类现实世界情境中的应用。透過对现有数据集的系统化改变和个体系列以及它们之间关系的特性调整，RHiOTS框架提供了一种多样化的数据分布模拟方法。此外，RHiOTS框架还包含一个创新的视觉化工具，将复杂的、多维度稳健性评估结果转化为直观、易于理解的图表，从而为研究者和实践者提供了一个评估和比较时间序列预测算法的有效工具。</title><link>https://arxiv.org/abs/2408.03399</link><description>&lt;p&gt;
RHiOTS: A Framework for Evaluating Hierarchical Time Series Forecasting Algorithms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03399
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为RHiOTS的框架，用于评估具有层次结构的时间序列预测算法的稳健性，尤其是对于在诸如零售销售这类现实世界情境中的应用。透過对现有数据集的系统化改变和个体系列以及它们之间关系的特性调整，RHiOTS框架提供了一种多样化的数据分布模拟方法。此外，RHiOTS框架还包含一个创新的视觉化工具，将复杂的、多维度稳健性评估结果转化为直观、易于理解的图表，从而为研究者和实践者提供了一个评估和比较时间序列预测算法的有效工具。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03399v1 Announce Type: cross  Abstract: We introduce the Robustness of Hierarchically Organized Time Series (RHiOTS) framework, designed to assess the robustness of hierarchical time series forecasting models and algorithms on real-world datasets. Hierarchical time series, where lower-level forecasts must sum to upper-level ones, are prevalent in various contexts, such as retail sales across countries. Current empirical evaluations of forecasting methods are often limited to a small set of benchmark datasets, offering a narrow view of algorithm behavior. RHiOTS addresses this gap by systematically altering existing datasets and modifying the characteristics of individual series and their interrelations. It uses a set of parameterizable transformations to simulate those changes in the data distribution. Additionally, RHiOTS incorporates an innovative visualization component, turning complex, multidimensional robustness evaluation results into intuitive, easily interpretable v
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于非负变分自编码器（Non-negative VAE）的通用伽马信念网络（Generalized Gamma Belief Network），其通过扩展线性生成模型至非线性生成模型，增强了模型的表达能力。文章还介绍了一种逆向向上Gauss-Weibull生成网络用以估计潜在变量的后验分布，提高了模型的性能。</title><link>https://arxiv.org/abs/2408.03388</link><description>&lt;p&gt;
A Non-negative VAE:the Generalized Gamma Belief Network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03388
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于非负变分自编码器（Non-negative VAE）的通用伽马信念网络（Generalized Gamma Belief Network），其通过扩展线性生成模型至非线性生成模型，增强了模型的表达能力。文章还介绍了一种逆向向上Gauss-Weibull生成网络用以估计潜在变量的后验分布，提高了模型的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03388v1 Announce Type: cross  Abstract: The gamma belief network (GBN), often regarded as a deep topic model, has demonstrated its potential for uncovering multi-layer interpretable latent representations in text data. Its notable capability to acquire interpretable latent factors is partially attributed to sparse and non-negative gamma-distributed latent variables. However, the existing GBN and its variations are constrained by the linear generative model, thereby limiting their expressiveness and applicability. To address this limitation, we introduce the generalized gamma belief network (Generalized GBN) in this paper, which extends the original linear generative model to a more expressive non-linear generative model. Since the parameters of the Generalized GBN no longer possess an analytic conditional posterior, we further propose an upward-downward Weibull inference network to approximate the posterior distribution of the latent variables. The parameters of both the gen
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Prioritize Alignment in Dataset Distillation（PAD）的改进方法，旨在提高数据集蒸馏中信息的准确度和有效性。通过首先根据压缩率筛选目标数据集，去除难以被提取的信息，然后仅使用深度模型层来施以蒸馏，以避免引入过多低层次的信息，从而提高了信息提取和嵌入的准确性，提高了压缩数据集的质量。</title><link>https://arxiv.org/abs/2408.03360</link><description>&lt;p&gt;
Prioritize Alignment in Dataset Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03360
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Prioritize Alignment in Dataset Distillation（PAD）的改进方法，旨在提高数据集蒸馏中信息的准确度和有效性。通过首先根据压缩率筛选目标数据集，去除难以被提取的信息，然后仅使用深度模型层来施以蒸馏，以避免引入过多低层次的信息，从而提高了信息提取和嵌入的准确性，提高了压缩数据集的质量。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03360v1 Announce Type: cross  Abstract: Dataset Distillation aims to compress a large dataset into a significantly more compact, synthetic one without compromising the performance of the trained models. To achieve this, existing methods use the agent model to extract information from the target dataset and embed it into the distilled dataset. Consequently, the quality of extracted and embedded information determines the quality of the distilled dataset. In this work, we find that existing methods introduce misaligned information in both information extraction and embedding stages. To alleviate this, we propose Prioritize Alignment in Dataset Distillation (PAD), which aligns information from the following two perspectives. 1) We prune the target dataset according to the compressing ratio to filter the information that can be extracted by the agent model. 2) We use only deep layers of the agent model to perform the distillation to avoid excessively introducing low-level inform
&lt;/p&gt;</description></item><item><title>该文章提出LAMPO方法，利用大型语言模型作为偏好机器，通过对比学习对少样本多类顺序分类问题进行解决，显著提升了模型性能。</title><link>https://arxiv.org/abs/2408.03359</link><description>&lt;p&gt;
LAMPO: Large Language Models as Preference Machines for Few-shot Ordinal Classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03359
&lt;/p&gt;
&lt;p&gt;
该文章提出LAMPO方法，利用大型语言模型作为偏好机器，通过对比学习对少样本多类顺序分类问题进行解决，显著提升了模型性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03359v1 Announce Type: cross  Abstract: We introduce LAMPO, a novel paradigm that leverages Large Language Models (LLMs) for solving few-shot multi-class ordinal classification tasks. Unlike conventional methods, which concatenate all demonstration examples with the test instance and prompt LLMs to produce the pointwise prediction, our framework uses the LLM as a preference machine that makes a relative comparative decision between the test instance and each demonstration. A self-supervised method is then introduced to aggregate these binary comparisons into the final ordinal decision. LAMPO addresses several limitations inherent in previous methods, including context length constraints, ordering biases, and challenges associated with absolute point-wise estimation. Extensive experiments on seven public datasets demonstrate LAMPO's remarkably competitive performance across a diverse spectrum of applications (e.g., movie review analysis and hate speech detection). Notably, in
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为MLC-GCN的多层级生成连接体基于图卷积网络（GCN）的阿尔茨海默病（AD）分析模型，该模型首先提取空间-时间特征，然后生成多层级图，并通过GCN进行分类预测，旨在提高早期AD的诊断准确性。</title><link>https://arxiv.org/abs/2408.03358</link><description>&lt;p&gt;
MLC-GCN: Multi-Level Generated Connectome Based GCN for AD Analysis
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03358
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为MLC-GCN的多层级生成连接体基于图卷积网络（GCN）的阿尔茨海默病（AD）分析模型，该模型首先提取空间-时间特征，然后生成多层级图，并通过GCN进行分类预测，旨在提高早期AD的诊断准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03358v1 Announce Type: cross  Abstract: Alzheimer's Disease (AD) is a currently incurable neurodegeneartive disease. Accurately detecting AD, especially in the early stage, represents a high research priority. AD is characterized by progressive cognitive impairments that are related to alterations in brain functional connectivity (FC). Based on this association, many studies have been published over the decades using FC and machine learning to differentiate AD from healthy aging. The most recent development in this detection method highlights the use of graph neural network (GNN) as the brain functionality analysis. In this paper, we proposed a stack of spatio-temporal feature extraction and graph generation based AD classification model using resting state fMRI. The proposed multi-level generated connectome (MLC) based graph convolutional network (GCN) (MLC-GCN) contains a multi-graph generation block and a GCN prediction block. The multi-graph generation block consists of 
&lt;/p&gt;</description></item><item><title>该文章研究了大型语言模型（LLM）在分析黑客论坛上的网络威胁情报（CTI）数据中的应用，尤其是评估了基于OpenAI GPT-3.5-turbo模型的LLM系统提取CTI信息的准确性。通过对三个黑客论坛的500篇讨论线程进行测试，LLM系统能够准确提取出10个关键CTI变量信息的样本，表明LLM系统在自动化识别和解析网络威胁信息方面展现了出色的能力。</title><link>https://arxiv.org/abs/2408.03354</link><description>&lt;p&gt;
The Use of Large Language Models (LLM) for Cyber Threat Intelligence (CTI) in Cybercrime Forums
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03354
&lt;/p&gt;
&lt;p&gt;
该文章研究了大型语言模型（LLM）在分析黑客论坛上的网络威胁情报（CTI）数据中的应用，尤其是评估了基于OpenAI GPT-3.5-turbo模型的LLM系统提取CTI信息的准确性。通过对三个黑客论坛的500篇讨论线程进行测试，LLM系统能够准确提取出10个关键CTI变量信息的样本，表明LLM系统在自动化识别和解析网络威胁信息方面展现了出色的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03354v1 Announce Type: cross  Abstract: Large language models (LLMs) can be used to analyze cyber threat intelligence (CTI) data from cybercrime forums, which contain extensive information and key discussions about emerging cyber threats. However, to date, the level of accuracy and efficiency of LLMs for such critical tasks has yet to be thoroughly evaluated. Hence, this study assesses the accuracy of an LLM system built on the OpenAI GPT-3.5-turbo model [7] to extract CTI information. To do so, a random sample of 500 daily conversations from three cybercrime forums, XSS, Exploit.in, and RAMP, was extracted, and the LLM system was instructed to summarize the conversations and code 10 key CTI variables, such as whether a large organization and/or a critical infrastructure is being targeted. Then, two coders reviewed each conversation and evaluated whether the information extracted by the LLM was accurate. The LLM system performed strikingly well, with an average accuracy scor
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于扩散模型的噪声中心化对抗域适应学习框架（Diff-Noise-Adv-DA），通过利用生成扩散模型和对抗学习技术，成功解决了人类活动识别（HAR）模型在跨用户场景中遇到的数据分布差异问题。</title><link>https://arxiv.org/abs/2408.03353</link><description>&lt;p&gt;
Adversarial Domain Adaptation for Cross-user Activity Recognition Using Diffusion-based Noise-centred Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03353
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于扩散模型的噪声中心化对抗域适应学习框架（Diff-Noise-Adv-DA），通过利用生成扩散模型和对抗学习技术，成功解决了人类活动识别（HAR）模型在跨用户场景中遇到的数据分布差异问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03353v1 Announce Type: cross  Abstract: Human Activity Recognition (HAR) plays a crucial role in various applications such as human-computer interaction and healthcare monitoring. However, challenges persist in HAR models due to the data distribution differences between training and real-world data distributions, particularly evident in cross-user scenarios. This paper introduces a novel framework, termed Diffusion-based Noise-centered Adversarial Learning Domain Adaptation (Diff-Noise-Adv-DA), designed to address these challenges by leveraging generative diffusion modeling and adversarial learning techniques. Traditional HAR models often struggle with the diversity of user behaviors and sensor data distributions. Diff-Noise-Adv-DA innovatively integrates the inherent noise within diffusion models, harnessing its latent information to enhance domain adaptation. Specifically, the framework transforms noise into a critical carrier of activity and domain class information, faci
&lt;/p&gt;</description></item><item><title>该文章引入了miniCTX，这是一个新的神经定理证明数据集，旨在评估模型在获取训练过程中未出现的定义、引理或其他相关上下文信息的情况下证明数学定理的能力。miniCTX包含了来自真实Lean项目和数学教材的数百个定理，每个定理都对应一个可能包含数万个Token的上下文。模型需要在能够访问与定理相关的代码库的情况下证明定理。文章还介绍了一种名为文件调优的简单技术，它通过基于文件内容条件的生成模型来训练模型以生成证明步骤。与该技术相比，传统仅在状态上进行微调的神经定理证明方法取得了显著的改进。此外，通过文件调优的模型在标准的小型F2F基准测试上也表现出色，获得了一个新的领域最佳成绩，证明步骤的通过率达到了33.61%。</title><link>https://arxiv.org/abs/2408.03350</link><description>&lt;p&gt;
miniCTX: Neural Theorem Proving with (Long-)Contexts
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03350
&lt;/p&gt;
&lt;p&gt;
该文章引入了miniCTX，这是一个新的神经定理证明数据集，旨在评估模型在获取训练过程中未出现的定义、引理或其他相关上下文信息的情况下证明数学定理的能力。miniCTX包含了来自真实Lean项目和数学教材的数百个定理，每个定理都对应一个可能包含数万个Token的上下文。模型需要在能够访问与定理相关的代码库的情况下证明定理。文章还介绍了一种名为文件调优的简单技术，它通过基于文件内容条件的生成模型来训练模型以生成证明步骤。与该技术相比，传统仅在状态上进行微调的神经定理证明方法取得了显著的改进。此外，通过文件调优的模型在标准的小型F2F基准测试上也表现出色，获得了一个新的领域最佳成绩，证明步骤的通过率达到了33.61%。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03350v1 Announce Type: new  Abstract: We introduce miniCTX, which tests a model's ability to prove formal mathematical theorems that depend on new definitions, lemmas, or other contextual information that was not observed during training. miniCTX contains theorems sourced from real Lean projects and textbooks, each associated with a context that can span tens of thousands of tokens. Models are tasked with proving a theorem given access to code from the theorem's repository, which contains context that is helpful or needed for the proof. As a baseline for miniCTX, we introduce file-tuning, a simple recipe that trains a model to generate a proof step conditioned on the preceding file contents. File-tuning substantially outperforms the traditional neural theorem proving approach that fine-tunes on states alone. Additionally, our file-tuned model improves performance on the standard miniF2F benchmark, achieving a pass rate of 33.61%, which is a new state-of-the-art for 1.3B para
&lt;/p&gt;</description></item><item><title>该文章创新贡献在于探讨了人工智能与解决数学开放问题之间的复杂关系，强调了传统证明发现任务的困难性，同时展示了AI技术在自动定理证明、SAT-solver和大型语言模型等方面的应用，尽管这些技术能够处理低逻辑复杂性的问题，但并未推翻证明发现任务本质困难的论点。</title><link>https://arxiv.org/abs/2408.03345</link><description>&lt;p&gt;
Artifical intelligence and inherent mathematical difficulty
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03345
&lt;/p&gt;
&lt;p&gt;
该文章创新贡献在于探讨了人工智能与解决数学开放问题之间的复杂关系，强调了传统证明发现任务的困难性，同时展示了AI技术在自动定理证明、SAT-solver和大型语言模型等方面的应用，尽管这些技术能够处理低逻辑复杂性的问题，但并未推翻证明发现任务本质困难的论点。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03345v1 Announce Type: cross  Abstract: This paper explores the relationship of artificial intelligence to the task of resolving open questions in mathematics. We first present an updated version of a traditional argument that limitative results from computability and complexity theory show that proof discovery is an inherently difficult problem. We then illustrate how several recent applications of artificial intelligence-inspired methods -- respectively involving automated theorem proving, SAT-solvers, and large language models -- do indeed raise novel questions about the nature of mathematical proof. We also argue that the results obtained by such techniques do not tell against our basic argument. This is so because they are embodiments of brute force search and are thus capable of deciding only statements of low logical complexity.
&lt;/p&gt;</description></item><item><title>该文章开发了一个名为“知识全景”（Ontoverse）的系统，它通过地理信息系统界面将知识图谱数据民主化，为用户提供创新的交互式探索途径，尤其适用于跨学科领域知识研究的深入分析和发现。</title><link>https://arxiv.org/abs/2408.03339</link><description>&lt;p&gt;
The Ontoverse: Democratising Access to Knowledge Graph-based Data Through a Cartographic Interface
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03339
&lt;/p&gt;
&lt;p&gt;
该文章开发了一个名为“知识全景”（Ontoverse）的系统，它通过地理信息系统界面将知识图谱数据民主化，为用户提供创新的交互式探索途径，尤其适用于跨学科领域知识研究的深入分析和发现。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03339v1 Announce Type: cross  Abstract: As the number of scientific publications and preprints is growing exponentially, several attempts have been made to navigate this complex and increasingly detailed landscape. These have almost exclusively taken unsupervised approaches that fail to incorporate domain knowledge and lack the structural organisation required for intuitive interactive human exploration and discovery. Especially in highly interdisciplinary fields, a deep understanding of the connectedness of research works across topics is essential for generating insights. We have developed a unique approach to data navigation that leans on geographical visualisation and uses hierarchically structured domain knowledge to enable end-users to explore knowledge spaces grounded in their desired domains of interest. This can take advantage of existing ontologies, proprietary intelligence schemata, or be directly derived from the underlying data through hierarchical topic modelli
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为PsyDI的多模态交互式个性化心理评估聊天bot，它通过不断对话个性化心理测验，为用户提供个性化的心理类型评估，尽管在心理指标的定量评估上仍存在挑战。</title><link>https://arxiv.org/abs/2408.03337</link><description>&lt;p&gt;
PsyDI: Towards a Personalized and Progressively In-depth Chatbot for Psychological Measurements
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03337
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为PsyDI的多模态交互式个性化心理评估聊天bot，它通过不断对话个性化心理测验，为用户提供个性化的心理类型评估，尽管在心理指标的定量评估上仍存在挑战。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03337v1 Announce Type: cross  Abstract: In the field of psychology, the static nature and lack of customization of psychological test scales, along with the challenge of quantifying psychological indicators, have long been critical issues. Despite numerous attempts to use AI to address psychological challenges, a dynamically interactive psychological test has yet to emerge. In contrast to traditional psychological assessment methods, we propose PsyDI, a multi-modal, interactive, and customized chatbot for psychological assessments, using the Myers-Briggs Type Indicator (MBTI) as an example. PsyDI initiates with user-related multi-modal information, then engaging in customized interaction to discern the user's MBTI type based on their multiple rounds of responses. Despite these advancements, accurately quantifying absolute value of psychological indicators remains challenging. To tackle such difficulty, we introduce the PsyDI framework that trains LLMs to discern the relative
&lt;/p&gt;</description></item><item><title>该文章概述了机器学习在工业5.0网络安全中的应用，提出了一个基于可解释人工智能的入侵检测系统模型，用以解决网络安全领域面临的挑战。通过XAI技术，该研究旨在提高入侵检测系统的透明度和可理解性，为未来的研究方向提供潜在的发展路径。</title><link>https://arxiv.org/abs/2408.03335</link><description>&lt;p&gt;
Explainable AI-based Intrusion Detection System for Industry 5.0: An Overview of the Literature, associated Challenges, the existing Solutions, and Potential Research Directions
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03335
&lt;/p&gt;
&lt;p&gt;
该文章概述了机器学习在工业5.0网络安全中的应用，提出了一个基于可解释人工智能的入侵检测系统模型，用以解决网络安全领域面临的挑战。通过XAI技术，该研究旨在提高入侵检测系统的透明度和可理解性，为未来的研究方向提供潜在的发展路径。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03335v1 Announce Type: cross  Abstract: Industry 5.0, which focuses on human and Artificial Intelligence (AI) collaboration for performing different tasks in manufacturing, involves a higher number of robots, Internet of Things (IoTs) devices and interconnections, Augmented/Virtual Reality (AR), and other smart devices. The huge involvement of these devices and interconnection in various critical areas, such as economy, health, education and defense systems, poses several types of potential security flaws. AI itself has been proven a very effective and powerful tool in different areas of cybersecurity, such as intrusion detection, malware detection, and phishing detection, among others. Just as in many application areas, cybersecurity professionals were reluctant to accept black-box ML solutions for cybersecurity applications. This reluctance pushed forward the adoption of eXplainable Artificial Intelligence (XAI) as a tool that helps explain how decisions are made in ML-bas
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于多agent的强化学习方法，能够根据覆盖范围动态调整数据传输策略，以提高HD地图质量的传输效率，特别是在现实环境中。</title><link>https://arxiv.org/abs/2408.03329</link><description>&lt;p&gt;
Coverage-aware and Reinforcement Learning Using Multi-agent Approach for HD Map QoS in a Realistic Environment
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03329
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于多agent的强化学习方法，能够根据覆盖范围动态调整数据传输策略，以提高HD地图质量的传输效率，特别是在现实环境中。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03329v1 Announce Type: cross  Abstract: One effective way to optimize the offloading process is by minimizing the transmission time. This is particularly true in a Vehicular Adhoc Network (VANET) where vehicles frequently download and upload High-definition (HD) map data which requires constant updates. This implies that latency and throughput requirements must be guaranteed by the wireless system. To achieve this, adjustable contention windows (CW) allocation strategies in the standard IEEE802.11p have been explored by numerous researchers. Nevertheless, their implementations demand alterations to the existing standard which is not always desirable. To address this issue, we proposed a Q-Learning algorithm that operates at the application layer. Moreover, it could be deployed in any wireless network thereby mitigating the compatibility issues. The solution has demonstrated a better network performance with relatively fewer optimization requirements as compared to the Deep Q
&lt;/p&gt;</description></item><item><title>该文章通过使用基于UNet架构的卷积神经网络，能够从干涉图像中准确重建不规则粗糙颗粒的三维形状，有效应用于不同对称性的复杂粒子上，展示了其在材料学和微纳加工领域的潜在应用价值。</title><link>https://arxiv.org/abs/2408.03327</link><description>&lt;p&gt;
Reconstruction of the shape of irregular rough particles from their interferometric images using a convolutional neural network
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03327
&lt;/p&gt;
&lt;p&gt;
该文章通过使用基于UNet架构的卷积神经网络，能够从干涉图像中准确重建不规则粗糙颗粒的三维形状，有效应用于不同对称性的复杂粒子上，展示了其在材料学和微纳加工领域的潜在应用价值。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03327v1 Announce Type: new  Abstract: We have developed a convolutional neural network (CNN) to reconstruct the shape of irregular rough particles from their interferometric images. The CNN is based on a UNET architecture with residual block modules. The database has been constructed using the experimental patterns generated by perfectly known pseudo-particles programmed on a Digital Micromirror Device (DMD) and under laser illumination. The CNN has been trained on a basis of 18000 experimental interferometric images using the AUSTRAL super computer (at CRIANN in Normandy). The CNN is tested in the case of centrosymmetric (stick, cross, dendrite) and non-centrosymmetric (like T, Y or L) particles. The size and the 3D orientation of the programmed particles are random. The different shapes are reconstructed by the CNN with good accuracy. Using three angles of view, the 3D reconstruction of particles from three reconstructed faces can be further done.
&lt;/p&gt;</description></item><item><title>该文章提出的StructEval框架通过在多个认知水平和关键概念上进行结构化评估，深化和拓宽了大型语言模型评估，提供了一种可靠的工具来抵抗数据污染的风险和减少潜在偏见的干扰，从而更可靠和一致地得出有关模型能力的结果。</title><link>https://arxiv.org/abs/2408.03281</link><description>&lt;p&gt;
StructEval: Deepen and Broaden Large Language Model Assessment via Structured Evaluation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03281
&lt;/p&gt;
&lt;p&gt;
该文章提出的StructEval框架通过在多个认知水平和关键概念上进行结构化评估，深化和拓宽了大型语言模型评估，提供了一种可靠的工具来抵抗数据污染的风险和减少潜在偏见的干扰，从而更可靠和一致地得出有关模型能力的结果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03281v1 Announce Type: cross  Abstract: Evaluation is the baton for the development of large language models. Current evaluations typically employ a single-item assessment paradigm for each atomic test objective, which struggles to discern whether a model genuinely possesses the required capabilities or merely memorizes/guesses the answers to specific questions. To this end, we propose a novel evaluation framework referred to as StructEval. Starting from an atomic test objective, StructEval deepens and broadens the evaluation by conducting a structured assessment across multiple cognitive levels and critical concepts, and therefore offers a comprehensive, robust and consistent evaluation for LLMs. Experiments on three widely-used benchmarks demonstrate that StructEval serves as a reliable tool for resisting the risk of data contamination and reducing the interference of potential biases, thereby providing more reliable and consistent conclusions regarding model capabilities.
&lt;/p&gt;</description></item><item><title>该文章提出了一种使用自然istic人类驾驶先验和强化学习技术的对抗性安全关键场景生成方法，旨在从现实和挑战性的自动驾驶车辆决策系统评估中获取大规模测试场景。这种方法能够通过模拟真实交通交互环境以及实施的两阶段流程，模拟驾驶策略，进而生成既有真实感又具备挑战性的多样化场景。</title><link>https://arxiv.org/abs/2408.03200</link><description>&lt;p&gt;
Adversarial Safety-Critical Scenario Generation using Naturalistic Human Driving Priors
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03200
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种使用自然istic人类驾驶先验和强化学习技术的对抗性安全关键场景生成方法，旨在从现实和挑战性的自动驾驶车辆决策系统评估中获取大规模测试场景。这种方法能够通过模拟真实交通交互环境以及实施的两阶段流程，模拟驾驶策略，进而生成既有真实感又具备挑战性的多样化场景。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03200v1 Announce Type: new  Abstract: Evaluating the decision-making system is indispensable in developing autonomous vehicles, while realistic and challenging safety-critical test scenarios play a crucial role. Obtaining these scenarios is non-trivial, thanks to the long-tailed distribution, sparsity, and rarity in real-world data sets. To tackle this problem, in this paper, we introduce a natural adversarial scenario generation solution using naturalistic human driving priors and reinforcement learning techniques. By doing this, we can obtain large-scale test scenarios that are both diverse and realistic. Specifically, we build a simulation environment that mimics natural traffic interaction scenarios. Informed by this environment, we implement a two-stage procedure. The first stage incorporates conventional rule-based models, e.g., IDM~(Intelligent Driver Model) and MOBIL~(Minimizing Overall Braking Induced by Lane changes) model, to coarsely and discretely capture and ca
&lt;/p&gt;</description></item><item><title>该文章提出了一种新型的自适应增强学习中稀疏奖励问题的解决方案，通过结合历史经验中的成功率来构造密集且信息量大的奖励信号。该方法使用从Beta分布中采样的成功率，这些分布随着数据的积累而逐渐变得可靠。在初始阶段，自适应成功率鼓励探索，随着数据的积累，逐渐变为鼓励利用的好方法。通过结合核密度估计（KDE）与随机傅里叶特征（RFF），该方法在处理高维连续状态空间时具有高效的计算效率。</title><link>https://arxiv.org/abs/2408.03029</link><description>&lt;p&gt;
Highly Efficient Self-Adaptive Reward Shaping for Reinforcement Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.03029
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新型的自适应增强学习中稀疏奖励问题的解决方案，通过结合历史经验中的成功率来构造密集且信息量大的奖励信号。该方法使用从Beta分布中采样的成功率，这些分布随着数据的积累而逐渐变得可靠。在初始阶段，自适应成功率鼓励探索，随着数据的积累，逐渐变为鼓励利用的好方法。通过结合核密度估计（KDE）与随机傅里叶特征（RFF），该方法在处理高维连续状态空间时具有高效的计算效率。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.03029v1 Announce Type: cross  Abstract: Reward shaping addresses the challenge of sparse rewards in reinforcement learning by constructing denser and more informative reward signals. To achieve self-adaptive and highly efficient reward shaping, we propose a novel method that incorporates success rates derived from historical experiences into shaped rewards. Our approach utilizes success rates sampled from Beta distributions, which dynamically evolve from uncertain to reliable values as more data is collected. Initially, the self-adaptive success rates exhibit more randomness to encourage exploration. Over time, they become more certain to enhance exploitation, thus achieving a better balance between exploration and exploitation. We employ Kernel Density Estimation (KDE) combined with Random Fourier Features (RFF) to derive the Beta distributions, resulting in a computationally efficient implementation in high-dimensional continuous state spaces. This method provides a non-pa
&lt;/p&gt;</description></item><item><title>该文章提出使用标准机器学习工具在硬件上实现 recurrent neural network，通过在 spintronic oscillator 上构建多层网络，并通过 backpropagation through time（BPTT）进行训练，从而可以在低能源成本下处理时间序列数据。文章通过模拟证明了该方法的有效性，并在解决序列数字分类任务时取得了与软件网络相当的 $89.83\pm2.91~\%$ 准确率。文章还提供了关于如何选择振荡器的时间常数以及网络超参数的指导，以便适应不同的输入时间尺度。</title><link>https://arxiv.org/abs/2408.02835</link><description>&lt;p&gt;
Training a multilayer dynamical spintronic network with standard machine learning tools to perform time series classification
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02835
&lt;/p&gt;
&lt;p&gt;
该文章提出使用标准机器学习工具在硬件上实现 recurrent neural network，通过在 spintronic oscillator 上构建多层网络，并通过 backpropagation through time（BPTT）进行训练，从而可以在低能源成本下处理时间序列数据。文章通过模拟证明了该方法的有效性，并在解决序列数字分类任务时取得了与软件网络相当的 $89.83\pm2.91~\%$ 准确率。文章还提供了关于如何选择振荡器的时间常数以及网络超参数的指导，以便适应不同的输入时间尺度。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02835v1 Announce Type: cross  Abstract: The ability to process time-series at low energy cost is critical for many applications. Recurrent neural network, which can perform such tasks, are computationally expensive when implementing in software on conventional computers. Here we propose to implement a recurrent neural network in hardware using spintronic oscillators as dynamical neurons. Using numerical simulations, we build a multi-layer network and demonstrate that we can use backpropagation through time (BPTT) and standard machine learning tools to train this network. Leveraging the transient dynamics of the spintronic oscillators, we solve the sequential digits classification task with $89.83\pm2.91~\%$ accuracy, as good as the equivalent software network. We devise guidelines on how to choose the time constant of the oscillators as well as hyper-parameters of the network to adapt to different input time scales.
&lt;/p&gt;</description></item><item><title>该文章介绍了SpecRover，一种通过大型语言模型进行代码意图提取的工具，旨在自动化程序改进，通过结合LLM和程序分析能力，提供高质量的代码修复和增强。</title><link>https://arxiv.org/abs/2408.02232</link><description>&lt;p&gt;
SpecRover: Code Intent Extraction via LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02232
&lt;/p&gt;
&lt;p&gt;
该文章介绍了SpecRover，一种通过大型语言模型进行代码意图提取的工具，旨在自动化程序改进，通过结合LLM和程序分析能力，提供高质量的代码修复和增强。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02232v1 Announce Type: cross  Abstract: Autonomous program improvement typically involves automatically producing bug fixes and feature additions. Such program improvement can be accomplished by a combination of large language model (LLM) and program analysis capabilities, in the form of an LLM agent. Since program repair or program improvement typically requires a specification of intended behavior - specification inference can be useful for producing high quality program patches. In this work, we examine efficient and low-cost workflows for iterative specification inference within an LLM agent. Given a GitHub issue to be resolved in a software project, our goal is to conduct iterative code search accompanied by specification inference - thereby inferring intent from both the project structure and behavior. The intent thus captured is examined by a reviewer agent with the goal of vetting the patches as well as providing a measure of confidence in the vetted patches. Our app
&lt;/p&gt;</description></item><item><title>该文章聚焦于数据评估和选择在指令微调大型语言模型中的应用，全面梳理了现有文献，为这类策略提供了一种分类清晰、层级精细的体系结构，以提高指令微调的效率和效果。</title><link>https://arxiv.org/abs/2408.02085</link><description>&lt;p&gt;
Unleashing the Power of Data Tsunami: A Comprehensive Survey on Data Assessment and Selection for Instruction Tuning of Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.02085
&lt;/p&gt;
&lt;p&gt;
该文章聚焦于数据评估和选择在指令微调大型语言模型中的应用，全面梳理了现有文献，为这类策略提供了一种分类清晰、层级精细的体系结构，以提高指令微调的效率和效果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.02085v1 Announce Type: new  Abstract: Instruction tuning plays a critical role in aligning large language models (LLMs) with human preference. Despite the vast amount of open instruction datasets, naively training a LLM on all existing instructions may not be optimal and practical. To pinpoint the most beneficial datapoints, data assessment and selection methods have been proposed in the fields of natural language processing (NLP) and deep learning. However, under the context of instruction tuning, there still exists a gap in knowledge on what kind of data evaluation metrics can be employed and how they can be integrated into the selection mechanism. To bridge this gap, we present a comprehensive review on existing literature of data assessment and selection especially for instruction tuning of LLMs. We systematically categorize all applicable methods into quality-based, diversity-based, and importance-based ones where a unified, fine-grained taxonomy is structured. For each
&lt;/p&gt;</description></item><item><title>该文章提出MAO框架，利用多 agent 协调来高效自动生成过程模型，通过设计创新提示策略，有效提升语言模型在多 agent 协作中的效率，这可能为领域专家提供宝贵的见解。</title><link>https://arxiv.org/abs/2408.01916</link><description>&lt;p&gt;
MAO: A Framework for Process Model Generation with Multi-Agent Orchestration
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01916
&lt;/p&gt;
&lt;p&gt;
该文章提出MAO框架，利用多 agent 协调来高效自动生成过程模型，通过设计创新提示策略，有效提升语言模型在多 agent 协作中的效率，这可能为领域专家提供宝贵的见解。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01916v1 Announce Type: new  Abstract: Process models are frequently used in software engineering to describe business requirements, guide software testing and control system improvement. However, traditional process modeling methods often require the participation of numerous experts, which is expensive and time-consuming. Therefore, the exploration of a more efficient and cost-effective automated modeling method has emerged as a focal point in current research. This article explores a framework for automatically generating process models with multi-agent orchestration (MAO), aiming to enhance the efficiency of process modeling and offer valuable insights for domain experts. Our framework MAO leverages large language models as the cornerstone for multi-agent, employing an innovative prompt strategy to ensure efficient collaboration among multi-agent. Specifically, 1) generation. The first phase of MAO is to generate a slightly rough process model from the text description; 2
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于循环神经网络（RNNs）的跨模态注意力框架，用于音频-视频深度伪造检测。该框架能够利用上下文信息学习模态之间的贡献特征，有效克服了音频和视频信号之间的分布性模态差异，提高了检测深度伪造的准确性和鲁棒性。</title><link>https://arxiv.org/abs/2408.01532</link><description>&lt;p&gt;
Contextual Cross-Modal Attention for Audio-Visual Deepfake Detection and Localization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01532
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于循环神经网络（RNNs）的跨模态注意力框架，用于音频-视频深度伪造检测。该框架能够利用上下文信息学习模态之间的贡献特征，有效克服了音频和视频信号之间的分布性模态差异，提高了检测深度伪造的准确性和鲁棒性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01532v1 Announce Type: cross  Abstract: In the digital age, the emergence of deepfakes and synthetic media presents a significant threat to societal and political integrity. Deepfakes based on multi-modal manipulation, such as audio-visual, are more realistic and pose a greater threat. Current multi-modal deepfake detectors are often based on the attention-based fusion of heterogeneous data streams from multiple modalities. However, the heterogeneous nature of the data (such as audio and visual signals) creates a distributional modality gap and poses a significant challenge in effective fusion and hence multi-modal deepfake detection. In this paper, we propose a novel multi-modal attention framework based on recurrent neural networks (RNNs) that leverages contextual information for audio-visual deepfake detection. The proposed approach applies attention to multi-modal multi-sequence representations and learns the contributing features among them for deepfake detection and lo
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于Therblig的Backbone Framework（TBBF），通过将高阶机器人任务分解为基本动作元素（therbligs），并结合当前的基础模型，提高了机器人对任务的理解能力和泛化能力。这种框架通过两个阶段来实现：首先通过Meta-RGate SynerFusion（MGSF）网络在离线训练阶段进行准确的动作元素分割，然后在使用新任务演示后，通过ActionREG方法将高阶知识编码到图像中，从而在线上测试阶段实现任务的理解。</title><link>https://arxiv.org/abs/2408.01334</link><description>&lt;p&gt;
A Backbone for Long-Horizon Robot Task Understanding
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.01334
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于Therblig的Backbone Framework（TBBF），通过将高阶机器人任务分解为基本动作元素（therbligs），并结合当前的基础模型，提高了机器人对任务的理解能力和泛化能力。这种框架通过两个阶段来实现：首先通过Meta-RGate SynerFusion（MGSF）网络在离线训练阶段进行准确的动作元素分割，然后在使用新任务演示后，通过ActionREG方法将高阶知识编码到图像中，从而在线上测试阶段实现任务的理解。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.01334v2 Announce Type: replace  Abstract: End-to-end robot learning, particularly for long-horizon tasks, often results in unpredictable outcomes and poor generalization. To address these challenges, we propose a novel Therblig-based Backbone Framework (TBBF) to enhance robot task understanding and transferability. This framework uses therbligs (basic action elements) as the backbone to decompose high-level robot tasks into elemental robot configurations, which are then integrated with current foundation models to improve task understanding. The approach consists of two stages: offline training and online testing. During the offline training stage, we developed the Meta-RGate SynerFusion (MGSF) network for accurate therblig segmentation across various tasks. In the online testing stage, after a one-shot demonstration of a new task is collected, our MGSF network extracts high-level knowledge, which is then encoded into the image using Action Registration (ActionREG). Addition
&lt;/p&gt;</description></item><item><title>该文章提出了SentenceVAE方法，通过将大型语言模型（LLMs）的输入/输出层集成以提升句子级别的LLMs（SLLMs）的推理效率，通过句子级别的预测实现了速度提升和准确性提高，同时支持长距离的上下文信息处理。</title><link>https://arxiv.org/abs/2408.00655</link><description>&lt;p&gt;
SentenceVAE: Enable Next-sentence Prediction for Large Language Models with Faster Speed, Higher Accuracy and Longer Context
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.00655
&lt;/p&gt;
&lt;p&gt;
该文章提出了SentenceVAE方法，通过将大型语言模型（LLMs）的输入/输出层集成以提升句子级别的LLMs（SLLMs）的推理效率，通过句子级别的预测实现了速度提升和准确性提高，同时支持长距离的上下文信息处理。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.00655v3 Announce Type: replace  Abstract: Current large language models (LLMs) primarily utilize next-token prediction method for inference, which significantly impedes their processing speed. In this paper, we introduce a novel inference methodology termed next-sentence prediction, aimed at enhancing the inference efficiency of LLMs. We present Sentence Variational Autoencoder (SentenceVAE), a tiny model consisting of a Sentence Encoder and a Sentence Decoder. The Sentence Encoder can effectively condense the information within a sentence into a singular token, while the Sentence Decoder can reconstruct this compressed token back into sentence. By integrating SentenceVAE into the input and output layers of LLMs, we develop Sentence-level LLMs (SLLMs) that employ a sentence-by-sentence inference method. In addition, the SentenceVAE module of SLLMs can maintain the integrity of the original semantic content by segmenting the context into sentences, thereby improving accuracy 
&lt;/p&gt;</description></item><item><title>该文章探讨了大型语言模型(LLMs)在抽象归纳推理能力上的不足，提出了一种新的框架“SolLearner”，旨在通过直接从数据中学习似然函数来测试模型的归纳推理能力。</title><link>https://arxiv.org/abs/2408.00114</link><description>&lt;p&gt;
Inductive or Deductive? Rethinking the Fundamental Reasoning Abilities of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2408.00114
&lt;/p&gt;
&lt;p&gt;
该文章探讨了大型语言模型(LLMs)在抽象归纳推理能力上的不足，提出了一种新的框架“SolLearner”，旨在通过直接从数据中学习似然函数来测试模型的归纳推理能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2408.00114v2 Announce Type: replace  Abstract: Reasoning encompasses two typical types: deductive reasoning and inductive reasoning. Despite extensive research into the reasoning capabilities of Large Language Models (LLMs), most studies have failed to rigorously differentiate between inductive and deductive reasoning, leading to a blending of the two. This raises an essential question: In LLM reasoning, which poses a greater challenge - deductive or inductive reasoning? While the deductive reasoning capabilities of LLMs, (i.e. their capacity to follow instructions in reasoning tasks), have received considerable attention, their abilities in true inductive reasoning remain largely unexplored. To investigate into the true inductive reasoning capabilities of LLMs, we propose a novel framework, SolverLearner. This framework enables LLMs to learn the underlying function (i.e., $y = f_w(x)$), that maps input data points $(x)$ to their corresponding output values $(y)$, using only in-c
&lt;/p&gt;</description></item><item><title>该文章提出了一种中文的多领域任务导向对话系统TransferTOD，该系统通过迁移学习能力实现了领域特定的预训练模型到通用领域对话场景的迁移，从而提高了对话的广泛适用性和通用性。</title><link>https://arxiv.org/abs/2407.21693</link><description>&lt;p&gt;
TransferTOD: A Generalizable Chinese Multi-Domain Task-Oriented Dialogue System with Transfer Capabilities
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.21693
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种中文的多领域任务导向对话系统TransferTOD，该系统通过迁移学习能力实现了领域特定的预训练模型到通用领域对话场景的迁移，从而提高了对话的广泛适用性和通用性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.21693v2 Announce Type: replace  Abstract: Task-oriented dialogue (TOD) systems aim to efficiently handle task-oriented conversations, including information collection. How to utilize TOD accurately, efficiently and effectively for information collection has always been a critical and challenging task. Recent studies have demonstrated that Large Language Models (LLMs) excel in dialogue, instruction generation, and reasoning, and can significantly enhance the performance of TOD through fine-tuning. However, current datasets primarily cater to user-led systems and are limited to predefined specific scenarios and slots, thereby necessitating improvements in the proactiveness, diversity, and capabilities of TOD. In this study, we present a detailed multi-domain task-oriented data construction process for conversations, and a Chinese dialogue dataset generated based on this process, TransferTOD, which authentically simulates human-computer dialogues in 30 popular life service scen
&lt;/p&gt;</description></item><item><title>该文章提出MetaOpenFOAM框架，这是一个基于LLM的多agent协作平台，用于解决CFD领域中的自动化问题。通过将复杂的CFD任务分解为多个agent负责的不同子任务，该框架能够在仅提供自然语言描述的情况下完成CFD模拟任务。此外，利用Retrieval-Augmented Generation（RAG）技术，MetaOpenFOAM增强了搜索和集成OpenFOAM教程数据库的能力，从而提高了自然语言驱动的CFD解决方案的效率和准确性。</title><link>https://arxiv.org/abs/2407.21320</link><description>&lt;p&gt;
MetaOpenFOAM: an LLM-based multi-agent framework for CFD
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.21320
&lt;/p&gt;
&lt;p&gt;
该文章提出MetaOpenFOAM框架，这是一个基于LLM的多agent协作平台，用于解决CFD领域中的自动化问题。通过将复杂的CFD任务分解为多个agent负责的不同子任务，该框架能够在仅提供自然语言描述的情况下完成CFD模拟任务。此外，利用Retrieval-Augmented Generation（RAG）技术，MetaOpenFOAM增强了搜索和集成OpenFOAM教程数据库的能力，从而提高了自然语言驱动的CFD解决方案的效率和准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.21320v2 Announce Type: replace  Abstract: Remarkable progress has been made in automated problem solving through societies of agents based on large language models (LLMs). Computational fluid dynamics (CFD), as a complex problem, presents unique challenges in automated simulations that require sophisticated solutions. MetaOpenFOAM, as a novel multi-agent collaborations framework, aims to complete CFD simulation tasks with only natural language as input. These simulation tasks include mesh pre-processing, simulation and so on. MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks. Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs. Tests on a benchmark for natural language-based CFD sol
&lt;/p&gt;</description></item><item><title>该文章在大型语言模型的超参数调优对真实世界应用的影响方面进行了深入的实证研究，提供了针对两个顶级LLMs（Llama-3-8B和Mistral-7B）和两种常见调优方法的实用超参数推荐配置，为实践者提供了更好的一开始起点，进而提高了他们的性能。</title><link>https://arxiv.org/abs/2407.18990</link><description>&lt;p&gt;
Stay Tuned: An Empirical Study of the Impact of Hyperparameters on LLM Tuning in Real-World Applications
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.18990
&lt;/p&gt;
&lt;p&gt;
该文章在大型语言模型的超参数调优对真实世界应用的影响方面进行了深入的实证研究，提供了针对两个顶级LLMs（Llama-3-8B和Mistral-7B）和两种常见调优方法的实用超参数推荐配置，为实践者提供了更好的一开始起点，进而提高了他们的性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.18990v2 Announce Type: replace-cross  Abstract: Fine-tuning Large Language Models (LLMs) is an effective method to enhance their performance on downstream tasks. However, choosing the appropriate setting of tuning hyperparameters (HPs) is a labor-intensive and computationally expensive process. Here, we provide recommended HP configurations for practical use-cases that represent a better starting point for practitioners, when considering two SOTA LLMs and two commonly used tuning methods. We describe Coverage-based Search (CBS), a process for ranking HP configurations based on an offline extensive grid search, such that the top ranked configurations collectively provide a practical robust recommendation for a wide range of datasets and domains. We focus our experiments on Llama-3-8B and Mistral-7B, as well as full fine-tuning and LoRa, conducting a total of &amp;gt; 10,000 tuning experiments. Our results suggest that, in general, Llama-3-8B and LoRA should be preferred, when possib
&lt;/p&gt;</description></item><item><title>该文章提出了动态语言组混合专家模型（DLG-MoE），通过优化多语言和代码切换场景下MoE框架的效率与灵活性，并在语言路由和独立的内部分组路由方面取得了创新，实现了出色的识别性能。</title><link>https://arxiv.org/abs/2407.18581</link><description>&lt;p&gt;
Dynamic Language Group-Based MoE: Enhancing Efficiency and Flexibility for Code-Switching Speech Recognition
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.18581
&lt;/p&gt;
&lt;p&gt;
该文章提出了动态语言组混合专家模型（DLG-MoE），通过优化多语言和代码切换场景下MoE框架的效率与灵活性，并在语言路由和独立的内部分组路由方面取得了创新，实现了出色的识别性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.18581v1 Announce Type: cross  Abstract: The Mixture of Experts (MoE) approach is ideally suited for tackling multilingual and code-switching (CS) challenges due to its multi-expert architecture. This work introduces the DLG-MoE, which is optimized for bilingual and CS scenarios. Our novel Dynamic Language Group-based MoE layer features a language router with shared weights for explicit language modeling, while independent unsupervised routers within the language group handle attributes beyond language. This structure not only enhances expert extension capabilities but also supports dynamic top-k training, allowing for flexible inference across various top-k values and improving overall performance. The model requires no pre-training and supports streaming recognition, achieving state-of-the-art (SOTA) results with unmatched flexibility compared to other methods. The Code will be released.
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为 CLIP with Generative Latent Replay 的强有力基线方法，用于解决增量学习中的遗忘问题。该方法通过利用生成式回放技术，同时在保持模型零样本能力的同时，在截然不同的任务域中适应模型。通过在多个任务域上的广泛实验，文章展示了该方法在适应新任务方面的有效性，同时显著提升了 CL 基准测试中的零样本能力。</title><link>https://arxiv.org/abs/2407.15793</link><description>&lt;p&gt;
CLIP with Generative Latent Replay: a Strong Baseline for Incremental Learning
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.15793
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为 CLIP with Generative Latent Replay 的强有力基线方法，用于解决增量学习中的遗忘问题。该方法通过利用生成式回放技术，同时在保持模型零样本能力的同时，在截然不同的任务域中适应模型。通过在多个任务域上的广泛实验，文章展示了该方法在适应新任务方面的有效性，同时显著提升了 CL 基准测试中的零样本能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.15793v2 Announce Type: replace  Abstract: With the emergence of Transformers and Vision-Language Models (VLMs) such as CLIP, large pre-trained models have become a common strategy to enhance performance in Continual Learning scenarios. This led to the development of numerous prompting strategies to effectively fine-tune transformer-based models without succumbing to catastrophic forgetting. However, these methods struggle to specialize the model on domains significantly deviating from the pre-training and preserving its zero-shot capabilities. In this work, we propose Continual Generative training for Incremental prompt-Learning, a novel approach to mitigate forgetting while adapting a VLM, which exploits generative replay to align prompts to tasks. We also introduce a new metric to evaluate zero-shot capabilities within CL benchmarks. Through extensive experiments on different domains, we demonstrate the effectiveness of our framework in adapting to new tasks while improvin
&lt;/p&gt;</description></item><item><title>该文章主要介绍了LinkedIn公司开发的一种名为LiNR的大规模、基于GPU的检索系统，该系统能够支持数十亿个条目的索引，并在生产环境中使用TensorFlow和PyTorch等工具。该系统将物品和模型权重整合到模型二进制文件中，并将索引构建视为模型训练的一种形式。文章还讨论了如何通过全扫描和高效过滤来扩展系统处理更大索引的能力，以及如何通过预过滤来解决k最近邻搜索中的常见问题。此外，文章还提供了多嵌入检索算法和解决检索中的冷启动问题的方法，并介绍了通过量化提高支持更大索引的能力。总之，LiNR代表了工业界在GPU上大规模检索系统设计和实施方面的重大创新。</title><link>https://arxiv.org/abs/2407.13218</link><description>&lt;p&gt;
LiNR: Model Based Neural Retrieval on GPUs at LinkedIn
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.13218
&lt;/p&gt;
&lt;p&gt;
该文章主要介绍了LinkedIn公司开发的一种名为LiNR的大规模、基于GPU的检索系统，该系统能够支持数十亿个条目的索引，并在生产环境中使用TensorFlow和PyTorch等工具。该系统将物品和模型权重整合到模型二进制文件中，并将索引构建视为模型训练的一种形式。文章还讨论了如何通过全扫描和高效过滤来扩展系统处理更大索引的能力，以及如何通过预过滤来解决k最近邻搜索中的常见问题。此外，文章还提供了多嵌入检索算法和解决检索中的冷启动问题的方法，并介绍了通过量化提高支持更大索引的能力。总之，LiNR代表了工业界在GPU上大规模检索系统设计和实施方面的重大创新。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.13218v3 Announce Type: replace-cross  Abstract: This paper introduces LiNR, LinkedIn's large-scale, GPU-based retrieval system. LiNR supports a billion-sized index on GPU models. We discuss our experiences and challenges in creating scalable, differentiable search indexes using TensorFlow and PyTorch at production scale. In LiNR, both items and model weights are integrated into the model binary. Viewing index construction as a form of model training, we describe scaling our system for large indexes, incorporating full scans and efficient filtering. A key focus is on enabling attribute-based pre-filtering for exhaustive GPU searches, addressing the common challenge of post-filtering in KNN searches that often reduces system quality. We further provide multi-embedding retrieval algorithms and strategies for tackling cold start issues in retrieval. Our advancements in supporting larger indexes through quantization are also discussed. We believe LiNR represents one of the indust
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为CCVA-FL的系统，用于在医疗影像领域中通过联邦学习解决来自不同客户端的图像数据之间的差异化问题，并介绍了一种旨在最小化跨客户端差异的方法，涉及使用Scalable Diffusion Models with Transformers（DiT）生成反映目标客户端图像数据的合成图像，这些合成图像被用于共享以帮助其他客户端的图像数据进入目标客户端的图像空间，从而在分布式医疗影像数据中实现更好的模型训练效果。</title><link>https://arxiv.org/abs/2407.11652</link><description>&lt;p&gt;
CCVA-FL: Cross-Client Variations Adaptive Federated Learning for Medical Imaging
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.11652
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为CCVA-FL的系统，用于在医疗影像领域中通过联邦学习解决来自不同客户端的图像数据之间的差异化问题，并介绍了一种旨在最小化跨客户端差异的方法，涉及使用Scalable Diffusion Models with Transformers（DiT）生成反映目标客户端图像数据的合成图像，这些合成图像被用于共享以帮助其他客户端的图像数据进入目标客户端的图像空间，从而在分布式医疗影像数据中实现更好的模型训练效果。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.11652v4 Announce Type: replace  Abstract: Federated Learning (FL) offers a privacy-preserving approach to train models on decentralized data. Its potential in healthcare is significant, but challenges arise due to cross-client variations in medical image data, exacerbated by limited annotations. This paper introduces Cross-Client Variations Adaptive Federated Learning (CCVA-FL) to address these issues. CCVA-FL aims to minimize cross-client variations by transforming images into a common feature space. It involves expert annotation of a subset of images from each client, followed by the selection of a client with the least data complexity as the target. Synthetic medical images are then generated using Scalable Diffusion Models with Transformers (DiT) based on the target client's annotated images. These synthetic images, capturing diversity and representing the original data, are shared with other clients. Each client then translates its local images into the target image spa
&lt;/p&gt;</description></item><item><title>该文章对Kolmogorov-Arnold Networks（KAN）进行了全面调查，揭示了其在理论基础、架构设计、应用场景和研究进展方面的重要性，特别是其在处理复杂数据模式和非线性关系方面的灵活性和优越性。尽管存在挑战，KAN显示出在多个领域实现创新解决方案的潜力，可能彻底改变我们解决复杂计算问题的能力。</title><link>https://arxiv.org/abs/2407.11075</link><description>&lt;p&gt;
A Comprehensive Survey on Kolmogorov Arnold Networks (KAN)
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.11075
&lt;/p&gt;
&lt;p&gt;
该文章对Kolmogorov-Arnold Networks（KAN）进行了全面调查，揭示了其在理论基础、架构设计、应用场景和研究进展方面的重要性，特别是其在处理复杂数据模式和非线性关系方面的灵活性和优越性。尽管存在挑战，KAN显示出在多个领域实现创新解决方案的潜力，可能彻底改变我们解决复杂计算问题的能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.11075v2 Announce Type: replace-cross  Abstract: Through this comprehensive survey of Kolmogorov-Arnold Networks(KAN), we have gained a thorough understanding of its theoretical foundation, architectural design, application scenarios, and current research progress. KAN, with its unique architecture and flexible activation functions, excels in handling complex data patterns and nonlinear relationships, demonstrating wide-ranging application potential. While challenges remain, KAN is poised to pave the way for innovative solutions in various fields, potentially revolutionizing how we approach complex computational problems.
&lt;/p&gt;</description></item><item><title>该文章提出了一种评估大型语言模型使用案例中偏见和公平性的行动导向框架，并通过对模型的偏见和公平性风险的分类、使用案例的税务分类以及各种风险评估指标的正式定义，帮助实践者确定适用于特定模型使用案例的指标。此外，该研究开发了几个新的偏见和公平性指标，包括创新的对抗性指标和基于刻板印象检测器的指标，从而不仅关注模型的内部属性，还关注问题和上下文的敏感性。</title><link>https://arxiv.org/abs/2407.10853</link><description>&lt;p&gt;
An Actionable Framework for Assessing Bias and Fairness in Large Language Model Use Cases
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.10853
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种评估大型语言模型使用案例中偏见和公平性的行动导向框架，并通过对模型的偏见和公平性风险的分类、使用案例的税务分类以及各种风险评估指标的正式定义，帮助实践者确定适用于特定模型使用案例的指标。此外，该研究开发了几个新的偏见和公平性指标，包括创新的对抗性指标和基于刻板印象检测器的指标，从而不仅关注模型的内部属性，还关注问题和上下文的敏感性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.10853v2 Announce Type: replace-cross  Abstract: Large language models (LLMs) can exhibit bias in a variety of ways. Such biases can create or exacerbate unfair outcomes for certain groups within a protected attribute, including, but not limited to sex, race, sexual orientation, or age. This paper aims to provide a technical guide for practitioners to assess bias and fairness risks in LLM use cases. The main contribution of this work is a decision framework that allows practitioners to determine which metrics to use for a specific LLM use case. To achieve this, this study categorizes LLM bias and fairness risks, maps those risks to a taxonomy of LLM use cases, and then formally defines various metrics to assess each type of risk. As part of this work, several new bias and fairness metrics are introduced, including innovative counterfactual metrics as well as metrics based on stereotype classifiers. Instead of focusing solely on the model itself, the sensitivity of both prompt
&lt;/p&gt;</description></item><item><title>该文章发现的创新是，大型语言模型（LLMs）在人工智能中的应用融合了符号和连接主义两种AI传统范式，提出了一种新型的神经符号自动机（Neuro-Symbolic AI），这种机器在模仿人类的语言处理能力和逻辑推理能力方面取得了显著进步。</title><link>https://arxiv.org/abs/2407.08516</link><description>&lt;p&gt;
Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2407.08516
&lt;/p&gt;
&lt;p&gt;
该文章发现的创新是，大型语言模型（LLMs）在人工智能中的应用融合了符号和连接主义两种AI传统范式，提出了一种新型的神经符号自动机（Neuro-Symbolic AI），这种机器在模仿人类的语言处理能力和逻辑推理能力方面取得了显著进步。
&lt;/p&gt;
&lt;p&gt;
arXiv:2407.08516v4 Announce Type: replace  Abstract: This article explores the convergence of connectionist and symbolic artificial intelligence (AI), from historical debates to contemporary advancements. Traditionally considered distinct paradigms, connectionist AI focuses on neural networks, while symbolic AI emphasizes symbolic representation and logic. Recent advancements in large language models (LLMs), exemplified by ChatGPT and GPT-4, highlight the potential of connectionist architectures in handling human language as a form of symbols. The study argues that LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence. By utilizing LLMs for text-based knowledge modeling and representation, LAAs integrate neuro-symbolic AI principles, showcasing enhanced reasoning and decision-making capabilities. Comparing LAAs with Knowledge Graphs within the neuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking human-like reasoning processes, scaling effective
&lt;/p&gt;</description></item><item><title>该文章揭示了个性化扩散模型在对抗性攻击下的脆弱性，并提出了一种保护隐私的新方法，该方法通过在图像生成过程中引入特定的过滤技术，可以在抵抗对抗性攻击的同时最小化信息损失。</title><link>https://arxiv.org/abs/2406.18944</link><description>&lt;p&gt;
Investigating and Defending Shortcut Learning in Personalized Diffusion Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.18944
&lt;/p&gt;
&lt;p&gt;
该文章揭示了个性化扩散模型在对抗性攻击下的脆弱性，并提出了一种保护隐私的新方法，该方法通过在图像生成过程中引入特定的过滤技术，可以在抵抗对抗性攻击的同时最小化信息损失。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.18944v3 Announce Type: replace  Abstract: Personalized diffusion models have gained popularity for adapting pre-trained text-to-image models to generate images of specific topics with minimal training data. However, these models are vulnerable to minor adversarial perturbations, leading to degraded performance on corrupted datasets. Such vulnerabilities are further exploited to craft protective perturbations on sensitive images like portraits that prevent unauthorized generation. In response, diffusion-based purification methods have been proposed to remove these perturbations and retain generation performance. However, existing works turn to over-purifying the images, which causes information loss. In this paper, we take a closer look at the fine-tuning process of personalized diffusion models through the lens of shortcut learning. And we propose a hypothesis explaining the manipulation mechanisms of existing perturbation methods, demonstrating that perturbed images signifi
&lt;/p&gt;</description></item><item><title>该文章提出了一种模型无关的方法，用于从数据特定子群中自动提取逻辑规则，尤其是在不牺牲主要类性能的情况下，极大地提高了对稀有类别的理解能力。这种方法标志着在可解释人工智能领域的一个新的研究方向，它通过自动提取规则来自定义特征，提高了机器学习模型对特定区域数据的解释性，相比于现有方法，该方法具有更广泛的适用性。</title><link>https://arxiv.org/abs/2406.17885</link><description>&lt;p&gt;
Enabling Regional Explainability by Automatic and Model-agnostic Rule Extraction
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.17885
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种模型无关的方法，用于从数据特定子群中自动提取逻辑规则，尤其是在不牺牲主要类性能的情况下，极大地提高了对稀有类别的理解能力。这种方法标志着在可解释人工智能领域的一个新的研究方向，它通过自动提取规则来自定义特征，提高了机器学习模型对特定区域数据的解释性，相比于现有方法，该方法具有更广泛的适用性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.17885v2 Announce Type: replace-cross  Abstract: In Explainable AI, rule extraction translates model knowledge into logical rules, such as IF-THEN statements, crucial for understanding patterns learned by black-box models. This could significantly aid in fields like disease diagnosis, disease progression estimation, or drug discovery. However, such application domains often contain imbalanced data, with the class of interest underrepresented. Existing methods inevitably compromise the performance of rules for the minor class to maximise the overall performance. As the first attempt in this field, we propose a model-agnostic approach for extracting rules from specific subgroups of data, featuring automatic rule generation for numerical features. This method enhances the regional explainability of machine learning models and offers wider applicability compared to existing methods. We additionally introduce a new method for selecting features to compose rules, reducing computati
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为“命令学习”（Imperative Learning）的自监督神经符号学习框架，用于提高机器人的自主能力。该框架通过三部分组成——神经模块、推理引擎和记忆系统，实现了神经和符号推理的结合，不需要大量标记数据，通过形式化的双层优化问题，解决了数据驱动方法的标签依赖问题和基于符号推理的长处。</title><link>https://arxiv.org/abs/2406.16087</link><description>&lt;p&gt;
Imperative Learning: A Self-supervised Neural-Symbolic Learning Framework for Robot Autonomy
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.16087
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为“命令学习”（Imperative Learning）的自监督神经符号学习框架，用于提高机器人的自主能力。该框架通过三部分组成——神经模块、推理引擎和记忆系统，实现了神经和符号推理的结合，不需要大量标记数据，通过形式化的双层优化问题，解决了数据驱动方法的标签依赖问题和基于符号推理的长处。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.16087v4 Announce Type: replace  Abstract: Data-driven methods such as reinforcement and imitation learning have achieved remarkable success in robot autonomy. However, their data-centric nature still hinders them from generalizing well to ever-changing environments. Moreover, collecting large datasets for robotic tasks is often impractical and expensive. To overcome these challenges, we introduce a new self-supervised neural-symbolic (NeSy) computational framework, imperative learning (IL), for robot autonomy, leveraging the generalization abilities of symbolic reasoning. The framework of IL consists of three primary components: a neural module, a reasoning engine, and a memory system. We formulate IL as a special bilevel optimization (BLO), which enables reciprocal learning over the three modules. This overcomes the label-intensive obstacles associated with data-driven approaches and takes advantage of symbolic reasoning concerning logical reasoning, physical principles, ge
&lt;/p&gt;</description></item><item><title>该文章通过研究神经元的激活来提供一个统一的解释，以揭示大型语言模型在处理链式思维（CoT）问题中的数学推理能力。通过分析，揭示了在Llama2模型的前馈层中，特定的神经元对于模型的数学推理能力至关重要。</title><link>https://arxiv.org/abs/2406.12288</link><description>&lt;p&gt;
An Investigation of Neuron Activation as a Unified Lens to Explain Chain-of-Thought Eliciting Arithmetic Reasoning of LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.12288
&lt;/p&gt;
&lt;p&gt;
该文章通过研究神经元的激活来提供一个统一的解释，以揭示大型语言模型在处理链式思维（CoT）问题中的数学推理能力。通过分析，揭示了在Llama2模型的前馈层中，特定的神经元对于模型的数学推理能力至关重要。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.12288v2 Announce Type: replace  Abstract: Large language models (LLMs) have shown strong arithmetic reasoning capabilities when prompted with Chain-of-Thought (CoT) prompts. However, we have only a limited understanding of how they are processed by LLMs. To demystify it, prior work has primarily focused on ablating different components in the CoT prompt and empirically observing their resulting LLM performance change. Yet, the reason why these components are important to LLM reasoning is not explored. To fill this gap, in this work, we investigate ``neuron activation'' as a lens to provide a unified explanation to observations made by prior work. Specifically, we look into neurons within the feed-forward layers of LLMs that may have activated their arithmetic reasoning capabilities, using Llama2 as an example. To facilitate this investigation, we also propose an approach based on GPT-4 to automatically identify neurons that imply arithmetic reasoning. Our analyses revealed t
&lt;/p&gt;</description></item><item><title>该文章发布了一个名为Nemotron-4 340B的模型家族，包括三种不同配置的模型，并在NVIDIA Open Model License Agreement许可下提供开放访问。这些模型能够在多种评估基准上与开放访问模型竞争，同时设计为能够在配备8块GPU的单一DGX H100上运行，并能在FP8精度下部署。文章强调了使用这些模型生成合成数据的重要性和有效性，其中超过98%的数据是在模型对齐过程中合成的。此外，为了支持开放研究并促进模型开发，作者还公开了训练数据和代码。</title><link>https://arxiv.org/abs/2406.11704</link><description>&lt;p&gt;
Nemotron-4 340B Technical Report
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2406.11704
&lt;/p&gt;
&lt;p&gt;
该文章发布了一个名为Nemotron-4 340B的模型家族，包括三种不同配置的模型，并在NVIDIA Open Model License Agreement许可下提供开放访问。这些模型能够在多种评估基准上与开放访问模型竞争，同时设计为能够在配备8块GPU的单一DGX H100上运行，并能在FP8精度下部署。文章强调了使用这些模型生成合成数据的重要性和有效性，其中超过98%的数据是在模型对齐过程中合成的。此外，为了支持开放研究并促进模型开发，作者还公开了训练数据和代码。
&lt;/p&gt;
&lt;p&gt;
arXiv:2406.11704v2 Announce Type: replace-cross  Abstract: We release the Nemotron-4 340B model family, including Nemotron-4-340B-Base, Nemotron-4-340B-Instruct, and Nemotron-4-340B-Reward. Our models are open access under the NVIDIA Open Model License Agreement, a permissive model license that allows distribution, modification, and use of the models and its outputs. These models perform competitively to open access models on a wide range of evaluation benchmarks, and were sized to fit on a single DGX H100 with 8 GPUs when deployed in FP8 precision. We believe that the community can benefit from these models in various research studies and commercial applications, especially for generating synthetic data to train smaller language models. Notably, over 98% of data used in our model alignment process is synthetically generated, showcasing the effectiveness of these models in generating synthetic data. To further support open research and facilitate model development, we are also open-sou
&lt;/p&gt;</description></item><item><title>该文章探讨了利用生成式人工智能技术整合城市数字孪生，以解决智慧城市发展中面临的智慧城市应用数据质量、可用性和成本问题。通过生成城市数据、场景和3D城市模型，有助于提升城市规划和设计的智能水平。</title><link>https://arxiv.org/abs/2405.19464</link><description>&lt;p&gt;
Leveraging Generative AI for Urban Digital Twins: A Scoping Review on the Autonomous Generation of Urban Data, Scenarios, Designs, and 3D City Models for Smart City Advancement
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.19464
&lt;/p&gt;
&lt;p&gt;
该文章探讨了利用生成式人工智能技术整合城市数字孪生，以解决智慧城市发展中面临的智慧城市应用数据质量、可用性和成本问题。通过生成城市数据、场景和3D城市模型，有助于提升城市规划和设计的智能水平。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.19464v2 Announce Type: replace  Abstract: The digital transformation of modern cities by integrating advanced information, communication, and computing technologies has marked the epoch of data-driven smart city applications for efficient and sustainable urban management. Despite their effectiveness, these applications often rely on massive amounts of high-dimensional and multi-domain data for monitoring and characterizing different urban sub-systems, presenting challenges in application areas that are limited by data quality and availability, as well as costly efforts for generating urban scenarios and design alternatives. As an emerging research area in deep learning, Generative Artificial Intelligence (AI) models have demonstrated their unique values in data and code generation. This survey paper aims to explore the innovative integration of generative AI techniques and urban digital twins to address challenges in the realm of smart cities in various urban sectors, such a
&lt;/p&gt;</description></item><item><title>该文章提出了一种利用大型语言模型（LLM）结合ChatGPT API的策略，自动化创建知识图谱和促进城市决策支持系统的创新方法，为优化多式联运物流运输提供了新的可能性。</title><link>https://arxiv.org/abs/2405.19255</link><description>&lt;p&gt;
Towards Next-Generation Urban Decision Support Systems through AI-Powered Construction of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.19255
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种利用大型语言模型（LLM）结合ChatGPT API的策略，自动化创建知识图谱和促进城市决策支持系统的创新方法，为优化多式联运物流运输提供了新的可能性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.19255v2 Announce Type: replace  Abstract: The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. Yet, addressing complex urban and environmental management problems normally requires in-depth domain science and informatics expertise. This expertise is essential for deriving data and simulation-driven for informed decision support. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated workflow that encompasses natural language processing, methontology-based prompt tuning, and transformers. This workflow automates the creation of scenario-based ontology using existing research articles and technical manuals of urban datasets and simulations. The outcomes of our methodology are knowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL). These facilitate the development of urban decisio
&lt;/p&gt;</description></item><item><title>该文章提出了PPCEF（Probabilistically Plausible Counterfactual Explanations with Normalizing Flows）方法，该方法在生成假设性的实例时，不仅确保了新实例能够改变原本预测的类别，同时避免了不合理的假设性实例的生成，它通过基于正常化流动的参数化密度估计，实现了在保证实例在数据分布的合理性前提下，有效生成具有高可行性的假设性实例。</title><link>https://arxiv.org/abs/2405.17640</link><description>&lt;p&gt;
Probabilistically Plausible Counterfactual Explanations with Normalizing Flows
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.17640
&lt;/p&gt;
&lt;p&gt;
该文章提出了PPCEF（Probabilistically Plausible Counterfactual Explanations with Normalizing Flows）方法，该方法在生成假设性的实例时，不仅确保了新实例能够改变原本预测的类别，同时避免了不合理的假设性实例的生成，它通过基于正常化流动的参数化密度估计，实现了在保证实例在数据分布的合理性前提下，有效生成具有高可行性的假设性实例。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.17640v2 Announce Type: replace-cross  Abstract: We present PPCEF, a novel method for generating probabilistically plausible counterfactual explanations (CFs). PPCEF advances beyond existing methods by combining a probabilistic formulation that leverages the data distribution with the optimization of plausibility within a unified framework. Compared to reference approaches, our method enforces plausibility by directly optimizing the explicit density function without assuming a particular family of parametrized distributions. This ensures CFs are not only valid (i.e., achieve class change) but also align with the underlying data's probability density. For that purpose, our approach leverages normalizing flows as powerful density estimators to capture the complex high-dimensional data distribution. Furthermore, we introduce a novel loss that balances the trade-off between achieving class change and maintaining closeness to the original instance while also incorporating a probab
&lt;/p&gt;</description></item><item><title>该文章提出了Filtered Corpus Training（FiCT）方法，这是一种训练语言模型（LMs）的新方法，通过从训练数据中过滤掉特定的句法结构来训练模型，并检验了语言模型对基于间接证据的语言泛化能力。通过在LSTM和Transformer两种不同类型的语言模型上进行实验，该研究开发了一系列针对各种语言现象的过滤后的语料库。实验结果显示，尽管Transformer在理解文本和生成源代码方面表现得更好，但两种类型的语言模型在基于间接证据的语言泛化测试中表现出了几乎相同的优异水平，这表明了语言模型具有出色的间接泛化能力。</title><link>https://arxiv.org/abs/2405.15750</link><description>&lt;p&gt;
Filtered Corpus Training (FiCT) Shows that Language Models can Generalize from Indirect Evidence
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2405.15750
&lt;/p&gt;
&lt;p&gt;
该文章提出了Filtered Corpus Training（FiCT）方法，这是一种训练语言模型（LMs）的新方法，通过从训练数据中过滤掉特定的句法结构来训练模型，并检验了语言模型对基于间接证据的语言泛化能力。通过在LSTM和Transformer两种不同类型的语言模型上进行实验，该研究开发了一系列针对各种语言现象的过滤后的语料库。实验结果显示，尽管Transformer在理解文本和生成源代码方面表现得更好，但两种类型的语言模型在基于间接证据的语言泛化测试中表现出了几乎相同的优异水平，这表明了语言模型具有出色的间接泛化能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2405.15750v2 Announce Type: replace-cross  Abstract: This paper introduces Filtered Corpus Training, a method that trains language models (LMs) on corpora with certain linguistic constructions filtered out from the training data, and uses it to measure the ability of LMs to perform linguistic generalization on the basis of indirect evidence. We apply the method to both LSTM and Transformer LMs (of roughly comparable size), developing filtered corpora that target a wide range of linguistic phenomena. Our results show that while transformers are better qua LMs (as measured by perplexity), both models perform equally and surprisingly well on linguistic generalization measures, suggesting that they are capable of generalizing from indirect evidence.
&lt;/p&gt;</description></item><item><title>该文章通过融合预训练的视觉Transformer（ViT）与时间卷积网络（TCNet），显著提高了对脑电图（EEG）的回归分析准确性。</title><link>https://arxiv.org/abs/2404.15311</link><description>&lt;p&gt;
Fusing Pretrained ViTs with TCNet for Enhanced EEG Regression
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.15311
&lt;/p&gt;
&lt;p&gt;
该文章通过融合预训练的视觉Transformer（ViT）与时间卷积网络（TCNet），显著提高了对脑电图（EEG）的回归分析准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.15311v2 Announce Type: replace-cross  Abstract: The task of Electroencephalogram (EEG) analysis is paramount to the development of Brain-Computer Interfaces (BCIs). However, to reach the goal of developing robust, useful BCIs depends heavily on the speed and the accuracy at which BCIs can understand neural dynamics. In response to that goal, this paper details the integration of pre-trained Vision Transformers (ViTs) with Temporal Convolutional Networks (TCNet) to enhance the precision of EEG regression. The core of this approach lies in harnessing the sequential data processing strengths of ViTs along with the superior feature extraction capabilities of TCNet, to significantly improve EEG analysis accuracy. In addition, we analyze the importance of how to construct optimal patches for the attention mechanism to analyze, balancing both speed and accuracy tradeoffs. Our results showcase a substantial improvement in regression accuracy, as evidenced by the reduction of Root Me
&lt;/p&gt;</description></item><item><title>该文章引入了Oak Ridge Base Foundation Model for Earth System Predictability（ORBIT），这是一个具有113亿参数的先进视觉转换器模型，采用了创新的混合张量数据并行策略。ORBIT通过这一策略超越了当前气候人工智能模型的大小限制，实现了对环境动态复杂性和数据整合的改善，从而提高了地球系统预测的准确性。</title><link>https://arxiv.org/abs/2404.14712</link><description>&lt;p&gt;
ORBIT: Oak Ridge Base Foundation Model for Earth System Predictability
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.14712
&lt;/p&gt;
&lt;p&gt;
该文章引入了Oak Ridge Base Foundation Model for Earth System Predictability（ORBIT），这是一个具有113亿参数的先进视觉转换器模型，采用了创新的混合张量数据并行策略。ORBIT通过这一策略超越了当前气候人工智能模型的大小限制，实现了对环境动态复杂性和数据整合的改善，从而提高了地球系统预测的准确性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.14712v2 Announce Type: replace-cross  Abstract: Earth system predictability is challenged by the complexity of environmental dynamics and the multitude of variables involved. Current AI foundation models, although advanced by leveraging large and heterogeneous data, are often constrained by their size and data integration, limiting their effectiveness in addressing the full range of Earth system prediction challenges. To overcome these limitations, we introduce the Oak Ridge Base Foundation Model for Earth System Predictability (ORBIT), an advanced vision transformer model that scales up to 113 billion parameters using a novel hybrid tensor-data orthogonal parallelism technique. As the largest model of its kind, ORBIT surpasses the current climate AI foundation model size by a thousandfold. Performance scaling tests conducted on the Frontier supercomputer have demonstrated that ORBIT achieves 684 petaFLOPS to 1.6 exaFLOPS sustained throughput, with scaling efficiency maintai
&lt;/p&gt;</description></item><item><title>该文章提出了一种通过对比学习对正负样本进行比例缩放的方法，改进了基于复合图像检索的任务，使用生成数据的方法解决正样本不足的问题，同时通过两阶段训练框架增加负样本数量，优化了模型在检索任务中的表现。</title><link>https://arxiv.org/abs/2404.11317</link><description>&lt;p&gt;
Improving Composed Image Retrieval via Contrastive Learning with Scaling Positives and Negatives
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2404.11317
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种通过对比学习对正负样本进行比例缩放的方法，改进了基于复合图像检索的任务，使用生成数据的方法解决正样本不足的问题，同时通过两阶段训练框架增加负样本数量，优化了模型在检索任务中的表现。
&lt;/p&gt;
&lt;p&gt;
arXiv:2404.11317v2 Announce Type: replace  Abstract: The Composed Image Retrieval (CIR) task aims to retrieve target images using a composed query consisting of a reference image and a modified text. Advanced methods often utilize contrastive learning as the optimization objective, which benefits from adequate positive and negative examples. However, the triplet for CIR incurs high manual annotation costs, resulting in limited positive examples. Furthermore, existing methods commonly use in-batch negative sampling, which reduces the negative number available for the model. To address the problem of lack of positives, we propose a data generation method by leveraging a multi-modal large language model to construct triplets for CIR. To introduce more negatives during fine-tuning, we design a two-stage fine-tuning framework for CIR, whose second stage introduces plenty of static representations of negatives to optimize the representation space rapidly. The above two improvements can be ef
&lt;/p&gt;</description></item><item><title>该文章通过理论分析和技术验证，揭示了大型语言模型在与人类反馈对齐过程中的学习动态，并为优化模型更新和培训准确性提供了严格保证。实验结果证实了其在当代大型语言模型以及对齐任务上的理论见解，为未来对齐方法的研究提供了重要参考。</title><link>https://arxiv.org/abs/2403.18742</link><description>&lt;p&gt;
Understanding the Learning Dynamics of Alignment with Human Feedback
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.18742
&lt;/p&gt;
&lt;p&gt;
该文章通过理论分析和技术验证，揭示了大型语言模型在与人类反馈对齐过程中的学习动态，并为优化模型更新和培训准确性提供了严格保证。实验结果证实了其在当代大型语言模型以及对齐任务上的理论见解，为未来对齐方法的研究提供了重要参考。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.18742v5 Announce Type: replace-cross  Abstract: Aligning large language models (LLMs) with human intentions has become a critical task for safely deploying models in real-world systems. While existing alignment approaches have seen empirical success, theoretically understanding how these methods affect model behavior remains an open question. Our work provides an initial attempt to theoretically analyze the learning dynamics of human preference alignment. We formally show how the distribution of preference datasets influences the rate of model updates and provide rigorous guarantees on the training accuracy. Our theory also reveals an intricate phenomenon where the optimization is prone to prioritizing certain behaviors with higher preference distinguishability. We empirically validate our findings on contemporary LLMs and alignment tasks, reinforcing our theoretical insights and shedding light on considerations for future alignment approaches. Disclaimer: This paper contain
&lt;/p&gt;</description></item><item><title>该文章通过提出Meta-Prompting for Visual Recognition (MPVR)方法，实现了自动化生成针对特定任务的零射识别任务视觉提示。这种方法只需输入任务的简短描述和类标签列表，就可以自动创建出覆盖广泛视觉概念和任务相关风格的多样化的提示集，从而显著提高了VLM在零射识别任务中的表现。该创新通过简化人工干预，成功将人从提示生成过程中解放出来，实现了提示自动化的目标。此外，这种方法使用大型语言模型（LLM）产生的特定类别提示，这种方法虽然可靠，但仍然存在局限性，即手动编写提示不能覆盖所有相关的视觉概念和任务特有风格。通过引入Meta-Prompting，文章作者成功自动化了生成任务特异性视觉提示的过程，这是当前技术中的重大突破。</title><link>https://arxiv.org/abs/2403.11755</link><description>&lt;p&gt;
Meta-Prompting for Automating Zero-shot Visual Recognition with LLMs
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.11755
&lt;/p&gt;
&lt;p&gt;
该文章通过提出Meta-Prompting for Visual Recognition (MPVR)方法，实现了自动化生成针对特定任务的零射识别任务视觉提示。这种方法只需输入任务的简短描述和类标签列表，就可以自动创建出覆盖广泛视觉概念和任务相关风格的多样化的提示集，从而显著提高了VLM在零射识别任务中的表现。该创新通过简化人工干预，成功将人从提示生成过程中解放出来，实现了提示自动化的目标。此外，这种方法使用大型语言模型（LLM）产生的特定类别提示，这种方法虽然可靠，但仍然存在局限性，即手动编写提示不能覆盖所有相关的视觉概念和任务特有风格。通过引入Meta-Prompting，文章作者成功自动化了生成任务特异性视觉提示的过程，这是当前技术中的重大突破。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.11755v3 Announce Type: replace  Abstract: Prompt ensembling of Large Language Model (LLM) generated category-specific prompts has emerged as an effective method to enhance zero-shot recognition ability of Vision-Language Models (VLMs). To obtain these category-specific prompts, the present methods rely on hand-crafting the prompts to the LLMs for generating VLM prompts for the downstream tasks. However, this requires manually composing these task-specific prompts and still, they might not cover the diverse set of visual concepts and task-specific styles associated with the categories of interest. To effectively take humans out of the loop and completely automate the prompt generation process for zero-shot recognition, we propose Meta-Prompting for Visual Recognition (MPVR). Taking as input only minimal information about the target task, in the form of its short natural language description, and a list of associated class labels, MPVR automatically produces a diverse set of c
&lt;/p&gt;</description></item><item><title>该文章提出并验证了大型语言模型在自动生成机器人路线方面的潜力，使得机器人调度问题可以通过自然语言描述直接得到解决方案。</title><link>https://arxiv.org/abs/2403.10795</link><description>&lt;p&gt;
Can Large Language Models Solve Robot Routing?
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.10795
&lt;/p&gt;
&lt;p&gt;
该文章提出并验证了大型语言模型在自动生成机器人路线方面的潜力，使得机器人调度问题可以通过自然语言描述直接得到解决方案。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.10795v2 Announce Type: replace-cross  Abstract: Routing problems are common in mobile robotics, encompassing tasks such as inspection, surveillance, and coverage. Depending on the objective and constraints, these problems often reduce to variants of the Traveling Salesman Problem (TSP), with solutions traditionally derived by translating high-level objectives into an optimization formulation and using modern solvers to arrive at a solution. Here, we explore the potential of Large Language Models (LLMs) to replace the entire pipeline from tasks described in natural language to the generation of robot routes. We systematically investigate the performance of LLMs in robot routing by constructing a dataset with 80 unique robot routing problems across 8 variants in both single and multi-robot settings. We evaluate LLMs through three frameworks: single attempt, self-debugging, and self-debugging with self-verification and various contexts, including mathematical formulations, pseu
&lt;/p&gt;</description></item><item><title>该文章揭示了在由具有不同道德倾向学习代理组成的异质化社会群体中，道德行为动态的复杂性。通过对学习代理在不同时间点面对不同道德类型对手的交互行为的研究，该研究强调了在现实世界中引入道德能力的AI系统，需要考虑道德多样性的重要性。</title><link>https://arxiv.org/abs/2403.04202</link><description>&lt;p&gt;
Dynamics of Moral Behavior in Heterogeneous Populations of Learning Agents
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2403.04202
&lt;/p&gt;
&lt;p&gt;
该文章揭示了在由具有不同道德倾向学习代理组成的异质化社会群体中，道德行为动态的复杂性。通过对学习代理在不同时间点面对不同道德类型对手的交互行为的研究，该研究强调了在现实世界中引入道德能力的AI系统，需要考虑道德多样性的重要性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2403.04202v5 Announce Type: replace-cross  Abstract: Growing concerns about safety and alignment of AI systems highlight the importance of embedding moral capabilities in artificial agents: a promising solution is the use of learning from experience, i.e., Reinforcement Learning. In multi-agent (social) environments, complex population-level phenomena may emerge from interactions between individual learning agents. Many of the existing studies rely on simulated social dilemma environments to study the interactions of independent learning agents; however, they tend to ignore the moral heterogeneity that is likely to be present in societies of agents in practice. For example, at different points in time a single learning agent may face opponents who are consequentialist (i.e., focused on maximizing outcomes over time), norm-based (i.e., conforming to specific norms), or virtue-based (i.e., considering a combination of different virtues). The extent to which agents' co-development m
&lt;/p&gt;</description></item><item><title>该文章介绍了一种基于条件生成对抗网络（conditional GAN）的随机地理空间降尺度方法，该方法能从非常低分辨率的输入数据中生成高分辨率的精确气候数据，显示出在高缩放因子下的优越应用潜力。</title><link>https://arxiv.org/abs/2402.14049</link><description>&lt;p&gt;
Generative Adversarial Models for Extreme Geospatial Downscaling
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.14049
&lt;/p&gt;
&lt;p&gt;
该文章介绍了一种基于条件生成对抗网络（conditional GAN）的随机地理空间降尺度方法，该方法能从非常低分辨率的输入数据中生成高分辨率的精确气候数据，显示出在高缩放因子下的优越应用潜力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.14049v2 Announce Type: replace-cross  Abstract: Addressing the challenges of climate change requires accurate and high-resolution mapping of geospatial data, especially climate and weather variables. However, many existing geospatial datasets, such as the gridded outputs of the state-of-the-art numerical climate models (e.g., general circulation models), are only available at very coarse spatial resolutions due to the model complexity and extremely high computational demand. Deep-learning-based methods, particularly generative adversarial networks (GANs) and their variants, have proved effective for refining natural images and have shown great promise in improving geospatial datasets. This paper describes a conditional GAN-based stochastic geospatial downscaling method that can accommodates very high scaling factors. Compared to most existing methods, the method can generate high-resolution accurate climate datasets from very low-resolution inputs. More importantly, the meth
&lt;/p&gt;</description></item><item><title>该文章提出了一种人工智能辅助的智能手机远程眼部成像质量评估系统，能够提供即时的临床级反馈，有效改善了在远程医疗服务中使用智能手机捕获的眼部图像的质量，尤其在印度等低收入和中等收入国家，对消除眼科疾病的诊断延迟和提高医疗服务可及性方面具有重大意义。</title><link>https://arxiv.org/abs/2402.07118</link><description>&lt;p&gt;
Next-Generation Teleophthalmology: AI-enabled Quality Assessment Aiding Remote Smartphone-based Consultation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.07118
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种人工智能辅助的智能手机远程眼部成像质量评估系统，能够提供即时的临床级反馈，有效改善了在远程医疗服务中使用智能手机捕获的眼部图像的质量，尤其在印度等低收入和中等收入国家，对消除眼科疾病的诊断延迟和提高医疗服务可及性方面具有重大意义。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.07118v2 Announce Type: replace-cross  Abstract: Blindness and other eye diseases are a global health concern, particularly in low- and middle-income countries like India. In this regard, during the COVID-19 pandemic, teleophthalmology became a lifeline, and the Grabi attachment for smartphone-based eye imaging gained in use. However, quality of user-captured image often remained inadequate, requiring clinician vetting and delays. In this backdrop, we propose an AI-based quality assessment system with instant feedback mimicking clinicians' judgments and tested on patient-captured images. Dividing the complex problem hierarchically, here we tackle a nontrivial part, and demonstrate a proof of the concept.
&lt;/p&gt;</description></item><item><title>该文章创新地提出了LiRank，一个在LinkedIn上实现的大规模排名模型框架，该框架结合了最新的模型架构和优化方法。LiRank通过引入诸如Residual DCN这样的改进模型，以及对SOTA（state-of-the-art）架构的组合和调优，如在DCNv2架构上添加注意力机制和残差连接，展现了其在工业界中的排名能力。此外，文章还介绍了创新的校准技术和深度学习探索/利用方法的实现，并详细解释了如何通过量化和词汇压缩来训练和压缩大型排名模型，以实现有效的生产级服务。文章还描述了在Feed排名、Job推荐和广告点击率预测等大规模应用场景中的部署设置，总结了从各种A/B测试中获得的学习经验。</title><link>https://arxiv.org/abs/2402.06859</link><description>&lt;p&gt;
LiRank: Industrial Large Scale Ranking Models at LinkedIn
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2402.06859
&lt;/p&gt;
&lt;p&gt;
该文章创新地提出了LiRank，一个在LinkedIn上实现的大规模排名模型框架，该框架结合了最新的模型架构和优化方法。LiRank通过引入诸如Residual DCN这样的改进模型，以及对SOTA（state-of-the-art）架构的组合和调优，如在DCNv2架构上添加注意力机制和残差连接，展现了其在工业界中的排名能力。此外，文章还介绍了创新的校准技术和深度学习探索/利用方法的实现，并详细解释了如何通过量化和词汇压缩来训练和压缩大型排名模型，以实现有效的生产级服务。文章还描述了在Feed排名、Job推荐和广告点击率预测等大规模应用场景中的部署设置，总结了从各种A/B测试中获得的学习经验。
&lt;/p&gt;
&lt;p&gt;
arXiv:2402.06859v2 Announce Type: replace-cross  Abstract: We present LiRank, a large-scale ranking framework at LinkedIn that brings to production state-of-the-art modeling architectures and optimization methods. We unveil several modeling improvements, including Residual DCN, which adds attention and residual connections to the famous DCNv2 architecture. We share insights into combining and tuning SOTA architectures to create a unified model, including Dense Gating, Transformers and Residual DCN. We also propose novel techniques for calibration and describe how we productionalized deep learning based explore/exploit methods. To enable effective, production-grade serving of large ranking models, we detail how to train and compress models using quantization and vocabulary compression. We provide details about the deployment setup for large-scale use cases of Feed ranking, Jobs Recommendations, and Ads click-through rate (CTR) prediction. We summarize our learnings from various A/B test
&lt;/p&gt;</description></item><item><title>该文章提出了一个名为M-CAT（Multi-modal Contrastive Anticipative Transformer）的模型，该模型是一种视频变换器架构，它结合了多模态特征和动作及物体描述的文本信息。文章通过两个阶段的训练方法，首先训练模型将视频片段与未来动作的描述进行对齐，然后对其进行微调，以提高动作预测的准确性。此外，文章还探讨了文本描述在限定潜在动作选择中的作用，证明了文本描述在动作预测中的有效性。</title><link>https://arxiv.org/abs/2401.12972</link><description>&lt;p&gt;
On the Efficacy of Text-Based Input Modalities for Action Anticipation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.12972
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个名为M-CAT（Multi-modal Contrastive Anticipative Transformer）的模型，该模型是一种视频变换器架构，它结合了多模态特征和动作及物体描述的文本信息。文章通过两个阶段的训练方法，首先训练模型将视频片段与未来动作的描述进行对齐，然后对其进行微调，以提高动作预测的准确性。此外，文章还探讨了文本描述在限定潜在动作选择中的作用，证明了文本描述在动作预测中的有效性。
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.12972v2 Announce Type: replace  Abstract: Anticipating future actions is a highly challenging task due to the diversity and scale of potential future actions; yet, information from different modalities help narrow down plausible action choices. Each modality can provide diverse and often complementary context for the model to learn from. While previous multi-modal methods leverage information from modalities such as video and audio, we primarily explore how text descriptions of actions and objects can also lead to more accurate action anticipation by providing additional contextual cues, e.g., about the environment and its contents. We propose a Multi-modal Contrastive Anticipative Transformer (M-CAT), a video transformer architecture that jointly learns from multi-modal features and text descriptions of actions and objects. We train our model in two stages, where the model first learns to align video clips with descriptions of future actions, and is subsequently fine-tuned 
&lt;/p&gt;</description></item><item><title>该文章提出了一种名为Emotional Chain-of-Thought的插件化引导方法，旨在通过与人类情绪智力准则的集成来增强大型语言模型在多种情绪生成任务中的表现。提出的一种名为Emotional Generation Score的自动评估方法，该模型基于情绪智力理论，提供了一种全新视角来评估情绪生成任务。实验结果表明</title><link>https://arxiv.org/abs/2401.06836</link><description>&lt;p&gt;
Enhancing Emotional Generation Capability of Large Language Models via Emotional Chain-of-Thought
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.06836
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种名为Emotional Chain-of-Thought的插件化引导方法，旨在通过与人类情绪智力准则的集成来增强大型语言模型在多种情绪生成任务中的表现。提出的一种名为Emotional Generation Score的自动评估方法，该模型基于情绪智力理论，提供了一种全新视角来评估情绪生成任务。实验结果表明
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.06836v3 Announce Type: replace-cross  Abstract: Large Language Models (LLMs) have shown remarkable performance in various emotion recognition tasks, thereby piquing the research community's curiosity for exploring their potential in emotional intelligence. However, several issues in the field of emotional generation tasks remain unresolved, including human preference alignment and emotional generation assessment. In this paper, we propose the Emotional Chain-of-Thought (ECoT), a plug-and-play prompting method that enhances the performance of LLMs on various emotional generation tasks by aligning with human emotional intelligence guidelines. To assess the reliability of ECoT, we propose an automated model-based evaluation method called Emotional Generation Score (EGS). EGS incorporates Goleman's Emotional Intelligence Theory as a consensus of human experts, providing a new perspective on the evaluation of emotional generation tasks. Extensive experimental results demonstrate 
&lt;/p&gt;</description></item><item><title>该文章创新性地创建了“I am a Strange Dataset”这一新数据集，用于评估和检测大型语言模型对包含自我参照语言的句子进行生成和验证的能力。该数据集的设计包括两个子任务：一是要求模型完成含有自我参照情况的句子，二是判断这些包含自我参照的句子是否真实。通过与非自我参照句子的对比，该数据集能够更全面地评估语言模型处理这类语句的能力。文章通过专家手工制作并经非专家审核，测试了多种规模的语言模型，展示了评估和管理语言模型在处理自我参照语言方面的性能改进。</title><link>https://arxiv.org/abs/2401.05300</link><description>&lt;p&gt;
I am a Strange Dataset: Metalinguistic Tests for Language Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.05300
&lt;/p&gt;
&lt;p&gt;
该文章创新性地创建了“I am a Strange Dataset”这一新数据集，用于评估和检测大型语言模型对包含自我参照语言的句子进行生成和验证的能力。该数据集的设计包括两个子任务：一是要求模型完成含有自我参照情况的句子，二是判断这些包含自我参照的句子是否真实。通过与非自我参照句子的对比，该数据集能够更全面地评估语言模型处理这类语句的能力。文章通过专家手工制作并经非专家审核，测试了多种规模的语言模型，展示了评估和管理语言模型在处理自我参照语言方面的性能改进。
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.05300v2 Announce Type: replace-cross  Abstract: Statements involving metalinguistic self-reference ("This paper has six sections.") are prevalent in many domains. Can current large language models (LLMs) handle such language? In this paper, we present "I am a Strange Dataset", a new dataset for addressing this question. There are two subtasks: generation and verification. In generation, models continue statements like "The penultimate word in this sentence is" (where a correct continuation is "is"). In verification, models judge the truth of statements like "The penultimate word in this sentence is sentence." (false). We also provide minimally different metalinguistic non-self-reference examples to complement the main dataset by probing for whether models can handle metalinguistic language at all. The dataset is hand-crafted by experts and validated by non-expert annotators. We test a variety of open-source LLMs (7B to 70B parameters) as well as closed-source LLMs through AP
&lt;/p&gt;</description></item><item><title>该文章提供一种名为BiasPainter的框架，能够准确、自动且全面地触发图像生成模型中的社会偏见，弥补了以往研究在评估图像生成模型偏见时的局限性，包括准确度不足、过度依赖人工劳动及分析不全面的问题。</title><link>https://arxiv.org/abs/2401.00763</link><description>&lt;p&gt;
New Job, New Gender? Measuring the Social Bias in Image Generation Models
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.00763
&lt;/p&gt;
&lt;p&gt;
该文章提供一种名为BiasPainter的框架，能够准确、自动且全面地触发图像生成模型中的社会偏见，弥补了以往研究在评估图像生成模型偏见时的局限性，包括准确度不足、过度依赖人工劳动及分析不全面的问题。
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.00763v2 Announce Type: replace-cross  Abstract: Image generation models can generate or edit images from a given text. Recent advancements in image generation technology, exemplified by DALL-E and Midjourney, have been groundbreaking. These advanced models, despite their impressive capabilities, are often trained on massive Internet datasets, making them susceptible to generating content that perpetuates social stereotypes and biases, which can lead to severe consequences. Prior research on assessing bias within image generation models suffers from several shortcomings, including limited accuracy, reliance on extensive human labor, and lack of comprehensive analysis. In this paper, we propose BiasPainter, a novel evaluation framework that can accurately, automatically and comprehensively trigger social bias in image generation models. BiasPainter uses a diverse range of seed images of individuals and prompts the image generation models to edit these images using gender, race
&lt;/p&gt;</description></item><item><title>该文章提出了SAFE-SIM，一种利用扩散模型生成的具有可控对抗行为的封闭式安全关键性仿真框架，能够模拟接近真实世界条件下的长尾安全关键性场景，并允许对规划器进行更全面和互动的评估。</title><link>https://arxiv.org/abs/2401.00391</link><description>&lt;p&gt;
SAFE-SIM: Safety-Critical Closed-Loop Traffic Simulation with Diffusion-Controllable Adversaries
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2401.00391
&lt;/p&gt;
&lt;p&gt;
该文章提出了SAFE-SIM，一种利用扩散模型生成的具有可控对抗行为的封闭式安全关键性仿真框架，能够模拟接近真实世界条件下的长尾安全关键性场景，并允许对规划器进行更全面和互动的评估。
&lt;/p&gt;
&lt;p&gt;
arXiv:2401.00391v3 Announce Type: replace  Abstract: Evaluating the performance of autonomous vehicle planning algorithms necessitates simulating long-tail safety-critical traffic scenarios. However, traditional methods for generating such scenarios often fall short in terms of controllability and realism; they also neglect the dynamics of agent interactions. To address these limitations, we introduce SAFE-SIM, a novel diffusion-based controllable closed-loop safety-critical simulation framework. Our approach yields two distinct advantages: 1) generating realistic long-tail safety-critical scenarios that closely reflect real-world conditions, and 2) providing controllable adversarial behavior for more comprehensive and interactive evaluations. We develop a novel approach to simulate safety-critical scenarios through an adversarial term in the denoising process of diffusion models, which allows an adversarial agent to challenge a planner with plausible maneuvers while all agents in the 
&lt;/p&gt;</description></item><item><title>该文章提出了一个新的方法来识别历史数据集中与时间和个性相关的变化，并通过分析美国前42位总统的国情咨文演讲数据集进行了示范，该方法在作者鉴别任务中达到了95%的准确率，并能够精确到总统任期的日期。</title><link>https://arxiv.org/abs/2312.01185</link><description>&lt;p&gt;
A ripple in time: a discontinuity in American history
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2312.01185
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个新的方法来识别历史数据集中与时间和个性相关的变化，并通过分析美国前42位总统的国情咨文演讲数据集进行了示范，该方法在作者鉴别任务中达到了95%的准确率，并能够精确到总统任期的日期。
&lt;/p&gt;
&lt;p&gt;
arXiv:2312.01185v5 Announce Type: replace-cross  Abstract: In this technical note we suggest a novel approach to discover temporal (related and unrelated to language dilation) and personality (authorship attribution) in historical datasets. We exemplify our approach on the State of the Union speeches given by the past 42 US presidents: this dataset is known for its relatively small amount of data, and high variability of the amount and style of texts. Nevertheless we manage to achieve about 95\% accuracy on the authorship attribution task, and pin down the date of writing to a single presidential term.
&lt;/p&gt;</description></item><item><title>该文章提出了一种利用规划令牌来指导语言模型进行更结构化的链式推理的方法，以提高它们在数学问题解决任务中的表现。</title><link>https://arxiv.org/abs/2310.05707</link><description>&lt;p&gt;
Guiding Language Model Reasoning with Planning Tokens
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2310.05707
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种利用规划令牌来指导语言模型进行更结构化的链式推理的方法，以提高它们在数学问题解决任务中的表现。
&lt;/p&gt;
&lt;p&gt;
arXiv:2310.05707v4 Announce Type: replace-cross  Abstract: Large language models (LLMs) have recently attracted considerable interest for their ability to perform complex reasoning tasks, such as chain-of-thought (CoT) reasoning. However, most of the existing approaches to enhance this ability rely heavily on data-driven methods, while neglecting the structural aspects of the model's reasoning capacity. To encourage a more structural generation of CoT steps, we propose a hierarchical generation scheme: we let the LM generate a planning token at the start of each reasoning step, intuitively serving as a high-level plan of the current step, and add their embeddings to the model parameters. Our approach requires a negligible increase in trainable parameters (0.001%) and can be applied through either full fine-tuning or a more parameter-efficient scheme. We demonstrate our method's effectiveness by applying it to three different LLMs, showing notable accuracy improvements across three math
&lt;/p&gt;</description></item><item><title>该文章提出一种使用多根节点改良蒙特卡罗树搜索（IMCTS）算法的强化学习（RL）方法，用于解决桁架结构离散尺寸优化的难题。这种方法通过优化搜索树的生成过程、利用最佳奖励进行回传更新、采用加速技术减少搜索宽度并控制迭代次数，以及设定终止条件，以训练代理找到满足多种条件的最优结构重量解决方案。实验结果表明，该方法能够在有限计算成本下稳定地找到最优设计，并且适用于广泛的应用场景。</title><link>https://arxiv.org/abs/2309.06045</link><description>&lt;p&gt;
Improved Monte Carlo tree search formulation with multiple root nodes for discrete sizing optimization of truss structures
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2309.06045
&lt;/p&gt;
&lt;p&gt;
该文章提出一种使用多根节点改良蒙特卡罗树搜索（IMCTS）算法的强化学习（RL）方法，用于解决桁架结构离散尺寸优化的难题。这种方法通过优化搜索树的生成过程、利用最佳奖励进行回传更新、采用加速技术减少搜索宽度并控制迭代次数，以及设定终止条件，以训练代理找到满足多种条件的最优结构重量解决方案。实验结果表明，该方法能够在有限计算成本下稳定地找到最优设计，并且适用于广泛的应用场景。
&lt;/p&gt;
&lt;p&gt;
arXiv:2309.06045v4 Announce Type: replace  Abstract: This paper proposes a novel reinforcement learning (RL) algorithm using improved Monte Carlo tree search (IMCTS) formulation for discrete optimum design of truss structures. IMCTS with multiple root nodes includes update process, the best reward, accelerating technique, and terminal condition. Update process means that once a final solution is found, it is used as the initial solution for next search tree. The best reward is used in the backpropagation step. Accelerating technique is introduced by decreasing the width of search tree and reducing maximum number of iterations. The agent is trained to minimize the total structural weight under various constraints until the terminal condition is satisfied. Then, optimal solution is the minimum value of all solutions found by search trees. These numerical examples show that the agent can find optimal solution with low computational cost, stably produces an optimal design, and is suitable 
&lt;/p&gt;</description></item><item><title>该文章提出了一种针对异常检测的全面增强学习框架，通过考虑不同类别的异常标准差异，选代地应用适当的增强策略，并采用分段训练策略缓解过度拟合问题，同时在无干扰的图像重构过程中保持性能，在MTVae异常检测数据集上的评估结果表明该方法表现出优越性能。</title><link>https://arxiv.org/abs/2308.15068</link><description>&lt;p&gt;
A Comprehensive Augmentation Framework for Anomaly Detection
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2308.15068
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种针对异常检测的全面增强学习框架，通过考虑不同类别的异常标准差异，选代地应用适当的增强策略，并采用分段训练策略缓解过度拟合问题，同时在无干扰的图像重构过程中保持性能，在MTVae异常检测数据集上的评估结果表明该方法表现出优越性能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2308.15068v4 Announce Type: replace-cross  Abstract: Data augmentation methods are commonly integrated into the training of anomaly detection models. Previous approaches have primarily focused on replicating real-world anomalies or enhancing diversity, without considering that the standard of anomaly varies across different classes, potentially leading to a biased training distribution.This paper analyzes crucial traits of simulated anomalies that contribute to the training of reconstructive networks and condenses them into several methods, thus creating a comprehensive framework by selectively utilizing appropriate combinations.Furthermore, we integrate this framework with a reconstruction-based approach and concurrently propose a split training strategy that alleviates the issue of overfitting while avoiding introducing interference to the reconstruction process. The evaluations conducted on the MVTec anomaly detection dataset demonstrate that our method outperforms the previou
&lt;/p&gt;</description></item><item><title>该文章提出了一种新的方法，用于联合线性特征学习和非参数函数估计，旨在更有效地利用隐藏特征进行学习。该方法通过最小化经验风险并加入对函数导数的惩罚，确保了估计的变异性。通过利用 Hermite 多项式的正交性和旋转不变性，该文章介绍了一个新的估计器，名为 RegFeaL。通过交替最小化，该估计器能够在多索引模型中有效地学习隐藏特征，并增强预测、计算和解释能力。</title><link>https://arxiv.org/abs/2307.12754</link><description>&lt;p&gt;
Nonparametric Linear Feature Learning in Regression Through Regularisation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2307.12754
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种新的方法，用于联合线性特征学习和非参数函数估计，旨在更有效地利用隐藏特征进行学习。该方法通过最小化经验风险并加入对函数导数的惩罚，确保了估计的变异性。通过利用 Hermite 多项式的正交性和旋转不变性，该文章介绍了一个新的估计器，名为 RegFeaL。通过交替最小化，该估计器能够在多索引模型中有效地学习隐藏特征，并增强预测、计算和解释能力。
&lt;/p&gt;
&lt;p&gt;
arXiv:2307.12754v4 Announce Type: replace-cross  Abstract: Representation learning plays a crucial role in automated feature selection, particularly in the context of high-dimensional data, where non-parametric methods often struggle. In this study, we focus on supervised learning scenarios where the pertinent information resides within a lower-dimensional linear subspace of the data, namely the multi-index model. If this subspace were known, it would greatly enhance prediction, computation, and interpretation. To address this challenge, we propose a novel method for joint linear feature learning and non-parametric function estimation, aimed at more effectively leveraging hidden features for learning. Our approach employs empirical risk minimisation, augmented with a penalty on function derivatives, ensuring versatility. Leveraging the orthogonality and rotation invariance properties of Hermite polynomials, we introduce our estimator, named RegFeaL. By using alternative minimisation, w
&lt;/p&gt;</description></item><item><title>该文章提出了一种基于点的值迭代算法，用于具有神经感知机制的部分 observable Markov 决策过程（POMDPs），解决了在连续状态空间中直接优化累积折扣奖励的问题。通过利用模型的内在结构和神经感知机制的特性，该算法能够有效地进行决策优化。</title><link>https://arxiv.org/abs/2306.17639</link><description>&lt;p&gt;
Point-Based Value Iteration for POMDPs with Neural Perception Mechanisms
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2306.17639
&lt;/p&gt;
&lt;p&gt;
该文章提出了一种基于点的值迭代算法，用于具有神经感知机制的部分 observable Markov 决策过程（POMDPs），解决了在连续状态空间中直接优化累积折扣奖励的问题。通过利用模型的内在结构和神经感知机制的特性，该算法能够有效地进行决策优化。
&lt;/p&gt;
&lt;p&gt;
arXiv:2306.17639v2 Announce Type: replace-cross  Abstract: The increasing trend to integrate neural networks and conventional software components in safety-critical settings calls for methodologies for their formal modelling, verification and correct-by-construction policy synthesis. We introduce neuro-symbolic partially observable Markov decision processes (NS-POMDPs), a variant of continuous-state POMDPs with discrete observations and actions, in which the agent perceives a continuous-state environment using a neural {\revise perception mechanism} and makes decisions symbolically. The perception mechanism classifies inputs such as images and sensor values into symbolic percepts, which are used in decision making.   We study the problem of optimising discounted cumulative rewards for NS-POMDPs. Working directly with the continuous state space, we exploit the underlying structure of the model and the neural perception mechanism to propose a novel piecewise linear and convex representat
&lt;/p&gt;</description></item><item><title>该文章通过重新形式化蒸馏过程的动力学，提供了对真实数据集内在冗余的理论和实证洞察。文章提出了一种基于经验损失值的数据静态裁剪标准，并进一步根据数据对蒸馏贡献的因果效应，找到最能影响蒸馏过程的数据样本，从而有效利用训练数据集，超越了现有技术。</title><link>https://arxiv.org/abs/2305.18381</link><description>&lt;p&gt;
Distill Gold from Massive Ores: Bi-level Data Pruning towards Efficient Dataset Distillation
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2305.18381
&lt;/p&gt;
&lt;p&gt;
该文章通过重新形式化蒸馏过程的动力学，提供了对真实数据集内在冗余的理论和实证洞察。文章提出了一种基于经验损失值的数据静态裁剪标准，并进一步根据数据对蒸馏贡献的因果效应，找到最能影响蒸馏过程的数据样本，从而有效利用训练数据集，超越了现有技术。
&lt;/p&gt;
&lt;p&gt;
arXiv:2305.18381v4 Announce Type: replace-cross  Abstract: Data-efficient learning has garnered significant attention, especially given the current trend of large multi-modal models. Recently, dataset distillation has become an effective approach by synthesizing data samples that are essential for network training. However, it remains to be explored which samples are essential for the dataset distillation process itself. In this work, we study the data efficiency and selection for the dataset distillation task. By re-formulating the dynamics of distillation, we provide insight into the inherent redundancy in the real dataset, both theoretically and empirically. We propose to use the empirical loss value as a static data pruning criterion. To further compensate for the variation of the data value in training, we find the most contributing samples based on their causal effects on the distillation. The proposed selection strategy can efficiently exploit the training dataset, outperform th
&lt;/p&gt;</description></item><item><title>该文章提出的注意力相似结构再参数化技术，通过允许不同网络架构之间变换的等效参数变换，能够在不增加训练成本的情况下，为工业和实际应用中性能提高提供可能。</title><link>https://arxiv.org/abs/2304.06345</link><description>&lt;p&gt;
ASR: Attention-alike Structural Re-parameterization
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2304.06345
&lt;/p&gt;
&lt;p&gt;
该文章提出的注意力相似结构再参数化技术，通过允许不同网络架构之间变换的等效参数变换，能够在不增加训练成本的情况下，为工业和实际应用中性能提高提供可能。
&lt;/p&gt;
&lt;p&gt;
arXiv:2304.06345v3 Announce Type: replace  Abstract: The structural re-parameterization (SRP) technique is a novel deep learning technique that achieves interconversion between different network architectures through equivalent parameter transformations. This technique enables the mitigation of the extra costs for performance improvement during training, such as parameter size and inference time, through these transformations during inference, and therefore SRP has great potential for industrial and practical applications. The existing SRP methods have successfully considered many commonly used architectures, such as normalizations, pooling methods, and multi-branch convolution. However, the widely used attention modules which drastically slow inference speed cannot be directly implemented by SRP due to these modules usually act on the backbone network in a multiplicative manner and the modules' output is input-dependent during inference, which limits the application scenarios of SRP. 
&lt;/p&gt;</description></item><item><title>该文章提出了一个用于保护图像生成式对抗网络（GANs）知识产权的全新指纹识别方案，有效突破了以往仅适用于分类模型、难以适应GANs的隐形性和鲁棒性瓶颈。通过构建一个由目标GAN和分类器组成的复合深度学习模型，并从中生成指纹样本，将其嵌入到分类器中以实现所有权验证。这种方案为现代图像翻译GANs的实际保护提供了一些具体的策略和方法。</title><link>https://arxiv.org/abs/2106.11760</link><description>&lt;p&gt;
Fingerprinting Image-to-Image Generative Adversarial Networks
&lt;/p&gt;
&lt;p&gt;
https://arxiv.org/abs/2106.11760
&lt;/p&gt;
&lt;p&gt;
该文章提出了一个用于保护图像生成式对抗网络（GANs）知识产权的全新指纹识别方案，有效突破了以往仅适用于分类模型、难以适应GANs的隐形性和鲁棒性瓶颈。通过构建一个由目标GAN和分类器组成的复合深度学习模型，并从中生成指纹样本，将其嵌入到分类器中以实现所有权验证。这种方案为现代图像翻译GANs的实际保护提供了一些具体的策略和方法。
&lt;/p&gt;
&lt;p&gt;
arXiv:2106.11760v5 Announce Type: replace-cross  Abstract: Generative Adversarial Networks (GANs) have been widely used in various application scenarios. Since the production of a commercial GAN requires substantial computational and human resources, the copyright protection of GANs is urgently needed. This paper presents a novel fingerprinting scheme for the Intellectual Property (IP) protection of image-to-image GANs based on a trusted third party. We break through the stealthiness and robustness bottlenecks suffered by previous fingerprinting methods for classification models being naively transferred to GANs. Specifically, we innovatively construct a composite deep learning model from the target GAN and a classifier. Then we generate fingerprint samples from this composite model, and embed them in the classifier for effective ownership verification. This scheme inspires some concrete methodologies to practically protect the modern image-to-image translation GANs. Theoretical analys
&lt;/p&gt;</description></item></channel></rss>